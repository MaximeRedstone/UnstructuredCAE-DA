Path ['/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/mredstone/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/', '/Users/maxime/IndividualProject/code/Data_Assimilation/src/']

------------------------- Simulation Started at 2020-08-27 13:54:22.545321 ------------------- 

data fp  /home/mredstone/unstructuredCAE/data/subdomain_8/
domain, other, pickle, dim 8 ['6'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | MeanHist_80P_150E_1D0L                                                       |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_8/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
When creating TucodecEncode1D, inputSize =  16206 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
Number of parameters: 567553
------------------------------ Training subdomain 8 at 2020-08-27 13:54:27.762473. ------------------------------
Loading data started 2020-08-27 13:54:27.762532
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
shape of mean (16206,) and std (16206,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fa710a6c1d0>
Loading data finished 2020-08-27 13:54:35.915554
Loop AE Train begins at  13:54:35.918792
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [1/150], TRAIN: -loss:21524.45, av_diff: 0.90, time taken (m): 0.03m
epoch [1/150], TEST: -loss:19597.8799, time taken(m): 0.01m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [6/150], TRAIN: -loss:3893.35, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [11/150], TRAIN: -loss:2624.65, av_diff: 0.05, time taken (m): 0.02m
epoch [11/150], TEST: -loss:6651.8970, time taken(m): 0.01m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [16/150], TRAIN: -loss:2197.92, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [21/150], TRAIN: -loss:1952.65, av_diff: 0.01, time taken (m): 0.02m
epoch [21/150], TEST: -loss:3305.3489, time taken(m): 0.01m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [26/150], TRAIN: -loss:1760.09, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [31/150], TRAIN: -loss:1593.02, av_diff: 0.00, time taken (m): 0.03m
epoch [31/150], TEST: -loss:2157.3923, time taken(m): 0.01m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [36/150], TRAIN: -loss:1438.88, av_diff: 0.00, time taken (m): 0.03m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [41/150], TRAIN: -loss:1300.61, av_diff: 0.00, time taken (m): 0.04m
epoch [41/150], TEST: -loss:1753.1778, time taken(m): 0.02m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [46/150], TRAIN: -loss:1168.32, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [51/150], TRAIN: -loss:1055.20, av_diff: 0.00, time taken (m): 0.05m
epoch [51/150], TEST: -loss:1530.9364, time taken(m): 0.02m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [56/150], TRAIN: -loss:953.18, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [61/150], TRAIN: -loss:860.12, av_diff: 0.00, time taken (m): 0.04m
epoch [61/150], TEST: -loss:1343.1470, time taken(m): 0.02m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [66/150], TRAIN: -loss:786.24, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [71/150], TRAIN: -loss:705.04, av_diff: 0.00, time taken (m): 0.04m
epoch [71/150], TEST: -loss:1199.2647, time taken(m): 0.02m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [76/150], TRAIN: -loss:647.11, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [81/150], TRAIN: -loss:577.59, av_diff: 0.00, time taken (m): 0.05m
epoch [81/150], TEST: -loss:1060.0575, time taken(m): 0.02m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [86/150], TRAIN: -loss:519.15, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [91/150], TRAIN: -loss:475.61, av_diff: 0.00, time taken (m): 0.04m
epoch [91/150], TEST: -loss:996.8476, time taken(m): 0.02m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [96/150], TRAIN: -loss:428.26, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [101/150], TRAIN: -loss:384.20, av_diff: 0.00, time taken (m): 0.05m
epoch [101/150], TEST: -loss:871.4133, time taken(m): 0.02m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [106/150], TRAIN: -loss:360.39, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [111/150], TRAIN: -loss:326.23, av_diff: 0.00, time taken (m): 0.05m
epoch [111/150], TEST: -loss:821.8791, time taken(m): 0.02m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [116/150], TRAIN: -loss:291.78, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [121/150], TRAIN: -loss:274.70, av_diff: 0.00, time taken (m): 0.05m
epoch [121/150], TEST: -loss:750.9197, time taken(m): 0.02m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [126/150], TRAIN: -loss:248.94, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [131/150], TRAIN: -loss:219.42, av_diff: 0.00, time taken (m): 0.05m
epoch [131/150], TEST: -loss:703.9428, time taken(m): 0.02m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [136/150], TRAIN: -loss:218.07, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [141/150], TRAIN: -loss:195.38, av_diff: 0.00, time taken (m): 0.04m
epoch [141/150], TEST: -loss:682.0491, time taken(m): 0.02m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [146/150], TRAIN: -loss:179.34, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [150/150], TRAIN: -loss:163.62, av_diff: 0.00, time taken (m): 0.05m
epoch [150/150], TEST: -loss:652.4704, time taken(m): 0.02m
Loop AE Train Ends at  14:00:55.679089
------------------------------ DA subdomain 8 at 2020-08-27 14:00:55.755739. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
shape of mean (16206,) and std (16206,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 16206) , test_X = (107, 16206), X = (537, 16206)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
shape of mean (16206,) and std (16206,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting mean historical data
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
Shape of w_0 =  (429,)
minCostFunction = 9.4939 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.2793, add (DA)= 0.0007decode = 0.3638 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 9.8579 s, inc stats = 33.8008, 
minCostFunction = 10.4757 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.2578, add (DA)= 0.0004decode = 0.3444 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 10.8204 s, inc stats = 10.8251, 
minCostFunction = 7.3331 s, v_trunc (Latent to Reduced) = 0.0853, dec (Reduced to Full) = 0.2487, add (DA)= 0.0002decode = 0.3342 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 7.6676 s, inc stats = 7.6798, 
minCostFunction = 3.9272 s, v_trunc (Latent to Reduced) = 0.0869, dec (Reduced to Full) = 0.2571, add (DA)= 0.0001decode = 0.3441 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2714 s, inc stats = 4.2771, 
minCostFunction = 4.3637 s, v_trunc (Latent to Reduced) = 0.0890, dec (Reduced to Full) = 0.2615, add (DA)= 0.0001decode = 0.3508 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 4.7148 s, inc stats = 4.7196, 
minCostFunction = 6.2642 s, v_trunc (Latent to Reduced) = 0.0887, dec (Reduced to Full) = 0.2180, add (DA)= 0.0004decode = 0.3071 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 6.5719 s, inc stats = 6.5892, 
minCostFunction = 6.4697 s, v_trunc (Latent to Reduced) = 0.0826, dec (Reduced to Full) = 0.2554, add (DA)= 0.0001decode = 0.3382 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.8080 s, inc stats = 6.8192, 
minCostFunction = 3.5937 s, v_trunc (Latent to Reduced) = 0.0821, dec (Reduced to Full) = 0.2502, add (DA)= 0.0001decode = 0.3326 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 3.9264 s, inc stats = 3.9318, 
minCostFunction = 5.6712 s, v_trunc (Latent to Reduced) = 0.0831, dec (Reduced to Full) = 0.2403, add (DA)= 0.0001decode = 0.3237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.9950 s, inc stats = 6.0241, 
minCostFunction = 3.9431 s, v_trunc (Latent to Reduced) = 0.0874, dec (Reduced to Full) = 0.2306, add (DA)= 0.0002decode = 0.3183 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 4.2616 s, inc stats = 4.2727, 
minCostFunction = 2.6637 s, v_trunc (Latent to Reduced) = 0.0906, dec (Reduced to Full) = 0.1656, add (DA)= 0.0001decode = 0.2564 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.9202 s, inc stats = 2.9305, 
DA - - L2: 769.38, L1: 2337.62, % Improve: 28.95%, DA_MAE: 0.01, mse_ref: 0.04, mse_DA: 0.031, time(s): 9.0338s,
\% improve_point: 14.96, mse_ref_points: 2.2559370428275446e-06, mse_da_points: 1.9147109792984395e-06, % improve_overlap: 4.54, mse_ref_overlap: 0.02804, mse_da_overlap: 0.02678
minCostFunction = 4.2303 s, v_trunc (Latent to Reduced) = 0.0895, dec (Reduced to Full) = 0.1790, add (DA)= 0.0001decode = 0.2686 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4990 s, inc stats = 4.5084, 
minCostFunction = 6.4900 s, v_trunc (Latent to Reduced) = 0.0851, dec (Reduced to Full) = 0.1904, add (DA)= 0.0002decode = 0.2758 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.7659 s, inc stats = 6.7696, 
minCostFunction = 3.8032 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1773, add (DA)= 0.0001decode = 0.2633 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0667 s, inc stats = 4.0725, 
minCostFunction = 4.4220 s, v_trunc (Latent to Reduced) = 0.0913, dec (Reduced to Full) = 0.3727, add (DA)= 0.0001decode = 0.4641 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8863 s, inc stats = 4.9012, 
minCostFunction = 3.8817 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.2050, add (DA)= 0.0001decode = 0.2916 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1733 s, inc stats = 4.2016, 
minCostFunction = 4.2516 s, v_trunc (Latent to Reduced) = 0.0853, dec (Reduced to Full) = 0.3526, add (DA)= 0.0005decode = 0.4385 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.6903 s, inc stats = 4.6973, 
minCostFunction = 4.6392 s, v_trunc (Latent to Reduced) = 0.0882, dec (Reduced to Full) = 0.2660, add (DA)= 0.0001decode = 0.3544 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.9937 s, inc stats = 5.0009, 
minCostFunction = 6.7075 s, v_trunc (Latent to Reduced) = 0.1344, dec (Reduced to Full) = 3.2917, add (DA)= 0.0001decode = 3.4262 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 10.1338 s, inc stats = 10.1440, 
minCostFunction = 3.7537 s, v_trunc (Latent to Reduced) = 0.0842, dec (Reduced to Full) = 0.1771, add (DA)= 0.0004decode = 0.2618 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 4.0158 s, inc stats = 4.0284, 
minCostFunction = 4.8116 s, v_trunc (Latent to Reduced) = 0.0844, dec (Reduced to Full) = 0.1533, add (DA)= 0.0001decode = 0.2378 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0496 s, inc stats = 5.0643, 
DA - - L2: 1099.14, L1: 2763.57, % Improve: 18.27%, DA_MAE: 0.01, mse_ref: 0.03, mse_DA: 0.029, time(s): 7.2756s,
\% improve_point: 1.77, mse_ref_points: 1.8754003806679073e-06, mse_da_points: 1.7837843012619556e-06, % improve_overlap: -2.28, mse_ref_overlap: 0.02452, mse_da_overlap: 0.02479
minCostFunction = 3.7838 s, v_trunc (Latent to Reduced) = 0.0821, dec (Reduced to Full) = 0.1545, add (DA)= 0.0001decode = 0.2367 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0207 s, inc stats = 4.0347, 
minCostFunction = 3.5678 s, v_trunc (Latent to Reduced) = 0.0823, dec (Reduced to Full) = 0.1568, add (DA)= 0.0001decode = 0.2392 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8072 s, inc stats = 3.8132, 
minCostFunction = 4.1064 s, v_trunc (Latent to Reduced) = 0.0857, dec (Reduced to Full) = 0.2410, add (DA)= 0.0001decode = 0.3268 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4333 s, inc stats = 4.4432, 
minCostFunction = 7.3454 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.3261, add (DA)= 0.0001decode = 0.4123 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 7.7582 s, inc stats = 7.7703, 
minCostFunction = 7.8169 s, v_trunc (Latent to Reduced) = 0.0957, dec (Reduced to Full) = 0.2318, add (DA)= 0.0001decode = 0.3277 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 8.1447 s, inc stats = 8.1580, 
minCostFunction = 7.4844 s, v_trunc (Latent to Reduced) = 0.0897, dec (Reduced to Full) = 0.3381, add (DA)= 0.0001decode = 0.4280 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.9125 s, inc stats = 7.9467, 
minCostFunction = 6.5598 s, v_trunc (Latent to Reduced) = 0.0902, dec (Reduced to Full) = 0.3106, add (DA)= 0.0001decode = 0.4010 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.9609 s, inc stats = 6.9708, 
minCostFunction = 7.0184 s, v_trunc (Latent to Reduced) = 0.0851, dec (Reduced to Full) = 0.2205, add (DA)= 0.0001decode = 0.3058 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.3244 s, inc stats = 7.3777, 
minCostFunction = 6.7760 s, v_trunc (Latent to Reduced) = 0.1054, dec (Reduced to Full) = 0.2244, add (DA)= 0.0001decode = 0.3300 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.1061 s, inc stats = 7.1198, 
minCostFunction = 5.9791 s, v_trunc (Latent to Reduced) = 0.0929, dec (Reduced to Full) = 0.3011, add (DA)= 0.0001decode = 0.3941 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.3732 s, inc stats = 6.3926, 
DA - - L2: 1416.87, L1: 3096.27, % Improve: 20.73%, DA_MAE: 0.01, mse_ref: 0.03, mse_DA: 0.027, time(s): 6.9949s,
\% improve_point: 2.41, mse_ref_points: 1.7201198188311993e-06, mse_da_points: 1.6384577015365499e-06, % improve_overlap: 0.10, mse_ref_overlap: 0.02332, mse_da_overlap: 0.02313
minCostFunction = 6.4775 s, v_trunc (Latent to Reduced) = 0.0847, dec (Reduced to Full) = 0.2576, add (DA)= 0.0001decode = 0.3425 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.8201 s, inc stats = 6.8293, 
minCostFunction = 5.9342 s, v_trunc (Latent to Reduced) = 0.0933, dec (Reduced to Full) = 0.3087, add (DA)= 0.0001decode = 0.4021 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.3364 s, inc stats = 6.3487, 
minCostFunction = 5.9724 s, v_trunc (Latent to Reduced) = 0.0894, dec (Reduced to Full) = 0.2224, add (DA)= 0.0001decode = 0.3120 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.2845 s, inc stats = 6.2915, 
minCostFunction = 4.1641 s, v_trunc (Latent to Reduced) = 0.0823, dec (Reduced to Full) = 0.2140, add (DA)= 0.0001decode = 0.2965 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4607 s, inc stats = 4.4799, 
minCostFunction = 6.3746 s, v_trunc (Latent to Reduced) = 0.0850, dec (Reduced to Full) = 0.2722, add (DA)= 0.0004decode = 0.3577 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.7325 s, inc stats = 6.7373, 
minCostFunction = 6.3451 s, v_trunc (Latent to Reduced) = 0.0826, dec (Reduced to Full) = 0.2564, add (DA)= 0.0001decode = 0.3392 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.6844 s, inc stats = 6.6926, 
minCostFunction = 5.2554 s, v_trunc (Latent to Reduced) = 0.0949, dec (Reduced to Full) = 0.2192, add (DA)= 0.0001decode = 0.3142 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.5697 s, inc stats = 5.5874, 
minCostFunction = 6.1778 s, v_trunc (Latent to Reduced) = 0.0910, dec (Reduced to Full) = 0.2198, add (DA)= 0.0002decode = 0.3110 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.4889 s, inc stats = 6.5115, 
minCostFunction = 5.9931 s, v_trunc (Latent to Reduced) = 0.0913, dec (Reduced to Full) = 0.2774, add (DA)= 0.0001decode = 0.3688 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.3620 s, inc stats = 6.3791, 
minCostFunction = 6.0549 s, v_trunc (Latent to Reduced) = 0.0913, dec (Reduced to Full) = 0.3613, add (DA)= 0.0004decode = 0.4531 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 6.5085 s, inc stats = 6.5151, 
DA - - L2: 1807.86, L1: 3439.45, % Improve: 23.87%, DA_MAE: 0.01, mse_ref: 0.03, mse_DA: 0.030, time(s): 6.8108s,
\% improve_point: 4.24, mse_ref_points: 2.0093060615593753e-06, mse_da_points: 1.8733398193580705e-06, % improve_overlap: 1.67, mse_ref_overlap: 0.02685, mse_da_overlap: 0.02636
minCostFunction = 7.6031 s, v_trunc (Latent to Reduced) = 0.0947, dec (Reduced to Full) = 0.3149, add (DA)= 0.0001decode = 0.4098 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 8.0130 s, inc stats = 8.0176, 
minCostFunction = 6.4546 s, v_trunc (Latent to Reduced) = 0.0849, dec (Reduced to Full) = 0.3353, add (DA)= 0.0001decode = 0.4203 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.8750 s, inc stats = 6.8799, 
minCostFunction = 6.9176 s, v_trunc (Latent to Reduced) = 0.0931, dec (Reduced to Full) = 0.3326, add (DA)= 0.0001decode = 0.4259 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.3436 s, inc stats = 7.3510, 
minCostFunction = 6.7230 s, v_trunc (Latent to Reduced) = 0.1562, dec (Reduced to Full) = 0.2523, add (DA)= 0.0001decode = 0.4088 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.1319 s, inc stats = 7.1403, 
minCostFunction = 4.0205 s, v_trunc (Latent to Reduced) = 0.0851, dec (Reduced to Full) = 0.2272, add (DA)= 0.0005decode = 0.3128 s, unnorm = 0.0010 s, TOTAL = unnormalising + decoding + minimising = 4.3344 s, inc stats = 4.3431, 
minCostFunction = 5.7025 s, v_trunc (Latent to Reduced) = 0.0826, dec (Reduced to Full) = 0.3405, add (DA)= 0.0001decode = 0.4233 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1260 s, inc stats = 6.1392, 
minCostFunction = 6.3154 s, v_trunc (Latent to Reduced) = 0.0914, dec (Reduced to Full) = 0.3167, add (DA)= 0.0001decode = 0.4082 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.7237 s, inc stats = 6.7459, 
minCostFunction = 5.6489 s, v_trunc (Latent to Reduced) = 0.0933, dec (Reduced to Full) = 0.2381, add (DA)= 0.0001decode = 0.3316 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.9806 s, inc stats = 5.9898, 
minCostFunction = 5.4879 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.2408, add (DA)= 0.0003decode = 0.3272 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.8153 s, inc stats = 5.8369, 
minCostFunction = 6.2760 s, v_trunc (Latent to Reduced) = 0.0903, dec (Reduced to Full) = 0.3212, add (DA)= 0.0001decode = 0.4117 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.6878 s, inc stats = 6.6957, 
DA - - L2: 2517.65, L1: 3917.29, % Improve: 22.97%, DA_MAE: 0.02, mse_ref: 0.05, mse_DA: 0.048, time(s): 6.7531s,
\% improve_point: 4.90, mse_ref_points: 3.221484364129604e-06, mse_da_points: 2.9839934942337604e-06, % improve_overlap: 1.40, mse_ref_overlap: 0.04142, mse_da_overlap: 0.04068
minCostFunction = 6.1249 s, v_trunc (Latent to Reduced) = 0.0845, dec (Reduced to Full) = 0.3012, add (DA)= 0.0001decode = 0.3859 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.5109 s, inc stats = 6.5180, 
minCostFunction = 6.5956 s, v_trunc (Latent to Reduced) = 0.0952, dec (Reduced to Full) = 0.3214, add (DA)= 0.0001decode = 0.4168 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.0125 s, inc stats = 7.0159, 
minCostFunction = 5.8556 s, v_trunc (Latent to Reduced) = 0.0845, dec (Reduced to Full) = 0.3092, add (DA)= 0.0001decode = 0.3939 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.2496 s, inc stats = 6.2650, 
minCostFunction = 6.3217 s, v_trunc (Latent to Reduced) = 0.0846, dec (Reduced to Full) = 0.2767, add (DA)= 0.0001decode = 0.3616 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.6835 s, inc stats = 6.7027, 
minCostFunction = 4.9610 s, v_trunc (Latent to Reduced) = 0.1704, dec (Reduced to Full) = 0.2340, add (DA)= 0.0001decode = 0.4046 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3657 s, inc stats = 5.3763, 
minCostFunction = 3.5890 s, v_trunc (Latent to Reduced) = 0.0902, dec (Reduced to Full) = 0.2424, add (DA)= 0.0001decode = 0.3328 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9219 s, inc stats = 3.9484, 
minCostFunction = 5.9099 s, v_trunc (Latent to Reduced) = 0.0997, dec (Reduced to Full) = 0.2596, add (DA)= 0.0001decode = 0.3594 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.2694 s, inc stats = 6.2805, 
minCostFunction = 6.2424 s, v_trunc (Latent to Reduced) = 0.0870, dec (Reduced to Full) = 0.3041, add (DA)= 0.0001decode = 0.3912 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.6337 s, inc stats = 6.6399, 
minCostFunction = 5.6691 s, v_trunc (Latent to Reduced) = 0.0849, dec (Reduced to Full) = 0.2471, add (DA)= 0.0001decode = 0.3321 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.0013 s, inc stats = 6.0047, 
minCostFunction = 5.9086 s, v_trunc (Latent to Reduced) = 0.0919, dec (Reduced to Full) = 0.2110, add (DA)= 0.0002decode = 0.3032 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.2119 s, inc stats = 41.4333, 
DA - - L2: 3000.23, L1: 4260.01, % Improve: 24.98%, DA_MAE: 0.02, mse_ref: 0.06, mse_DA: 0.056, time(s): 7.2234s,
\% improve_point: 8.00, mse_ref_points: 3.9865537709573335e-06, mse_da_points: 3.4807726086415766e-06, % improve_overlap: 6.85, mse_ref_overlap: 0.05376, mse_da_overlap: 0.04651
minCostFunction = 5.0417 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.8315, add (DA)= 0.0005decode = 0.9354 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.9772 s, inc stats = 5.9924, 
minCostFunction = 6.5233 s, v_trunc (Latent to Reduced) = 0.0922, dec (Reduced to Full) = 0.3369, add (DA)= 0.0006decode = 0.4297 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 6.9533 s, inc stats = 6.9768, 
minCostFunction = 5.8431 s, v_trunc (Latent to Reduced) = 0.0839, dec (Reduced to Full) = 0.2561, add (DA)= 0.0001decode = 0.3401 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1833 s, inc stats = 6.2112, 
minCostFunction = 4.0683 s, v_trunc (Latent to Reduced) = 0.1204, dec (Reduced to Full) = 0.2003, add (DA)= 0.0001decode = 0.3209 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.3893 s, inc stats = 4.3989, 
minCostFunction = 5.4260 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.2354, add (DA)= 0.0001decode = 0.3219 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.7480 s, inc stats = 5.7632, 
minCostFunction = 5.7589 s, v_trunc (Latent to Reduced) = 0.1455, dec (Reduced to Full) = 0.2146, add (DA)= 0.0001decode = 0.3602 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1192 s, inc stats = 6.1243, 
minCostFunction = 5.4671 s, v_trunc (Latent to Reduced) = 0.0889, dec (Reduced to Full) = 0.3243, add (DA)= 0.0001decode = 0.4133 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.8805 s, inc stats = 5.8944, 
minCostFunction = 5.4351 s, v_trunc (Latent to Reduced) = 0.0915, dec (Reduced to Full) = 0.2877, add (DA)= 0.0001decode = 0.3793 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.8145 s, inc stats = 5.8262, 
minCostFunction = 5.7788 s, v_trunc (Latent to Reduced) = 0.0908, dec (Reduced to Full) = 0.2431, add (DA)= 0.0001decode = 0.3340 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1130 s, inc stats = 6.1180, 
minCostFunction = 5.4767 s, v_trunc (Latent to Reduced) = 0.1256, dec (Reduced to Full) = 0.1685, add (DA)= 0.0002decode = 0.2943 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.7712 s, inc stats = 5.7844, 
DA - - L2: 3456.14, L1: 4549.54, % Improve: 26.55%, DA_MAE: 0.02, mse_ref: 0.07, mse_DA: 0.061, time(s): 7.0389s,
\% improve_point: 10.93, mse_ref_points: 4.534062502031193e-06, mse_da_points: 3.7801819226183515e-06, % improve_overlap: 10.93, mse_ref_overlap: 0.06341, mse_da_overlap: 0.05101
minCostFunction = 3.5879 s, v_trunc (Latent to Reduced) = 0.0835, dec (Reduced to Full) = 0.1532, add (DA)= 0.0001decode = 0.2369 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8249 s, inc stats = 3.8393, 
minCostFunction = 3.7828 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1560, add (DA)= 0.0001decode = 0.2422 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0251 s, inc stats = 4.0381, 
minCostFunction = 4.6230 s, v_trunc (Latent to Reduced) = 0.0917, dec (Reduced to Full) = 0.1460, add (DA)= 0.0001decode = 0.2378 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8610 s, inc stats = 4.8654, 
minCostFunction = 4.3501 s, v_trunc (Latent to Reduced) = 0.0834, dec (Reduced to Full) = 0.2226, add (DA)= 0.0001decode = 0.3060 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.6563 s, inc stats = 4.6652, 
minCostFunction = 5.5449 s, v_trunc (Latent to Reduced) = 0.0840, dec (Reduced to Full) = 0.2221, add (DA)= 0.0001decode = 0.3062 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.8513 s, inc stats = 5.8675, 
minCostFunction = 5.6984 s, v_trunc (Latent to Reduced) = 0.0913, dec (Reduced to Full) = 0.2309, add (DA)= 0.0001decode = 0.3223 s, unnorm = 0.0020 s, TOTAL = unnormalising + decoding + minimising = 6.0228 s, inc stats = 6.0271, 
minCostFunction = 6.3777 s, v_trunc (Latent to Reduced) = 0.1021, dec (Reduced to Full) = 0.2223, add (DA)= 0.0002decode = 0.3246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.7024 s, inc stats = 6.7149, 
minCostFunction = 5.5347 s, v_trunc (Latent to Reduced) = 0.1072, dec (Reduced to Full) = 0.2668, add (DA)= 0.0002decode = 0.3744 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 5.9097 s, inc stats = 5.9161, 
minCostFunction = 5.8688 s, v_trunc (Latent to Reduced) = 0.0836, dec (Reduced to Full) = 0.2427, add (DA)= 0.0001decode = 0.3264 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1953 s, inc stats = 6.2046, 
minCostFunction = 5.8811 s, v_trunc (Latent to Reduced) = 0.0898, dec (Reduced to Full) = 0.2338, add (DA)= 0.0001decode = 0.3238 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.2050 s, inc stats = 6.2119, 
DA - - L2: 3917.28, L1: 4809.92, % Improve: 28.20%, DA_MAE: 0.02, mse_ref: 0.08, mse_DA: 0.064, time(s): 6.8413s,
\% improve_point: 13.91, mse_ref_points: 4.955875660212499e-06, mse_da_points: 3.950420317912965e-06, % improve_overlap: 14.29, mse_ref_overlap: 0.07135, mse_da_overlap: 0.05446
minCostFunction = 5.8115 s, v_trunc (Latent to Reduced) = 0.0935, dec (Reduced to Full) = 0.3354, add (DA)= 0.0001decode = 0.4290 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.2406 s, inc stats = 6.2490, 
minCostFunction = 5.3628 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.3791, add (DA)= 0.0004decode = 0.4659 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 5.8291 s, inc stats = 5.8460, 
minCostFunction = 4.8478 s, v_trunc (Latent to Reduced) = 0.1376, dec (Reduced to Full) = 0.3098, add (DA)= 0.0001decode = 0.4475 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2954 s, inc stats = 5.3218, 
minCostFunction = 4.8357 s, v_trunc (Latent to Reduced) = 0.0832, dec (Reduced to Full) = 0.3295, add (DA)= 0.0002decode = 0.4130 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.2490 s, inc stats = 5.2698, 
minCostFunction = 5.2210 s, v_trunc (Latent to Reduced) = 0.0865, dec (Reduced to Full) = 0.2341, add (DA)= 0.0001decode = 0.3208 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.5419 s, inc stats = 5.5576, 
minCostFunction = 4.7542 s, v_trunc (Latent to Reduced) = 0.1013, dec (Reduced to Full) = 0.3057, add (DA)= 0.0001decode = 0.4072 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1615 s, inc stats = 5.1826, 
minCostFunction = 4.9204 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.2599, add (DA)= 0.0001decode = 0.3464 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2668 s, inc stats = 5.2731, 
minCostFunction = 5.1331 s, v_trunc (Latent to Reduced) = 0.0940, dec (Reduced to Full) = 0.2566, add (DA)= 0.0003decode = 0.3510 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4843 s, inc stats = 5.4911, 
minCostFunction = 4.8777 s, v_trunc (Latent to Reduced) = 0.0840, dec (Reduced to Full) = 0.2303, add (DA)= 0.0001decode = 0.3144 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1922 s, inc stats = 5.2308, 
minCostFunction = 5.0310 s, v_trunc (Latent to Reduced) = 0.0857, dec (Reduced to Full) = 0.3183, add (DA)= 0.0001decode = 0.4042 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.4354 s, inc stats = 5.4415, 
DA - - L2: 4402.63, L1: 5061.99, % Improve: 29.94%, DA_MAE: 0.02, mse_ref: 0.09, mse_DA: 0.067, time(s): 6.6927s,
\% improve_point: 16.68, mse_ref_points: 5.414844296634659e-06, mse_da_points: 4.12703383823257e-06, % improve_overlap: 16.46, mse_ref_overlap: 0.07948, mse_da_overlap: 0.05903
minCostFunction = 4.9409 s, v_trunc (Latent to Reduced) = 0.0874, dec (Reduced to Full) = 0.2918, add (DA)= 0.0001decode = 0.3794 s, unnorm = 0.0007 s, TOTAL = unnormalising + decoding + minimising = 5.3211 s, inc stats = 5.3350, 
minCostFunction = 3.0558 s, v_trunc (Latent to Reduced) = 0.0900, dec (Reduced to Full) = 0.2102, add (DA)= 0.0001decode = 0.3003 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 3.3563 s, inc stats = 3.3763, 
minCostFunction = 3.0532 s, v_trunc (Latent to Reduced) = 0.0842, dec (Reduced to Full) = 0.2473, add (DA)= 0.0001decode = 0.3317 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.3850 s, inc stats = 3.3976, 
minCostFunction = 3.3127 s, v_trunc (Latent to Reduced) = 0.0918, dec (Reduced to Full) = 0.2358, add (DA)= 0.0001decode = 0.3277 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6406 s, inc stats = 3.6492, 
minCostFunction = 3.3110 s, v_trunc (Latent to Reduced) = 0.0940, dec (Reduced to Full) = 0.2414, add (DA)= 0.0001decode = 0.3356 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6467 s, inc stats = 3.6553, 
minCostFunction = 3.7929 s, v_trunc (Latent to Reduced) = 0.0920, dec (Reduced to Full) = 0.3291, add (DA)= 0.0001decode = 0.4212 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.2143 s, inc stats = 4.2197, 
minCostFunction = 4.9866 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1977, add (DA)= 0.0001decode = 0.3014 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2881 s, inc stats = 5.3027, 
minCostFunction = 3.8605 s, v_trunc (Latent to Reduced) = 0.0949, dec (Reduced to Full) = 0.9740, add (DA)= 0.0001decode = 1.0690 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.9296 s, inc stats = 4.9504, 
minCostFunction = 5.0067 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.3521, add (DA)= 0.0002decode = 0.4386 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.4455 s, inc stats = 5.4546, 
minCostFunction = 4.8455 s, v_trunc (Latent to Reduced) = 0.0938, dec (Reduced to Full) = 0.2074, add (DA)= 0.0001decode = 0.3014 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1470 s, inc stats = 5.1540, 
DA - - L2: 4866.17, L1: 5279.99, % Improve: 31.53%, DA_MAE: 0.02, mse_ref: 0.09, mse_DA: 0.069, time(s): 6.4709s,
\% improve_point: 18.85, mse_ref_points: 5.724376246191642e-06, mse_da_points: 4.238177324326182e-06, % improve_overlap: 18.18, mse_ref_overlap: 0.08537, mse_da_overlap: 0.06230
minCostFunction = 4.9346 s, v_trunc (Latent to Reduced) = 0.0908, dec (Reduced to Full) = 0.2012, add (DA)= 0.0001decode = 0.2921 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2268 s, inc stats = 5.2532, 
minCostFunction = 4.6619 s, v_trunc (Latent to Reduced) = 0.0856, dec (Reduced to Full) = 0.2691, add (DA)= 0.0001decode = 0.3549 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0169 s, inc stats = 5.0234, 
minCostFunction = 3.3121 s, v_trunc (Latent to Reduced) = 0.0873, dec (Reduced to Full) = 0.2226, add (DA)= 0.0001decode = 0.3100 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6222 s, inc stats = 3.6290, 
minCostFunction = 4.3017 s, v_trunc (Latent to Reduced) = 0.0883, dec (Reduced to Full) = 0.2688, add (DA)= 0.0001decode = 0.3574 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.6592 s, inc stats = 4.6645, 
minCostFunction = 4.9231 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.3364, add (DA)= 0.0001decode = 0.4227 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3459 s, inc stats = 5.3561, 
minCostFunction = 4.7037 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.2291, add (DA)= 0.0001decode = 0.3130 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0168 s, inc stats = 5.0352, 
DA - - L2: 5141.36, L1: 5405.00, % Improve: 32.32%, DA_MAE: 0.02, mse_ref: 0.09, mse_DA: 0.069, time(s): 6.3789s,
\% improve_point: 20.02, mse_ref_points: 5.8540618251705225e-06, mse_da_points: 4.272144804573243e-06, % improve_overlap: 19.24, mse_ref_overlap: 0.08806, mse_da_overlap: 0.06351
Results of DA at 2020-08-27 14:14:37.153480. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              42.031254      0.012622  ...  41.275709     9.857882
1              40.456183      0.013497  ...  10.827404    10.820444
2              33.340418      0.014444  ...   7.682256     7.667628
3              25.624146      0.015342  ...   4.280431     4.271405
4              24.660595      0.015883  ...   4.721760     4.714765
..                   ...           ...  ...        ...          ...
102            45.557836      0.046607  ...   5.026608     5.016947
103            45.512690      0.046824  ...   3.632462     3.622221
104            45.556302      0.047023  ...   4.668086     4.659153
105            45.780812      0.047157  ...   5.359510     5.345913
106            46.080515      0.047203  ...   5.038375     5.016824

[107 rows x 20 columns]
data fp  /home/mredstone/unstructuredCAE/data/subdomain_6/
domain, other, pickle, dim 6 ['8'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | MeanHist_80P_150E_1D0L                                                       |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_6/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
When creating TucodecEncode1D, inputSize =  26032 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
Number of parameters: 567553
------------------------------ Training subdomain 6 at 2020-08-27 14:14:51.117347. ------------------------------
Loading data started 2020-08-27 14:14:51.117463
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fa7133c95f8>
Loading data finished 2020-08-27 14:15:05.129141
Loop AE Train begins at  14:15:05.133671
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [1/150], TRAIN: -loss:12701.08, av_diff: 0.30, time taken (m): 0.04m
epoch [1/150], TEST: -loss:98714.9453, time taken(m): 0.01m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [6/150], TRAIN: -loss:5635.69, av_diff: 0.04, time taken (m): 0.03m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [11/150], TRAIN: -loss:4862.00, av_diff: 0.02, time taken (m): 0.06m
epoch [11/150], TEST: -loss:97716.6050, time taken(m): 0.02m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [16/150], TRAIN: -loss:4389.72, av_diff: 0.01, time taken (m): 0.07m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [21/150], TRAIN: -loss:4031.33, av_diff: 0.00, time taken (m): 0.06m
epoch [21/150], TEST: -loss:93263.7812, time taken(m): 0.02m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [26/150], TRAIN: -loss:3730.59, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [31/150], TRAIN: -loss:3467.45, av_diff: 0.01, time taken (m): 0.06m
epoch [31/150], TEST: -loss:89675.3169, time taken(m): 0.02m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [36/150], TRAIN: -loss:3219.54, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [41/150], TRAIN: -loss:2964.84, av_diff: 0.01, time taken (m): 0.06m
epoch [41/150], TEST: -loss:88860.2920, time taken(m): 0.02m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [46/150], TRAIN: -loss:2735.93, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [51/150], TRAIN: -loss:2539.33, av_diff: 0.01, time taken (m): 0.07m
epoch [51/150], TEST: -loss:87344.9238, time taken(m): 0.03m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [56/150], TRAIN: -loss:2363.96, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [61/150], TRAIN: -loss:2165.05, av_diff: 0.01, time taken (m): 0.06m
epoch [61/150], TEST: -loss:85913.9639, time taken(m): 0.02m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [66/150], TRAIN: -loss:2020.64, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [71/150], TRAIN: -loss:1836.79, av_diff: 0.01, time taken (m): 0.06m
epoch [71/150], TEST: -loss:84626.6465, time taken(m): 0.03m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [76/150], TRAIN: -loss:1741.68, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [81/150], TRAIN: -loss:1570.44, av_diff: 0.01, time taken (m): 0.07m
epoch [81/150], TEST: -loss:83335.6533, time taken(m): 0.02m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [86/150], TRAIN: -loss:1440.18, av_diff: 0.00, time taken (m): 0.07m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [91/150], TRAIN: -loss:1328.18, av_diff: 0.01, time taken (m): 0.06m
epoch [91/150], TEST: -loss:82324.6592, time taken(m): 0.03m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [96/150], TRAIN: -loss:1239.96, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [101/150], TRAIN: -loss:1149.63, av_diff: 0.00, time taken (m): 0.07m
epoch [101/150], TEST: -loss:81071.4878, time taken(m): 0.02m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [106/150], TRAIN: -loss:1071.61, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [111/150], TRAIN: -loss:981.49, av_diff: 0.00, time taken (m): 0.06m
epoch [111/150], TEST: -loss:79880.6045, time taken(m): 0.03m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [116/150], TRAIN: -loss:922.79, av_diff: 0.01, time taken (m): 0.07m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [121/150], TRAIN: -loss:839.46, av_diff: 0.00, time taken (m): 0.06m
epoch [121/150], TEST: -loss:78901.4590, time taken(m): 0.02m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [126/150], TRAIN: -loss:781.85, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [131/150], TRAIN: -loss:732.35, av_diff: 0.00, time taken (m): 0.06m
epoch [131/150], TEST: -loss:78323.5986, time taken(m): 0.03m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [136/150], TRAIN: -loss:694.16, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [141/150], TRAIN: -loss:667.42, av_diff: 0.01, time taken (m): 0.06m
epoch [141/150], TEST: -loss:77490.7705, time taken(m): 0.03m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [146/150], TRAIN: -loss:594.56, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [150/150], TRAIN: -loss:561.39, av_diff: 0.01, time taken (m): 0.07m
epoch [150/150], TEST: -loss:76696.5674, time taken(m): 0.03m
Loop AE Train Ends at  14:24:48.061787
------------------------------ DA subdomain 6 at 2020-08-27 14:24:48.151024. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 26032) , test_X = (107, 26032), X = (537, 26032)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting mean historical data
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
Shape of w_0 =  (429,)
minCostFunction = 9.4351 s, v_trunc (Latent to Reduced) = 0.1074, dec (Reduced to Full) = 0.2189, add (DA)= 0.0007decode = 0.3271 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 9.7627 s, inc stats = 61.9460, 
minCostFunction = 5.2125 s, v_trunc (Latent to Reduced) = 0.1036, dec (Reduced to Full) = 0.1968, add (DA)= 0.0006decode = 0.3010 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.5137 s, inc stats = 5.5255, 
minCostFunction = 4.9541 s, v_trunc (Latent to Reduced) = 0.1053, dec (Reduced to Full) = 0.1715, add (DA)= 0.0002decode = 0.2770 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2312 s, inc stats = 5.2348, 
minCostFunction = 3.8856 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1815, add (DA)= 0.0005decode = 0.2855 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1712 s, inc stats = 4.1757, 
minCostFunction = 3.9734 s, v_trunc (Latent to Reduced) = 0.1041, dec (Reduced to Full) = 0.1765, add (DA)= 0.0001decode = 0.2807 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.2542 s, inc stats = 4.2599, 
minCostFunction = 4.2693 s, v_trunc (Latent to Reduced) = 0.1031, dec (Reduced to Full) = 0.2032, add (DA)= 0.0002decode = 0.3066 s, unnorm = 0.0007 s, TOTAL = unnormalising + decoding + minimising = 4.5767 s, inc stats = 4.5830, 
minCostFunction = 3.3923 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1880, add (DA)= 0.0001decode = 0.2922 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6847 s, inc stats = 3.6935, 
minCostFunction = 3.9378 s, v_trunc (Latent to Reduced) = 0.1047, dec (Reduced to Full) = 0.1956, add (DA)= 0.0001decode = 0.3004 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.2383 s, inc stats = 4.2509, 
minCostFunction = 3.3750 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1924, add (DA)= 0.0002decode = 0.2962 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 3.6713 s, inc stats = 3.6762, 
minCostFunction = 3.1627 s, v_trunc (Latent to Reduced) = 0.1050, dec (Reduced to Full) = 0.3077, add (DA)= 0.0002decode = 0.4130 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 3.5759 s, inc stats = 3.5873, 
minCostFunction = 4.5829 s, v_trunc (Latent to Reduced) = 0.2688, dec (Reduced to Full) = 2.4196, add (DA)= 0.0002decode = 2.6886 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.2717 s, inc stats = 7.2768, 
DA - - L2: 169806.04, L1: 12439.34, % Improve: 65.13%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.081, time(s): 10.7720s,
\% improve_point: 61.81, mse_ref_points: 8.162003865993753e-06, mse_da_points: 3.1178915205605456e-06, % improve_overlap: 61.84, mse_ref_overlap: 0.21247, mse_da_overlap: 0.08111
minCostFunction = 4.6611 s, v_trunc (Latent to Reduced) = 0.1309, dec (Reduced to Full) = 0.5365, add (DA)= 0.0001decode = 0.6676 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3288 s, inc stats = 5.3423, 
minCostFunction = 4.8937 s, v_trunc (Latent to Reduced) = 0.1358, dec (Reduced to Full) = 0.8779, add (DA)= 0.0001decode = 1.0139 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.9077 s, inc stats = 5.9144, 
minCostFunction = 5.5325 s, v_trunc (Latent to Reduced) = 0.1564, dec (Reduced to Full) = 0.8917, add (DA)= 0.0001decode = 1.0483 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.5809 s, inc stats = 6.5859, 
minCostFunction = 5.6049 s, v_trunc (Latent to Reduced) = 0.1332, dec (Reduced to Full) = 0.7831, add (DA)= 0.0001decode = 0.9165 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.5216 s, inc stats = 6.5268, 
minCostFunction = 5.9842 s, v_trunc (Latent to Reduced) = 0.1189, dec (Reduced to Full) = 0.3737, add (DA)= 0.0003decode = 0.4930 s, unnorm = 0.0024 s, TOTAL = unnormalising + decoding + minimising = 6.4796 s, inc stats = 6.5130, 
minCostFunction = 5.2400 s, v_trunc (Latent to Reduced) = 0.1365, dec (Reduced to Full) = 1.0656, add (DA)= 0.0001decode = 1.2022 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.4424 s, inc stats = 6.4605, 
minCostFunction = 5.0759 s, v_trunc (Latent to Reduced) = 0.1608, dec (Reduced to Full) = 0.2750, add (DA)= 0.0001decode = 0.4360 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.5120 s, inc stats = 5.5208, 
minCostFunction = 4.4538 s, v_trunc (Latent to Reduced) = 0.1033, dec (Reduced to Full) = 0.2786, add (DA)= 0.0002decode = 0.3821 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.8361 s, inc stats = 4.8399, 
minCostFunction = 6.0444 s, v_trunc (Latent to Reduced) = 0.1080, dec (Reduced to Full) = 0.2782, add (DA)= 0.0002decode = 0.3865 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.4311 s, inc stats = 6.4403, 
minCostFunction = 5.9103 s, v_trunc (Latent to Reduced) = 0.1141, dec (Reduced to Full) = 0.3568, add (DA)= 0.0001decode = 0.4711 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.3816 s, inc stats = 6.3946, 
DA - - L2: 142697.12, L1: 10663.29, % Improve: 62.44%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.086, time(s): 8.5264s,
\% improve_point: 58.41, mse_ref_points: 7.984749960522767e-06, mse_da_points: 3.317226556375648e-06, % improve_overlap: 58.43, mse_ref_overlap: 0.20783, mse_da_overlap: 0.08629
minCostFunction = 5.8752 s, v_trunc (Latent to Reduced) = 0.1082, dec (Reduced to Full) = 0.2777, add (DA)= 0.0002decode = 0.3861 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.2615 s, inc stats = 6.2768, 
minCostFunction = 4.0393 s, v_trunc (Latent to Reduced) = 0.1659, dec (Reduced to Full) = 1.6552, add (DA)= 0.0007decode = 1.8219 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 5.8617 s, inc stats = 5.8880, 
minCostFunction = 5.7498 s, v_trunc (Latent to Reduced) = 0.1389, dec (Reduced to Full) = 0.2933, add (DA)= 0.0002decode = 0.4324 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.1824 s, inc stats = 6.2085, 
minCostFunction = 5.6445 s, v_trunc (Latent to Reduced) = 0.1252, dec (Reduced to Full) = 0.7734, add (DA)= 0.0002decode = 0.8988 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.5435 s, inc stats = 6.5502, 
minCostFunction = 5.4171 s, v_trunc (Latent to Reduced) = 0.1332, dec (Reduced to Full) = 0.5706, add (DA)= 0.0001decode = 0.7040 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.1213 s, inc stats = 6.1407, 
minCostFunction = 5.4519 s, v_trunc (Latent to Reduced) = 0.2005, dec (Reduced to Full) = 0.3747, add (DA)= 0.0001decode = 0.5754 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.0275 s, inc stats = 6.0344, 
minCostFunction = 4.2935 s, v_trunc (Latent to Reduced) = 0.1367, dec (Reduced to Full) = 0.3208, add (DA)= 0.0025decode = 0.4601 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 4.7538 s, inc stats = 4.7800, 
minCostFunction = 5.5608 s, v_trunc (Latent to Reduced) = 0.1761, dec (Reduced to Full) = 0.6423, add (DA)= 0.0001decode = 0.8186 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.3795 s, inc stats = 6.3859, 
minCostFunction = 5.3737 s, v_trunc (Latent to Reduced) = 0.1576, dec (Reduced to Full) = 0.8854, add (DA)= 0.0001decode = 1.0431 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.4170 s, inc stats = 6.4336, 
minCostFunction = 4.5744 s, v_trunc (Latent to Reduced) = 0.1064, dec (Reduced to Full) = 1.6848, add (DA)= 0.0002decode = 1.7915 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.3661 s, inc stats = 6.3741, 
DA - - L2: 97403.01, L1: 8933.78, % Improve: 61.64%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.089, time(s): 7.7467s,
\% improve_point: 56.91, mse_ref_points: 7.910012560614941e-06, mse_da_points: 3.403680766047977e-06, % improve_overlap: 56.94, mse_ref_overlap: 0.20586, mse_da_overlap: 0.08852
minCostFunction = 4.9379 s, v_trunc (Latent to Reduced) = 0.1149, dec (Reduced to Full) = 0.3710, add (DA)= 0.0002decode = 0.4862 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4243 s, inc stats = 5.4297, 
minCostFunction = 5.2000 s, v_trunc (Latent to Reduced) = 0.1288, dec (Reduced to Full) = 0.9101, add (DA)= 0.0002decode = 1.0391 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.2392 s, inc stats = 6.2488, 
minCostFunction = 5.4994 s, v_trunc (Latent to Reduced) = 0.1542, dec (Reduced to Full) = 0.7456, add (DA)= 0.0001decode = 0.9000 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.3996 s, inc stats = 6.4078, 
minCostFunction = 4.5404 s, v_trunc (Latent to Reduced) = 0.1728, dec (Reduced to Full) = 1.1474, add (DA)= 0.0001decode = 1.3204 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.8610 s, inc stats = 5.8705, 
minCostFunction = 4.4727 s, v_trunc (Latent to Reduced) = 0.1691, dec (Reduced to Full) = 0.8569, add (DA)= 0.0006decode = 1.0267 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4997 s, inc stats = 5.5202, 
minCostFunction = 3.4154 s, v_trunc (Latent to Reduced) = 0.1163, dec (Reduced to Full) = 1.1105, add (DA)= 0.0002decode = 1.2271 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.6426 s, inc stats = 4.6676, 
minCostFunction = 5.4278 s, v_trunc (Latent to Reduced) = 0.1326, dec (Reduced to Full) = 0.5657, add (DA)= 0.0001decode = 0.6985 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1264 s, inc stats = 6.1315, 
minCostFunction = 3.9669 s, v_trunc (Latent to Reduced) = 0.1474, dec (Reduced to Full) = 1.3920, add (DA)= 0.0002decode = 1.5396 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.5067 s, inc stats = 5.5159, 
minCostFunction = 4.7385 s, v_trunc (Latent to Reduced) = 0.1405, dec (Reduced to Full) = 0.6921, add (DA)= 0.0002decode = 0.8329 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.5716 s, inc stats = 5.5969, 
minCostFunction = 4.0136 s, v_trunc (Latent to Reduced) = 0.1801, dec (Reduced to Full) = 1.2726, add (DA)= 0.0001decode = 1.4529 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4666 s, inc stats = 5.4726, 
DA - - L2: 74359.68, L1: 8095.18, % Improve: 61.35%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.090, time(s): 7.2448s,
\% improve_point: 56.47, mse_ref_points: 7.946701020050124e-06, mse_da_points: 3.4546587391250492e-06, % improve_overlap: 56.52, mse_ref_overlap: 0.20679, mse_da_overlap: 0.08978
minCostFunction = 4.4496 s, v_trunc (Latent to Reduced) = 0.1523, dec (Reduced to Full) = 1.0889, add (DA)= 0.0002decode = 1.2414 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6912 s, inc stats = 5.7011, 
minCostFunction = 4.6197 s, v_trunc (Latent to Reduced) = 0.1841, dec (Reduced to Full) = 0.6844, add (DA)= 0.0001decode = 0.8686 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4885 s, inc stats = 5.5216, 
minCostFunction = 4.5840 s, v_trunc (Latent to Reduced) = 0.1408, dec (Reduced to Full) = 0.3259, add (DA)= 0.0002decode = 0.4670 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.0513 s, inc stats = 5.0598, 
minCostFunction = 4.0677 s, v_trunc (Latent to Reduced) = 0.1589, dec (Reduced to Full) = 0.4899, add (DA)= 0.0001decode = 0.6490 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7168 s, inc stats = 4.7276, 
minCostFunction = 4.7085 s, v_trunc (Latent to Reduced) = 0.1237, dec (Reduced to Full) = 0.2579, add (DA)= 0.0001decode = 0.3818 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0904 s, inc stats = 5.1071, 
minCostFunction = 5.3566 s, v_trunc (Latent to Reduced) = 0.1664, dec (Reduced to Full) = 0.3514, add (DA)= 0.0002decode = 0.5181 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.8749 s, inc stats = 5.8848, 
minCostFunction = 4.5449 s, v_trunc (Latent to Reduced) = 0.1667, dec (Reduced to Full) = 0.3670, add (DA)= 0.0001decode = 0.5339 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0790 s, inc stats = 5.0920, 
minCostFunction = 4.7840 s, v_trunc (Latent to Reduced) = 0.1441, dec (Reduced to Full) = 0.3768, add (DA)= 0.0001decode = 0.5211 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3053 s, inc stats = 5.3164, 
minCostFunction = 4.7350 s, v_trunc (Latent to Reduced) = 0.1209, dec (Reduced to Full) = 0.4198, add (DA)= 0.0002decode = 0.5410 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2762 s, inc stats = 5.2836, 
minCostFunction = 4.7692 s, v_trunc (Latent to Reduced) = 0.1113, dec (Reduced to Full) = 0.4161, add (DA)= 0.0002decode = 0.5276 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2970 s, inc stats = 5.3043, 
DA - - L2: 60183.89, L1: 7372.80, % Improve: 60.61%, DA_MAE: 0.00, mse_ref: 0.22, mse_DA: 0.100, time(s): 6.8639s,
\% improve_point: 54.48, mse_ref_points: 8.33451961454621e-06, mse_da_points: 3.830061661138254e-06, % improve_overlap: 54.54, mse_ref_overlap: 0.21685, mse_da_overlap: 0.09949
minCostFunction = 5.3582 s, v_trunc (Latent to Reduced) = 0.1134, dec (Reduced to Full) = 0.3717, add (DA)= 0.0007decode = 0.4859 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 5.8445 s, inc stats = 5.8601, 
minCostFunction = 5.4531 s, v_trunc (Latent to Reduced) = 0.1108, dec (Reduced to Full) = 0.2514, add (DA)= 0.0002decode = 0.3624 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.8157 s, inc stats = 5.8427, 
minCostFunction = 3.4154 s, v_trunc (Latent to Reduced) = 0.1653, dec (Reduced to Full) = 0.6702, add (DA)= 0.0002decode = 0.8357 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.2513 s, inc stats = 4.2817, 
minCostFunction = 5.7852 s, v_trunc (Latent to Reduced) = 0.1599, dec (Reduced to Full) = 0.2716, add (DA)= 0.0002decode = 0.4317 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.2171 s, inc stats = 6.2263, 
minCostFunction = 5.7722 s, v_trunc (Latent to Reduced) = 0.1145, dec (Reduced to Full) = 0.2990, add (DA)= 0.0002decode = 0.4137 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.1861 s, inc stats = 6.2125, 
minCostFunction = 5.6627 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.3498, add (DA)= 0.0001decode = 0.4541 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.1170 s, inc stats = 6.1253, 
minCostFunction = 3.8892 s, v_trunc (Latent to Reduced) = 0.1394, dec (Reduced to Full) = 1.2131, add (DA)= 0.0002decode = 1.3528 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.2423 s, inc stats = 5.2481, 
minCostFunction = 4.5180 s, v_trunc (Latent to Reduced) = 0.1885, dec (Reduced to Full) = 0.6074, add (DA)= 0.0002decode = 0.7961 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3143 s, inc stats = 5.3450, 
minCostFunction = 3.7140 s, v_trunc (Latent to Reduced) = 0.1589, dec (Reduced to Full) = 1.3432, add (DA)= 0.0001decode = 1.5023 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2164 s, inc stats = 5.2244, 
minCostFunction = 5.4690 s, v_trunc (Latent to Reduced) = 0.1300, dec (Reduced to Full) = 0.4790, add (DA)= 0.0002decode = 0.6092 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.0784 s, inc stats = 71.0781, 
DA - - L2: 50771.46, L1: 7033.82, % Improve: 59.35%, DA_MAE: 0.00, mse_ref: 0.23, mse_DA: 0.109, time(s): 7.7300s,
\% improve_point: 52.68, mse_ref_points: 8.707829174779674e-06, mse_da_points: 4.184425785773652e-06, % improve_overlap: 52.75, mse_ref_overlap: 0.22656, mse_da_overlap: 0.10872
minCostFunction = 3.4293 s, v_trunc (Latent to Reduced) = 0.1098, dec (Reduced to Full) = 0.1942, add (DA)= 0.0004decode = 0.3044 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 3.7342 s, inc stats = 3.7408, 
minCostFunction = 3.4684 s, v_trunc (Latent to Reduced) = 0.1036, dec (Reduced to Full) = 0.1972, add (DA)= 0.0006decode = 0.3016 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 3.7704 s, inc stats = 3.7839, 
minCostFunction = 3.6545 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1746, add (DA)= 0.0001decode = 0.2797 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9343 s, inc stats = 3.9471, 
minCostFunction = 3.3369 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1774, add (DA)= 0.0002decode = 0.2811 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 3.6181 s, inc stats = 3.6314, 
minCostFunction = 2.5388 s, v_trunc (Latent to Reduced) = 0.1052, dec (Reduced to Full) = 0.1911, add (DA)= 0.0001decode = 0.2965 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 2.8355 s, inc stats = 2.8481, 
minCostFunction = 2.5675 s, v_trunc (Latent to Reduced) = 0.1041, dec (Reduced to Full) = 0.1699, add (DA)= 0.0001decode = 0.2741 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.8417 s, inc stats = 2.8488, 
minCostFunction = 3.3221 s, v_trunc (Latent to Reduced) = 0.1128, dec (Reduced to Full) = 0.1872, add (DA)= 0.0002decode = 0.3003 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6226 s, inc stats = 3.6384, 
minCostFunction = 3.1774 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1602, add (DA)= 0.0001decode = 0.2653 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.4429 s, inc stats = 3.4558, 
minCostFunction = 2.5133 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.1731, add (DA)= 0.0001decode = 0.2772 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.7907 s, inc stats = 2.7963, 
minCostFunction = 3.7129 s, v_trunc (Latent to Reduced) = 0.1563, dec (Reduced to Full) = 1.2050, add (DA)= 0.0001decode = 1.3615 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0747 s, inc stats = 5.0863, 
DA - - L2: 43934.78, L1: 6719.36, % Improve: 58.67%, DA_MAE: 0.00, mse_ref: 0.23, mse_DA: 0.116, time(s): 7.1455s,
\% improve_point: 51.47, mse_ref_points: 8.992561675798104e-06, mse_da_points: 4.440287538842281e-06, % improve_overlap: 51.55, mse_ref_overlap: 0.23395, mse_da_overlap: 0.11534
minCostFunction = 3.8605 s, v_trunc (Latent to Reduced) = 0.1432, dec (Reduced to Full) = 1.0862, add (DA)= 0.0002decode = 1.2297 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0904 s, inc stats = 5.1048, 
minCostFunction = 5.1791 s, v_trunc (Latent to Reduced) = 0.1353, dec (Reduced to Full) = 0.4396, add (DA)= 0.0001decode = 0.5751 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.7544 s, inc stats = 5.7648, 
minCostFunction = 4.8099 s, v_trunc (Latent to Reduced) = 0.1365, dec (Reduced to Full) = 0.6899, add (DA)= 0.0002decode = 0.8267 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6368 s, inc stats = 5.6580, 
minCostFunction = 4.8340 s, v_trunc (Latent to Reduced) = 0.1139, dec (Reduced to Full) = 0.3793, add (DA)= 0.0002decode = 0.4936 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 5.3279 s, inc stats = 5.3439, 
minCostFunction = 5.1787 s, v_trunc (Latent to Reduced) = 0.1413, dec (Reduced to Full) = 0.3466, add (DA)= 0.0001decode = 0.4880 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.6669 s, inc stats = 5.6832, 
minCostFunction = 4.9690 s, v_trunc (Latent to Reduced) = 0.1145, dec (Reduced to Full) = 0.4123, add (DA)= 0.0001decode = 0.5269 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4961 s, inc stats = 5.5111, 
minCostFunction = 5.4745 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.3656, add (DA)= 0.0001decode = 0.4697 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.9443 s, inc stats = 5.9525, 
minCostFunction = 5.5482 s, v_trunc (Latent to Reduced) = 0.1122, dec (Reduced to Full) = 0.3153, add (DA)= 0.0001decode = 0.4277 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.9761 s, inc stats = 5.9846, 
minCostFunction = 5.0779 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.2966, add (DA)= 0.0002decode = 0.4016 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4797 s, inc stats = 5.4909, 
minCostFunction = 4.9923 s, v_trunc (Latent to Reduced) = 0.1098, dec (Reduced to Full) = 0.3246, add (DA)= 0.0002decode = 0.4346 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4271 s, inc stats = 5.4352, 
DA - - L2: 38975.24, L1: 6564.77, % Improve: 57.92%, DA_MAE: 0.00, mse_ref: 0.24, mse_DA: 0.121, time(s): 6.9541s,
\% improve_point: 50.43, mse_ref_points: 9.19327380729071e-06, mse_da_points: 4.639081215497916e-06, % improve_overlap: 50.52, mse_ref_overlap: 0.23914, mse_da_overlap: 0.12045
minCostFunction = 4.9943 s, v_trunc (Latent to Reduced) = 0.1306, dec (Reduced to Full) = 0.7013, add (DA)= 0.0002decode = 0.8321 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.8267 s, inc stats = 5.8338, 
minCostFunction = 5.1023 s, v_trunc (Latent to Reduced) = 0.1189, dec (Reduced to Full) = 0.4345, add (DA)= 0.0004decode = 0.5539 s, unnorm = 0.0008 s, TOTAL = unnormalising + decoding + minimising = 5.6571 s, inc stats = 5.6768, 
minCostFunction = 5.1698 s, v_trunc (Latent to Reduced) = 0.1118, dec (Reduced to Full) = 0.4209, add (DA)= 0.0002decode = 0.5329 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.7028 s, inc stats = 5.7165, 
minCostFunction = 5.4472 s, v_trunc (Latent to Reduced) = 0.1427, dec (Reduced to Full) = 0.2971, add (DA)= 0.0001decode = 0.4399 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.8873 s, inc stats = 5.8962, 
minCostFunction = 5.5684 s, v_trunc (Latent to Reduced) = 0.1141, dec (Reduced to Full) = 0.3637, add (DA)= 0.0002decode = 0.4781 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.0466 s, inc stats = 6.0712, 
minCostFunction = 5.6432 s, v_trunc (Latent to Reduced) = 0.1368, dec (Reduced to Full) = 0.6656, add (DA)= 0.0008decode = 0.8034 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 6.4470 s, inc stats = 6.4538, 
minCostFunction = 6.0597 s, v_trunc (Latent to Reduced) = 0.1023, dec (Reduced to Full) = 0.2632, add (DA)= 0.0002decode = 0.3657 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.4256 s, inc stats = 6.4457, 
minCostFunction = 6.2592 s, v_trunc (Latent to Reduced) = 0.1460, dec (Reduced to Full) = 0.2128, add (DA)= 0.0001decode = 0.3590 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.6184 s, inc stats = 6.6383, 
minCostFunction = 5.3257 s, v_trunc (Latent to Reduced) = 0.1730, dec (Reduced to Full) = 0.4448, add (DA)= 0.0001decode = 0.6180 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.9440 s, inc stats = 5.9564, 
minCostFunction = 3.9501 s, v_trunc (Latent to Reduced) = 0.1902, dec (Reduced to Full) = 0.7967, add (DA)= 0.0001decode = 0.9871 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.9373 s, inc stats = 4.9424, 
DA - - L2: 34963.56, L1: 6345.37, % Improve: 58.33%, DA_MAE: 0.00, mse_ref: 0.24, mse_DA: 0.121, time(s): 6.8455s,
\% improve_point: 51.06, mse_ref_points: 9.337354967549963e-06, mse_da_points: 4.6360146751084525e-06, % improve_overlap: 51.15, mse_ref_overlap: 0.24287, mse_da_overlap: 0.12033
minCostFunction = 6.0055 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.3812, add (DA)= 0.0002decode = 0.4854 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 6.4912 s, inc stats = 6.5032, 
minCostFunction = 6.3466 s, v_trunc (Latent to Reduced) = 0.1061, dec (Reduced to Full) = 0.2721, add (DA)= 0.0002decode = 0.3786 s, unnorm = 0.0007 s, TOTAL = unnormalising + decoding + minimising = 6.7258 s, inc stats = 6.7413, 
minCostFunction = 4.0960 s, v_trunc (Latent to Reduced) = 0.1806, dec (Reduced to Full) = 0.9625, add (DA)= 0.0001decode = 1.1432 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2394 s, inc stats = 5.2490, 
minCostFunction = 4.7224 s, v_trunc (Latent to Reduced) = 0.1444, dec (Reduced to Full) = 1.0542, add (DA)= 0.0002decode = 1.1988 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.9214 s, inc stats = 5.9263, 
minCostFunction = 5.7749 s, v_trunc (Latent to Reduced) = 0.1144, dec (Reduced to Full) = 0.3572, add (DA)= 0.0002decode = 0.4719 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.2470 s, inc stats = 6.2566, 
minCostFunction = 4.8435 s, v_trunc (Latent to Reduced) = 0.1183, dec (Reduced to Full) = 0.5857, add (DA)= 0.0002decode = 0.7042 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.5479 s, inc stats = 5.5529, 
minCostFunction = 5.9322 s, v_trunc (Latent to Reduced) = 0.1494, dec (Reduced to Full) = 0.3363, add (DA)= 0.0002decode = 0.4859 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.4183 s, inc stats = 6.4346, 
minCostFunction = 4.8927 s, v_trunc (Latent to Reduced) = 0.1484, dec (Reduced to Full) = 0.4499, add (DA)= 0.0003decode = 0.5987 s, unnorm = 0.0006 s, TOTAL = unnormalising + decoding + minimising = 5.4919 s, inc stats = 5.4973, 
minCostFunction = 5.3895 s, v_trunc (Latent to Reduced) = 0.1532, dec (Reduced to Full) = 0.2509, add (DA)= 0.0002decode = 0.4043 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.7940 s, inc stats = 5.8044, 
minCostFunction = 5.5422 s, v_trunc (Latent to Reduced) = 0.1657, dec (Reduced to Full) = 0.6275, add (DA)= 0.0001decode = 0.7935 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.3358 s, inc stats = 6.3409, 
DA - - L2: 31704.00, L1: 6180.27, % Improve: 58.94%, DA_MAE: 0.00, mse_ref: 0.25, mse_DA: 0.120, time(s): 6.7651s,
\% improve_point: 51.91, mse_ref_points: 9.469048767158467e-06, mse_da_points: 4.602953110117671e-06, % improve_overlap: 52.01, mse_ref_overlap: 0.24630, mse_da_overlap: 0.11945
minCostFunction = 5.4847 s, v_trunc (Latent to Reduced) = 0.1495, dec (Reduced to Full) = 0.9950, add (DA)= 0.0001decode = 1.1447 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.6295 s, inc stats = 6.6382, 
minCostFunction = 4.5180 s, v_trunc (Latent to Reduced) = 0.1607, dec (Reduced to Full) = 0.9700, add (DA)= 0.0002decode = 1.1309 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6490 s, inc stats = 5.6603, 
minCostFunction = 4.3710 s, v_trunc (Latent to Reduced) = 0.1535, dec (Reduced to Full) = 0.7212, add (DA)= 0.0003decode = 0.8751 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.2465 s, inc stats = 5.2560, 
minCostFunction = 4.5605 s, v_trunc (Latent to Reduced) = 0.1420, dec (Reduced to Full) = 1.3560, add (DA)= 0.0002decode = 1.4982 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.0588 s, inc stats = 6.0675, 
minCostFunction = 4.8578 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.2531, add (DA)= 0.0001decode = 0.3569 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2148 s, inc stats = 5.2225, 
minCostFunction = 4.5382 s, v_trunc (Latent to Reduced) = 0.1224, dec (Reduced to Full) = 0.9016, add (DA)= 0.0002decode = 1.0243 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.5627 s, inc stats = 5.5701, 
DA - - L2: 30031.64, L1: 6092.58, % Improve: 59.23%, DA_MAE: 0.00, mse_ref: 0.25, mse_DA: 0.120, time(s): 6.7075s,
\% improve_point: 52.33, mse_ref_points: 9.545959776422533e-06, mse_da_points: 4.5919326099759565e-06, % improve_overlap: 52.43, mse_ref_overlap: 0.24830, mse_da_overlap: 0.11917
Results of DA at 2020-08-27 14:39:33.098327. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              80.531052      0.001691  ...  72.205928     9.762681
1              77.045400      0.001697  ...   5.527791     5.513732
2              68.439855      0.001704  ...   5.236849     5.231241
3              67.082202      0.001711  ...   4.177899     4.171177
4              64.838008      0.001717  ...   4.262023     4.254232
..                   ...           ...  ...        ...          ...
102            63.913646      0.002206  ...   5.662516     5.649018
103            63.925429      0.002198  ...   5.258141     5.246509
104            63.930331      0.002188  ...   6.069762     6.058830
105            64.225224      0.002178  ...   5.224744     5.214814
106            65.009622      0.002168  ...   5.574465     5.562714

[107 rows x 20 columns]
------------------------- Ended at 2020-08-27 14:39:34.309818 -------------------- 

