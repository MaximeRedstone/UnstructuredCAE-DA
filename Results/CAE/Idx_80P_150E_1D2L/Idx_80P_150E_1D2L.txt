Path ['/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/mredstone/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/', '/Users/maxime/IndividualProject/code/Data_Assimilation/src/']

------------------------- Simulation Started at 2020-08-29 15:16:51.808700 ------------------- 

data fp  /home/mredstone/unstructuredCAE/data/subdomain_8/
domain, other, pickle, dim 8 ['6'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_80P_150E_1D2L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_8/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
91, 85, 32, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
89, 83, 30, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
87, 81, 28, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
85, 79, 26, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
83, 77, 24, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
81, 75, 22, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
79, 73, 20, stride=(2, 2, 2, )  kernel_size=(3, 3, 2, )  padding=(0, 1, 1, )  
39, 37, 11, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 1, 0, )  
19, 19, 5, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 1, )  
9, 9, 3, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
5, 5, 2, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
OUT: 3, 3, 1, Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
When creating TucodecEncode1D, inputSize =  16206 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
Number of parameters: 17442127
------------------------------ Training subdomain 8 at 2020-08-29 15:16:57.198995. ------------------------------
Loading data started 2020-08-29 15:16:57.199100
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (16206,) and std (16206,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fed57014240>
Loading data finished 2020-08-29 15:17:05.356394
Loop AE Train begins at  15:17:05.359712
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [1/150], TRAIN: -loss:15712.59, av_diff: 0.94, time taken (m): 0.01m
epoch [1/150], TEST: -loss:15663.6870, time taken(m): 0.00m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [6/150], TRAIN: -loss:4064.53, av_diff: 0.14, time taken (m): 0.01m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [11/150], TRAIN: -loss:1183.85, av_diff: 0.01, time taken (m): 0.01m
epoch [11/150], TEST: -loss:6117.0056, time taken(m): 0.00m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [16/150], TRAIN: -loss:632.56, av_diff: 0.01, time taken (m): 0.01m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [21/150], TRAIN: -loss:574.98, av_diff: 0.02, time taken (m): 0.01m
epoch [21/150], TEST: -loss:1804.6925, time taken(m): 0.00m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [26/150], TRAIN: -loss:466.08, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [31/150], TRAIN: -loss:457.67, av_diff: 0.01, time taken (m): 0.02m
epoch [31/150], TEST: -loss:953.7088, time taken(m): 0.01m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [36/150], TRAIN: -loss:505.62, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [41/150], TRAIN: -loss:404.54, av_diff: 0.01, time taken (m): 0.02m
epoch [41/150], TEST: -loss:882.1405, time taken(m): 0.01m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [46/150], TRAIN: -loss:444.93, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [51/150], TRAIN: -loss:419.18, av_diff: 0.01, time taken (m): 0.02m
epoch [51/150], TEST: -loss:1041.2018, time taken(m): 0.01m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [56/150], TRAIN: -loss:362.53, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [61/150], TRAIN: -loss:383.27, av_diff: 0.01, time taken (m): 0.02m
epoch [61/150], TEST: -loss:832.5477, time taken(m): 0.01m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [66/150], TRAIN: -loss:366.79, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [71/150], TRAIN: -loss:411.74, av_diff: 0.01, time taken (m): 0.02m
epoch [71/150], TEST: -loss:1050.0387, time taken(m): 0.01m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [76/150], TRAIN: -loss:503.12, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [81/150], TRAIN: -loss:339.07, av_diff: 0.01, time taken (m): 0.02m
epoch [81/150], TEST: -loss:1011.7858, time taken(m): 0.01m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [86/150], TRAIN: -loss:430.16, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [91/150], TRAIN: -loss:340.86, av_diff: 0.00, time taken (m): 0.02m
epoch [91/150], TEST: -loss:960.8649, time taken(m): 0.01m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [96/150], TRAIN: -loss:356.76, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [101/150], TRAIN: -loss:398.25, av_diff: 0.01, time taken (m): 0.02m
epoch [101/150], TEST: -loss:1031.0496, time taken(m): 0.01m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [106/150], TRAIN: -loss:374.71, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [111/150], TRAIN: -loss:324.43, av_diff: 0.00, time taken (m): 0.02m
epoch [111/150], TEST: -loss:929.1248, time taken(m): 0.01m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [116/150], TRAIN: -loss:405.87, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [121/150], TRAIN: -loss:380.64, av_diff: 0.01, time taken (m): 0.02m
epoch [121/150], TEST: -loss:1102.6485, time taken(m): 0.01m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [126/150], TRAIN: -loss:324.74, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [131/150], TRAIN: -loss:403.94, av_diff: 0.01, time taken (m): 0.02m
epoch [131/150], TEST: -loss:862.3754, time taken(m): 0.01m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [136/150], TRAIN: -loss:378.63, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [141/150], TRAIN: -loss:398.11, av_diff: 0.01, time taken (m): 0.02m
epoch [141/150], TEST: -loss:1069.9879, time taken(m): 0.01m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [146/150], TRAIN: -loss:357.52, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [150/150], TRAIN: -loss:347.26, av_diff: 0.00, time taken (m): 0.02m
epoch [150/150], TEST: -loss:828.9996, time taken(m): 0.01m
Loop AE Train Ends at  15:20:26.301060
------------------------------ DA subdomain 8 at 2020-08-29 15:20:26.412454. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (16206,) and std (16206,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 16206) , test_X = (107, 16206), X = (537, 16206)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (16206,) and std (16206,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
u_c before reduction of space:  [-1.07445013 -1.39747826 -1.43522087 -1.09659915 -1.96876959 -1.61903685
 -2.75738126 -1.9394162  -1.47525387 -1.19151468]
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
u_c taken from control states: [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
u_c before reduction of space:  [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
data[u_c] post encoding of state:  [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
Shape of w_0 =  (429,)
J_b = 0.0, J_o = 13170.130033154976
J_b = 0.5, J_o = 835982.2141284298
J_b = 0.00616784545105773, J_o = 121.68149928840322
J_b = 0.006169295982088766, J_o = 119.64836172873672
J_b = 0.006184768313086449, J_o = 111.76887042931212
J_b = 0.006401380947053868, J_o = 84.2998482594767
J_b = 0.012179905175122747, J_o = 9.327454380800264
J_b = 0.01368494129997612, J_o = 6.247656940960995
J_b = 0.01404184682838988, J_o = 5.440322249740964
J_b = 0.014952471873525906, J_o = 3.8133695874788067
J_b = 0.01635642327045189, J_o = 2.6225862566797797
J_b = 0.018596654958029993, J_o = 1.4607185532282674
J_b = 0.02089547306470625, J_o = 0.9478343595853105
J_b = 0.02201660131550536, J_o = 0.7794216279735504
J_b = 0.022727310913324018, J_o = 0.6945778363489321
J_b = 0.023206236661596318, J_o = 0.6213612981729728
J_b = 0.024565387966584504, J_o = 0.4948821179659896
J_b = 0.027432633299912523, J_o = 40.125347451030805
J_b = 0.02457187123529275, J_o = 0.4945864208606071
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
W_opt:  [-0.04693481 -0.04569607 -0.04457104 -0.04344589 -0.04228585 -0.04118455
 -0.04029149 -0.03954647 -0.0388994  -0.03830928]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1128 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1268, add (DA)= 0.0001decode = 0.1300 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2429 s, inc stats = 19.6254, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.59058452e-10 6.69536597e-10 7.99956401e-10 2.09955496e-10
 2.89497888e-09]
u_DA:    [2.55440021e-09 4.77423989e-09 6.51513436e-09 3.61146357e-09
 8.77824880e-09]
ref_MAE: [6.83736854e-09 9.82215903e-09 1.22599765e-08 8.33420675e-09
 1.75690108e-08]
da_MAE:  [2.39534176e-09 4.10470329e-09 5.71517795e-09 3.40150807e-09
 5.88326992e-09]
% 9.814793786023243 da_MAE 0.07113964844110633 ref_MAE 0.07888172731159229
u_c taken from control states: [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
u_c before reduction of space:  [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
data[u_c] post encoding of state:  [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
J_b = 0.0, J_o = 13172.751099609046
J_b = 0.5, J_o = 835952.9559952085
J_b = 0.006169545159827946, J_o = 120.69889011662116
J_b = 0.006170985043973946, J_o = 118.68072217735627
J_b = 0.006186343808197955, J_o = 110.86020447504606
J_b = 0.00640136650733404, J_o = 83.6125985417998
J_b = 0.012090893973189265, J_o = 9.452026242997206
J_b = 0.013624515938303031, J_o = 6.295326822794633
J_b = 0.01396779457502945, J_o = 5.502774217998732
J_b = 0.014834098924870922, J_o = 3.9249540388738566
J_b = 0.016170040619862807, J_o = 2.7502799779981766
J_b = 0.018546558565911, J_o = 1.5169576144526353
J_b = 0.020803661174608218, J_o = 1.001712378395818
J_b = 0.022043756135241985, J_o = 0.808147015706472
J_b = 0.022994717194646387, J_o = 0.6922548876555059
J_b = 0.023872170414531407, J_o = 0.5963636125211014
J_b = 0.02517857764530493, J_o = 0.5049835242066865
J_b = 0.027207241302782872, J_o = 9.969992431714198
J_b = 0.02519332472482693, J_o = 0.5042912235958074
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
W_opt:  [-0.04771536 -0.04645487 -0.04530103 -0.0441386  -0.0429355  -0.0417941
 -0.04087399 -0.040111   -0.03945113 -0.03885047]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0579 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1211, add (DA)= 0.0001decode = 0.1240 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1820 s, inc stats = 0.1944, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.55941737e-10 6.62352071e-10 7.92173583e-10 2.07331885e-10
 2.86625852e-09]
u_DA:    [2.55359510e-09 4.77211795e-09 6.51321434e-09 3.61090029e-09
 8.77620375e-09]
ref_MAE: [6.84048526e-09 9.82934355e-09 1.22677594e-08 8.33683036e-09
 1.75977311e-08]
da_MAE:  [2.39765336e-09 4.10976588e-09 5.72104076e-09 3.40356840e-09
 5.90994524e-09]
% 9.884911075217232 da_MAE 0.07108131105269933 ref_MAE 0.07887836754178809
u_c taken from control states: [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
u_c before reduction of space:  [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
data[u_c] post encoding of state:  [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
J_b = 0.0, J_o = 13175.057121459085
J_b = 0.5000000000000002, J_o = 835929.2860798377
J_b = 0.006170925815712708, J_o = 120.07901387609053
J_b = 0.006172358923678341, J_o = 118.07037535630076
J_b = 0.006187645408645012, J_o = 110.28744029651452
J_b = 0.006401656198177957, J_o = 83.18160436733623
J_b = 0.01203284993745788, J_o = 9.548068794396386
J_b = 0.01358643603201283, J_o = 6.335671917334498
J_b = 0.01392117424545534, J_o = 5.552231070864925
J_b = 0.01475898084293049, J_o = 4.00697807608025
J_b = 0.01605234386273143, J_o = 2.8427195461975425
J_b = 0.0185168155400117, J_o = 1.5622606438642457
J_b = 0.02076418472937307, J_o = 1.0428218330093695
J_b = 0.022090161101718422, J_o = 0.8350267669293001
J_b = 0.023139169469735477, J_o = 0.6932479676822029
J_b = 0.024751950561220374, J_o = 0.5509255455272922
J_b = 0.026365882822248093, J_o = 0.4866293479102365
J_b = 0.02710590610415482, J_o = 2.0809036166139423
J_b = 0.026386965795298374, J_o = 0.48503107620027686
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
W_opt:  [-0.0492574  -0.04795438 -0.04674255 -0.04550169 -0.04420444 -0.04297278
 -0.04198979 -0.04118308 -0.04049032 -0.03986137]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0498 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1210, add (DA)= 0.0001decode = 0.1240 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1739 s, inc stats = 0.1812, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.53005788e-10 6.54985772e-10 7.84201925e-10 2.04950663e-10
 2.83767774e-09]
u_DA:    [2.55192845e-09 4.76786023e-09 6.50992333e-09 3.60881959e-09
 8.77121341e-09]
ref_MAE: [6.84342121e-09 9.83670985e-09 1.22757310e-08 8.33921158e-09
 1.76263119e-08]
da_MAE:  [2.39892266e-09 4.11287446e-09 5.72572141e-09 3.40386893e-09
 5.93353566e-09]
% 9.966589982179197 da_MAE 0.07110533404478188 ref_MAE 0.07897660882855333
u_c taken from control states: [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
u_c before reduction of space:  [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
data[u_c] post encoding of state:  [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
J_b = 0.0, J_o = 13177.030797937077
J_b = 0.4999999999999999, J_o = 835913.3442823507
J_b = 0.006171867513508843, J_o = 120.06020659092104
J_b = 0.00617330046007275, J_o = 118.05180204240517
J_b = 0.006188585223421103, J_o = 110.26993037016507
J_b = 0.006402571910298134, J_o = 83.17038803037977
J_b = 0.012025694085354017, J_o = 9.58612163146579
J_b = 0.013585861441790312, J_o = 6.356831388969162
J_b = 0.013918586403702431, J_o = 5.575433588043141
J_b = 0.014748590969543564, J_o = 4.039078185414258
J_b = 0.01603137076952625, J_o = 2.8764695997626797
J_b = 0.01852476656004266, J_o = 1.5808253932186678
J_b = 0.02077214384424544, J_o = 1.0594541360330625
J_b = 0.022123938994405016, J_o = 0.8482175417840387
J_b = 0.023180168899453974, J_o = 0.7046931521226879
J_b = 0.02482220179637207, J_o = 0.5746803979036018
J_b = 0.025923372007278494, J_o = 0.502160927119306
J_b = 0.02651278646721254, J_o = 2.482017876871971
J_b = 0.025933868178455183, J_o = 0.5013542343221984
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
W_opt:  [-0.04857816 -0.04730319 -0.04611949 -0.04491259 -0.04365545 -0.04246312
 -0.04150974 -0.04072571 -0.04005138 -0.03943861]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0580 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.1377, add (DA)= 0.0001decode = 0.1412 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1993 s, inc stats = 0.2132, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.50259704e-10 6.47469651e-10 7.76012997e-10 2.02794545e-10
 2.80926541e-09]
u_DA:    [2.55207846e-09 4.76925794e-09 6.51087905e-09 3.60953806e-09
 8.77238825e-09]
ref_MAE: [6.84616729e-09 9.84422597e-09 1.22839199e-08 8.34136770e-09
 1.76547243e-08]
da_MAE:  [2.40181875e-09 4.12178829e-09 5.73486605e-09 3.40674352e-09
 5.96312284e-09]
% 10.057513769861743 da_MAE 0.07120058651627251 ref_MAE 0.07916235085395533
u_c taken from control states: [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
u_c before reduction of space:  [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
data[u_c] post encoding of state:  [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
J_b = 0.0, J_o = 13178.291594635753
J_b = 0.5, J_o = 835912.49264195
J_b = 0.006171949898159934, J_o = 121.15534233098441
J_b = 0.006173395002405944, J_o = 119.12986011622627
J_b = 0.006188809447696734, J_o = 111.28103531074379
J_b = 0.006404611681767877, J_o = 83.93540094561757
J_b = 0.012113295220833304, J_o = 9.510299889197299
J_b = 0.01365483127439002, J_o = 6.338464124996193
J_b = 0.013997305659614958, J_o = 5.546493176268643
J_b = 0.014856834655874781, J_o = 3.9757823609684984
J_b = 0.016186548949181367, J_o = 2.7985753788413756
J_b = 0.018603059537149386, J_o = 1.5457785669626096
J_b = 0.02085744491741741, J_o = 1.02894174961699
J_b = 0.022122772424963168, J_o = 0.8307959069076759
J_b = 0.0231144889287582, J_o = 0.704190858740509
J_b = 0.024244964484398873, J_o = 0.5897252643962128
J_b = 0.025783047225409746, J_o = 0.5061970793995176
J_b = 0.027151584555342893, J_o = 4.359639951046346
J_b = 0.025801314945317434, J_o = 0.5053118754134466
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
W_opt:  [-0.04832086 -0.04706927 -0.04590725 -0.04472457 -0.0434944  -0.04232719
 -0.04139179 -0.04062031 -0.03995482 -0.0393485 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0766 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1247 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2014 s, inc stats = 0.2097, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.47725615e-10 6.39834920e-10 7.67606400e-10 2.00845392e-10
 2.78106495e-09]
u_DA:    [2.55410156e-09 4.77155171e-09 6.51304669e-09 3.61018346e-09
 8.77687997e-09]
ref_MAE: [6.84870138e-09 9.85186070e-09 1.22923265e-08 8.34331685e-09
 1.76829247e-08]
da_MAE:  [2.40637595e-09 4.13171679e-09 5.74544029e-09 3.40933806e-09
 5.99581502e-09]
% 10.115165752702149 da_MAE 0.07134993775805808 ref_MAE 0.07937928389760926
u_c taken from control states: [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
u_c before reduction of space:  [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
data[u_c] post encoding of state:  [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
J_b = 0.0, J_o = 13178.683218392305
J_b = 0.5000000000000002, J_o = 835926.5835908981
J_b = 0.006171176946279177, J_o = 123.19836619579618
J_b = 0.0061726446285739435, J_o = 121.14116322321863
J_b = 0.006188299906384753, J_o = 113.16785879028231
J_b = 0.00640747379573569, J_o = 85.36276037652152
J_b = 0.012281417936148332, J_o = 9.348940403702407
J_b = 0.013782166213969951, J_o = 6.290909197696168
J_b = 0.014146782184921422, J_o = 5.4746600273770145
J_b = 0.0150746499380651, J_o = 3.827968345793612
J_b = 0.016513592289008387, J_o = 2.621610605567085
J_b = 0.018733447878190087, J_o = 1.4727956272476286
J_b = 0.02105638957748097, J_o = 0.9591241586574031
J_b = 0.022140089334584424, J_o = 0.7978945956333333
J_b = 0.022785937448912354, J_o = 0.7179899457193674
J_b = 0.023266994695632814, J_o = 0.6425449743160079
J_b = 0.02464309374849666, J_o = 0.5119301698789341
J_b = 0.027337335889260263, J_o = 42.89996780063149
J_b = 0.02464842099509142, J_o = 0.5116925688114905
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
W_opt:  [-0.04663931 -0.04545158 -0.04435881 -0.04325908 -0.04212338 -0.04104526
 -0.04017326 -0.03944666 -0.03881457 -0.0382356 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0599 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1332, add (DA)= 0.0001decode = 0.1361 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1961 s, inc stats = 0.2006, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.45414566e-10 6.32167219e-10 7.58993678e-10 1.99061453e-10
 2.75311061e-09]
u_DA:    [2.55458842e-09 4.77411534e-09 6.51584606e-09 3.61122627e-09
 8.77865999e-09]
ref_MAE: [6.85101243e-09 9.85952840e-09 1.23009393e-08 8.34510079e-09
 1.77108791e-08]
da_MAE:  [2.40917385e-09 4.14194812e-09 5.75685238e-09 3.41216481e-09
 6.02554939e-09]
% 10.123028955200265 da_MAE 0.07149340643512159 ref_MAE 0.0795458565236753
u_c taken from control states: [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
u_c before reduction of space:  [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
data[u_c] post encoding of state:  [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
J_b = 0.0, J_o = 13178.60266550022
J_b = 0.5, J_o = 835947.7360121589
J_b = 0.006169999236342214, J_o = 125.62828141628054
J_b = 0.006171493315708846, J_o = 123.53398859152992
J_b = 0.006187430162286263, J_o = 115.41506045010708
J_b = 0.006410546014370222, J_o = 87.07123840569095
J_b = 0.012482927470569605, J_o = 9.179776172478192
J_b = 0.013932454583791037, J_o = 6.248440100843413
J_b = 0.014328822544706679, J_o = 5.396156061682806
J_b = 0.015351068529907877, J_o = 3.6518682583592437
J_b = 0.016940707066892158, J_o = 2.4117455021293592
J_b = 0.018872547145460574, J_o = 1.4076344993169392
J_b = 0.021282527410379184, J_o = 0.9152923887505591
J_b = 0.02203814637860851, J_o = 0.7747731538795423
J_b = 0.02246643726665723, J_o = 0.7023104107752378
J_b = 0.02307119374415127, J_o = 0.6057825399225905
J_b = 0.02451416070407817, J_o = 0.48308108054861154
J_b = 0.02661770936806749, J_o = 11.099266399812233
J_b = 0.0245278061496103, J_o = 0.4824618990106174
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
W_opt:  [-0.04651491 -0.04534576 -0.04426941 -0.04318718 -0.04206978 -0.04100822
 -0.04014851 -0.03943148 -0.03880696 -0.03823429]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0549 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1331, add (DA)= 0.0001decode = 0.1360 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1910 s, inc stats = 0.2047, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.43304370e-10 6.24568914e-10 7.50208833e-10 1.97358192e-10
 2.72543930e-09]
u_DA:    [2.55616733e-09 4.77716832e-09 6.51755460e-09 3.61120615e-09
 8.78166950e-09]
ref_MAE: [6.85312262e-09 9.86712671e-09 1.23097241e-08 8.34680405e-09
 1.77385504e-08]
da_MAE:  [2.41286296e-09 4.15259940e-09 5.76734576e-09 3.41384796e-09
 6.05623021e-09]
% 10.098579759275356 da_MAE 0.07160322394842848 ref_MAE 0.07964637683887532
u_c taken from control states: [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
u_c before reduction of space:  [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
data[u_c] post encoding of state:  [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
J_b = 0.0, J_o = 13177.995631217796
J_b = 0.5000000000000001, J_o = 835976.1384800896
J_b = 0.0061684049940698175, J_o = 128.41542600950112
J_b = 0.006169928910018076, J_o = 126.2792087049412
J_b = 0.006186184013466175, J_o = 117.99563482021085
J_b = 0.0064137554617395886, J_o = 89.04206461743932
J_b = 0.012714262907713136, J_o = 9.022950458613158
J_b = 0.014102724526770118, J_o = 6.222531983331198
J_b = 0.014543117184443068, J_o = 5.3175635818264455
J_b = 0.015683947078611014, J_o = 3.4621654952200895
J_b = 0.017444243141415138, J_o = 2.1912804461880278
J_b = 0.019022661937802773, J_o = 1.3645175158420473
J_b = 0.020948745542646682, J_o = 0.9385203337633599
J_b = 0.02166798289718325, J_o = 0.7831915197519046
J_b = 0.02273359947321648, J_o = 0.6153889547134876
J_b = 0.023610268459492004, J_o = 0.5199706042224596
J_b = 0.024768519055769673, J_o = 0.43996268726829574
J_b = 0.02616548902187469, J_o = 7.1282293203457385
J_b = 0.02477921343271633, J_o = 0.4394153539796013
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
W_opt:  [-0.04695416 -0.04578515 -0.04470605 -0.04361906 -0.04249482 -0.0414262
 -0.04056217 -0.03984356 -0.03921874 -0.03864635]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0653 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1308, add (DA)= 0.0001decode = 0.1339 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1992 s, inc stats = 0.2128, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.41392414e-10 6.17124672e-10 7.41304022e-10 1.95657765e-10
 2.69807043e-09]
u_DA:    [2.55821315e-09 4.78133916e-09 6.51991474e-09 3.61105506e-09
 8.78362439e-09]
ref_MAE: [6.85503458e-09 9.87457095e-09 1.23186289e-08 8.34850448e-09
 1.77659192e-08]
da_MAE:  [2.41682073e-09 4.16421449e-09 5.77861072e-09 3.41539730e-09
 6.08555396e-09]
% 10.055771912841719 da_MAE 0.07163436584955052 ref_MAE 0.07964309369594563
u_c taken from control states: [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
u_c before reduction of space:  [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
data[u_c] post encoding of state:  [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
J_b = 0.0, J_o = 13176.557641341475
J_b = 0.5, J_o = 836014.4923155383
J_b = 0.006166235876699952, J_o = 131.59051761868886
J_b = 0.006167793323494529, J_o = 129.40718390515914
J_b = 0.00618440608930335, J_o = 120.93855126023492
J_b = 0.006416984810626677, J_o = 91.29925602764658
J_b = 0.012977247537884231, J_o = 8.89172356155341
J_b = 0.014294157232596262, J_o = 6.2204607360005575
J_b = 0.01479588593643247, J_o = 5.237041118764402
J_b = 0.016067533571739893, J_o = 3.2754795303027318
J_b = 0.017959280601889484, J_o = 1.9739574413085703
J_b = 0.019208876121929556, J_o = 1.3229027136186682
J_b = 0.02049060751533802, J_o = 0.9826577092257425
J_b = 0.021538277263421696, J_o = 0.7731034746081721
J_b = 0.022446769338680533, J_o = 0.6312251009323147
J_b = 0.02304253135102404, J_o = 0.5633156452821922
J_b = 0.02348469141926098, J_o = 0.5104865323494759
J_b = 0.024632606744265192, J_o = 5.397446660763096
J_b = 0.023499103534349114, J_o = 0.509282343868474
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
W_opt:  [-0.04446941 -0.04337554 -0.04239033 -0.04142145 -0.04043479 -0.03949786
 -0.03872752 -0.03807609 -0.03750288 -0.03697504]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0483 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1352, add (DA)= 0.0001decode = 0.1384 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1868 s, inc stats = 0.1992, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.39685243e-10 6.09896256e-10 7.32366769e-10 1.93899910e-10
 2.67103269e-09]
u_DA:    [2.55935751e-09 4.78758120e-09 6.52561966e-09 3.61399546e-09
 8.78867348e-09]
ref_MAE: [6.85674175e-09 9.88179937e-09 1.23275662e-08 8.35026233e-09
 1.77929570e-08]
da_MAE:  [2.41967226e-09 4.17768494e-09 5.79325289e-09 3.42009555e-09
 6.11764079e-09]
% 9.97880497278935 da_MAE 0.07156478033647241 ref_MAE 0.07949770086349173
u_c taken from control states: [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
u_c before reduction of space:  [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
data[u_c] post encoding of state:  [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
J_b = 0.0, J_o = 13174.185534188118
J_b = 0.5, J_o = 836063.0150514117
J_b = 0.006163477923547495, J_o = 135.07914308692975
J_b = 0.006165071490292379, J_o = 132.8450506949129
J_b = 0.0061820695355711075, J_o = 124.17696606443076
J_b = 0.006420042169473086, J_o = 93.79718654386245
J_b = 0.013267467709861197, J_o = 8.800553145481313
J_b = 0.014502254181111467, J_o = 6.249402952655764
J_b = 0.015089067613610901, J_o = 5.149231661250613
J_b = 0.01647545640679219, J_o = 3.115748829102457
J_b = 0.01840642468393009, J_o = 1.7610507897733423
J_b = 0.01937112217180086, J_o = 1.2678230206807253
J_b = 0.020679370000951842, J_o = 0.9365519118969441
J_b = 0.022051130650973385, J_o = 0.6845803500366279
J_b = 0.023057935070535936, J_o = 0.5780150256350658
J_b = 0.023014903980099803, J_o = 0.5483685677927044
J_b = 0.022990238144625058, J_o = 0.5207826501643068
J_b = 0.02318264303503888, J_o = 0.5515911680352702
J_b = 0.023046757647274253, J_o = 0.5119315474844408
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
W_opt:  [-0.04350289 -0.04244335 -0.04149852 -0.04057656 -0.03964198 -0.0387555
 -0.03802461 -0.03740612 -0.03686186 -0.03636146]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0472 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1320, add (DA)= 0.0001decode = 0.1349 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1822 s, inc stats = 0.1876, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.38163792e-10 6.02968365e-10 7.23469436e-10 1.91990355e-10
 2.64435435e-09]
u_DA:    [2.56388610e-09 4.79401621e-09 6.53045020e-09 3.61569064e-09
 8.79687962e-09]
ref_MAE: [6.85826320e-09 9.88872726e-09 1.23364635e-08 8.35217189e-09
 1.78196353e-08]
da_MAE:  [2.42572230e-09 4.19104784e-09 5.80698077e-09 3.42370029e-09
 6.15252526e-09]
% 9.840731901607256 da_MAE 0.07145938692336808 ref_MAE 0.07925905836478499
u_c taken from control states: [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
u_c before reduction of space:  [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
data[u_c] post encoding of state:  [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
J_b = 0.0, J_o = 13171.508172991194
J_b = 0.5000000000000001, J_o = 836115.5861320845
J_b = 0.0061604889119548705, J_o = 138.75228037255107
J_b = 0.0061621198807309124, J_o = 136.46562632039735
J_b = 0.006179516881008702, J_o = 127.59097451324567
J_b = 0.006423074884897581, J_o = 96.44379770804697
J_b = 0.013572480794586386, J_o = 8.767220346322324
J_b = 0.014719690529229605, J_o = 6.314659403206888
J_b = 0.015419821075663864, J_o = 5.048146664758544
J_b = 0.016888295445982388, J_o = 2.9884960080493963
J_b = 0.01881054625306696, J_o = 1.6003493972702343
J_b = 0.019654475102682045, J_o = 1.2773253814122225
J_b = 0.02018360102770193, J_o = 1.0834668456413408
J_b = 0.021597864197190498, J_o = 0.7450354284745051
J_b = 0.02308021714235585, J_o = 0.5328306046051128
J_b = 0.023670904038116117, J_o = 0.47010141013784146
J_b = 0.02371194222009938, J_o = 0.4460435108666904
J_b = 0.024131504696320385, J_o = 1.322015913798473
J_b = 0.023728949246334438, J_o = 0.44384035859841753
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
W_opt:  [-0.04458635 -0.04349806 -0.0425253  -0.04157196 -0.04060183 -0.03968255
 -0.03893008 -0.03829983 -0.03774961 -0.03724661]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0566 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1219, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1815 s, inc stats = 0.1874, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.36775465e-10 5.96407949e-10 7.14679933e-10 1.89822694e-10
 2.61805933e-09]
u_DA:    [2.56209283e-09 4.79664980e-09 6.53095495e-09 3.61266978e-09
 8.79767332e-09]
ref_MAE: [6.85965153e-09 9.89528767e-09 1.23452530e-08 8.35433955e-09
 1.78459303e-08]
da_MAE:  [2.42531736e-09 4.20024185e-09 5.81627501e-09 3.42284708e-09
 6.17961398e-09]
% 9.691412788234754 da_MAE 0.0714158111910653 ref_MAE 0.07907975686033251
\% improve_point: 9.55, mse_ref_points: 1.0621773324976533e-05, mse_da_points: 9.60741187836669e-06, % improve_overlap: 10.39, mse_ref_overlap: 0.16551, mse_da_overlap: 0.14832
DA - - L2: 265.12, L1: 902.66, % Improve: 9.97%, DA_MAE: 0.07, mse_ref: 0.17, mse_DA: 0.156, time(s): 2.1854s,
u_c taken from control states: [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
u_c before reduction of space:  [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
data[u_c] post encoding of state:  [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
J_b = 0.0, J_o = 13168.405999258008
J_b = 0.5000000000000001, J_o = 836175.7217563206
J_b = 0.0061570717219740275, J_o = 142.9093638970839
J_b = 0.006158744111412903, J_o = 140.56449684493427
J_b = 0.006176582932094253, J_o = 131.46098466868213
J_b = 0.006426326421633268, J_o = 99.46223248121623
J_b = 0.013918243749560381, J_o = 8.807142590949478
J_b = 0.014963807066833744, J_o = 6.435656963548958
J_b = 0.015832490131205877, J_o = 4.908596185121551
J_b = 0.017383188671369183, J_o = 2.8573699702729605
J_b = 0.019338036496721132, J_o = 1.738291981175787
J_b = 0.019617085756203915, J_o = 1.3645637716818115
J_b = 0.019789663131010077, J_o = 1.2338898452785516
J_b = 0.020299918369032704, J_o = 1.0426341011738254
J_b = 0.021275803602704917, J_o = 0.8206064311883132
J_b = 0.022949196066601396, J_o = 0.5434886831167268
J_b = 0.02407898635182261, J_o = 0.4113322842815647
J_b = 0.0249394598165791, J_o = 2.095283268787123
J_b = 0.024104708418529713, J_o = 0.40923168966392504
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
W_opt:  [-0.04483685 -0.04373597 -0.04275691 -0.04179879 -0.04082377 -0.03990137
 -0.03914951 -0.03852444 -0.03798228 -0.03748958]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0476 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1373, add (DA)= 0.0001decode = 0.1403 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1880 s, inc stats = 0.2019, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.35478150e-10 5.90242914e-10 7.06081240e-10 1.87308876e-10
 2.59215896e-09]
u_DA:    [2.56583901e-09 4.80209457e-09 6.53603447e-09 3.61378895e-09
 8.80458166e-09]
ref_MAE: [6.86094884e-09 9.90145271e-09 1.23538517e-08 8.35685337e-09
 1.78718307e-08]
da_MAE:  [2.43036086e-09 4.21185165e-09 5.82995323e-09 3.42648007e-09
 6.21242271e-09]
% 9.571103800814344 da_MAE 0.0715541650316721 ref_MAE 0.07912754444559555
u_c taken from control states: [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
u_c before reduction of space:  [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
data[u_c] post encoding of state:  [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
J_b = 0.0, J_o = 13164.914115403726
J_b = 0.49999999999999994, J_o = 836240.0210353733
J_b = 0.006153415562048371, J_o = 147.182591512125
J_b = 0.006155129741079032, J_o = 144.77899013843773
J_b = 0.006173414317406113, J_o = 135.44450562317417
J_b = 0.006429398385985193, J_o = 102.58530323388983
J_b = 0.014274016228511904, J_o = 8.923654170920479
J_b = 0.015213284491403285, J_o = 6.60351579119814
J_b = 0.016314893518863553, J_o = 4.709350208004817
J_b = 0.017992211624717865, J_o = 2.704842175003991
J_b = 0.019934150175241902, J_o = 2.0552361894454743
J_b = 0.019579727548781872, J_o = 1.5617462458074933
J_b = 0.019549661109257238, J_o = 1.4789847184468787
J_b = 0.019838818272254723, J_o = 1.2258083399899529
J_b = 0.020744039117120767, J_o = 0.9540548956763042
J_b = 0.022515203573982172, J_o = 0.6090603371895982
J_b = 0.024250198372035344, J_o = 0.4132349514165664
J_b = 0.025091632753625952, J_o = 0.6330489956623458
J_b = 0.024373032320940822, J_o = 0.4052335079030655
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
W_opt:  [-0.04500443 -0.04389368 -0.04291205 -0.04195308 -0.0409777  -0.04005737
 -0.03931115 -0.03869645 -0.03816766 -0.03769069]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0478 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1363, add (DA)= 0.0001decode = 0.1392 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1871 s, inc stats = 0.2018, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.34226233e-10 5.84489302e-10 6.97753412e-10 1.84363782e-10
 2.56665341e-09]
u_DA:    [2.56386958e-09 4.80596518e-09 6.53819760e-09 3.61169676e-09
 8.80708435e-09]
ref_MAE: [6.86220076e-09 9.90720632e-09 1.23621795e-08 8.35979846e-09
 1.78973362e-08]
da_MAE:  [2.42964335e-09 4.22147588e-09 5.84044418e-09 3.42733298e-09
 6.24043094e-09]
% 9.479177284995588 da_MAE 0.07183116919349786 ref_MAE 0.0793531996716943
u_c taken from control states: [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
u_c before reduction of space:  [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
data[u_c] post encoding of state:  [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
J_b = 0.0, J_o = 13162.36795093934
J_b = 0.5000000000000001, J_o = 836292.1217997291
J_b = 0.006150463593496172, J_o = 150.90753626001285
J_b = 0.006152213751927253, J_o = 148.45336739505427
J_b = 0.006170882108525381, J_o = 138.92003699585558
J_b = 0.006432239100898967, J_o = 105.32023636923074
J_b = 0.014582766950850345, J_o = 9.084477471315777
J_b = 0.01543058268592603, J_o = 6.783090723956848
J_b = 0.016795203385580406, J_o = 4.4826632879257495
J_b = 0.018643796779837934, J_o = 2.6014958325566697
J_b = 0.02004884330397915, J_o = 1.81760513977811
J_b = 0.019765534035683572, J_o = 1.6600778596110632
J_b = 0.019656726804873015, J_o = 1.5285698242605552
J_b = 0.019935866894495086, J_o = 1.2530893070435742
J_b = 0.021099512353202846, J_o = 0.9266408279679778
J_b = 0.02327245052135325, J_o = 0.5413295972336087
J_b = 0.025076199553649346, J_o = 0.36306963604545195
J_b = 0.02577114583680637, J_o = 0.31178609713340455
J_b = 0.027342262512178847, J_o = 1.1277874087913873
J_b = 0.025871942288559758, J_o = 0.3067500737994288
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
W_opt:  [-0.04720211 -0.04602813 -0.04498039 -0.04394334 -0.04287805 -0.0418745
 -0.04107328 -0.04042687 -0.03988011 -0.0393927 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0502 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1384, add (DA)= 0.0001decode = 0.1415 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1919 s, inc stats = 0.1976, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.32963287e-10 5.79138594e-10 6.89758411e-10 1.81044255e-10
 2.54153660e-09]
u_DA:    [2.56859635e-09 4.81282458e-09 6.53883338e-09 3.61270837e-09
 8.81210065e-09]
ref_MAE: [6.86346371e-09 9.91255703e-09 1.23701745e-08 8.36311799e-09
 1.79224531e-08]
da_MAE:  [2.43563307e-09 4.23368599e-09 5.84907497e-09 3.43166411e-09
 6.27056406e-09]
% 9.303940891633118 da_MAE 0.07232902321523345 ref_MAE 0.07974880488336561
u_c taken from control states: [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
u_c before reduction of space:  [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
data[u_c] post encoding of state:  [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
J_b = 0.0, J_o = 13161.442392731433
J_b = 0.5, J_o = 836324.611645954
J_b = 0.006148644671601145, J_o = 153.85020893496534
J_b = 0.006150422839924813, J_o = 151.3566724577457
J_b = 0.00616938996871056, J_o = 141.66851635468015
J_b = 0.006434929771710678, J_o = 107.49172883542705
J_b = 0.014826840644036774, J_o = 9.249369801251843
J_b = 0.01560324226836023, J_o = 6.946766768495363
J_b = 0.017222256015002487, J_o = 4.266639683205241
J_b = 0.01924804634020223, J_o = 2.6022779884579683
J_b = 0.019993542877779453, J_o = 1.8640230092836418
J_b = 0.019936478368268288, J_o = 1.7263728469086321
J_b = 0.020032430276562374, J_o = 1.5636003911539458
J_b = 0.020949696294736475, J_o = 1.1190470028519963
J_b = 0.02261310537808477, J_o = 0.7127565858753517
J_b = 0.02484127966996823, J_o = 0.424900387591685
J_b = 0.025632956874793996, J_o = 0.34780738048229853
J_b = 0.026286052122233398, J_o = 0.9130642911043801
J_b = 0.02567061187166411, J_o = 0.34521020392450874
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
W_opt:  [-0.04667232 -0.04550092 -0.04446616 -0.04344866 -0.04240741 -0.04142792
 -0.04064438 -0.04001197 -0.03947762 -0.03900262]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0904 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1386, add (DA)= 0.0001decode = 0.1417 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2321 s, inc stats = 0.2443, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.31640723e-10 5.74143625e-10 6.82125159e-10 1.77462030e-10
 2.51677784e-09]
u_DA:    [2.57014671e-09 4.81758934e-09 6.54306610e-09 3.61473815e-09
 8.81736695e-09]
ref_MAE: [6.86478627e-09 9.91755200e-09 1.23778078e-08 8.36670021e-09
 1.79472118e-08]
da_MAE:  [2.43850599e-09 4.24344571e-09 5.86094094e-09 3.43727612e-09
 6.30058911e-09]
% 9.134762520751446 da_MAE 0.07296703297979792 ref_MAE 0.0803024732054014
u_c taken from control states: [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
u_c before reduction of space:  [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
data[u_c] post encoding of state:  [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
J_b = 0.0, J_o = 13162.732442264023
J_b = 0.5000000000000001, J_o = 836329.8732670071
J_b = 0.006148395758451927, J_o = 155.67911753978552
J_b = 0.006150191147401214, J_o = 153.16137779512619
J_b = 0.006169341962860255, J_o = 143.37803693511995
J_b = 0.006437453379286837, J_o = 108.84656339319085
J_b = 0.014978917308884118, J_o = 9.364479516329506
J_b = 0.015712932262394504, J_o = 7.05368907075272
J_b = 0.01750423099073617, J_o = 4.118940519836504
J_b = 0.019660218289390297, J_o = 2.6557289421023182
J_b = 0.01999652832576029, J_o = 1.9415403210140025
J_b = 0.020048801126090973, J_o = 1.7699033755649385
J_b = 0.020145702918964108, J_o = 1.6678005472966366
J_b = 0.021117952852544218, J_o = 1.1890412539356716
J_b = 0.02246272077332036, J_o = 0.8246591618784228
J_b = 0.02469030908659843, J_o = 0.4837779641830217
J_b = 0.02559428949298667, J_o = 0.3784183986954325
J_b = 0.026236168358875527, J_o = 1.279469120480011
J_b = 0.02562032050220023, J_o = 0.3764948951975941
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
W_opt:  [-0.04639689 -0.04522583 -0.04419713 -0.04318919 -0.04215977 -0.04119182
 -0.04041609 -0.03978937 -0.03925992 -0.03879   ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1188 s, v_trunc (Latent to Reduced) = 0.0045, dec (Reduced to Full) = 0.1313, add (DA)= 0.0001decode = 0.1381 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2569 s, inc stats = 0.2707, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.30228709e-10 5.69423050e-10 6.74887187e-10 1.73737500e-10
 2.49234533e-09]
u_DA:    [2.57019557e-09 4.81840467e-09 6.54502497e-09 3.61460924e-09
 8.81914561e-09]
ref_MAE: [6.86619828e-09 9.92227257e-09 1.23850458e-08 8.37042474e-09
 1.79716443e-08]
da_MAE:  [2.43996686e-09 4.24898162e-09 5.87013779e-09 3.44087174e-09
 6.32680028e-09]
% 8.998639506450171 da_MAE 0.07354906568018982 ref_MAE 0.08082194077241622
u_c taken from control states: [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
u_c before reduction of space:  [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
data[u_c] post encoding of state:  [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
J_b = 0.0, J_o = 13166.802494607755
J_b = 0.49999999999999994, J_o = 836300.8654080046
J_b = 0.0061501216942053795, J_o = 156.10034822852316
J_b = 0.006151921008011763, J_o = 153.57709462105922
J_b = 0.006171113688613215, J_o = 143.77211975099982
J_b = 0.0064398112170337305, J_o = 109.16085322750195
J_b = 0.015013472477198765, J_o = 9.389841336448084
J_b = 0.015742738434887823, J_o = 7.0738015738220295
J_b = 0.017553765922253228, J_o = 4.108164404283692
J_b = 0.01972697021210537, J_o = 2.6753701750100163
J_b = 0.020015565163384815, J_o = 1.9587723829532395
J_b = 0.02008421753724331, J_o = 1.7799943901630955
J_b = 0.02018409799777935, J_o = 1.6804838458142135
J_b = 0.02118994351811712, J_o = 1.1906991543882748
J_b = 0.02253905820732401, J_o = 0.8237268113388857
J_b = 0.024790889914596836, J_o = 0.48243690275232776
J_b = 0.02566258390424391, J_o = 0.3783258253323377
J_b = 0.026359603158168664, J_o = 1.60499987544559
J_b = 0.0256850173010871, J_o = 0.37669437272853534
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
W_opt:  [-0.04642584 -0.04525169 -0.04422051 -0.04321091 -0.04217995 -0.04120955
 -0.04042936 -0.03979672 -0.03926075 -0.03878413]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0584 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1334, add (DA)= 0.0001decode = 0.1359 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1943 s, inc stats = 0.2010, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.28715834e-10 5.64869274e-10 6.68072611e-10 1.69995865e-10
 2.46819887e-09]
u_DA:    [2.56988660e-09 4.81785804e-09 6.54483699e-09 3.61439945e-09
 8.81844480e-09]
ref_MAE: [6.86771116e-09 9.92682635e-09 1.23918603e-08 8.37416638e-09
 1.79957908e-08]
da_MAE:  [2.44117076e-09 4.25298876e-09 5.87676438e-09 3.44440358e-09
 6.35024593e-09]
% 8.941420318472954 da_MAE 0.07397201101251492 ref_MAE 0.08123563015284055
u_c taken from control states: [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
u_c before reduction of space:  [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
data[u_c] post encoding of state:  [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
J_b = 0.0, J_o = 13173.409340066068
J_b = 0.4999999999999998, J_o = 836240.5667165213
J_b = 0.006153651579712253, J_o = 155.23306202016306
J_b = 0.006155442642150234, J_o = 152.72141015699358
J_b = 0.00617454730815538, J_o = 142.9621569853972
J_b = 0.006442012632227483, J_o = 108.52281279631639
J_b = 0.014940290796491475, J_o = 9.331036898364736
J_b = 0.01569945199745198, J_o = 7.013958889082675
J_b = 0.017386531410823056, J_o = 4.231822260428214
J_b = 0.01945834138429524, J_o = 2.6554485977977116
J_b = 0.02002924633617715, J_o = 1.9226612210882388
J_b = 0.020049035403180693, J_o = 1.7606572555505378
J_b = 0.020151236982407787, J_o = 1.6369912502936006
J_b = 0.02106546535172824, J_o = 1.1846279861415425
J_b = 0.022491883956643064, J_o = 0.8094594140522315
J_b = 0.024644395498233617, J_o = 0.4877671825694763
J_b = 0.025517853587325445, J_o = 0.3902527228552113
J_b = 0.02608898876180729, J_o = 0.8155556950182791
J_b = 0.02556013444255545, J_o = 0.3869788541074375
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
W_opt:  [-0.04619694 -0.04503125 -0.04400696 -0.04300623 -0.04198564 -0.04102278
 -0.04024279 -0.03960409 -0.03905857 -0.03857041]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0967 s, v_trunc (Latent to Reduced) = 0.0025, dec (Reduced to Full) = 0.1421, add (DA)= 0.0001decode = 0.1463 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2432 s, inc stats = 0.2581, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.27100270e-10 5.60369945e-10 6.61671363e-10 1.66367653e-10
 2.44430185e-09]
u_DA:    [2.56934194e-09 4.81602979e-09 6.54407061e-09 3.61458789e-09
 8.81647899e-09]
ref_MAE: [6.86932672e-09 9.93132568e-09 1.23982616e-08 8.37779459e-09
 1.80196878e-08]
da_MAE:  [2.44224167e-09 4.25565984e-09 5.88239925e-09 3.44822024e-09
 6.37217714e-09]
% 8.95489095207743 da_MAE 0.07421836096054338 ref_MAE 0.08151822952013572
u_c taken from control states: [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
u_c before reduction of space:  [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
data[u_c] post encoding of state:  [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
J_b = 0.0, J_o = 13180.662232769304
J_b = 0.5000000000000001, J_o = 836171.0810374893
J_b = 0.006157709405072376, J_o = 153.89159019768442
J_b = 0.006159487630111787, J_o = 151.39798604470025
J_b = 0.006178455363865506, J_o = 141.7098124982988
J_b = 0.006444003636417653, J_o = 107.53700736125829
J_b = 0.014827183868903736, J_o = 9.251637775016206
J_b = 0.015628890520423735, J_o = 6.9322782473283695
J_b = 0.01715592928600957, J_o = 4.389617567460236
J_b = 0.019101940763667724, J_o = 2.6578217505648993
J_b = 0.02007201084297277, J_o = 1.874473359638153
J_b = 0.019994018766473325, J_o = 1.7337962117020034
J_b = 0.020125039642292508, J_o = 1.5125704469747436
J_b = 0.021228073678991325, J_o = 1.041797555002561
J_b = 0.023199065122938272, J_o = 0.6226132039827954
J_b = 0.025255146937975346, J_o = 0.38495367353137955
J_b = 0.026190014039577512, J_o = 0.31646847506954334
J_b = 0.026739264450805277, J_o = 0.27616372576796433
J_b = 0.027933403289445557, J_o = 0.409510555359063
J_b = 0.026977305213326405, J_o = 0.26298431815578593
J_b = 0.02707422314630202, J_o = 0.24704611909220825
J_b = 0.02703711348975979, J_o = 0.24285402036862305
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
W_opt:  [-0.04855557 -0.04734168 -0.04624287 -0.04514418 -0.04400402 -0.04292144
 -0.04204873 -0.04133731 -0.04073034 -0.04018545]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0755 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.1308, add (DA)= 0.0001decode = 0.1349 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2104 s, inc stats = 0.2204, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.25412209e-10 5.55815314e-10 6.55672412e-10 1.62987152e-10
 2.42063571e-09]
u_DA:    [2.56922634e-09 4.81155142e-09 6.53560881e-09 3.60939724e-09
 8.80980015e-09]
ref_MAE: [6.87101478e-09 9.93588031e-09 1.24042605e-08 8.38117509e-09
 1.80433540e-08]
da_MAE:  [2.44381413e-09 4.25573611e-09 5.87993639e-09 3.44641009e-09
 6.38916444e-09]
% 8.996951897675064 da_MAE 0.07436695016768484 ref_MAE 0.08171918602557766
u_c taken from control states: [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
u_c before reduction of space:  [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
data[u_c] post encoding of state:  [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
J_b = 0.0, J_o = 13188.32498891346
J_b = 0.5000000000000001, J_o = 836093.3112170828
J_b = 0.006162238979210109, J_o = 151.9576880800804
J_b = 0.006163998450833981, J_o = 149.49044532799172
J_b = 0.0061827661481552556, J_o = 139.90602274959235
J_b = 0.006445513910652901, J_o = 106.12110731527844
J_b = 0.014664585282082518, J_o = 9.160131068724784
J_b = 0.01552341858592878, J_o = 6.83335798074576
J_b = 0.01686295372018922, J_o = 4.5764113300728235
J_b = 0.01866756017262448, J_o = 2.707897157737537
J_b = 0.020140466630133014, J_o = 1.864148239773107
J_b = 0.019904785237946962, J_o = 1.7029130696917556
J_b = 0.019822917282984763, J_o = 1.5451974550231937
J_b = 0.020219808505010445, J_o = 1.2430754889379658
J_b = 0.021575666674505924, J_o = 0.8932274730579752
J_b = 0.023763281554783845, J_o = 0.5413073449741994
J_b = 0.025229978198412484, J_o = 0.39586233156390804
J_b = 0.025926186874054482, J_o = 0.5343346486552081
J_b = 0.025355385660938017, J_o = 0.38737820338129014
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
W_opt:  [-0.04591593 -0.04476885 -0.04375344 -0.04276194 -0.04175106 -0.04079172
 -0.04000289 -0.03934391 -0.03877147 -0.03825215]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1318 s, v_trunc (Latent to Reduced) = 0.0040, dec (Reduced to Full) = 0.1450, add (DA)= 0.0001decode = 0.1509 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2828 s, inc stats = 0.2903, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.23702220e-10 5.51146947e-10 6.50047190e-10 1.59968170e-10
 2.39719159e-09]
u_DA:    [2.56797050e-09 4.80955749e-09 6.54067206e-09 3.61436332e-09
 8.81007747e-09]
ref_MAE: [6.87272477e-09 9.94054868e-09 1.24098858e-08 8.38419407e-09
 1.80667981e-08]
da_MAE:  [2.44426828e-09 4.25841054e-09 5.89062487e-09 3.45439515e-09
 6.41288588e-09]
% 9.033756427959583 da_MAE 0.07438879594791958 ref_MAE 0.0817762644986078
u_c taken from control states: [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
u_c before reduction of space:  [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
data[u_c] post encoding of state:  [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
J_b = 0.0, J_o = 13197.23622980179
J_b = 0.5000000000000002, J_o = 835996.4081617151
J_b = 0.0061678660945538415, J_o = 148.94255393838776
J_b = 0.006169596082389273, J_o = 146.51675456757604
J_b = 0.006188049285967184, J_o = 137.0954066861373
J_b = 0.006446394136057823, J_o = 103.91960878931378
J_b = 0.014410031457415146, J_o = 9.056006531035296
J_b = 0.015355057255747928, J_o = 6.704832667320307
J_b = 0.01646238076914257, J_o = 4.810461925168706
J_b = 0.018103840070052512, J_o = 2.842577350709675
J_b = 0.020103955294611165, J_o = 2.052340348283211
J_b = 0.019785608669721313, J_o = 1.642253538127163
J_b = 0.019743000726575817, J_o = 1.5555603547017807
J_b = 0.020004301203081724, J_o = 1.3007229232295094
J_b = 0.020948813496710145, J_o = 1.0071965504002849
J_b = 0.022791217259302516, J_o = 0.6515146483550854
J_b = 0.024443402625421756, J_o = 0.4669816114580683
J_b = 0.025329068534384797, J_o = 0.9815896485610396
J_b = 0.024509894096012393, J_o = 0.462958979581898
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
W_opt:  [-0.04448018 -0.04338317 -0.04241533 -0.04147746 -0.04052673 -0.03962195
 -0.03886802 -0.03822726 -0.03766298 -0.03714598]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0880 s, v_trunc (Latent to Reduced) = 0.0025, dec (Reduced to Full) = 0.1581, add (DA)= 0.0001decode = 0.1627 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2508 s, inc stats = 0.2580, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.21996737e-10 5.46336076e-10 6.44736978e-10 1.57370604e-10
 2.37397129e-09]
u_DA:    [2.56205670e-09 4.80094019e-09 6.53763998e-09 3.61143483e-09
 8.80229345e-09]
ref_MAE: [6.87443026e-09 9.94535955e-09 1.24151960e-08 8.38679164e-09
 1.80900184e-08]
da_MAE:  [2.44005996e-09 4.25460411e-09 5.89290301e-09 3.45406422e-09
 6.42832216e-09]
% 9.078622936449413 da_MAE 0.07419694459374737 ref_MAE 0.08160561024266771
\% improve_point: 8.23, mse_ref_points: 1.0557733016337815e-05, mse_da_points: 9.687996304976105e-06, % improve_overlap: 9.83, mse_ref_overlap: 0.16421, mse_da_overlap: 0.14807
DA - - L2: 433.06, L1: 1201.27, % Improve: 9.58%, DA_MAE: 0.07, mse_ref: 0.17, mse_DA: 0.157, time(s): 1.2584s,
u_c taken from control states: [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
u_c before reduction of space:  [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
data[u_c] post encoding of state:  [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
J_b = 0.0, J_o = 13205.844156351384
J_b = 0.49999999999999983, J_o = 835902.2908143357
J_b = 0.0061733332120845145, J_o = 145.96263591337936
J_b = 0.00617503373976186, J_o = 143.57824860094806
J_b = 0.006193172701653569, J_o = 134.31988706499905
J_b = 0.00644711816813758, J_o = 101.75344434162065
J_b = 0.014155188684419335, J_o = 9.006755578452854
J_b = 0.015187487448534976, J_o = 6.611355659672499
J_b = 0.016110075175349216, J_o = 5.009575964224824
J_b = 0.01763792517807354, J_o = 3.0077600584872277
J_b = 0.019755725621647884, J_o = 1.9852143070526869
J_b = 0.01981651980700266, J_o = 1.527659512993667
J_b = 0.01989721011485445, J_o = 1.406921144207902
J_b = 0.020338133916220143, J_o = 1.194488217297757
J_b = 0.02133195134441079, J_o = 0.9439123704218794
J_b = 0.023039995383645307, J_o = 0.6353829870719179
J_b = 0.024397600849092923, J_o = 0.4819106121316655
J_b = 0.025215353784041175, J_o = 0.6170896241938196
J_b = 0.0245675732730626, J_o = 0.46880210701095415
J_b = 0.025365490628684192, J_o = 0.4054338089679045
J_b = 0.02573240790224187, J_o = 0.37025210828363664
J_b = 0.026235128031124526, J_o = 0.3312410415980481
J_b = 0.026357814185763724, J_o = 0.321061951308646
J_b = 0.026336135667160077, J_o = 0.31874671422181244
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
W_opt:  [-0.0478777  -0.04670872 -0.04563216 -0.04455311 -0.04343236 -0.04235744
 -0.0414711  -0.04072504 -0.04007181 -0.03947333]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.2099 s, v_trunc (Latent to Reduced) = 0.0027, dec (Reduced to Full) = 0.1214, add (DA)= 0.0001decode = 0.1260 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3360 s, inc stats = 0.3578, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.20323665e-10 5.41365981e-10 6.39698272e-10 1.55219341e-10
 2.35097350e-09]
u_DA:    [2.56458317e-09 4.79676281e-09 6.53006792e-09 3.60749473e-09
 8.79830445e-09]
ref_MAE: [6.87610333e-09 9.95032964e-09 1.24202347e-08 8.38894290e-09
 1.81130162e-08]
da_MAE:  [2.44425951e-09 4.25539683e-09 5.89036964e-09 3.45227539e-09
 6.44733095e-09]
% 9.121941057392338 da_MAE 0.07392322581535837 ref_MAE 0.08134331507019005
u_c taken from control states: [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
u_c before reduction of space:  [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
data[u_c] post encoding of state:  [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
J_b = 0.0, J_o = 13212.846462960068
J_b = 0.5000000000000002, J_o = 835828.2173568069
J_b = 0.006177645432291486, J_o = 143.8262532117247
J_b = 0.0061793245371953385, J_o = 141.4719815945149
J_b = 0.006197234989503107, J_o = 132.33218085537234
J_b = 0.006447981321811947, J_o = 100.2095495739465
J_b = 0.013969703843307112, J_o = 9.013781350754641
J_b = 0.015067354389705292, J_o = 6.571431253744089
J_b = 0.015877857613736814, J_o = 5.145956146642402
J_b = 0.01734292550547759, J_o = 3.13798551994073
J_b = 0.019447196589972248, J_o = 1.772857378622394
J_b = 0.020035310051344624, J_o = 1.4268624758750825
J_b = 0.020296035486083906, J_o = 1.2831749056108088
J_b = 0.021031735629054065, J_o = 1.035095219517013
J_b = 0.02223844374829857, J_o = 0.7862490155291922
J_b = 0.023829599913395307, J_o = 0.581983832805633
J_b = 0.02441890895650701, J_o = 0.5032289135082741
J_b = 0.02498916599131458, J_o = 0.8141535569141202
J_b = 0.0244753000007317, J_o = 0.49852448002573163
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
W_opt:  [-0.04453831 -0.04345747 -0.04249021 -0.04154801 -0.04058985 -0.03967184
 -0.03889755 -0.03822781 -0.03762934 -0.03707408]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1197 s, v_trunc (Latent to Reduced) = 0.0009, dec (Reduced to Full) = 0.1615, add (DA)= 0.0001decode = 0.1642 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2840 s, inc stats = 0.2979, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.18725127e-10 5.36253265e-10 6.34887738e-10 1.53513023e-10
 2.32821264e-09]
u_DA:    [2.56250571e-09 4.79396239e-09 6.53275431e-09 3.61387845e-09
 8.79570887e-09]
ref_MAE: [6.87770187e-09 9.95544236e-09 1.24250452e-08 8.39064922e-09
 1.81357770e-08]
da_MAE:  [2.44378058e-09 4.25770913e-09 5.89786657e-09 3.46036543e-09
 6.46749623e-09]
% 9.14782867021112 da_MAE 0.07373227705022067 ref_MAE 0.08115631797348702
u_c taken from control states: [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
u_c before reduction of space:  [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
data[u_c] post encoding of state:  [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
J_b = 0.0, J_o = 13218.719404072634
J_b = 0.5, J_o = 835768.6451802568
J_b = 0.006181122381474622, J_o = 142.33213962672193
J_b = 0.006182786300385435, J_o = 139.99921811994318
J_b = 0.006200534768767388, J_o = 130.94350795779962
J_b = 0.006449013326114559, J_o = 99.13628114876556
J_b = 0.013837411296681555, J_o = 9.048450087168053
J_b = 0.014983820047457791, J_o = 6.56223406263388
J_b = 0.015723671843060994, J_o = 5.24583967820194
J_b = 0.01714814354702634, J_o = 3.2399886749599203
J_b = 0.019258765011108705, J_o = 1.7517158866420806
J_b = 0.02013838924905697, J_o = 1.4107804761049558
J_b = 0.02055260444869719, J_o = 1.2363354688978698
J_b = 0.021912261160743633, J_o = 0.8675782914143335
J_b = 0.023734779748937236, J_o = 0.6204756814868607
J_b = 0.024496145370875938, J_o = 0.5317456765271276
J_b = 0.024714470598051576, J_o = 0.48347850299636286
J_b = 0.025335259290301983, J_o = 0.7289195159460993
J_b = 0.024801078787239958, J_o = 0.47386170842198266
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
W_opt:  [-0.04517859 -0.04409487 -0.04311075 -0.04214198 -0.04114949 -0.04019556
 -0.03939216 -0.03869719 -0.0380756  -0.03749748]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1417 s, v_trunc (Latent to Reduced) = 0.0018, dec (Reduced to Full) = 0.1594, add (DA)= 0.0001decode = 0.1631 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3048 s, inc stats = 0.3108, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.17241019e-10 5.31065943e-10 6.30249576e-10 1.52236650e-10
 2.30571533e-09]
u_DA:    [2.56351795e-09 4.79052077e-09 6.53008599e-09 3.61326016e-09
 8.79275810e-09]
ref_MAE: [6.87918597e-09 9.96062968e-09 1.24296834e-08 8.39192559e-09
 1.81582743e-08]
da_MAE:  [2.44627693e-09 4.25945483e-09 5.89983642e-09 3.46102351e-09
 6.48704277e-09]
% 9.20369802127318 da_MAE 0.07361634663337027 ref_MAE 0.08107857371836384
u_c taken from control states: [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
u_c before reduction of space:  [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
data[u_c] post encoding of state:  [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
J_b = 0.0, J_o = 13223.269463055363
J_b = 0.5000000000000001, J_o = 835727.749451889
J_b = 0.006183525233079237, J_o = 141.79460177702316
J_b = 0.006185183762878775, J_o = 139.46926446089378
J_b = 0.006202874747407233, J_o = 130.44357871635992
J_b = 0.0064505485308059074, J_o = 98.75145205796488
J_b = 0.013783722288477704, J_o = 9.09019968947593
J_b = 0.014955443733577798, J_o = 6.5771069873681896
J_b = 0.015664400429219332, J_o = 5.307612521264314
J_b = 0.01706957270548533, J_o = 3.3039612766327027
J_b = 0.019194657664517625, J_o = 1.7874240997840605
J_b = 0.020154394420591176, J_o = 1.4212965139638478
J_b = 0.020744426521387464, J_o = 1.207029052366163
J_b = 0.0221261203261677, J_o = 0.8721260370180783
J_b = 0.023674005843730864, J_o = 0.6447812832088771
J_b = 0.024286528682047972, J_o = 0.5772142965887971
J_b = 0.02434185814128034, J_o = 0.5497324998342245
J_b = 0.024828780850322498, J_o = 1.428936353996439
J_b = 0.024364446036014117, J_o = 0.5466597868294168
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
W_opt:  [-0.04418739 -0.04313531 -0.04218714 -0.04126132 -0.04031871 -0.03941311
 -0.03864574 -0.03797704 -0.03737557 -0.03681412]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0614 s, v_trunc (Latent to Reduced) = 0.0035, dec (Reduced to Full) = 0.1283, add (DA)= 0.0001decode = 0.1337 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1952 s, inc stats = 0.2013, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.15905242e-10 5.25890154e-10 6.25733649e-10 1.51332210e-10
 2.28350666e-09]
u_DA:    [2.55832944e-09 4.78755736e-09 6.52910226e-09 3.61122627e-09
 8.78814207e-09]
ref_MAE: [6.88052175e-09 9.96580547e-09 1.24341993e-08 8.39283003e-09
 1.81804830e-08]
da_MAE:  [2.44242420e-09 4.26166721e-09 5.90336861e-09 3.45989406e-09
 6.50463540e-09]
% 9.268907294990713 da_MAE 0.07357213555798392 ref_MAE 0.08108811804701431
u_c taken from control states: [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
u_c before reduction of space:  [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
data[u_c] post encoding of state:  [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
J_b = 0.0, J_o = 13225.658205860436
J_b = 0.5, J_o = 835717.7125148388
J_b = 0.00618415229933867, J_o = 142.86466944357227
J_b = 0.006185822112767577, J_o = 140.52348778298474
J_b = 0.006203633456009247, J_o = 131.4357884070226
J_b = 0.006452992261392601, J_o = 99.51742716538148
J_b = 0.013864363213801563, J_o = 9.112647087191379
J_b = 0.015020786352782646, J_o = 6.611737888204752
J_b = 0.01575533356292808, J_o = 5.303907561697931
J_b = 0.01717496132025666, J_o = 3.2965382393888643
J_b = 0.019315047308372985, J_o = 1.782995903761475
J_b = 0.020233491419469358, J_o = 1.4325813427727878
J_b = 0.02068644671907087, J_o = 1.2481738077109288
J_b = 0.022078917374140288, J_o = 0.8794482130429965
J_b = 0.023851348067260632, J_o = 0.6318097867438693
J_b = 0.024657405714598863, J_o = 0.5277228213924448
J_b = 0.025318150445155806, J_o = 0.45941070918582394
J_b = 0.026046660162627477, J_o = 0.5140791703534132
J_b = 0.025524130785341846, J_o = 0.4442557322996387
J_b = 0.026260249757430004, J_o = 0.3950370682990823
J_b = 0.026630859619180488, J_o = 0.3771234018058583
J_b = 0.02673539983649544, J_o = 0.371475850728561
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
W_opt:  [-0.04797616 -0.04685895 -0.0458038  -0.04473283 -0.04361147 -0.04252702
 -0.04162515 -0.04085394 -0.04016841 -0.03953069]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0747 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.1248, add (DA)= 0.0001decode = 0.1289 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2037 s, inc stats = 0.2138, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.14744936e-10 5.20837858e-10 6.21291542e-10 1.50709221e-10
 2.26161690e-09]
u_DA:    [2.56259585e-09 4.78708569e-09 6.52655188e-09 3.60626019e-09
 8.79094803e-09]
ref_MAE: [6.88168206e-09 9.97085776e-09 1.24386414e-08 8.39345302e-09
 1.82023728e-08]
da_MAE:  [2.44785092e-09 4.26624784e-09 5.90526034e-09 3.45555097e-09
 6.52933113e-09]
% 9.292928532656365 da_MAE 0.07365810985239209 ref_MAE 0.08120437432368267
u_c taken from control states: [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
u_c before reduction of space:  [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
data[u_c] post encoding of state:  [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
J_b = 0.0, J_o = 13226.471706841781
J_b = 0.49999999999999994, J_o = 835730.2179885306
J_b = 0.006183482253307019, J_o = 145.1124436407489
J_b = 0.00618517547425283, J_o = 142.73838098678453
J_b = 0.006203236497674797, J_o = 133.52173564888713
J_b = 0.006456090825582295, J_o = 101.12883874465524
J_b = 0.014043401135813352, J_o = 9.131025268927681
J_b = 0.015154546544712308, J_o = 6.66630972847514
J_b = 0.015961650936697012, J_o = 5.24755958398031
J_b = 0.017420933899747398, J_o = 3.2361737567454014
J_b = 0.019583009624048478, J_o = 1.8174834909801785
J_b = 0.020235501402782206, J_o = 1.4655250905806227
J_b = 0.020514308916501033, J_o = 1.3168351650166104
J_b = 0.021326052884908138, J_o = 1.0480237863293984
J_b = 0.0226258744873407, J_o = 0.7879023096155141
J_b = 0.024129352193557826, J_o = 0.6026677687884147
J_b = 0.024733462077200046, J_o = 0.5265893325345984
J_b = 0.02535609794300164, J_o = 0.6865148814228053
J_b = 0.02483310622998566, J_o = 0.5190573404975654
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
W_opt:  [-0.0446365  -0.04358412 -0.04263224 -0.04170065 -0.04075022 -0.03983686
 -0.03906512 -0.0383946  -0.03779223 -0.03722976]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1320 s, v_trunc (Latent to Reduced) = 0.0073, dec (Reduced to Full) = 0.1618, add (DA)= 0.0001decode = 0.1709 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3030 s, inc stats = 0.3108, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.13760382e-10 5.16041998e-10 6.16855025e-10 1.50287603e-10
 2.24007040e-09]
u_DA:    [2.56247061e-09 4.79299445e-09 6.53242444e-09 3.61412314e-09
 8.79484413e-09]
ref_MAE: [6.88266661e-09 9.97565362e-09 1.24430779e-08 8.39387464e-09
 1.82239193e-08]
da_MAE:  [2.44871023e-09 4.27695245e-09 5.91556942e-09 3.46383554e-09
 6.55477373e-09]
% 9.288762714557631 da_MAE 0.07385632979487192 ref_MAE 0.08141916261429345
u_c taken from control states: [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
u_c before reduction of space:  [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
data[u_c] post encoding of state:  [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
J_b = 0.0, J_o = 13226.57445711393
J_b = 0.49999999999999983, J_o = 835754.019464402
J_b = 0.006182165625976303, J_o = 148.02201704778594
J_b = 0.006183888677380265, J_o = 145.60604554652912
J_b = 0.006202267892355873, J_o = 136.2249389621746
J_b = 0.006459576902014515, J_o = 103.22498335551737
J_b = 0.014278448282120427, J_o = 9.172346089318925
J_b = 0.01532676958048026, J_o = 6.747399188700993
J_b = 0.016247614961873026, J_o = 5.151131201478538
J_b = 0.017767864782588134, J_o = 3.1442479151993927
J_b = 0.019971668511679235, J_o = 2.044170325137565
J_b = 0.020082681282318403, J_o = 1.5886679031250086
J_b = 0.020177068867092363, J_o = 1.4613461259556075
J_b = 0.02064211951302028, J_o = 1.2415632407610455
J_b = 0.021688529406246625, J_o = 0.9806855909571595
J_b = 0.023445686892752254, J_o = 0.6707932075637669
J_b = 0.024731162516866956, J_o = 0.5238346127039497
J_b = 0.025604800179347024, J_o = 0.6506156341620759
J_b = 0.024924287230861177, J_o = 0.5091803318413798
J_b = 0.02576399693487921, J_o = 0.4410757470851996
J_b = 0.02620064180340862, J_o = 0.401413703567458
J_b = 0.026781080862261435, J_o = 0.3598802255586643
J_b = 0.026912027024784152, J_o = 0.3497768509496993
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
W_opt:  [-0.04791455 -0.04680751 -0.04576657 -0.04471393 -0.04361429 -0.04255443
 -0.04167875 -0.0409367  -0.04028124 -0.03967397]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1243 s, v_trunc (Latent to Reduced) = 0.0040, dec (Reduced to Full) = 0.1542, add (DA)= 0.0001decode = 0.1623 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2867 s, inc stats = 0.3060, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.12924285e-10 5.11616873e-10 6.12357296e-10 1.50003159e-10
 2.21887809e-09]
u_DA:    [2.56361910e-09 4.79395316e-09 6.52940863e-09 3.60705749e-09
 8.79528265e-09]
ref_MAE: [6.88350271e-09 9.98007875e-09 1.24475756e-08 8.39415908e-09
 1.82451116e-08]
da_MAE:  [2.45069482e-09 4.28233629e-09 5.91705133e-09 3.45705433e-09
 6.57640456e-09]
% 9.26883322446169 da_MAE 0.07416289074999756 ref_MAE 0.08173915688031506
u_c taken from control states: [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
u_c before reduction of space:  [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
data[u_c] post encoding of state:  [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
J_b = 0.0, J_o = 13225.29722252992
J_b = 0.4999999999999998, J_o = 835796.6570014847
J_b = 0.006179765465819659, J_o = 151.8502628131117
J_b = 0.006181527078121081, J_o = 149.38010995125904
J_b = 0.006200317609336273, J_o = 139.78623421798576
J_b = 0.006463385046349019, J_o = 105.99850271108915
J_b = 0.014591817464481214, J_o = 9.262341124623903
J_b = 0.015551712519267662, J_o = 6.8758987705010135
J_b = 0.016662487868608918, J_o = 4.979980283991952
J_b = 0.018296277277785062, J_o = 3.0067931940749384
J_b = 0.020388132681204887, J_o = 2.1217146910680103
J_b = 0.02010491340577589, J_o = 1.7316961873855408
J_b = 0.020061122102840147, J_o = 1.6370454823534175
J_b = 0.020336571993187225, J_o = 1.3742126599011355
J_b = 0.021350039266541845, J_o = 1.061025883709862
J_b = 0.023287031729002143, J_o = 0.6941347832540785
J_b = 0.024871170959165002, J_o = 0.5194759284030706
J_b = 0.025764016421806986, J_o = 0.9021449288087886
J_b = 0.02495617102189655, J_o = 0.5144415340282356
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
W_opt:  [-0.04428903 -0.04324307 -0.04230872 -0.04140076 -0.04047856 -0.03959616
 -0.03885478 -0.03821647 -0.03764705 -0.03711854]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1430 s, v_trunc (Latent to Reduced) = 0.0046, dec (Reduced to Full) = 0.1414, add (DA)= 0.0001decode = 0.1479 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2910 s, inc stats = 0.3001, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.12220091e-10 5.07632790e-10 6.07753997e-10 1.49799423e-10
 2.19804247e-09]
u_DA:    [2.56047778e-09 4.79741592e-09 6.53720212e-09 3.61074879e-09
 8.79921564e-09]
ref_MAE: [6.88420690e-09 9.98406283e-09 1.24521789e-08 8.39436282e-09
 1.82659472e-08]
da_MAE:  [2.44825769e-09 4.28978313e-09 5.92944812e-09 3.46094937e-09
 6.60117317e-09]
% 9.221277944358164 da_MAE 0.07462751179247872 ref_MAE 0.08220815418258101
u_c taken from control states: [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
u_c before reduction of space:  [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
data[u_c] post encoding of state:  [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
J_b = 0.0, J_o = 13222.798742086055
J_b = 0.5, J_o = 835853.9892859987
J_b = 0.006176517038190227, J_o = 156.2555493052122
J_b = 0.006178322263283008, J_o = 153.72411152420963
J_b = 0.006197577997606016, J_o = 143.88946031618931
J_b = 0.006467158278128243, J_o = 109.2084541399534
J_b = 0.014954762310887574, J_o = 9.424906461948314
J_b = 0.015809081952719573, J_o = 7.059252518041095
J_b = 0.017204916267793923, J_o = 4.717848807131352
J_b = 0.019041034687937775, J_o = 2.8796559022905943
J_b = 0.020432010248533816, J_o = 1.9814466734275458
J_b = 0.020316507106298797, J_o = 1.8188262154537305
J_b = 0.020429383507477444, J_o = 1.5478055628920517
J_b = 0.021508022997678684, J_o = 1.099566537311736
J_b = 0.02354876153662563, J_o = 0.6903396174764033
J_b = 0.0254436617399228, J_o = 0.4723631216592514
J_b = 0.026521364379170832, J_o = 0.390304503984204
J_b = 0.027213063500515586, J_o = 0.8696770124477045
J_b = 0.02656552967063923, J_o = 0.38745590171555905
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
W_opt:  [-0.04677044 -0.04566507 -0.04466034 -0.04366795 -0.04264768 -0.04167166
 -0.04086358 -0.04018003 -0.03957773 -0.03902229]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1648 s, v_trunc (Latent to Reduced) = 0.0015, dec (Reduced to Full) = 0.1665, add (DA)= 0.0001decode = 0.1699 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3348 s, inc stats = 0.3404, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.11637400e-10 5.04117536e-10 6.03006327e-10 1.49631762e-10
 2.17756750e-09]
u_DA:    [2.56652095e-09 4.80649452e-09 6.53882480e-09 3.61293376e-09
 8.80609940e-09]
ref_MAE: [6.88478959e-09 9.98757809e-09 1.24569266e-08 8.39453048e-09
 1.82864222e-08]
da_MAE:  [2.45488355e-09 4.30237698e-09 5.93581847e-09 3.46330200e-09
 6.62853190e-09]
% 9.151666103573996 da_MAE 0.07520078482217124 ref_MAE 0.08277618487522935
u_c taken from control states: [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
u_c before reduction of space:  [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
data[u_c] post encoding of state:  [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
J_b = 0.0, J_o = 13220.92047834452
J_b = 0.5000000000000001, J_o = 835901.3469279842
J_b = 0.006173841162343342, J_o = 160.0651780430934
J_b = 0.006175683649665975, J_o = 157.481379534337
J_b = 0.006195336847773987, J_o = 147.44101638770164
J_b = 0.00647048162128603, J_o = 111.99685801540267
J_b = 0.015267155348559623, J_o = 9.621129010808948
J_b = 0.016031668301112495, J_o = 7.250683085537526
J_b = 0.017734664580918515, J_o = 4.432373672348363
J_b = 0.01983484466549052, J_o = 2.8721920638365055
J_b = 0.020401405712878427, J_o = 2.100001439112597
J_b = 0.02051820533065451, J_o = 1.8926796483166652
J_b = 0.020649338451726815, J_o = 1.7686523872678217
J_b = 0.021750461854937255, J_o = 1.2579375801513546
J_b = 0.023238062310146485, J_o = 0.870415248975262
J_b = 0.025306106899345666, J_o = 0.5586487783893561
J_b = 0.026096075079930003, J_o = 0.4661316081244777
J_b = 0.026677437608773176, J_o = 0.6721680008678976
J_b = 0.026175234350471144, J_o = 0.4597696363247529
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
W_opt:  [-0.04590825 -0.04480768 -0.04382491 -0.04286416 -0.04188346 -0.04094937
 -0.04017712 -0.03952658 -0.03895604 -0.03843289]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0486 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.0512, add (DA)= 0.0001decode = 0.0542 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1029 s, inc stats = 0.1088, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.11146534e-10 5.01068104e-10 5.98068109e-10 1.49436433e-10
 2.15744314e-09]
u_DA:    [2.56738524e-09 4.81089331e-09 6.54385371e-09 3.61392361e-09
 8.81156241e-09]
ref_MAE: [6.88528046e-09 9.99062752e-09 1.24618648e-08 8.39472581e-09
 1.83065465e-08]
da_MAE:  [2.45623871e-09 4.30982521e-09 5.94578560e-09 3.46448718e-09
 6.65411927e-09]
% 9.086627307033233 da_MAE 0.07579991340681914 ref_MAE 0.0833759777704113
\% improve_point: 7.92, mse_ref_points: 1.0631501349576348e-05, mse_da_points: 9.78902504570572e-06, % improve_overlap: 9.64, mse_ref_overlap: 0.16526, mse_da_overlap: 0.14933
DA - - L2: 566.65, L1: 1384.89, % Improve: 9.46%, DA_MAE: 0.07, mse_ref: 0.17, mse_DA: 0.159, time(s): 0.9427s,
u_c taken from control states: [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
u_c before reduction of space:  [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
data[u_c] post encoding of state:  [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
J_b = 0.0, J_o = 13220.868137646428
J_b = 0.49999999999999994, J_o = 835925.0826496631
J_b = 0.006172528362479989, J_o = 162.80923457377133
J_b = 0.006174397415240826, J_o = 160.1881072095449
J_b = 0.006194333978023131, J_o = 150.00110209208646
J_b = 0.006473445856975543, J_o = 114.01315105341355
J_b = 0.01549119792025982, J_o = 9.793158352535771
J_b = 0.016193351641655557, J_o = 7.4067714410104575
J_b = 0.018150400334203703, J_o = 4.175648587221771
J_b = 0.02054250441806007, J_o = 2.9681135974802513
J_b = 0.020515428063644692, J_o = 2.180385827895
J_b = 0.020647431357843936, J_o = 1.9526309925894552
J_b = 0.020805266494853186, J_o = 1.8502776208857048
J_b = 0.021787355577645134, J_o = 1.376145169509007
J_b = 0.023340484939177265, J_o = 0.9199205067429672
J_b = 0.02596799047120718, J_o = 0.5453309830188194
J_b = 0.02662353414317332, J_o = 0.41938296580771584
J_b = 0.027597562717356878, J_o = 9.245530937907478
J_b = 0.026631726835970468, J_o = 0.4185466903083274
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
W_opt:  [-0.0466127  -0.04548888 -0.0444809  -0.0434901  -0.04247436 -0.0415076
 -0.04071353 -0.04005041 -0.03947284 -0.03894563]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0489 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1205, add (DA)= 0.0001decode = 0.1234 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1724 s, inc stats = 0.1845, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.10714157e-10 4.98417793e-10 5.92919989e-10 1.49155827e-10
 2.13764929e-09]
u_DA:    [2.56775408e-09 4.81160447e-09 6.54387766e-09 3.61253471e-09
 8.81293124e-09]
ref_MAE: [6.88571284e-09 9.99327783e-09 1.24670130e-08 8.39500642e-09
 1.83263404e-08]
da_MAE:  [2.45703992e-09 4.31318668e-09 5.95095767e-09 3.46337888e-09
 6.67528195e-09]
% 9.023911916321259 da_MAE 0.0764004898068748 ref_MAE 0.08397864913316841
u_c taken from control states: [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
u_c before reduction of space:  [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
data[u_c] post encoding of state:  [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
J_b = 0.0, J_o = 13221.993830434698
J_b = 0.49999999999999994, J_o = 835933.6848057024
J_b = 0.006172088577215572, J_o = 164.87953825258884
J_b = 0.006173977542083812, J_o = 162.2304322097861
J_b = 0.0061941265006783515, J_o = 151.93353810708604
J_b = 0.006476211921001922, J_o = 115.53844279246238
J_b = 0.015659377435161215, J_o = 9.937499862005074
J_b = 0.016316892678971025, J_o = 7.532571968950168
J_b = 0.018478117028568053, J_o = 3.9412454166218276
J_b = 0.021165067797911594, J_o = 3.1642349697900674
J_b = 0.020701837468148722, J_o = 2.2024637331477286
J_b = 0.020744576603101875, J_o = 2.003215108800835
J_b = 0.020969270319931305, J_o = 1.884248360490028
J_b = 0.021516603710295016, J_o = 1.5967504847882987
J_b = 0.023069463740282063, J_o = 1.066708560060097
J_b = 0.02569097034026706, J_o = 0.6093709951775386
J_b = 0.02682577024259382, J_o = 0.42500793897597633
J_b = 0.028124127322499207, J_o = 15.030860340194621
J_b = 0.026834840799608472, J_o = 0.42412786496859534
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
W_opt:  [-0.04682841 -0.04569302 -0.0446732  -0.04366851 -0.04263656 -0.0416549
 -0.04085117 -0.04018317 -0.0396037  -0.03907637]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0553 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1245 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1799 s, inc stats = 0.1935, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.10324570e-10 4.96032474e-10 5.87566990e-10 1.48764690e-10
 2.11816178e-09]
u_DA:    [2.56966433e-09 4.81188240e-09 6.54520798e-09 3.61171236e-09
 8.81593255e-09]
ref_MAE: [6.88610242e-09 9.99566315e-09 1.24723660e-08 8.39539755e-09
 1.83458279e-08]
da_MAE:  [2.45933976e-09 4.31584992e-09 5.95764099e-09 3.46294767e-09
 6.69777077e-09]
% 8.955351742449466 da_MAE 0.07703659338043421 ref_MAE 0.08461408205181944
u_c taken from control states: [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
u_c before reduction of space:  [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
data[u_c] post encoding of state:  [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
J_b = 0.0, J_o = 13225.327063202927
J_b = 0.4999999999999998, J_o = 835913.7644744384
J_b = 0.0061732927126409536, J_o = 165.67060243102063
J_b = 0.006175189350074467, J_o = 163.01071974524774
J_b = 0.006195420149365295, J_o = 152.67158344424516
J_b = 0.006478651339437008, J_o = 116.12134931365813
J_b = 0.015721390814784603, J_o = 9.994157088311471
J_b = 0.016367485114346485, J_o = 7.579398914107715
J_b = 0.018583813698608315, J_o = 3.880128204267109
J_b = 0.021360708307665052, J_o = 3.2578930871283425
J_b = 0.020789187411468752, J_o = 2.209285255992588
J_b = 0.02081760219481484, J_o = 2.0210428266844023
J_b = 0.02105361849961158, J_o = 1.8935752230238894
J_b = 0.02154956831225831, J_o = 1.629653400646508
J_b = 0.023106557574664795, J_o = 1.08886379728682
J_b = 0.025664703573400803, J_o = 0.6251341017003322
J_b = 0.02691785467728077, J_o = 0.4270480895382916
J_b = 0.028374680871170743, J_o = 16.198631288115195
J_b = 0.026927484238413662, J_o = 0.4261935061389839
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
W_opt:  [-0.04689861 -0.04575506 -0.04472916 -0.04372008 -0.04268466 -0.04169936
 -0.04089076 -0.04021718 -0.03963196 -0.03909897]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0540 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1221, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1791 s, inc stats = 0.1925, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.09948503e-10 4.93752631e-10 5.82013591e-10 1.48253604e-10
 2.09894886e-09]
u_DA:    [2.56973590e-09 4.81196274e-09 6.54563952e-09 3.61164093e-09
 8.81613200e-09]
ref_MAE: [6.88647849e-09 9.99794299e-09 1.24779194e-08 8.39590864e-09
 1.83650408e-08]
da_MAE:  [2.45978739e-09 4.31821011e-09 5.96362593e-09 3.46338732e-09
 6.71718314e-09]
% 8.906459053126358 da_MAE 0.07764596182229165 ref_MAE 0.08523761510991794
u_c taken from control states: [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
u_c before reduction of space:  [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
data[u_c] post encoding of state:  [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
J_b = 0.0, J_o = 13231.820908653266
J_b = 0.5000000000000001, J_o = 835852.6556918814
J_b = 0.006176870483170022, J_o = 164.58763247802534
J_b = 0.006178756933246377, J_o = 161.94207478361577
J_b = 0.0061988790673941675, J_o = 151.65941827699356
J_b = 0.006480588945463233, J_o = 115.32198058675972
J_b = 0.015627408521488702, J_o = 9.915749281578316
J_b = 0.016311049019699746, J_o = 7.506979768560134
J_b = 0.01835357935818707, J_o = 4.113749886072271
J_b = 0.020892699256131773, J_o = 3.0788696125284654
J_b = 0.02067066923247814, J_o = 2.2246203603772203
J_b = 0.020765029868284355, J_o = 2.0011891522276755
J_b = 0.0209629392427731, J_o = 1.8920903816149077
J_b = 0.021706157134408887, J_o = 1.5167013176093525
J_b = 0.023295374664052838, J_o = 1.0109736429636367
J_b = 0.02603211705471322, J_o = 0.5893877701321357
J_b = 0.02681831718250056, J_o = 0.43508249932312226
J_b = 0.02781434181251133, J_o = 11.999777212487007
J_b = 0.026825947003135633, J_o = 0.4342197085959079
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
W_opt:  [-0.04677092 -0.04562777 -0.04460253 -0.04359799 -0.04257006 -0.04158959
 -0.04077767 -0.04009369 -0.03949417 -0.03894464]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0467 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1194, add (DA)= 0.0001decode = 0.1222 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1689 s, inc stats = 0.1826, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.09563501e-10 4.91404697e-10 5.76283580e-10 1.47638952e-10
 2.07997878e-09]
u_DA:    [2.56804722e-09 4.80997534e-09 6.54391743e-09 3.61182321e-09
 8.81276048e-09]
ref_MAE: [6.88686349e-09 1.00002909e-08 1.24836494e-08 8.39652329e-09
 1.83840109e-08]
da_MAE:  [2.45848372e-09 4.31857065e-09 5.96763385e-09 3.46418426e-09
 6.73278170e-09]
% 8.880533828352208 da_MAE 0.0781902004792617 ref_MAE 0.08581064372344942
u_c taken from control states: [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
u_c before reduction of space:  [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
data[u_c] post encoding of state:  [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
J_b = 0.0, J_o = 13239.758787483988
J_b = 0.5, J_o = 835772.2320461306
J_b = 0.0061815619515591495, J_o = 162.58609861801227
J_b = 0.006183429318620877, J_o = 159.96736893064747
J_b = 0.006203347900612602, J_o = 149.7903723902578
J_b = 0.006482208048496672, J_o = 113.84914157381475
J_b = 0.015455799689982647, J_o = 9.790222774176796
J_b = 0.016202042824324057, J_o = 7.389090378748946
J_b = 0.01798827809764769, J_o = 4.42759769217753
J_b = 0.020191805368548865, J_o = 2.9733615875256025
J_b = 0.02055699010458178, J_o = 2.199402041878406
J_b = 0.020735998211380127, J_o = 1.9625676498109943
J_b = 0.020871775927058404, J_o = 1.8484222085799211
J_b = 0.022160025361917468, J_o = 1.2689881854533813
J_b = 0.02370391552169967, J_o = 0.8669855189462963
J_b = 0.025844999593425177, J_o = 0.5607009342026285
J_b = 0.026558393566123564, J_o = 0.4741559524500291
J_b = 0.0273372482632667, J_o = 1.096234672830879
J_b = 0.026608924003689235, J_o = 0.4704217622635482
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
W_opt:  [-0.04630528 -0.0451717  -0.0441603  -0.04317763 -0.04217844 -0.0412234
 -0.04042259 -0.03973765 -0.03913034 -0.03856942]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0471 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1194, add (DA)= 0.0001decode = 0.1217 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1689 s, inc stats = 0.1762, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.09167886e-10 4.88825632e-10 5.70426386e-10 1.46961570e-10
 2.06121629e-09]
u_DA:    [2.56629146e-09 4.80891053e-09 6.54327080e-09 3.61319939e-09
 8.80893814e-09]
ref_MAE: [6.88725911e-09 1.00028700e-08 1.24895066e-08 8.39720067e-09
 1.84027734e-08]
da_MAE:  [2.45712357e-09 4.32008490e-09 5.97284441e-09 3.46623782e-09
 6.74772185e-09]
% 8.90900410060007 da_MAE 0.0787579382753399 ref_MAE 0.0864607280859235
u_c taken from control states: [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
u_c before reduction of space:  [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
data[u_c] post encoding of state:  [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
J_b = 0.0, J_o = 13249.093988070508
J_b = 0.49999999999999983, J_o = 835672.1565895001
J_b = 0.006187386578906439, J_o = 159.57720535838678
J_b = 0.006189224690609758, J_o = 156.99959818566754
J_b = 0.006208831215445152, J_o = 146.9844281322868
J_b = 0.006483322563140683, J_o = 111.6478861187022
J_b = 0.015199815683336433, J_o = 9.644089393341792
J_b = 0.016034841511920202, J_o = 7.243000631348329
J_b = 0.017516647999019634, J_o = 4.767756602786469
J_b = 0.019411043035629544, J_o = 3.0018157895814426
J_b = 0.020582109376362366, J_o = 2.1069682979821263
J_b = 0.020623021318503177, J_o = 1.9126173393933672
J_b = 0.02085622480037824, J_o = 1.6616683517499975
J_b = 0.022085009477932398, J_o = 1.172217183020363
J_b = 0.024157122979921532, J_o = 0.7338317856772123
J_b = 0.025900737616500205, J_o = 0.5214655300094261
J_b = 0.026754744085282958, J_o = 0.44680480621853247
J_b = 0.027502795155153383, J_o = 0.5485791290116806
J_b = 0.026910930514344043, J_o = 0.43707357147406967
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
W_opt:  [-0.04689898 -0.04575575 -0.04472094 -0.04371095 -0.0426807  -0.04169027
 -0.04085162 -0.04012497 -0.03947383 -0.03886692]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0878 s, v_trunc (Latent to Reduced) = 0.0151, dec (Reduced to Full) = 0.1082, add (DA)= 0.0001decode = 0.1255 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2134 s, inc stats = 0.2193, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.08751588e-10 4.85885982e-10 5.64475598e-10 1.46260814e-10
 2.04262631e-09]
u_DA:    [2.56621336e-09 4.80454056e-09 6.53919308e-09 3.61303066e-09
 8.80388495e-09]
ref_MAE: [6.88767541e-09 1.00058096e-08 1.24954573e-08 8.39790143e-09
 1.84213633e-08]
da_MAE:  [2.45746177e-09 4.31865458e-09 5.97471748e-09 3.46676984e-09
 6.76125864e-09]
% 9.134545936254874 da_MAE 0.07934734400428586 ref_MAE 0.08732399438473182
u_c taken from control states: [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
u_c before reduction of space:  [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
data[u_c] post encoding of state:  [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
J_b = 0.0, J_o = 13260.264836268634
J_b = 0.5, J_o = 835545.6322966875
J_b = 0.006194736764967589, J_o = 155.16604531124995
J_b = 0.006196531191161143, J_o = 152.64984050553943
J_b = 0.006215671737225779, J_o = 142.87622098475097
J_b = 0.006483639382130862, J_o = 108.4409381344513
J_b = 0.014823176887443383, J_o = 9.516383944133569
J_b = 0.01578597351210819, J_o = 7.086241533582016
J_b = 0.016929937220520528, J_o = 5.144732718038826
J_b = 0.01855640558794145, J_o = 3.197469035304366
J_b = 0.02067580119538768, J_o = 2.173350490504623
J_b = 0.02045853103889191, J_o = 1.8614998202911308
J_b = 0.02040939541800377, J_o = 1.7463138764757455
J_b = 0.02071767883543178, J_o = 1.463940067149445
J_b = 0.02189101930581038, J_o = 1.1132819036339998
J_b = 0.024040643412015856, J_o = 0.728979329182805
J_b = 0.025449579555721597, J_o = 0.5766873628703573
J_b = 0.026369044590760178, J_o = 0.692355010887189
J_b = 0.025648629510535648, J_o = 0.5652711946648505
J_b = 0.02640554418273491, J_o = 0.5082787557994872
J_b = 0.026870974956568837, J_o = 0.46608697058962284
J_b = 0.027727061414082967, J_o = 0.40095404959521574
J_b = 0.02811039920661587, J_o = 0.37397040316530683
J_b = 0.02809593450946033, J_o = 0.3663832795260623
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
W_opt:  [-0.04894214 -0.04775721 -0.0466452  -0.04553716 -0.04439023 -0.04327742
 -0.04233192 -0.04150737 -0.04076431 -0.04006684]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0633 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1308, add (DA)= 0.0001decode = 0.1337 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1971 s, inc stats = 0.2110, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.08305532e-10 4.82462075e-10 5.58462189e-10 1.45577141e-10
 2.02417701e-09]
u_DA:    [2.56328467e-09 4.79494648e-09 6.53102363e-09 3.60675368e-09
 8.79555040e-09]
ref_MAE: [6.88812146e-09 1.00092335e-08 1.25014708e-08 8.39858510e-09
 1.84398126e-08]
da_MAE:  [2.45497914e-09 4.31248440e-09 5.97256144e-09 3.46117654e-09
 6.77137339e-09]
% 9.431187696720002 da_MAE 0.08007460040960984 ref_MAE 0.0884129960117738
u_c taken from control states: [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
u_c before reduction of space:  [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
data[u_c] post encoding of state:  [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
J_b = 0.0, J_o = 13271.71107134676
J_b = 0.5, J_o = 835411.5810327372
J_b = 0.006202520061911004, J_o = 150.10847616037051
J_b = 0.006204263130590569, J_o = 147.66445302418904
J_b = 0.006222855863172569, J_o = 138.1746972309172
J_b = 0.006483154119320377, J_o = 104.79706208109434
J_b = 0.014389000275428493, J_o = 9.499744299179875
J_b = 0.01549732652080863, J_o = 6.990498196398312
J_b = 0.01636276124092998, J_o = 5.489907948613753
J_b = 0.017811698510413927, J_o = 3.503975852993456
J_b = 0.020186850273676796, J_o = 2.093751901359761
J_b = 0.020659167328500913, J_o = 1.6797061992219335
J_b = 0.020865841280669754, J_o = 1.5276147386150152
J_b = 0.021502863662047577, J_o = 1.276097662491946
J_b = 0.022732591577290538, J_o = 1.0009764190804755
J_b = 0.024487959203157245, J_o = 0.7435246919440743
J_b = 0.025287115816151503, J_o = 0.6375367021107927
J_b = 0.026267887987401532, J_o = 1.1868777605843503
J_b = 0.025373626068877206, J_o = 0.6307845901221356
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
W_opt:  [-0.04436933 -0.04329968 -0.04233438 -0.04140416 -0.0404656  -0.03955635
 -0.03876283 -0.03804935 -0.03739285 -0.0367699 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0485 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1732 s, inc stats = 0.1869, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.07834030e-10 4.78433214e-10 5.52434779e-10 1.44958044e-10
 2.00583168e-09]
u_DA:    [2.55957289e-09 4.78714220e-09 6.53257447e-09 3.61321130e-09
 8.78933603e-09]
ref_MAE: [6.88859296e-09 1.00132624e-08 1.25074982e-08 8.39920420e-09
 1.84581580e-08]
da_MAE:  [2.45173886e-09 4.30870899e-09 5.98013969e-09 3.46825326e-09
 6.78350435e-09]
% 9.70443159368027 da_MAE 0.08128706057193631 ref_MAE 0.09002331122846897
u_c taken from control states: [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
u_c before reduction of space:  [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
data[u_c] post encoding of state:  [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
J_b = 0.0, J_o = 13281.540845273585
J_b = 0.4999999999999997, J_o = 835293.7722620904
J_b = 0.006209360773964115, J_o = 145.43043454271378
J_b = 0.006211054931962601, J_o = 143.0551526237339
J_b = 0.006229125950613095, J_o = 133.83569207124702
J_b = 0.006482120211719941, J_o = 101.46452383622548
J_b = 0.013981755463987793, J_o = 9.635213750582171
J_b = 0.015226809159283641, J_o = 6.998106835196967
J_b = 0.015908212995055206, J_o = 5.77623978348724
J_b = 0.017245766121853447, J_o = 3.805232814951036
J_b = 0.019613016263067714, J_o = 2.1244267202969884
J_b = 0.020853454431554393, J_o = 1.6011159706570652
J_b = 0.022127634764765463, J_o = 1.2508000663588856
J_b = 0.023462474261253533, J_o = 1.007336898401227
J_b = 0.02416531222975699, J_o = 0.8828451595253968
J_b = 0.024513114103415275, J_o = 0.8201310862139108
J_b = 0.024831850151095177, J_o = 0.7606340968029421
J_b = 0.025717905794907535, J_o = 3.1652642714262136
J_b = 0.024852606048880416, J_o = 0.7588105763065806
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
W_opt:  [-0.04328785 -0.04224724 -0.04130824 -0.04040727 -0.03950217 -0.03862355
 -0.03784897 -0.03714364 -0.03648897 -0.03586402]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0482 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1733 s, inc stats = 0.1893, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.07356564e-10 4.73721671e-10 5.46402527e-10 1.44446624e-10
 1.98759721e-09]
u_DA:    [2.55485713e-09 4.77599510e-09 6.52717275e-09 3.61087237e-09
 8.77855481e-09]
ref_MAE: [6.88907043e-09 1.00179740e-08 1.25135304e-08 8.39971562e-09
 1.84763925e-08]
da_MAE:  [2.44750057e-09 4.30227343e-09 5.98077023e-09 3.46642574e-09
 6.79095760e-09]
% 9.870570703840942 da_MAE 0.08308255707771486 ref_MAE 0.09218138595409424
u_c taken from control states: [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
u_c before reduction of space:  [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
data[u_c] post encoding of state:  [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
J_b = 0.0, J_o = 13289.25352918933
J_b = 0.5, J_o = 835202.2319970861
J_b = 0.006214683031570219, J_o = 141.85552512479046
J_b = 0.006216338957450073, J_o = 139.53397965834782
J_b = 0.006234002166835173, J_o = 130.52587640311023
J_b = 0.006481287098226521, J_o = 98.94272115068503
J_b = 0.01366335227023073, J_o = 9.85758365000525
J_b = 0.0150170227823079, J_o = 7.0792584842335735
J_b = 0.01558958382626129, J_o = 6.009483161095216
J_b = 0.016823053167068707, J_o = 4.091813798769586
J_b = 0.019129711283808647, J_o = 2.4710940685358893
J_b = 0.02090962922983421, J_o = 1.6419335642840158
J_b = 0.022646099288427934, J_o = 1.249960068051145
J_b = 0.023394869362012783, J_o = 1.0937731503188255
J_b = 0.024100934701980915, J_o = 0.9599566111632823
J_b = 0.024793449826284796, J_o = 0.8719665568009537
J_b = 0.025462914539872764, J_o = 0.7923669215868766
J_b = 0.02781525176073425, J_o = 9.870213971296979
J_b = 0.025490086391385492, J_o = 0.7903254325018884
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
W_opt:  [-0.04434647 -0.04326877 -0.04228003 -0.04132202 -0.040354   -0.03941166
 -0.03858085 -0.03782262 -0.0371178  -0.03644332]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0761 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1208, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1998 s, inc stats = 0.2119, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.06895271e-10 4.68325805e-10 5.40358129e-10 1.44076891e-10
 1.96948698e-09]
u_DA:    [2.55294860e-09 4.77217792e-09 6.52304623e-09 3.61182814e-09
 8.77430625e-09]
ref_MAE: [6.88953172e-09 1.00233698e-08 1.25195748e-08 8.40008535e-09
 1.84945027e-08]
da_MAE:  [2.44605333e-09 4.30385211e-09 5.98268810e-09 3.46775125e-09
 6.80481927e-09]
% 9.919883142199852 da_MAE 0.08544234391221982 ref_MAE 0.09485150207686621
\% improve_point: 8.01, mse_ref_points: 1.093467375116263e-05, mse_da_points: 1.0056833157267735e-05, % improve_overlap: 9.50, mse_ref_overlap: 0.16998, mse_da_overlap: 0.15384
DA - - L2: 764.31, L1: 1596.82, % Improve: 9.41%, DA_MAE: 0.07, mse_ref: 0.18, mse_DA: 0.163, time(s): 0.7613s,
u_c taken from control states: [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
u_c before reduction of space:  [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
data[u_c] post encoding of state:  [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
J_b = 0.0, J_o = 13294.852943916174
J_b = 0.5, J_o = 835141.8285718847
J_b = 0.0062182124051686155, J_o = 139.97305405009968
J_b = 0.006219847631785835, J_o = 137.68060679295704
J_b = 0.006237290049036194, J_o = 128.7870467404875
J_b = 0.006481483890541398, J_o = 97.6324701482259
J_b = 0.013488414878701543, J_o = 10.055536498012497
J_b = 0.014906051077507084, J_o = 7.176445412466884
J_b = 0.015427167272258126, J_o = 6.173595518871284
J_b = 0.016582822118305394, J_o = 4.31215516559118
J_b = 0.018787862913336485, J_o = 2.721544495563859
J_b = 0.020967586512008852, J_o = 1.7105185395129636
J_b = 0.02305407610236925, J_o = 1.2824083727655777
J_b = 0.02351038681233128, J_o = 1.1635357224962641
J_b = 0.024141728149252716, J_o = 1.0280618763116993
J_b = 0.02504847225785289, J_o = 0.9096193983993874
J_b = 0.026324578569586685, J_o = 0.7956617649702937
J_b = 0.028779129353597468, J_o = 10.377148680278786
J_b = 0.02634900221051641, J_o = 0.794209411175955
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
W_opt:  [-0.04561243 -0.04449644 -0.04345339 -0.04243037 -0.04138902 -0.04037328
 -0.03948062 -0.03866743 -0.0379125  -0.03718965]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0478 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1363, add (DA)= 0.0001decode = 0.1393 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1872 s, inc stats = 0.2010, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.06464669e-10 4.62306412e-10 5.34309434e-10 1.43850693e-10
 1.95152696e-09]
u_DA:    [2.55104282e-09 4.76785293e-09 6.51901958e-09 3.61116304e-09
 8.76994294e-09]
ref_MAE: [6.88996232e-09 1.00293892e-08 1.25256235e-08 8.40031155e-09
 1.85124627e-08]
da_MAE:  [2.44457815e-09 4.30554652e-09 5.98471014e-09 3.46731235e-09
 6.81841598e-09]
% 10.029786298824066 da_MAE 0.08823016323623978 ref_MAE 0.09806597051028966
u_c taken from control states: [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
u_c before reduction of space:  [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
data[u_c] post encoding of state:  [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
J_b = 0.0, J_o = 13297.730561012351
J_b = 0.5000000000000001, J_o = 835127.2010626122
J_b = 0.006219111382206561, J_o = 140.95608356183834
J_b = 0.006220757014474019, J_o = 138.64902609610215
J_b = 0.00623831042532688, J_o = 129.69830983255403
J_b = 0.006484058177266698, J_o = 98.33566236870442
J_b = 0.013561071713239167, J_o = 10.070922145392363
J_b = 0.014966730590434305, J_o = 7.212034601263765
J_b = 0.01550015680453741, J_o = 6.194133885530931
J_b = 0.01667173570860093, J_o = 4.3206155348612025
J_b = 0.01892513442900785, J_o = 2.7072141475759115
J_b = 0.02106509704123054, J_o = 1.723634448903692
J_b = 0.0230606572022129, J_o = 1.3033506490705749
J_b = 0.023566961241728857, J_o = 1.1792711013366135
J_b = 0.02420454831403153, J_o = 1.0437349915253207
J_b = 0.025090980217612205, J_o = 0.9278195252497139
J_b = 0.026234488938024027, J_o = 0.8198845644062345
J_b = 0.02866186262011653, J_o = 8.832586744159997
J_b = 0.026263670510672996, J_o = 0.8180883035125684
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
W_opt:  [-0.04535713 -0.04425158 -0.04321883 -0.04220826 -0.04118182 -0.04018038
 -0.03929779 -0.03849134 -0.03774097 -0.0370213 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0853 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2103 s, inc stats = 0.2142, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.06081310e-10 4.55773014e-10 5.28256124e-10 1.43750828e-10
 1.93374738e-09]
u_DA:    [2.55132908e-09 4.76842916e-09 6.51999382e-09 3.61136709e-09
 8.77064374e-09]
ref_MAE: [6.89034568e-09 1.00359226e-08 1.25316768e-08 8.40041141e-09
 1.85302423e-08]
da_MAE:  [2.44524777e-09 4.31265614e-09 5.99173769e-09 3.46761626e-09
 6.83689636e-09]
% 9.988466130540248 da_MAE 0.09121504459766283 ref_MAE 0.10133706279236224
u_c taken from control states: [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
u_c before reduction of space:  [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
data[u_c] post encoding of state:  [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
J_b = 0.0, J_o = 13298.052121848441
J_b = 0.5000000000000001, J_o = 835155.2579286662
J_b = 0.006217556830713287, J_o = 144.59444137421934
J_b = 0.006219241568493478, J_o = 142.23244433996857
J_b = 0.006237212104815507, J_o = 133.0661336235087
J_b = 0.006488799613323741, J_o = 100.90772948636146
J_b = 0.013863915674681402, J_o = 9.93019561598404
J_b = 0.01518616350496193, J_o = 7.194670515542447
J_b = 0.015796729007843964, J_o = 6.075573843548662
J_b = 0.017060706456871893, J_o = 4.141529359750303
J_b = 0.01946709368635796, J_o = 2.451727501925865
J_b = 0.021130692448453798, J_o = 1.674914030095619
J_b = 0.02302493799850436, J_o = 1.2716839567844174
J_b = 0.023841056262447154, J_o = 1.1050185567997897
J_b = 0.024455616194817544, J_o = 0.9961682750022884
J_b = 0.024861800220444586, J_o = 0.931962832688194
J_b = 0.025494110753780302, J_o = 0.8435360417252222
J_b = 0.027720533718005532, J_o = 18.612640298218142
J_b = 0.025508133545929138, J_o = 0.8423239776912836
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
W_opt:  [-0.04399729 -0.04293836 -0.04196385 -0.04102218 -0.04007405 -0.03915014
 -0.03833062 -0.03757781 -0.03687459 -0.03619904]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0506 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1343, add (DA)= 0.0001decode = 0.1371 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1879 s, inc stats = 0.2013, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.05725784e-10 4.48912966e-10 5.22190579e-10 1.43720908e-10
 1.91617021e-09]
u_DA:    [2.55394192e-09 4.77269533e-09 6.52487994e-09 3.61203588e-09
 8.77567781e-09]
ref_MAE: [6.89070121e-09 1.00427827e-08 1.25377424e-08 8.40044133e-09
 1.85478194e-08]
da_MAE:  [2.44821613e-09 4.32378237e-09 6.00268936e-09 3.46831497e-09
 6.85950760e-09]
% 9.916381954837787 da_MAE 0.09410634654975363 ref_MAE 0.10446554944382304
u_c taken from control states: [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
u_c before reduction of space:  [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
data[u_c] post encoding of state:  [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
J_b = 0.0, J_o = 13296.37522568828
J_b = 0.4999999999999999, J_o = 835213.7920677243
J_b = 0.0062142486771169314, J_o = 149.95695787109338
J_b = 0.006215990080172416, J_o = 147.51534440743453
J_b = 0.006234565046097588, J_o = 138.03645137712135
J_b = 0.006494614569050075, J_o = 104.72185244502519
J_b = 0.014313906841193042, J_o = 9.797549470636053
J_b = 0.015505746247584147, J_o = 7.208041030729364
J_b = 0.016267101659388567, J_o = 5.872666650012691
J_b = 0.017635894578445336, J_o = 3.903777322649762
J_b = 0.02012527094356576, J_o = 2.1738020655339403
J_b = 0.021257655011651118, J_o = 1.7508176303001237
J_b = 0.021753278941999053, J_o = 1.542382578570294
J_b = 0.023157846949322686, J_o = 1.1526317470135472
J_b = 0.02495375395679667, J_o = 0.8833065257974791
J_b = 0.025873926428251145, J_o = 0.7587464544458312
J_b = 0.027146793112481093, J_o = 0.6443360069492156
J_b = 0.028440259848756675, J_o = 0.5765417173842684
J_b = 0.03025548102672686, J_o = 0.6378506917314284
J_b = 0.029051081321999753, J_o = 0.5456052692467956
J_b = 0.028982052881704665, J_o = 0.5239411282881661
J_b = 0.02940542565712738, J_o = 0.5064335217623915
J_b = 0.02941870631424011, J_o = 0.5043361990463102
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
W_opt:  [-0.05016378 -0.04896685 -0.04778449 -0.04658831 -0.04534483 -0.04412087
 -0.04305138 -0.04208373 -0.04118779 -0.04032751]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0581 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1189, add (DA)= 0.0001decode = 0.1218 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1800 s, inc stats = 0.1887, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.05377558e-10 4.41878790e-10 5.16128280e-10 1.43684712e-10
 1.89882950e-09]
u_DA:    [2.55933101e-09 4.77747508e-09 6.52405798e-09 3.60525926e-09
 8.78312030e-09]
ref_MAE: [6.89104944e-09 1.00498168e-08 1.25438047e-08 8.40047753e-09
 1.85651602e-08]
da_MAE:  [2.45395346e-09 4.33559629e-09 6.00792970e-09 3.46157455e-09
 6.88429080e-09]
% 9.827743265279961 da_MAE 0.09675229752218922 ref_MAE 0.1072971898738513
u_c taken from control states: [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
u_c before reduction of space:  [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
data[u_c] post encoding of state:  [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
J_b = 0.0, J_o = 13291.287392678198
J_b = 0.5000000000000003, J_o = 835315.9797330482
J_b = 0.006208416047443384, J_o = 157.26304693926102
J_b = 0.006210232990161946, J_o = 154.71529357455364
J_b = 0.00622961371249329, J_o = 144.8195794595281
J_b = 0.006500943825132148, J_o = 109.96151250028724
J_b = 0.014925191151898444, J_o = 9.798581485358437
J_b = 0.01593466367982476, J_o = 7.329322353921844
J_b = 0.01699738897336544, J_o = 5.524442175012874
J_b = 0.01854329849670097, J_o = 3.57373367406822
J_b = 0.02093759501832249, J_o = 2.415261879277401
J_b = 0.020837629775084184, J_o = 2.0237069130850234
J_b = 0.02082798540724949, J_o = 1.8981404861275142
J_b = 0.021218339488634424, J_o = 1.6057873693848936
J_b = 0.022502247903897238, J_o = 1.2394780352936683
J_b = 0.02468703717655405, J_o = 0.8648165031830036
J_b = 0.02595252382875979, J_o = 0.7235022043056643
J_b = 0.026970104632675743, J_o = 0.7331678669007768
J_b = 0.02639816687193119, J_o = 0.6961729432974834
J_b = 0.027280168986551463, J_o = 0.6241374694333155
J_b = 0.027837409751153154, J_o = 0.5680431763314855
J_b = 0.028969165051876283, J_o = 0.48851951202664223
J_b = 0.02923630533093837, J_o = 0.47195649951317487
J_b = 0.029202580426465233, J_o = 0.4691144267490256
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
W_opt:  [-0.04996368 -0.04876518 -0.04759894 -0.04642887 -0.04521946 -0.04403678
 -0.04301073 -0.04209291 -0.04125024 -0.040447  ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0579 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1218, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1826 s, inc stats = 0.1962, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.05043098e-10 4.34745352e-10 5.10083828e-10 1.43570601e-10
 1.88174317e-09]
u_DA:    [2.56185129e-09 4.78870406e-09 6.52963547e-09 3.60582623e-09
 8.79102726e-09]
ref_MAE: [6.89138390e-09 1.00569503e-08 1.25498491e-08 8.40059164e-09
 1.85822465e-08]
da_MAE:  [2.45680820e-09 4.35395870e-09 6.01955164e-09 3.46225563e-09
 6.90928409e-09]
% 9.737405275823512 da_MAE 0.09899173547784185 ref_MAE 0.10967082852020793
u_c taken from control states: [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
u_c before reduction of space:  [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
data[u_c] post encoding of state:  [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
J_b = 0.0, J_o = 13281.21070275319
J_b = 0.5, J_o = 835478.5960155306
J_b = 0.0061990879680820414, J_o = 166.99134710598358
J_b = 0.0062010024896240684, J_o = 164.30647866987874
J_b = 0.006221424052739017, J_o = 153.87210794869958
J_b = 0.006507325936348245, J_o = 117.01627343582157
J_b = 0.01573567103018134, J_o = 10.116647564194967
J_b = 0.016498936894944624, J_o = 7.6828220669396945
J_b = 0.018213295843962984, J_o = 4.813693154257526
J_b = 0.020385601474656734, J_o = 3.289419316956611
J_b = 0.02092791691835554, J_o = 2.4658083642854005
J_b = 0.02119069641726889, J_o = 2.1852352351267355
J_b = 0.02136223114895917, J_o = 2.04997974586473
J_b = 0.022833278159635807, J_o = 1.4210159591857685
J_b = 0.02452736442848614, J_o = 0.9979358752302705
J_b = 0.026506753095786696, J_o = 0.7150059140436957
J_b = 0.027198969589291407, J_o = 0.6330301281671082
J_b = 0.027981596670022837, J_o = 0.7134954278431871
J_b = 0.027406598974935435, J_o = 0.6174116653089159
J_b = 0.027959414086221025, J_o = 0.5572785126363434
J_b = 0.02845748120188046, J_o = 0.5084135063624662
J_b = 0.029205808584224335, J_o = 0.4547060433324196
J_b = 0.02972507695831563, J_o = 0.42552751776309583
J_b = 0.029942293330556015, J_o = 0.43851724556792093
J_b = 0.029806120321101148, J_o = 0.41318668691146765
J_b = 0.030239045151781618, J_o = 0.39807228224764446
J_b = 0.03023557021808722, J_o = 0.3948290559020848
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
W_opt:  [-0.0510453  -0.04980434 -0.0486062  -0.04740675 -0.04616773 -0.04496244
 -0.04392632 -0.04301238 -0.04218132 -0.04139443]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1443 s, v_trunc (Latent to Reduced) = 0.0040, dec (Reduced to Full) = 0.1108, add (DA)= 0.0001decode = 0.1168 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2612 s, inc stats = 0.2671, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.04717696e-10 4.27671876e-10 5.04088680e-10 1.43285485e-10
 1.86493696e-09]
u_DA:    [2.56670950e-09 4.80221373e-09 6.53692331e-09 3.60699673e-09
 8.80289044e-09]
ref_MAE: [6.89170930e-09 1.00640237e-08 1.25558443e-08 8.40087676e-09
 1.85990527e-08]
da_MAE:  [2.46199180e-09 4.37454186e-09 6.03283463e-09 3.46371124e-09
 6.93795347e-09]
% 9.613950353111498 da_MAE 0.10075477104572432 ref_MAE 0.11147159483055553
u_c taken from control states: [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
u_c before reduction of space:  [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
data[u_c] post encoding of state:  [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
J_b = 0.0, J_o = 13266.800334403142
J_b = 0.49999999999999983, J_o = 835693.6417252901
J_b = 0.006186742538229962, J_o = 178.78081135697212
J_b = 0.006188770081839891, J_o = 175.93710981632864
J_b = 0.006210397213679189, J_o = 164.87836964694912
J_b = 0.006513177059429538, J_o = 125.70046486054613
J_b = 0.016713040440640314, J_o = 10.998168452759263
J_b = 0.01718006871076651, J_o = 8.435514979614988
J_b = 0.01994919431669569, J_o = 3.83543554194796
J_b = 0.02258618789992376, J_o = 3.7111296100235442
J_b = 0.021167913048465936, J_o = 2.9901140993866586
J_b = 0.022087807287668904, J_o = 2.4919841442114596
J_b = 0.022590751036089693, J_o = 2.2298197369803403
J_b = 0.022940606831380553, J_o = 2.017060823672428
J_b = 0.024082664066035455, J_o = 1.542564548760645
J_b = 0.02598873405931906, J_o = 1.0512478645578076
J_b = 0.02846852085676932, J_o = 0.6755036300038555
J_b = 0.029608517519723394, J_o = 0.5393574412918258
J_b = 0.030508310779626065, J_o = 0.46346022520239194
J_b = 0.032264588018227146, J_o = 0.643277291775583
J_b = 0.03090929605610193, J_o = 0.43824220998733016
J_b = 0.031234517615927004, J_o = 0.40464984755872235
J_b = 0.031710634695739495, J_o = 0.37733527730029276
J_b = 0.03182059172424523, J_o = 0.37232417952801294
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
W_opt:  [-0.05252972 -0.05121241 -0.04996153 -0.04870291 -0.04739727 -0.04614389
 -0.04510097 -0.0442195  -0.04344449 -0.04272891]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0666 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1336, add (DA)= 0.0001decode = 0.1365 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2031 s, inc stats = 0.2167, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.04380733e-10 4.20931145e-10 4.98178239e-10 1.42730588e-10
 1.84842510e-09]
u_DA:    [2.57304099e-09 4.81754052e-09 6.54601187e-09 3.60951015e-09
 8.81555824e-09]
ref_MAE: [6.89204626e-09 1.00707645e-08 1.25617547e-08 8.40143165e-09
 1.86155646e-08]
da_MAE:  [2.46866026e-09 4.39660937e-09 6.04783363e-09 3.46677956e-09
 6.96713314e-09]
% 9.537143871826531 da_MAE 0.10197522126382591 ref_MAE 0.11272606860802736
u_c taken from control states: [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
u_c before reduction of space:  [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
data[u_c] post encoding of state:  [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
J_b = 0.0, J_o = 13249.244406018533
J_b = 0.5000000000000001, J_o = 835940.4641570388
J_b = 0.006172573707758025, J_o = 191.28212664618474
J_b = 0.006174713761179886, J_o = 188.28027020259808
J_b = 0.006197540997679745, J_o = 176.59894637199648
J_b = 0.006517122308677855, J_o = 135.09128214951315
J_b = 0.017758090913615677, J_o = 12.528623950879513
J_b = 0.017906323925400303, J_o = 9.649547455539675
J_b = 0.01958689589078946, J_o = 5.812360423452852
J_b = 0.022475831496097085, J_o = 3.1831544528902116
J_b = 0.024426941165099834, J_o = 2.7172276526941563
J_b = 0.024138112257456556, J_o = 2.4210376857470357
J_b = 0.0241378218398368, J_o = 2.3009596249104285
J_b = 0.024662499351988547, J_o = 1.8884511154212247
J_b = 0.025782935375718664, J_o = 1.5847581939093038
J_b = 0.028291618598480686, J_o = 1.0181253035124318
J_b = 0.03312921136673151, J_o = 0.5147469194038292
J_b = 0.035750013115587204, J_o = 17.80978133756633
J_b = 0.033149165962395685, J_o = 0.5134838414779263
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
W_opt:  [-0.05357431 -0.05216881 -0.05087784 -0.04957644 -0.04822346 -0.04694602
 -0.045926   -0.04511186 -0.04443215 -0.04383231]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0559 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1323, add (DA)= 0.0001decode = 0.1353 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1913 s, inc stats = 0.2006, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.03995245e-10 4.14750148e-10 4.92397964e-10 1.41813817e-10
 1.83220418e-09]
u_DA:    [2.57700187e-09 4.82895824e-09 6.55994181e-09 3.61422948e-09
 8.82913997e-09]
ref_MAE: [6.89243175e-09 1.00769455e-08 1.25675350e-08 8.40234842e-09
 1.86317855e-08]
da_MAE:  [2.47300663e-09 4.41420809e-09 6.06754385e-09 3.47241566e-09
 6.99693578e-09]
% 9.414286770410774 da_MAE 0.1028099512551841 ref_MAE 0.11349466443412835
u_c taken from control states: [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
u_c before reduction of space:  [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
data[u_c] post encoding of state:  [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
J_b = 0.0, J_o = 13229.482213614867
J_b = 0.5, J_o = 836203.9944131046
J_b = 0.00615744544011025, J_o = 203.60140715380481
J_b = 0.006159690053239476, J_o = 200.45253763307704
J_b = 0.006183632593284565, J_o = 188.19177556529587
J_b = 0.006518828153915922, J_o = 144.50418353624966
J_b = 0.0187917137060156, J_o = 14.606883237392534
J_b = 0.018633089050482013, J_o = 11.263791326562146
J_b = 0.019295233254528837, J_o = 8.361763831328917
J_b = 0.022853724831813485, J_o = 3.9144973453380807
J_b = 0.02532841754673855, J_o = 2.8424779373066005
J_b = 0.026901677247026516, J_o = 2.4366344064336958
J_b = 0.028189051757117063, J_o = 2.052954281471627
J_b = 0.03135674676440919, J_o = 1.3135953378292449
J_b = 0.035920965925542864, J_o = 0.7352615228914958
J_b = 0.03813786049322618, J_o = 0.6852006776656466
J_b = 0.036941892511508714, J_o = 0.5759337885817105
J_b = 0.03665407061947745, J_o = 0.5688990502719564
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
W_opt:  [-0.05714149 -0.05558649 -0.05415143 -0.05267089 -0.05111044 -0.04965442
 -0.04854281 -0.04771318 -0.04706463 -0.04652448]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0540 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1192, add (DA)= 0.0001decode = 0.1221 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1763 s, inc stats = 0.1885, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.03530716e-10 4.09244947e-10 4.86817668e-10 1.40494641e-10
 1.81626363e-09]
u_DA:    [2.58515244e-09 4.85076424e-09 6.56567340e-09 3.62145032e-09
 8.84537328e-09]
ref_MAE: [6.89289628e-09 1.00824507e-08 1.25731153e-08 8.40366760e-09
 1.86477260e-08]
da_MAE:  [2.48162172e-09 4.44151929e-09 6.07885573e-09 3.48095568e-09
 7.02910965e-09]
% 9.280592965742304 da_MAE 0.1033793421516705 ref_MAE 0.11395504614865055
u_c taken from control states: [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
u_c before reduction of space:  [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
data[u_c] post encoding of state:  [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
J_b = 0.0, J_o = 13210.872608101556
J_b = 0.4999999999999998, J_o = 836445.270622381
J_b = 0.006143605073833163, J_o = 214.33540735227274
J_b = 0.006145935939482865, J_o = 211.065235907381
J_b = 0.006170798506413044, J_o = 198.32575978728002
J_b = 0.006518874443435687, J_o = 152.82720985832898
J_b = 0.019698152331980252, J_o = 16.861267825264633
J_b = 0.019282866750732926, J_o = 13.004544768006753
J_b = 0.019530126701519393, J_o = 10.644392074078265
J_b = 0.024642292429676384, J_o = 4.2638301900830085
J_b = 0.026847998112269372, J_o = 3.3370129347020283
J_b = 0.028743976396262094, J_o = 2.818976641381916
J_b = 0.030393511550643702, J_o = 2.35787072284503
J_b = 0.033785083045428134, J_o = 1.6022886044214624
J_b = 0.04223664897514584, J_o = 1.6666379173009256
J_b = 0.03726967731429548, J_o = 1.1523670710380383
J_b = 0.040488297840996015, J_o = 0.7596778619652423
J_b = 0.040663864563474615, J_o = 0.684943825732694
J_b = 0.04060106671606142, J_o = 0.6975843198275331
J_b = 0.04063444607773487, J_o = 0.6734121600848358
J_b = 0.04050394821459591, J_o = 0.6442418011610046
J_b = 0.040598976879912124, J_o = 0.6199497471282905
J_b = 0.04139000469249854, J_o = 0.5690414288253967
J_b = 0.04214489020404465, J_o = 0.5494292768752784
J_b = 0.04248624043196611, J_o = 0.5422602534981765
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
W_opt:  [-0.06074988 -0.05903106 -0.05741107 -0.05568337 -0.0538301  -0.05211952
 -0.05087769 -0.05002611 -0.0494197  -0.04895887]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0638 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1206, add (DA)= 0.0001decode = 0.1235 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1874 s, inc stats = 0.2011, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.02948367e-10 4.04471064e-10 4.81478930e-10 1.38759006e-10
 1.80056035e-09]
u_DA:    [2.59145778e-09 4.85864079e-09 6.56742667e-09 3.62043173e-09
 8.84731997e-09]
ref_MAE: [6.89347863e-09 1.00872246e-08 1.25784540e-08 8.40540324e-09
 1.86634293e-08]
da_MAE:  [2.48850942e-09 4.45416972e-09 6.08594774e-09 3.48167273e-09
 7.04675962e-09]
% 9.209485050850567 da_MAE 0.10383311218864504 ref_MAE 0.11436559451920786
\% improve_point: 8.19, mse_ref_points: 1.1876968187108642e-05, mse_da_points: 1.0895824356545138e-05, % improve_overlap: 9.28, mse_ref_overlap: 0.18383, mse_da_overlap: 0.16694
DA - - L2: 1248.71, L1: 1918.04, % Improve: 9.46%, DA_MAE: 0.08, mse_ref: 0.19, mse_DA: 0.177, time(s): 0.6535s,
u_c taken from control states: [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
u_c before reduction of space:  [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
data[u_c] post encoding of state:  [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
J_b = 0.0, J_o = 13198.871817489257
J_b = 0.5000000000000001, J_o = 836603.4601662864
J_b = 0.006134551142342448, J_o = 221.52977854330538
J_b = 0.00613693773362794, J_o = 218.18123224764463
J_b = 0.006162394707339844, J_o = 205.13234516519697
J_b = 0.006518792339306411, J_o = 158.46156643853095
J_b = 0.020297246461784477, J_o = 18.61199010859079
J_b = 0.019725162246610403, J_o = 14.367604577865594
J_b = 0.019817156358523456, J_o = 12.14103298499044
J_b = 0.02468221255453439, J_o = 5.268346506066546
J_b = 0.026945471236474137, J_o = 4.2299909191853455
J_b = 0.028800194790244565, J_o = 3.620867087267902
J_b = 0.03153039656260755, J_o = 2.7579506978984814
J_b = 0.03526836537496007, J_o = 1.8711131499123723
J_b = 0.04448595576154248, J_o = 0.9942225861168079
J_b = 0.04617558392092911, J_o = 0.7805947423302649
J_b = 0.044274559178838345, J_o = 0.7145075626411905
J_b = 0.04386046699960825, J_o = 0.6962427327811251
J_b = 0.04302237517019868, J_o = 0.8476960813564366
J_b = 0.04369970378040593, J_o = 0.6887367897298204
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
W_opt:  [-0.06211942 -0.06029276 -0.05860178 -0.05680221 -0.0548737  -0.05310474
 -0.05184381 -0.05100792 -0.05043973 -0.0500323 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0514 s, v_trunc (Latent to Reduced) = 0.0175, dec (Reduced to Full) = 0.1000, add (DA)= 0.0001decode = 0.1193 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1708 s, inc stats = 0.1768, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.02207902e-10 4.00341711e-10 4.76432321e-10 1.36578941e-10
 1.78504688e-09]
u_DA:    [2.59100327e-09 4.86622902e-09 6.57263182e-09 3.62276286e-09
 8.84981993e-09]
ref_MAE: [6.89421909e-09 1.00913539e-08 1.25835006e-08 8.40758330e-09
 1.86789428e-08]
da_MAE:  [2.48879537e-09 4.46588731e-09 6.09619950e-09 3.48618392e-09
 7.06477305e-09]
% 9.080503445262028 da_MAE 0.1042838648237668 ref_MAE 0.11469912260345923
u_c taken from control states: [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
u_c before reduction of space:  [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
data[u_c] post encoding of state:  [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
J_b = 0.0, J_o = 13192.193089053117
J_b = 0.49999999999999994, J_o = 836695.8808334963
J_b = 0.006129278633163635, J_o = 226.03026959529572
J_b = 0.006131699119693163, J_o = 222.6340469629564
J_b = 0.006157517642674828, J_o = 209.3968432942645
J_b = 0.006518976964418543, J_o = 162.01101839014288
J_b = 0.020671343326387544, J_o = 19.80186510677384
J_b = 0.020006159892022184, J_o = 15.299158841378606
J_b = 0.020022366884279413, J_o = 13.084752257861549
J_b = 0.024203473597734112, J_o = 6.298913911368213
J_b = 0.02678983912973886, J_o = 4.878624200577043
J_b = 0.029128225587719818, J_o = 4.013357010801308
J_b = 0.03140142413933085, J_o = 3.306957526858212
J_b = 0.03395085230615332, J_o = 2.625188803005183
J_b = 0.041250938813355634, J_o = 1.412347504079199
J_b = 0.050995901191765274, J_o = 1.7492933010096139
J_b = 0.044762416855816015, J_o = 1.1269379792029992
J_b = 0.046470535207073116, J_o = 0.8468390631722433
J_b = 0.04614303085687637, J_o = 1.025466299297461
J_b = 0.046425920665975604, J_o = 0.8427304112799034
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
W_opt:  [-0.06436006 -0.06241407 -0.06063177 -0.05873877 -0.05671086 -0.05485541
 -0.05354339 -0.05268708 -0.05211881 -0.05172486]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0582 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1247, add (DA)= 0.0001decode = 0.1276 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1859 s, inc stats = 0.1936, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.01309961e-10 3.96659282e-10 4.71740027e-10 1.34058826e-10
 1.76969470e-09]
u_DA:    [2.59299885e-09 4.87009080e-09 6.57806019e-09 3.62473189e-09
 8.84994561e-09]
ref_MAE: [6.89511703e-09 1.00950363e-08 1.25881929e-08 8.41010342e-09
 1.86942950e-08]
da_MAE:  [2.49168889e-09 4.47343152e-09 6.10632016e-09 3.49067306e-09
 7.08025091e-09]
% 8.973370764076144 da_MAE 0.10463300343329646 ref_MAE 0.11494768543181737
u_c taken from control states: [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
u_c before reduction of space:  [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
data[u_c] post encoding of state:  [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
J_b = 0.0, J_o = 13187.943629421756
J_b = 0.4999999999999998, J_o = 836757.2945624421
J_b = 0.006125783840065376, J_o = 229.1914781123923
J_b = 0.0061282277995338245, J_o = 225.76223852313802
J_b = 0.0061542967005306076, J_o = 212.3946108734003
J_b = 0.0065192613144854986, J_o = 164.51339159092058
J_b = 0.020932396297495024, J_o = 20.676937133392567
J_b = 0.020205200375202917, J_o = 15.987400395962347
J_b = 0.02017476260867574, J_o = 13.751847792169944
J_b = 0.023688889541850944, J_o = 7.101482228353159
J_b = 0.026617040367894588, J_o = 5.428655168147483
J_b = 0.029255190039527375, J_o = 4.1824929093599685
J_b = 0.03174749268969314, J_o = 3.4982293612412105
J_b = 0.03433544468325707, J_o = 2.855401729952497
J_b = 0.03990117623307706, J_o = 1.7868955756996263
J_b = 0.04842213702663293, J_o = 0.8895535042358228
J_b = 0.04971493228339148, J_o = 0.853573699931671
J_b = 0.0485935857047789, J_o = 1.050924994192111
J_b = 0.04951553153021417, J_o = 0.8443331524622693
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
W_opt:  [-0.06550874 -0.06350949 -0.06165615 -0.05965595 -0.05749602 -0.05552714
 -0.05416311 -0.053309   -0.05277416 -0.05243155]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0551 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1329, add (DA)= 0.0001decode = 0.1358 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1910 s, inc stats = 0.2048, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.00263577e-10 3.93239796e-10 4.67427077e-10 1.31357262e-10
 1.75448519e-09]
u_DA:    [2.59964826e-09 4.87713587e-09 6.57786046e-09 3.62708026e-09
 8.85192371e-09]
ref_MAE: [6.89616342e-09 1.00984558e-08 1.25925059e-08 8.41280498e-09
 1.87095045e-08]
da_MAE:  [2.49938468e-09 4.48389607e-09 6.11043338e-09 3.49572300e-09
 7.09743853e-09]
% 8.765440670893016 da_MAE 0.10494867821888226 ref_MAE 0.11503171494510633
u_c taken from control states: [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
u_c before reduction of space:  [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
data[u_c] post encoding of state:  [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
J_b = 0.0, J_o = 13186.706562849995
J_b = 0.5000000000000002, J_o = 836781.8888384465
J_b = 0.0061244017779156935, J_o = 230.88727453503648
J_b = 0.006126858147729857, J_o = 227.44057820937934
J_b = 0.006153059425747531, J_o = 214.00398495506766
J_b = 0.006519877317994523, J_o = 165.86068471089538
J_b = 0.021072157657547615, J_o = 21.15997386216826
J_b = 0.02031342638687243, J_o = 16.367861052897844
J_b = 0.020259908124988475, J_o = 14.111332724162352
J_b = 0.023401423763330646, J_o = 7.585536139504855
J_b = 0.026512462284138786, J_o = 5.747395941267292
J_b = 0.02928164698036525, J_o = 4.3511370771220275
J_b = 0.03172194489401553, J_o = 3.692294262180681
J_b = 0.03421587718557825, J_o = 3.065942941836115
J_b = 0.0373942288262314, J_o = 2.3373146537361595
J_b = 0.0473637799092695, J_o = 1.2108549920789786
J_b = 0.04919091613487208, J_o = 0.9366544357759233
J_b = 0.04854521712432695, J_o = 1.070166431923638
J_b = 0.0490711830846255, J_o = 0.9298167584267263
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
W_opt:  [-0.06563463 -0.06361027 -0.06175437 -0.05976486 -0.05762208 -0.05566843
 -0.05431126 -0.0534564  -0.0529176  -0.05257023]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0466 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1228, add (DA)= 0.0001decode = 0.1256 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1722 s, inc stats = 0.1843, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.90502069e-11 3.89950532e-10 4.63494194e-10 1.28592688e-10
 1.73939802e-09]
u_DA:    [2.59443704e-09 4.87310495e-09 6.57887221e-09 3.62404954e-09
 8.84882951e-09]
ref_MAE: [6.89737679e-09 1.01017451e-08 1.25964388e-08 8.41556955e-09
 1.87245916e-08]
da_MAE:  [2.49538684e-09 4.48315442e-09 6.11537801e-09 3.49545686e-09
 7.10943149e-09]
% 8.550398286414161 da_MAE 0.10520937854977237 ref_MAE 0.11504629498472968
u_c taken from control states: [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
u_c before reduction of space:  [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
data[u_c] post encoding of state:  [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
J_b = 0.0, J_o = 13190.176714682859
J_b = 0.5, J_o = 836750.4370691157
J_b = 0.006126237865725545, J_o = 230.47060311170256
J_b = 0.0061286911851663305, J_o = 227.02819859479717
J_b = 0.006154859925868027, J_o = 213.6085845654659
J_b = 0.006521222295691691, J_o = 165.5301930607807
J_b = 0.021038710229698672, J_o = 21.028171453268314
J_b = 0.02028999823856798, J_o = 16.261277268349765
J_b = 0.02024368540360563, J_o = 14.009104722366425
J_b = 0.023498726247379278, J_o = 7.441400161454882
J_b = 0.0265558452419238, J_o = 5.652479256451431
J_b = 0.02927584783875479, J_o = 4.278814394524613
J_b = 0.03178748246742711, J_o = 3.6192371696361834
J_b = 0.03439820171933927, J_o = 2.9837820707427025
J_b = 0.038199991669923494, J_o = 2.153171744002155
J_b = 0.04958482020710372, J_o = 1.170450078935583
J_b = 0.04903481277548731, J_o = 0.9152124776628068
J_b = 0.047962888456411966, J_o = 1.2341085483493082
J_b = 0.048948149854221114, J_o = 0.9129035192767582
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
W_opt:  [-0.06564938 -0.06362449 -0.06177311 -0.05979271 -0.05766118 -0.05571641
 -0.05436152 -0.05350329 -0.05295783 -0.05260195]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0730 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1225, add (DA)= 0.0001decode = 0.1256 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1987 s, inc stats = 0.2036, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.76627957e-11 3.86673885e-10 4.59914276e-10 1.25869968e-10
 1.72440351e-09]
u_DA:    [2.59442087e-09 4.87579851e-09 6.58033538e-09 3.62485628e-09
 8.85246196e-09]
ref_MAE: [6.89876420e-09 1.01050217e-08 1.26000187e-08 8.41829227e-09
 1.87395862e-08]
da_MAE:  [2.49675808e-09 4.48912462e-09 6.12042110e-09 3.49898632e-09
 7.12805845e-09]
% 8.270430935669568 da_MAE 0.10550631437036347 ref_MAE 0.11501887062869698
u_c taken from control states: [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
u_c before reduction of space:  [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
data[u_c] post encoding of state:  [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
J_b = 0.0, J_o = 13197.393114432442
J_b = 0.5, J_o = 836674.7115617271
J_b = 0.006130618484545486, J_o = 228.4080494202915
J_b = 0.006133056625424938, J_o = 224.98699740378328
J_b = 0.006159063461472387, J_o = 211.6517819858221
J_b = 0.006523159166136481, J_o = 163.89480268312803
J_b = 0.02086960673894061, J_o = 20.42604782559641
J_b = 0.020164065207998714, J_o = 15.783521414947014
J_b = 0.02014956034801958, J_o = 13.55081847914851
J_b = 0.023895199838492216, J_o = 6.844189017052342
J_b = 0.026707488033894337, J_o = 5.247555618860183
J_b = 0.029298239533632895, J_o = 4.12719529200679
J_b = 0.03167435147852961, J_o = 3.4349433352399834
J_b = 0.034200417044789225, J_o = 2.7870875380071025
J_b = 0.040523017132413436, J_o = 1.6261916479750307
J_b = 0.05100879056648119, J_o = 1.665919394896368
J_b = 0.0450874143549772, J_o = 1.23658176416527
J_b = 0.048255263135508715, J_o = 0.8411391623822271
J_b = 0.04790520165578432, J_o = 2.5748904203919842
J_b = 0.0482490063525573, J_o = 0.8406138713243247
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
W_opt:  [-0.064989   -0.06300123 -0.0611849  -0.05924687 -0.05716272 -0.05525754
 -0.05392091 -0.05306267 -0.05250588 -0.05213178]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0489 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1210, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1728 s, inc stats = 0.1864, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.61191778e-11 3.83301686e-10 4.56662862e-10 1.23277038e-10
 1.70947493e-09]
u_DA:    [2.59498342e-09 4.87112947e-09 6.57827438e-09 3.62462104e-09
 8.84959999e-09]
ref_MAE: [6.90030782e-09 1.01083939e-08 1.26032701e-08 8.42088520e-09
 1.87545147e-08]
da_MAE:  [2.49886424e-09 4.48782779e-09 6.12161151e-09 3.50134400e-09
 7.14012505e-09]
% 8.081709573699511 da_MAE 0.10572091334492568 ref_MAE 0.1150161875885758
u_c taken from control states: [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
u_c before reduction of space:  [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
data[u_c] post encoding of state:  [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
J_b = 0.0, J_o = 13205.92222185505
J_b = 0.5000000000000001, J_o = 836583.1714490554
J_b = 0.00613590916311417, J_o = 225.72949900656116
J_b = 0.00613832751511599, J_o = 222.33628642721862
J_b = 0.006164123269802034, J_o = 209.11113534291724
J_b = 0.0065252638354064176, J_o = 161.77371873481306
J_b = 0.020647123152570005, J_o = 19.665736103052097
J_b = 0.01999997008282526, J_o = 15.183599585239387
J_b = 0.0200304367138804, J_o = 12.959691011373796
J_b = 0.024354098909340635, J_o = 6.1544299208191475
J_b = 0.026879758617237362, J_o = 4.771673768421501
J_b = 0.029121613361794946, J_o = 3.9653730399747285
J_b = 0.03142031511743801, J_o = 3.245725940320392
J_b = 0.034028728240866904, J_o = 2.5477167951053543
J_b = 0.04171258436908664, J_o = 1.3423619230930246
J_b = 0.04976822981942461, J_o = 1.3736632444798218
J_b = 0.04529160579874592, J_o = 1.033609225603815
J_b = 0.046246655162149576, J_o = 0.8155861737710963
J_b = 0.0459301729419969, J_o = 0.8711982561653042
J_b = 0.046164330971181174, J_o = 0.8086194476329583
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
W_opt:  [-0.06380194 -0.06187513 -0.06012302 -0.05826847 -0.05628167 -0.05445997
 -0.0531642  -0.05230991 -0.05173484 -0.05132925]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1047 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1212, add (DA)= 0.0001decode = 0.1240 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2289 s, inc stats = 0.2413, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.44567615e-11 3.79764643e-10 4.53722408e-10 1.20876996e-10
 1.69459192e-09]
u_DA:    [2.59105419e-09 4.86643084e-09 6.57530466e-09 3.62361682e-09
 8.84620251e-09]
ref_MAE: [6.90197023e-09 1.01119310e-08 1.26062105e-08 8.42328525e-09
 1.87693977e-08]
da_MAE:  [2.49659743e-09 4.48666620e-09 6.12158225e-09 3.50273982e-09
 7.15161059e-09]
% 7.964056839871693 da_MAE 0.1058437173604183 ref_MAE 0.11500258890840788
u_c taken from control states: [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
u_c before reduction of space:  [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
data[u_c] post encoding of state:  [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
J_b = 0.0, J_o = 13215.264269979745
J_b = 0.4999999999999998, J_o = 836481.8540143984
J_b = 0.006141764482567514, J_o = 222.6671196652382
J_b = 0.0061441600210215535, J_o = 219.3060017384543
J_b = 0.006169712431198007, J_o = 206.2077368046964
J_b = 0.006527446173668592, J_o = 159.35398544370528
J_b = 0.02039101327292741, J_o = 18.82666421089739
J_b = 0.01981282384759211, J_o = 14.525501970327262
J_b = 0.019900254280201923, J_o = 12.28813682272705
J_b = 0.02470262922249602, J_o = 5.419313821055968
J_b = 0.027020051724213633, J_o = 4.311658236095019
J_b = 0.028896600569746547, J_o = 3.686087267815389
J_b = 0.03159187639999648, J_o = 2.833341058584819
J_b = 0.03506039581692578, J_o = 1.9846794288331076
J_b = 0.044562713811618714, J_o = 1.032640371648419
J_b = 0.04662433128268219, J_o = 0.8167700857813944
J_b = 0.044596011281997465, J_o = 0.7300849227898683
J_b = 0.04418759613812287, J_o = 0.7099802409696687
J_b = 0.04406649003260132, J_o = 3.1646979558157797
J_b = 0.04418533991118285, J_o = 0.709513385616213
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
W_opt:  [-0.06221888 -0.06037218 -0.05868932 -0.05691237 -0.05501054 -0.05326156
 -0.05200456 -0.05115986 -0.05057589 -0.05014979]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0513 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1369, add (DA)= 0.0001decode = 0.1398 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1913 s, inc stats = 0.2033, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.27152583e-11 3.76038309e-10 4.51054278e-10 1.18705230e-10
 1.67973821e-09]
u_DA:    [2.59053809e-09 4.86433542e-09 6.57253286e-09 3.62328098e-09
 8.84678310e-09]
ref_MAE: [6.90371174e-09 1.01156573e-08 1.26088787e-08 8.42545701e-09
 1.87842515e-08]
da_MAE:  [2.49782284e-09 4.48829712e-09 6.12147858e-09 3.50457575e-09
 7.16704489e-09]
% 7.870982104901418 da_MAE 0.10592514228555622 ref_MAE 0.114974787212175
u_c taken from control states: [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
u_c before reduction of space:  [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
data[u_c] post encoding of state:  [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
J_b = 0.0, J_o = 13224.278269924442
J_b = 0.4999999999999999, J_o = 836383.7704410679
J_b = 0.006147434876575233, J_o = 219.66816117884724
J_b = 0.006149807907140283, J_o = 216.3387084841347
J_b = 0.006175120233167499, J_o = 203.36564171583345
J_b = 0.006529492797548415, J_o = 156.98927881140654
J_b = 0.02013818759809285, J_o = 18.03515722688924
J_b = 0.019630166717303322, J_o = 13.908760387602383
J_b = 0.01978160595311689, J_o = 11.63100034920638
J_b = 0.02488565349545906, J_o = 4.771216697818624
J_b = 0.027066469126740485, J_o = 3.8862094951847133
J_b = 0.029210445229853735, J_o = 3.2419791596679004
J_b = 0.031616656575024216, J_o = 2.5324115409096164
J_b = 0.03625949187957315, J_o = 1.5601948477325867
J_b = 0.043579747119631654, J_o = 1.1759045069076144
J_b = 0.0434079054403339, J_o = 0.7514116342173621
J_b = 0.04269108395735325, J_o = 0.7232317707708571
J_b = 0.04248690854834184, J_o = 0.7022588413475048
J_b = 0.04235133228535037, J_o = 0.6640011660794497
J_b = 0.04295031965062047, J_o = 0.6362747974638755
J_b = 0.0443220500277825, J_o = 0.6106393813540402
J_b = 0.04476118409321692, J_o = 0.6276383268813637
J_b = 0.04445447434825849, J_o = 0.606153753139354
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
W_opt:  [-0.06161391 -0.05981678 -0.05815778 -0.05639445 -0.05449943 -0.05275112
 -0.05148803 -0.05063158 -0.05003076 -0.04958346]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0581 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1847 s, inc stats = 0.1953, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.09474564e-11 3.72125834e-10 4.48603293e-10 1.16789300e-10
 1.66491394e-09]
u_DA:    [2.59063822e-09 4.85957298e-09 6.56770186e-09 3.62052452e-09
 8.84389790e-09]
ref_MAE: [6.90547954e-09 1.01195698e-08 1.26113297e-08 8.42737294e-09
 1.87990757e-08]
da_MAE:  [2.49969076e-09 4.48744714e-09 6.11909857e-09 3.50373522e-09
 7.17898396e-09]
% 7.7946118032221205 da_MAE 0.1060138405508849 ref_MAE 0.11497575426355568
u_c taken from control states: [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
u_c before reduction of space:  [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
data[u_c] post encoding of state:  [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
J_b = 0.0, J_o = 13231.820665568866
J_b = 0.4999999999999998, J_o = 836302.9227017319
J_b = 0.006152114896715674, J_o = 217.29627866777582
J_b = 0.006154470099798552, J_o = 213.99190901826108
J_b = 0.00617959226601593, J_o = 201.11806366577463
J_b = 0.006531302593059207, J_o = 155.12081418499142
J_b = 0.019935353121012536, J_o = 17.427782942604793
J_b = 0.019486168793093856, J_o = 13.438528891645374
J_b = 0.019697878764787808, J_o = 11.10425995077668
J_b = 0.024884156419538783, J_o = 4.451420815122417
J_b = 0.027053038467126842, J_o = 3.5416610152843218
J_b = 0.029453508561484276, J_o = 2.88017175840243
J_b = 0.031091557187212272, J_o = 2.417862346549761
J_b = 0.03675803483972871, J_o = 1.3178987708294696
J_b = 0.04378322329125225, J_o = 1.436734535616626
J_b = 0.03953167300682452, J_o = 1.0084390209761152
J_b = 0.04270896317451536, J_o = 0.6757496784678428
J_b = 0.042506850277702755, J_o = 0.6334019161893365
J_b = 0.04258161423752973, J_o = 0.5979676466086612
J_b = 0.04315672599178887, J_o = 5.568561375977893
J_b = 0.04258464871987059, J_o = 0.5977932224145567
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
W_opt:  [-0.06072249 -0.05897459 -0.05737053 -0.0556819  -0.05387583 -0.05220405
 -0.05097793 -0.0501237  -0.04950466 -0.04902718]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0521 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1331, add (DA)= 0.0001decode = 0.1359 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1881 s, inc stats = 21.7617, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.91985705e-11 3.68062815e-10 4.46302928e-10 1.15139571e-10
 1.65011577e-09]
u_DA:    [2.58876065e-09 4.85677525e-09 6.56693141e-09 3.62116827e-09
 8.84338835e-09]
ref_MAE: [6.90722842e-09 1.01236328e-08 1.26136300e-08 8.42902267e-09
 1.88138739e-08]
da_MAE:  [2.49956208e-09 4.48871243e-09 6.12062849e-09 3.50602870e-09
 7.19327258e-09]
% 7.704085730020142 da_MAE 0.10616369415481172 ref_MAE 0.11502534537364943
\% improve_point: 8.00, mse_ref_points: 1.2774427857187086e-05, mse_da_points: 1.1753912644034035e-05, % improve_overlap: 8.84, mse_ref_overlap: 0.19899, mse_da_overlap: 0.18188
DA - - L2: 1694.02, L1: 2234.20, % Improve: 9.27%, DA_MAE: 0.08, mse_ref: 0.21, mse_DA: 0.190, time(s): 0.9332s,
u_c taken from control states: [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
u_c before reduction of space:  [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
data[u_c] post encoding of state:  [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
J_b = 0.0, J_o = 13239.575333259383
J_b = 0.49999999999999983, J_o = 836219.6254382759
J_b = 0.0061569380922678165, J_o = 214.83322880794333
J_b = 0.006159274732461278, J_o = 211.5549786878809
J_b = 0.006184198894524858, J_o = 198.78448904240557
J_b = 0.006533137163414922, J_o = 153.18270381689268
J_b = 0.01972221688000123, J_o = 16.817642971939524
J_b = 0.019336867880607626, J_o = 12.968691281635412
J_b = 0.019622794046005382, J_o = 10.549708783755733
J_b = 0.02460645031786751, J_o = 4.315915071645541
J_b = 0.026942826584864455, J_o = 3.326220302155074
J_b = 0.028691542754935823, J_o = 2.8514593986166057
J_b = 0.03039300553402031, J_o = 2.3746464879894313
J_b = 0.03337580259151451, J_o = 1.681543486191188
J_b = 0.04000318750087377, J_o = 1.0129960869150614
J_b = 0.04140941114783703, J_o = 0.73823959987948
J_b = 0.04051374083908038, J_o = 0.6937896786110798
J_b = 0.040042449207536725, J_o = 0.8309020411436616
J_b = 0.040445593121980004, J_o = 0.6900847459467858
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
W_opt:  [-0.05973115 -0.05802954 -0.05648867 -0.05489306 -0.05320209 -0.05163187
 -0.0504578  -0.04961215 -0.04897657 -0.04846841]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1553 s, v_trunc (Latent to Reduced) = 0.0040, dec (Reduced to Full) = 0.1597, add (DA)= 0.0001decode = 0.1657 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3211 s, inc stats = 0.3335, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.74868470e-11 3.63921007e-10 4.44095001e-10 1.13726641e-10
 1.63532979e-09]
u_DA:    [2.58423000e-09 4.85278892e-09 6.56817226e-09 3.62186252e-09
 8.84048676e-09]
ref_MAE: [6.90894015e-09 1.01277746e-08 1.26158379e-08 8.43043560e-09
 1.88286599e-08]
da_MAE:  [2.49674315e-09 4.48886792e-09 6.12407726e-09 3.50813588e-09
 7.20515697e-09]
% 7.610743008205961 da_MAE 0.1063756929046332 ref_MAE 0.11513859551233475
u_c taken from control states: [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
u_c before reduction of space:  [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
data[u_c] post encoding of state:  [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
J_b = 0.0, J_o = 13248.039876648658
J_b = 0.4999999999999998, J_o = 836127.6325241785
J_b = 0.00616226445073478, J_o = 212.0132843942589
J_b = 0.006164579405885564, J_o = 208.76554403861041
J_b = 0.006189272260827275, J_o = 196.11572235669695
J_b = 0.00653497223001108, J_o = 150.97467147993012
J_b = 0.01947793795153522, J_o = 16.160112348826253
J_b = 0.019166896594731288, J_o = 12.463571927275694
J_b = 0.019553675843069985, J_o = 9.916250819723473
J_b = 0.024041627632324095, J_o = 4.2453335714158875
J_b = 0.026529564846885283, J_o = 3.1847192687255577
J_b = 0.028118338203329696, J_o = 2.7682502922228664
J_b = 0.029722275747090913, J_o = 2.3061409541805626
J_b = 0.032355417681675734, J_o = 1.6772320537009873
J_b = 0.037907954163968645, J_o = 0.9551168983703668
J_b = 0.04001099863482825, J_o = 0.7347724704691176
J_b = 0.03943004915175012, J_o = 0.6821825089862279
J_b = 0.038934657876863135, J_o = 1.0931412141043078
J_b = 0.039399282388736516, J_o = 0.6805162034555395
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
W_opt:  [-0.05890454 -0.05725027 -0.05575214 -0.05420927 -0.052579   -0.05105989
 -0.04990885 -0.04906164 -0.04840946 -0.04787548]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0876 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.4026, add (DA)= 0.0001decode = 0.4056 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4933 s, inc stats = 0.4992, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.58490690e-11 3.59746263e-10 4.41930800e-10 1.12519721e-10
 1.62055892e-09]
u_DA:    [2.58313037e-09 4.84917048e-09 6.56675292e-09 3.62126023e-09
 8.83880646e-09]
ref_MAE: [6.91057792e-09 1.01319494e-08 1.26180021e-08 8.43164252e-09
 1.88434307e-08]
da_MAE:  [2.49728130e-09 4.48942422e-09 6.12482212e-09 3.50874051e-09
 7.21824754e-09]
% 7.526601000303323 da_MAE 0.10662439671543801 ref_MAE 0.11530277665665534
u_c taken from control states: [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
u_c before reduction of space:  [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
data[u_c] post encoding of state:  [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
J_b = 0.0, J_o = 13254.605582631644
J_b = 0.5000000000000001, J_o = 836056.8193443638
J_b = 0.006166367973397835, J_o = 209.88542566029577
J_b = 0.006168666514374462, J_o = 206.6607804085873
J_b = 0.006193184284791803, J_o = 194.10232398621005
J_b = 0.006536433070634445, J_o = 149.3104916480074
J_b = 0.019292201421758918, J_o = 15.679683601501605
J_b = 0.019039518483604533, J_o = 12.095443985711885
J_b = 0.01951933114024349, J_o = 9.425459156334448
J_b = 0.02361153102062799, J_o = 4.205402331784126
J_b = 0.026161943254355696, J_o = 3.0889932418055848
J_b = 0.027869826818455352, J_o = 2.6600396730310583
J_b = 0.02923796876472424, J_o = 2.257433385731151
J_b = 0.03234048329269338, J_o = 1.5485756630314014
J_b = 0.040336669947966086, J_o = 1.973481420003354
J_b = 0.035003392706941056, J_o = 1.1909418861580514
J_b = 0.037343566885250645, J_o = 0.8317836129658653
J_b = 0.03806811852315821, J_o = 0.7186519112484374
J_b = 0.0382711895587887, J_o = 0.8065284291662342
J_b = 0.03811084759615234, J_o = 0.7102804116297312
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
W_opt:  [-0.05784503 -0.05623918 -0.05478863 -0.05330445 -0.0517422  -0.05028275
 -0.04916444 -0.04832647 -0.04766916 -0.04712139]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0885 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.1416, add (DA)= 0.0001decode = 0.1459 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2345 s, inc stats = 0.2405, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.43364723e-11 3.55566605e-10 4.39768385e-10 1.11517321e-10
 1.60581724e-09]
u_DA:    [2.58038094e-09 4.84474208e-09 6.56619034e-09 3.61953549e-09
 8.83700458e-09]
ref_MAE: [6.91209052e-09 1.01361290e-08 1.26201646e-08 8.43264492e-09
 1.88581724e-08]
da_MAE:  [2.49604447e-09 4.48917548e-09 6.12642195e-09 3.50801817e-09
 7.23118734e-09]
% 7.465624574603299 da_MAE 0.10691615197662553 ref_MAE 0.11554209069344586
u_c taken from control states: [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
u_c before reduction of space:  [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
data[u_c] post encoding of state:  [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
J_b = 0.0, J_o = 13258.749069905192
J_b = 0.5, J_o = 836014.2774671363
J_b = 0.006168840527830657, J_o = 208.79181438069833
J_b = 0.006171130811003874, J_o = 205.57879146364718
J_b = 0.006195560498184849, J_o = 193.06638228303126
J_b = 0.006537576118718603, J_o = 148.45166536199105
J_b = 0.01919481582165709, J_o = 15.429066243664007
J_b = 0.018974687629225568, J_o = 11.904354447188826
J_b = 0.01951278076165903, J_o = 9.157940837551347
J_b = 0.02341309346260002, J_o = 4.182609919836292
J_b = 0.025986919258059085, J_o = 3.044668760393663
J_b = 0.027706237957639997, J_o = 2.6146822240242615
J_b = 0.02902066342779634, J_o = 2.223450623811071
J_b = 0.032444763791768, J_o = 1.4522412068867658
J_b = 0.0405426898418019, J_o = 2.4881143921174655
J_b = 0.034472313255589596, J_o = 1.181720376811282
J_b = 0.03683037601752352, J_o = 0.8367870734076857
J_b = 0.03755398630762487, J_o = 0.7204858704173835
J_b = 0.037825491419457895, J_o = 1.0000451486236392
J_b = 0.037585659309586655, J_o = 0.713979643693506
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
W_opt:  [-0.05735728 -0.0557756  -0.05434709 -0.0528894  -0.05135762 -0.04992467
 -0.04882056 -0.04798594 -0.04732515 -0.04676965]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0920 s, v_trunc (Latent to Reduced) = 0.0024, dec (Reduced to Full) = 0.3656, add (DA)= 0.0001decode = 0.3699 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4620 s, inc stats = 0.4968, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.29778739e-11 3.51434584e-10 4.37563745e-10 1.10733856e-10
 1.59112741e-09]
u_DA:    [2.58373523e-09 4.84663299e-09 6.56842983e-09 3.62166217e-09
 8.84152226e-09]
ref_MAE: [6.91344912e-09 1.01402610e-08 1.26223692e-08 8.43342839e-09
 1.88728623e-08]
da_MAE:  [2.50075736e-09 4.49519841e-09 6.13086609e-09 3.51092831e-09
 7.25039485e-09]
% 7.399283265524979 da_MAE 0.1072733595639196 ref_MAE 0.11584506399828112
u_c taken from control states: [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
u_c before reduction of space:  [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
data[u_c] post encoding of state:  [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
J_b = 0.0, J_o = 13261.419995159886
J_b = 0.5, J_o = 835988.3944389906
J_b = 0.006170349801345876, J_o = 208.26692941780897
J_b = 0.0061726364078353475, J_o = 205.0590859274675
J_b = 0.006197026877056424, J_o = 192.56729259119257
J_b = 0.006538493446151572, J_o = 148.033409247552
J_b = 0.019145483641810537, J_o = 15.29868385999109
J_b = 0.018943746485525336, J_o = 11.805815410080204
J_b = 0.019517363865413213, J_o = 9.012616263503734
J_b = 0.023321061947629593, J_o = 4.170364311100917
J_b = 0.025904649595585843, J_o = 3.0239480445227933
J_b = 0.027613845293071905, J_o = 2.595411726263671
J_b = 0.028925157815251047, J_o = 2.203990681392102
J_b = 0.032439900335816584, J_o = 1.4085238670665587
J_b = 0.03998155376665023, J_o = 2.386615612422921
J_b = 0.0343130111540121, J_o = 1.1630192573109916
J_b = 0.03677443291348495, J_o = 0.8171127873186006
J_b = 0.037479502578918744, J_o = 0.7054044183279008
J_b = 0.03775480199156532, J_o = 1.5303008112622591
J_b = 0.03749299671834139, J_o = 0.7023928699112107
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
W_opt:  [-0.05723686 -0.05566507 -0.0542438  -0.0527944  -0.0512721  -0.0498471
 -0.04874658 -0.04791152 -0.0472476  -0.04668709]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1565 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.4587, add (DA)= 0.0001decode = 0.4616 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.6183 s, inc stats = 0.6264, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.17914433e-11 3.47408930e-10 4.35272486e-10 1.10169090e-10
 1.57651248e-09]
u_DA:    [2.58275809e-09 4.84527718e-09 6.56763589e-09 3.62095560e-09
 8.84033512e-09]
ref_MAE: [6.91463555e-09 1.01442867e-08 1.26246605e-08 8.43399315e-09
 1.88874772e-08]
da_MAE:  [2.50096664e-09 4.49786825e-09 6.13236340e-09 3.51078651e-09
 7.26382264e-09]
% 7.359071213471318 da_MAE 0.10761324925523925 ref_MAE 0.11616166921557004
u_c taken from control states: [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
u_c before reduction of space:  [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
data[u_c] post encoding of state:  [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
J_b = 0.0, J_o = 13262.40483347494
J_b = 0.5000000000000001, J_o = 835981.8025077987
J_b = 0.006170743851779737, J_o = 208.41932623612308
J_b = 0.006173032226348002, J_o = 205.20900442034787
J_b = 0.006197441555076166, J_o = 192.70759630884882
J_b = 0.006539172157270501, J_o = 148.14003028847674
J_b = 0.019153444105228044, J_o = 15.309437366819385
J_b = 0.018952906548289416, J_o = 11.816315425699832
J_b = 0.019529745598620144, J_o = 9.017244004462002
J_b = 0.02332955486842849, J_o = 4.180698190583764
J_b = 0.025917374626399592, J_o = 3.0317350409652386
J_b = 0.027629711856191393, J_o = 2.6021434797203256
J_b = 0.028945250141342506, J_o = 2.2095182158822557
J_b = 0.03247569005641476, J_o = 1.4104769287558985
J_b = 0.03994968578459304, J_o = 2.343910757690118
J_b = 0.03436245162850158, J_o = 1.1639996450596566
J_b = 0.0368323790320211, J_o = 0.8177467357186142
J_b = 0.037533858403874285, J_o = 0.7068140524289873
J_b = 0.03780607146344095, J_o = 1.5004207398211646
J_b = 0.037547573531530716, J_o = 0.7037391342033816
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
W_opt:  [-0.05726014 -0.05569039 -0.05426973 -0.05282036 -0.05129808 -0.04987341
 -0.04877377 -0.0479399  -0.04727709 -0.04671752]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1373 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.3411, add (DA)= 0.0001decode = 0.3453 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4828 s, inc stats = 0.5249, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.07918373e-11 3.43531796e-10 4.32861043e-10 1.09819411e-10
 1.56200501e-09]
u_DA:    [2.58275671e-09 4.84525412e-09 6.56756946e-09 3.62094205e-09
 8.84024769e-09]
ref_MAE: [6.91563516e-09 1.01481638e-08 1.26270719e-08 8.43434283e-09
 1.89019847e-08]
da_MAE:  [2.50196487e-09 4.50172232e-09 6.13470842e-09 3.51112264e-09
 7.27824269e-09]
% 7.32378626447834 da_MAE 0.10790018562761025 ref_MAE 0.11642705423371588
u_c taken from control states: [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
u_c before reduction of space:  [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
data[u_c] post encoding of state:  [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
J_b = 0.0, J_o = 13260.907263064895
J_b = 0.5, J_o = 836004.1635733086
J_b = 0.0061694656359252515, J_o = 209.6334358606643
J_b = 0.006171764327635737, J_o = 206.40861208572315
J_b = 0.006196283705880863, J_o = 193.85012611478228
J_b = 0.006539555001312349, J_o = 149.06912829219812
J_b = 0.019251285255190983, J_o = 15.540194874767185
J_b = 0.019025057026262487, J_o = 11.996979063758486
J_b = 0.01955455360728956, J_o = 9.256526307041186
J_b = 0.023494973734097636, J_o = 4.227080149833441
J_b = 0.026078658430344428, J_o = 3.08456203086721
J_b = 0.027814873913657216, J_o = 2.649970209226231
J_b = 0.029147031982660995, J_o = 2.25434420802521
J_b = 0.03257481960562854, J_o = 1.4839710739891079
J_b = 0.04081288006199469, J_o = 2.477941293011664
J_b = 0.03468992732207177, J_o = 1.201207014797349
J_b = 0.037049831546811685, J_o = 0.852896986217647
J_b = 0.03778555571349167, J_o = 0.7349218397702661
J_b = 0.03805413318995265, J_o = 0.880687943295053
J_b = 0.03783395228035157, J_o = 0.7252649425648137
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
W_opt:  [-0.05750936 -0.05592991 -0.05449973 -0.05303763 -0.05150056 -0.05006414
 -0.04896093 -0.04813044 -0.04747504 -0.04692525]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1201 s, v_trunc (Latent to Reduced) = 0.0051, dec (Reduced to Full) = 0.1396, add (DA)= 0.0001decode = 0.1465 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2667 s, inc stats = 0.2754, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.99819758e-11 3.39852918e-10 4.30303309e-10 1.09656587e-10
 1.54763202e-09]
u_DA:    [2.58423722e-09 4.84728880e-09 6.56858437e-09 3.62198035e-09
 8.84178865e-09]
ref_MAE: [6.91644502e-09 1.01518427e-08 1.26296296e-08 8.43450565e-09
 1.89163576e-08]
da_MAE:  [2.50425525e-09 4.50743588e-09 6.13828106e-09 3.51232376e-09
 7.29415663e-09]
% 7.277061701273603 da_MAE 0.10813728649142457 ref_MAE 0.11662409375233301
u_c taken from control states: [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
u_c before reduction of space:  [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
data[u_c] post encoding of state:  [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
J_b = 0.0, J_o = 13257.125909491006
J_b = 0.4999999999999999, J_o = 836053.215747471
J_b = 0.006166646711934435, J_o = 211.82900144898883
J_b = 0.0061689635075825285, J_o = 208.57872349437838
J_b = 0.006193675994495578, J_o = 195.91991183702643
J_b = 0.006539650811278434, J_o = 150.76146778505836
J_b = 0.019432293326994126, J_o = 15.985279973017644
J_b = 0.019155965604682676, J_o = 12.343229822554452
J_b = 0.01960075681345385, J_o = 9.710494534996826
J_b = 0.02385607932850246, J_o = 4.29247379451049
J_b = 0.02640950807467937, J_o = 3.18190559606299
J_b = 0.02811140957367784, J_o = 2.7491660037666303
J_b = 0.029576798302687002, J_o = 2.322710041967764
J_b = 0.03251470622365884, J_o = 1.6407871162053456
J_b = 0.03959052465483584, J_o = 1.3641626750572406
J_b = 0.03849877328741087, J_o = 0.8145797463131952
J_b = 0.03827008968890963, J_o = 0.7522267420179918
J_b = 0.03848371915652277, J_o = 0.726626584190674
J_b = 0.038717756645925534, J_o = 0.6970248806211955
J_b = 0.03899150198497868, J_o = 0.6715659377816645
J_b = 0.04098584577918607, J_o = 0.5602727447932949
J_b = 0.04096812642192113, J_o = 0.6578906619961913
J_b = 0.04097235356421723, J_o = 0.5477077516647222
J_b = 0.04127114573264914, J_o = 0.5417613175711937
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
W_opt:  [-0.05935299 -0.05773261 -0.05622355 -0.05464075 -0.05295187 -0.0513766
 -0.05019285 -0.0493319  -0.0486739  -0.04813601]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1692 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1280, add (DA)= 0.0001decode = 0.1308 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3000 s, inc stats = 0.3085, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.93461701e-11 3.36419975e-10 4.27582182e-10 1.09630025e-10
 1.53341958e-09]
u_DA:    [2.58645060e-09 4.84691054e-09 6.56249310e-09 3.61794541e-09
 8.83756605e-09]
ref_MAE: [6.91708082e-09 1.01552756e-08 1.26323508e-08 8.43453222e-09
 1.89305701e-08]
da_MAE:  [2.50710443e-09 4.51049056e-09 6.13491092e-09 3.50831539e-09
 7.30414647e-09]
% 7.22311234909836 da_MAE 0.10831862580032753 ref_MAE 0.11675173477246394
u_c taken from control states: [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
u_c before reduction of space:  [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
data[u_c] post encoding of state:  [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
J_b = 0.0, J_o = 13250.990226919253
J_b = 0.5, J_o = 836129.4601055994
J_b = 0.006162259096898809, J_o = 214.9943635078968
J_b = 0.006164601339521108, J_o = 211.70830014849088
J_b = 0.006189585260825628, J_o = 198.90830225885736
J_b = 0.006539360159088953, J_o = 153.21639946816993
J_b = 0.019696804461027177, J_o = 16.668070651172343
J_b = 0.01934621900048743, J_o = 12.87247237145074
J_b = 0.019682565036939124, J_o = 10.377374471429164
J_b = 0.02446587057760411, J_o = 4.376278438305067
J_b = 0.026924037979187465, J_o = 3.3355042625061584
J_b = 0.028528794358964354, J_o = 2.9009298655808746
J_b = 0.03029831465208233, J_o = 2.398147342700119
J_b = 0.03301524200313943, J_o = 1.7514332613993953
J_b = 0.03873181393709777, J_o = 0.973560070297371
J_b = 0.04139474680598587, J_o = 0.7653784493535637
J_b = 0.04075544084306303, J_o = 0.7001317411714556
J_b = 0.040242659872702834, J_o = 1.0132284031679624
J_b = 0.04071376087321269, J_o = 0.697873903472463
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
W_opt:  [-0.05976818 -0.05809649 -0.05657151 -0.05498924 -0.05331246 -0.05175513
 -0.05058988 -0.04974794 -0.04911101 -0.04859719]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1063 s, v_trunc (Latent to Reduced) = 0.0026, dec (Reduced to Full) = 0.1824, add (DA)= 0.0001decode = 0.1869 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2933 s, inc stats = 0.3011, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.88731771e-11 3.33270811e-10 4.24685511e-10 1.09683063e-10
 1.51938640e-09]
u_DA:    [2.58398950e-09 4.85053782e-09 6.56703263e-09 3.62145114e-09
 8.83890755e-09]
ref_MAE: [6.91755382e-09 1.01584248e-08 1.26352474e-08 8.43447918e-09
 1.89446033e-08]
da_MAE:  [2.50511632e-09 4.51726701e-09 6.14234712e-09 3.51176808e-09
 7.31952115e-09]
% 7.143991438081459 da_MAE 0.10846648670480767 ref_MAE 0.11681148951441274
u_c taken from control states: [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
u_c before reduction of space:  [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
data[u_c] post encoding of state:  [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
J_b = 0.0, J_o = 13241.57550690238
J_b = 0.49999999999999994, J_o = 836243.3403078637
J_b = 0.006155702104186948, J_o = 219.47733857122515
J_b = 0.006158079447734308, J_o = 216.14190576743314
J_b = 0.006183437778906196, J_o = 203.1469640447102
J_b = 0.006538454415312726, J_o = 156.7158290329454
J_b = 0.020074113628484644, J_o = 17.710401804051763
J_b = 0.019618166339453964, J_o = 13.680997405994948
J_b = 0.019828480531474676, J_o = 11.331190916100553
J_b = 0.025058268663448065, J_o = 4.599908460307126
J_b = 0.027261715247568513, J_o = 3.6743277395661247
J_b = 0.029716874710462055, J_o = 2.990336875011402
J_b = 0.031463326590291836, J_o = 2.5036704439373416
J_b = 0.03716795956411894, J_o = 1.3929014402314543
J_b = 0.04523798365636256, J_o = 2.302324870178167
J_b = 0.03923373488800391, J_o = 1.1655181905547973
J_b = 0.04263987606126067, J_o = 0.7893889414558362
J_b = 0.04268205347688345, J_o = 0.7257890474671425
J_b = 0.042686221413005834, J_o = 0.7528442459616438
J_b = 0.042678688860907955, J_o = 0.7156820705941157
J_b = 0.0425959323941309, J_o = 0.6841603017295433
J_b = 0.042860070546431324, J_o = 0.6592130286403233
J_b = 0.043574736033708386, J_o = 0.6349848687630288
J_b = 0.0440438567920918, J_o = 0.6255030664145247
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
W_opt:  [-0.06119834 -0.05947029 -0.05786554 -0.05616133 -0.0543328  -0.05264477
 -0.05142117 -0.05058369 -0.04998657 -0.04953216]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1325 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1617, add (DA)= 0.0001decode = 0.1645 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2971 s, inc stats = 0.3015, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.85417440e-11 3.30450985e-10 4.21606783e-10 1.09739088e-10
 1.50554586e-09]
u_DA:    [2.58987198e-09 4.85696937e-09 6.56689481e-09 3.62027983e-09
 8.84198947e-09]
ref_MAE: [6.91788525e-09 1.01612446e-08 1.26383262e-08 8.43442315e-09
 1.89584438e-08]
da_MAE:  [2.51133024e-09 4.52651839e-09 6.14528803e-09 3.51054074e-09
 7.33644360e-09]
% 6.9740876238131575 da_MAE 0.108729248429367 ref_MAE 0.1168806041801316
\% improve_point: 7.74, mse_ref_points: 1.3517294472565113e-05, mse_da_points: 1.248433406789175e-05, % improve_overlap: 8.43, mse_ref_overlap: 0.21176, mse_da_overlap: 0.19463
DA - - L2: 2070.70, L1: 2473.82, % Improve: 9.00%, DA_MAE: 0.09, mse_ref: 0.22, mse_DA: 0.202, time(s): 0.8577s,
u_c taken from control states: [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
u_c before reduction of space:  [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
data[u_c] post encoding of state:  [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
J_b = 0.0, J_o = 13230.20117392896
J_b = 0.49999999999999994, J_o = 836378.7829433818
J_b = 0.006147904466496485, J_o = 224.62850398552013
J_b = 0.006150321062594563, J_o = 221.23785592183663
J_b = 0.006176098087640724, J_o = 208.0247499151076
J_b = 0.006536976438286881, J_o = 160.76410585627028
J_b = 0.02050735285102592, J_o = 19.013602744477303
J_b = 0.01993367209629435, J_o = 14.696479034635166
J_b = 0.020030445971540627, J_o = 12.435743995989144
J_b = 0.024914503817391527, J_o = 5.503560307851453
J_b = 0.027253078315385836, J_o = 4.406523016677896
J_b = 0.029166335096379545, J_o = 3.7711946305686133
J_b = 0.03198458457032016, J_o = 2.8805217093768913
J_b = 0.03579957032854068, J_o = 1.9771213873985418
J_b = 0.04529458946299297, J_o = 1.070095860969236
J_b = 0.0471442048076643, J_o = 0.8408874695217117
J_b = 0.04515638049536184, J_o = 0.7718904446880983
J_b = 0.04472035985416258, J_o = 0.751991255053197
J_b = 0.04387464713602967, J_o = 1.0228636566515579
J_b = 0.044604965315303995, J_o = 0.7462670325583526
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
W_opt:  [-0.06215456 -0.06034742 -0.05869102 -0.05693556 -0.05505507 -0.05332866
 -0.05209599 -0.05127498 -0.05071088 -0.05030064]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1279 s, v_trunc (Latent to Reduced) = 0.0051, dec (Reduced to Full) = 0.1342, add (DA)= 0.0001decode = 0.1412 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2692 s, inc stats = 0.2892, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.83131012e-11 3.28013300e-10 4.18341945e-10 1.09709579e-10
 1.49190079e-09]
u_DA:    [2.58910231e-09 4.86205319e-09 6.57093729e-09 3.62208873e-09
 8.84394845e-09]
ref_MAE: [6.91811389e-09 1.01636823e-08 1.26415910e-08 8.43445266e-09
 1.89720889e-08]
da_MAE:  [2.51078921e-09 4.53403989e-09 6.15259534e-09 3.51237915e-09
 7.35204766e-09]
% 6.863119508635335 da_MAE 0.10908860096965299 ref_MAE 0.1171271792593132
u_c taken from control states: [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
u_c before reduction of space:  [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
data[u_c] post encoding of state:  [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
J_b = 0.0, J_o = 13220.209544472182
J_b = 0.5, J_o = 836497.7116429369
J_b = 0.0061410632877931595, J_o = 229.13474161042467
J_b = 0.006143513460868116, J_o = 225.6968601742165
J_b = 0.0061696486403343305, J_o = 212.2970878106094
J_b = 0.006535541152861152, J_o = 164.3260524557948
J_b = 0.02088237267046817, J_o = 20.24262540678312
J_b = 0.020211601497953192, J_o = 15.66116046532003
J_b = 0.020228682016888988, J_o = 13.413110079497866
J_b = 0.02441969374638294, J_o = 6.57455586580475
J_b = 0.027060297727737583, J_o = 5.090775316604066
J_b = 0.029498325515676174, J_o = 4.170845580168127
J_b = 0.0318279987018418, J_o = 3.4476350577749324
J_b = 0.03447642540807719, J_o = 2.7462573297795574
J_b = 0.041840252099853946, J_o = 1.5073828786752062
J_b = 0.052266226134133766, J_o = 1.8822410030041936
J_b = 0.04554481574363367, J_o = 1.2096508222557274
J_b = 0.04748406862223857, J_o = 0.90628794883974
J_b = 0.04717737724611361, J_o = 1.1689063328399099
J_b = 0.04745124629256116, J_o = 0.9028733790424143
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
W_opt:  [-0.06445078 -0.06252272 -0.06076914 -0.05891018 -0.05691832 -0.05509638
 -0.05381146 -0.05297538 -0.05242024 -0.05203446]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1259 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.1802, add (DA)= 0.0001decode = 0.1843 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3103 s, inc stats = 0.3157, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.81500293e-11 3.25974916e-10 4.14900206e-10 1.09512990e-10
 1.47844825e-09]
u_DA:    [2.59144987e-09 4.86643891e-09 6.57673348e-09 3.62408814e-09
 8.84483094e-09]
ref_MAE: [6.91827696e-09 1.01657207e-08 1.26450327e-08 8.43464925e-09
 1.89855414e-08]
da_MAE:  [2.51329984e-09 4.54046400e-09 6.16183328e-09 3.51457515e-09
 7.36638270e-09]
% 6.738625644611718 da_MAE 0.10970657523199756 ref_MAE 0.11763345328146468
u_c taken from control states: [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
u_c before reduction of space:  [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
data[u_c] post encoding of state:  [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
J_b = 0.0, J_o = 13211.470120355078
J_b = 0.5000000000000001, J_o = 836601.1982301527
J_b = 0.006135113458431421, J_o = 233.00348799435363
J_b = 0.006137591788790031, J_o = 229.52599415154026
J_b = 0.006164027312615199, J_o = 215.96960952046692
J_b = 0.006534124646167289, J_o = 167.4015228390566
J_b = 0.021202570152883467, J_o = 21.365964470902703
J_b = 0.020452170299396243, J_o = 16.54801704858607
J_b = 0.020409131034122233, J_o = 14.269674361810658
J_b = 0.02373918023683472, J_o = 7.629304918378511
J_b = 0.026807034703554448, J_o = 5.821053298871148
J_b = 0.02958406459850174, J_o = 4.413598116536774
J_b = 0.03218659897063342, J_o = 3.7324219526899602
J_b = 0.0349109243234743, J_o = 3.074695092221363
J_b = 0.039085830289321104, J_o = 2.1842798953266533
J_b = 0.05099153755055561, J_o = 1.247011902792572
J_b = 0.05004782899520451, J_o = 0.9911361080583756
J_b = 0.048738391784494565, J_o = 1.526453928318558
J_b = 0.04995211829219751, J_o = 0.9880224402690708
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
W_opt:  [-0.06585245 -0.06384545 -0.06201419 -0.06005467 -0.05794511 -0.05602352
 -0.05469358 -0.05385986 -0.05333524 -0.05299675]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1104 s, v_trunc (Latent to Reduced) = 0.0091, dec (Reduced to Full) = 0.1285, add (DA)= 0.0001decode = 0.1395 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2501 s, inc stats = 0.2544, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.80214742e-11 3.24314247e-10 4.11289852e-10 1.09092090e-10
 1.46517247e-09]
u_DA:    [2.59288290e-09 4.87477675e-09 6.57947636e-09 3.62426837e-09
 8.85000981e-09]
ref_MAE: [6.91840552e-09 1.01673814e-08 1.26486431e-08 8.43507015e-09
 1.89988172e-08]
da_MAE:  [2.51486143e-09 4.55046250e-09 6.16818651e-09 3.51517628e-09
 7.38483734e-09]
% 6.548807983605742 da_MAE 0.11053002420491595 ref_MAE 0.11827567077531288
u_c taken from control states: [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
u_c before reduction of space:  [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
data[u_c] post encoding of state:  [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
J_b = 0.0, J_o = 13205.26387527159
J_b = 0.49999999999999983, J_o = 836676.0564906711
J_b = 0.006130816370776559, J_o = 235.903431160379
J_b = 0.006133315476826587, J_o = 232.3967092731357
J_b = 0.0061599726080268195, J_o = 218.72476133800788
J_b = 0.00653317244482972, J_o = 169.71600341902106
J_b = 0.021440365733347875, J_o = 22.24422876965476
J_b = 0.0206338636905475, J_o = 17.244124581480072
J_b = 0.020549943170554683, J_o = 14.91958184543841
J_b = 0.023237321085264263, J_o = 8.562705018467117
J_b = 0.026591479454670056, J_o = 6.4166580609187465
J_b = 0.029958217638793992, J_o = 5.237678301043395
J_b = 0.03159713058232244, J_o = 4.262542141857759
J_b = 0.032577285626058654, J_o = 3.779653379677269
J_b = 0.03502405319087125, J_o = 3.075645166692591
J_b = 0.03948051114026514, J_o = 2.153660215098862
J_b = 0.049182993300507856, J_o = 1.170797528225581
J_b = 0.05219705108623983, J_o = 2.749942904043788
J_b = 0.049452668646995344, J_o = 1.1526327837114223
J_b = 0.04992915826908601, J_o = 1.0704817743704558
J_b = 0.050661733619453274, J_o = 1.0222444539735582
J_b = 0.050641165946257796, J_o = 1.0054000336746995
J_b = 0.0510940725560673, J_o = 0.9519133803496738
J_b = 0.05181086780500402, J_o = 0.9209883123721199
J_b = 0.053074381979682526, J_o = 0.9251404212544192
J_b = 0.052369895779212826, J_o = 0.9101258159368143
J_b = 0.05222489411884421, J_o = 0.9063776147877473
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
W_opt:  [-0.06554209 -0.06354524 -0.06169233 -0.05966552 -0.05746147 -0.05546565
 -0.05412614 -0.05334002 -0.05289314 -0.05264885]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.2676 s, v_trunc (Latent to Reduced) = 0.0033, dec (Reduced to Full) = 0.4054, add (DA)= 0.0001decode = 0.4108 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.6786 s, inc stats = 0.7006, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.78902776e-11 3.22985597e-10 4.07538538e-10 1.08406505e-10
 1.45204868e-09]
u_DA:    [2.59851422e-09 4.87618100e-09 6.57712436e-09 3.62375394e-09
 8.85074477e-09]
ref_MAE: [6.91853672e-09 1.01687100e-08 1.26523944e-08 8.43575574e-09
 1.90119410e-08]
da_MAE:  [2.52062394e-09 4.55319540e-09 6.16958582e-09 3.51534744e-09
 7.39869610e-09]
% 6.4201938008231165 da_MAE 0.1114353176434911 ref_MAE 0.11908051765603173
u_c taken from control states: [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
u_c before reduction of space:  [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
data[u_c] post encoding of state:  [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
J_b = 0.0, J_o = 13202.951436848693
J_b = 0.4999999999999998, J_o = 836706.5651915178
J_b = 0.006129073866970737, J_o = 237.28455321268186
J_b = 0.006131582708779824, J_o = 233.76413336968642
J_b = 0.006158343688076767, J_o = 220.03799932857856
J_b = 0.006532997398234161, J_o = 170.82218845813202
J_b = 0.02155447388642703, J_o = 22.672350659538353
J_b = 0.020721897471897455, J_o = 17.58306300227219
J_b = 0.020618997758563445, J_o = 15.230109374082417
J_b = 0.023024889011326242, J_o = 9.049914227691257
J_b = 0.02647848160517305, J_o = 6.710065678308688
J_b = 0.030359537089710967, J_o = 5.892726980733989
J_b = 0.031444503911858324, J_o = 4.507457376209628
J_b = 0.03193076413454413, J_o = 4.106010796652514
J_b = 0.0342779350555184, J_o = 3.2737068710278647
J_b = 0.038195186976394256, J_o = 2.470750466934822
J_b = 0.04894614477010066, J_o = 1.4075506828337159
J_b = 0.05453398456174521, J_o = 1.341736816321182
J_b = 0.05305396124977602, J_o = 1.3781341275853025
J_b = 0.05382092936640891, J_o = 1.1524637204317032
J_b = 0.05081762498247752, J_o = 1.070896702920826
J_b = 0.051183598676656034, J_o = 1.0273916079408614
J_b = 0.051402508521849175, J_o = 0.9830608938681634
J_b = 0.05198036071930441, J_o = 0.964011397907753
J_b = 0.052503499624899704, J_o = 0.9555684945062543
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
W_opt:  [-0.06582433 -0.06380371 -0.06193651 -0.05989731 -0.05768086 -0.05567469
 -0.05432957 -0.05354227 -0.0530981  -0.05285969]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1277 s, v_trunc (Latent to Reduced) = 0.0046, dec (Reduced to Full) = 0.1393, add (DA)= 0.0001decode = 0.1457 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2736 s, inc stats = 0.2929, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.77213780e-11 3.21909120e-10 4.03691696e-10 1.07429070e-10
 1.43905023e-09]
u_DA:    [2.59917792e-09 4.87843479e-09 6.57845151e-09 3.62426508e-09
 8.85245513e-09]
ref_MAE: [6.91870562e-09 1.01697865e-08 1.26562412e-08 8.43673317e-09
 1.90249394e-08]
da_MAE:  [2.52145654e-09 4.55652567e-09 6.17475982e-09 3.51683601e-09
 7.41340489e-09]
% 6.33844929581025 da_MAE 0.11226004279615112 ref_MAE 0.11985712595203638
u_c taken from control states: [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
u_c before reduction of space:  [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
data[u_c] post encoding of state:  [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
J_b = 0.0, J_o = 13203.71145501575
J_b = 0.5, J_o = 836702.9118281741
J_b = 0.0061293002349883064, J_o = 237.56709385111495
J_b = 0.0061318111305395, J_o = 234.0437853133652
J_b = 0.006158594016418913, J_o = 220.3062424893394
J_b = 0.006533554418730687, J_o = 171.04713242480784
J_b = 0.021578261609287424, J_o = 22.75070697193194
J_b = 0.020741304487187355, J_o = 17.643608247055205
J_b = 0.020635164428605655, J_o = 15.284399023481301
J_b = 0.022994721134604268, J_o = 9.137326447861174
J_b = 0.026462118197703256, J_o = 6.761612075400118
J_b = 0.030434151094838144, J_o = 5.998517544904716
J_b = 0.0314405026912709, J_o = 4.5448560673396345
J_b = 0.031887690934441944, J_o = 4.150971039683027
J_b = 0.034228029883661665, J_o = 3.3001259154868743
J_b = 0.03811289876790734, J_o = 2.5044758801516442
J_b = 0.04900473152583955, J_o = 1.432580562764088
J_b = 0.0546318769694085, J_o = 1.655279432398928
J_b = 0.05111629021976249, J_o = 1.266590428839414
J_b = 0.05170369237621301, J_o = 1.1239007063662279
J_b = 0.05069841476401938, J_o = 1.0946522323214876
J_b = 0.05046708181547034, J_o = 1.086636478678127
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
W_opt:  [-0.06617499 -0.06413017 -0.06227448 -0.06028633 -0.05814454 -0.05619908
 -0.05486609 -0.05404845 -0.05355243 -0.05325134]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1020 s, v_trunc (Latent to Reduced) = 0.0037, dec (Reduced to Full) = 0.1336, add (DA)= 0.0001decode = 0.1391 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2413 s, inc stats = 0.2515, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.74894442e-11 3.20983183e-10 3.99799777e-10 1.06129207e-10
 1.42615128e-09]
u_DA:    [2.59417693e-09 4.87924358e-09 6.58010809e-09 3.62583053e-09
 8.85042511e-09]
ref_MAE: [6.91893755e-09 1.01707124e-08 1.26601332e-08 8.43803303e-09
 1.90378384e-08]
da_MAE:  [2.51668749e-09 4.55826040e-09 6.18030831e-09 3.51970132e-09
 7.42427383e-09]
% 6.2757110192773045 da_MAE 0.11300566000791679 ref_MAE 0.12057243777134431
u_c taken from control states: [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
u_c before reduction of space:  [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
data[u_c] post encoding of state:  [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
J_b = 0.0, J_o = 13204.881772489236
J_b = 0.49999999999999994, J_o = 836696.0985002995
J_b = 0.006129712824773534, J_o = 237.86618900718622
J_b = 0.0061322261234547214, J_o = 234.33950247388864
J_b = 0.006159034642720736, J_o = 220.58866133755106
J_b = 0.006534353912445064, J_o = 171.27977674184334
J_b = 0.021603061182586935, J_o = 22.81911121067921
J_b = 0.02076187012212515, J_o = 17.696732467104955
J_b = 0.020652717957714905, J_o = 15.332407620397774
J_b = 0.022968955867042316, J_o = 9.21951882328395
J_b = 0.02644662466400085, J_o = 6.810811222320261
J_b = 0.030501346054973632, J_o = 6.0922534159670025
J_b = 0.03144104431594724, J_o = 4.578966638535146
J_b = 0.03185873654639395, J_o = 4.190900999328452
J_b = 0.03419311360474922, J_o = 3.3245593958873307
J_b = 0.03805123483386794, J_o = 2.5345201864207474
J_b = 0.04905476744376509, J_o = 1.4533349725126077
J_b = 0.05471213277491183, J_o = 1.986365470960594
J_b = 0.0507052323866552, J_o = 1.319857079544643
J_b = 0.05104527809291742, J_o = 1.1279058909035793
J_b = 0.05063423232890174, J_o = 1.1157459926700404
J_b = 0.06677031590126546, J_o = 1.7079048380839545
J_b = 0.05330975813666562, J_o = 1.0751875253285683
J_b = 0.05215356974356758, J_o = 1.0385239738205843
J_b = 0.051603320478127525, J_o = 0.998390568869343
J_b = 0.05205959775042175, J_o = 0.9758329361489384
J_b = 0.052797642120341666, J_o = 0.9666138560414501
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
W_opt:  [-0.06591405 -0.06388117 -0.06200465 -0.059956   -0.05772882 -0.055712
 -0.05435794 -0.05356399 -0.05311514 -0.05287378]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1550 s, v_trunc (Latent to Reduced) = 0.0027, dec (Reduced to Full) = 0.2596, add (DA)= 0.0001decode = 0.2642 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4193 s, inc stats = 0.4335, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.71688621e-11 3.20112855e-10 3.95912419e-10 1.04571922e-10
 1.41333972e-09]
u_DA:    [2.59886379e-09 4.87865736e-09 6.57774297e-09 3.62415629e-09
 8.85162864e-09]
ref_MAE: [6.91925813e-09 1.01715828e-08 1.26640205e-08 8.43959032e-09
 1.90506499e-08]
da_MAE:  [2.52169493e-09 4.55854451e-09 6.18183055e-09 3.51958437e-09
 7.43828892e-09]
% 6.233715615919938 da_MAE 0.11378242699857981 ref_MAE 0.12134684417323265
u_c taken from control states: [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
u_c before reduction of space:  [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
data[u_c] post encoding of state:  [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
J_b = 0.0, J_o = 13206.471677322483
J_b = 0.5, J_o = 836685.7287574589
J_b = 0.006130333593843644, J_o = 238.14446625224383
J_b = 0.006132849356745303, J_o = 234.61431791997285
J_b = 0.006159684161029663, J_o = 220.84989036406128
J_b = 0.006535371421010656, J_o = 171.49083251116986
J_b = 0.02162564555656169, J_o = 22.86787060542781
J_b = 0.02078112396776328, J_o = 17.73468354207352
J_b = 0.020669735904618108, J_o = 15.36696168896226
J_b = 0.02295356707431423, J_o = 9.282180141047183
J_b = 0.026436756490327087, J_o = 6.849248817239432
J_b = 0.030551870186937002, J_o = 6.160182289183281
J_b = 0.031445843860990294, J_o = 4.604582773777924
J_b = 0.031844579255453344, J_o = 4.2203667872412165
J_b = 0.03417382744442345, J_o = 3.3434872841066667
J_b = 0.0380123380588192, J_o = 2.557286176133524
J_b = 0.049085924183780376, J_o = 1.4682011262559527
J_b = 0.05477105771484646, J_o = 2.260757219335574
J_b = 0.050491345533426754, J_o = 1.3527194869436665
J_b = 0.05074104640062766, J_o = 1.1468143560873265
J_b = 0.050639868138105976, J_o = 1.1312720201542634
J_b = 0.05089794103408727, J_o = 1.1119444593193755
J_b = 0.05133657679442033, J_o = 1.075372855809114
J_b = 0.05168716380292065, J_o = 1.0479517839019448
J_b = 0.05015848202021295, J_o = 1.5503535630827134
J_b = 0.051296775237386745, J_o = 1.018731459452414
J_b = 0.06135104037396877, J_o = 1.1928780700801682
J_b = 0.05361731100998323, J_o = 0.9946168536197675
J_b = 0.053156706523711364, J_o = 0.9799976849263545
J_b = 0.0528733394047019, J_o = 0.9775544101124961
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
W_opt:  [-0.06607556 -0.06403505 -0.06215441 -0.06010508 -0.05787867 -0.05586097
 -0.05450188 -0.05369952 -0.05324087 -0.05298924]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1495 s, v_trunc (Latent to Reduced) = 0.0029, dec (Reduced to Full) = 0.2756, add (DA)= 0.0001decode = 0.2804 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4300 s, inc stats = 0.4374, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.67279780e-11 3.19229407e-10 3.92073227e-10 1.02858662e-10
 1.40059691e-09]
u_DA:    [2.59835870e-09 4.87872694e-09 6.57757578e-09 3.62430121e-09
 8.84986911e-09]
ref_MAE: [6.91969902e-09 1.01724662e-08 1.26678597e-08 8.44130358e-09
 1.90633927e-08]
da_MAE:  [2.52163072e-09 4.55949753e-09 6.18550255e-09 3.52144255e-09
 7.44927219e-09]
% 6.193360809082363 da_MAE 0.1145740525687753 ref_MAE 0.12213853257826592
u_c taken from control states: [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
u_c before reduction of space:  [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
data[u_c] post encoding of state:  [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
J_b = 0.0, J_o = 13210.47938491904
J_b = 0.49999999999999994, J_o = 836648.6326744268
J_b = 0.006132495336591875, J_o = 237.5761171525828
J_b = 0.006135007705963582, J_o = 234.05075012889853
J_b = 0.006161806312595181, J_o = 220.30537325942603
J_b = 0.006536986805437809, J_o = 171.02132538577277
J_b = 0.02157823362916754, J_o = 22.64202296762042
J_b = 0.02074721079949784, J_o = 17.553982347878314
J_b = 0.02064582558881887, J_o = 15.20213473217759
J_b = 0.02306810799817698, J_o = 9.022483870068303
J_b = 0.026505572983625162, J_o = 6.695948609581942
J_b = 0.030356797273292855, J_o = 5.869618638297339
J_b = 0.031464729513972195, J_o = 4.492837146708566
J_b = 0.0319537012142757, J_o = 4.093084595506408
J_b = 0.03429681635964247, J_o = 3.2643456612159465
J_b = 0.038196840667143295, J_o = 2.465025091491304
J_b = 0.048873084828084765, J_o = 1.4054465716089997
J_b = 0.05448798886139009, J_o = 1.457075013541032
J_b = 0.051389760745930914, J_o = 1.2162418935070693
J_b = 0.05230753340667825, J_o = 1.1768488829864228
J_b = 0.05072652873756553, J_o = 1.0768087817101522
J_b = 0.050529040875685216, J_o = 1.0696112984669937
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
W_opt:  [-0.06619284 -0.0641449  -0.06228614 -0.06029784 -0.05815645 -0.05620782
 -0.05486435 -0.05403056 -0.05351564 -0.05319438]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1626 s, v_trunc (Latent to Reduced) = 0.0024, dec (Reduced to Full) = 0.1372, add (DA)= 0.0001decode = 0.1415 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3042 s, inc stats = 0.3136, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.61543931e-11 3.18267385e-10 3.88327355e-10 1.01074843e-10
 1.38791090e-09]
u_DA:    [2.59388413e-09 4.87780205e-09 6.57956674e-09 3.62553124e-09
 8.84928715e-09]
ref_MAE: [6.92027260e-09 1.01734282e-08 1.26716056e-08 8.44308740e-09
 1.90760788e-08]
da_MAE:  [2.51772974e-09 4.55953466e-09 6.19123938e-09 3.52445639e-09
 7.46137625e-09]
% 6.159709071038034 da_MAE 0.1152802443189471 ref_MAE 0.12284727932718728
u_c taken from control states: [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
u_c before reduction of space:  [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
data[u_c] post encoding of state:  [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
J_b = 0.0, J_o = 13214.666639932311
J_b = 0.49999999999999994, J_o = 836610.4287791635
J_b = 0.006134724015592414, J_o = 237.04597032239786
J_b = 0.006137233376095763, J_o = 233.52484465216335
J_b = 0.006163999888131446, J_o = 219.7964077993835
J_b = 0.006538731056630839, J_o = 170.5797136387983
J_b = 0.021533672351139156, J_o = 22.4214032152387
J_b = 0.020715819922722926, J_o = 17.37807973092105
J_b = 0.020624255973909333, J_o = 15.041264885312327
J_b = 0.023186766307871635, J_o = 8.776821152345892
J_b = 0.026571150728391228, J_o = 6.549752944057909
J_b = 0.030154566617889875, J_o = 5.536339490963208
J_b = 0.03153196916467771, J_o = 4.373008855991939
J_b = 0.0322003974172946, J_o = 3.942316582681047
J_b = 0.034578130496100125, J_o = 3.176482945688016
J_b = 0.038613613288634295, J_o = 2.343155759878885
J_b = 0.048778281386005644, J_o = 1.309575301195181
J_b = 0.0539333230680545, J_o = 1.6385034940613519
J_b = 0.050399905211308896, J_o = 1.1985759727010987
J_b = 0.051145367378335777, J_o = 1.0680186631660953
J_b = 0.050439526782705975, J_o = 1.0533727697362512
J_b = 0.04987048469120294, J_o = 1.0288800703261625
J_b = 0.04997227006084348, J_o = 0.9951926527960742
J_b = 0.05158305145176664, J_o = 0.9508592619243552
J_b = 0.051475532843010464, J_o = 0.9631748796783313
J_b = 0.05153653081958274, J_o = 0.9448137852079075
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
W_opt:  [-0.06538377 -0.06337684 -0.06152705 -0.05951938 -0.05734148 -0.05536209
 -0.05401374 -0.05319884 -0.05271423 -0.05242875]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.2413 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.1667, add (DA)= 0.0001decode = 0.1698 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4112 s, inc stats = 0.4187, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.54574258e-11 3.17170753e-10 3.84707296e-10 9.92927499e-11
 1.37527558e-09]
u_DA:    [2.59815433e-09 4.87679221e-09 6.57713023e-09 3.62437306e-09
 8.85084586e-09]
ref_MAE: [6.92096957e-09 1.01745249e-08 1.26752256e-08 8.44486949e-09
 1.90887141e-08]
da_MAE:  [2.52269690e-09 4.55962145e-09 6.19242293e-09 3.52508031e-09
 7.47557028e-09]
% 6.122731043682207 da_MAE 0.11597404995769175 ref_MAE 0.12353794613651986
\% improve_point: 7.34, mse_ref_points: 1.4142139379863062e-05, mse_da_points: 1.3134299121712164e-05, % improve_overlap: 8.01, mse_ref_overlap: 0.22239, mse_da_overlap: 0.20553
DA - - L2: 2468.66, L1: 2701.25, % Improve: 8.68%, DA_MAE: 0.09, mse_ref: 0.23, mse_DA: 0.213, time(s): 0.7982s,
u_c taken from control states: [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
u_c before reduction of space:  [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
data[u_c] post encoding of state:  [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
J_b = 0.0, J_o = 13217.538689534245
J_b = 0.5, J_o = 836588.3716817368
J_b = 0.006136026463881867, J_o = 237.16366116373246
J_b = 0.0061385375992052595, J_o = 233.64004853269
J_b = 0.006165323042654811, J_o = 219.9019800348632
J_b = 0.006540319250948714, J_o = 170.65181846504768
J_b = 0.021541684017440926, J_o = 22.391474386405324
J_b = 0.020724985059437304, J_o = 17.354506428110383
J_b = 0.020634660895134386, J_o = 15.02049953620058
J_b = 0.023212677161729634, J_o = 8.753594070927022
J_b = 0.026585458674006274, J_o = 6.538501141309247
J_b = 0.030138736560940443, J_o = 5.502352573276381
J_b = 0.0315516041948606, J_o = 4.361077331330082
J_b = 0.032246524321898416, J_o = 3.926516356708442
J_b = 0.0346311442363215, J_o = 3.1675988354543705
J_b = 0.038685124315117905, J_o = 2.329855827196959
J_b = 0.04877475324052871, J_o = 1.3006698709966584
J_b = 0.05382889676301957, J_o = 1.8373635513386202
J_b = 0.05006407927006502, J_o = 1.212920164725959
J_b = 0.05066634040492411, J_o = 1.0750657041331484
J_b = 0.05033466123622736, J_o = 1.060356977563734
J_b = 0.050319760831423026, J_o = 1.0276634140067453
J_b = 0.05063936499459882, J_o = 0.9948987942555649
J_b = 0.05143347930055261, J_o = 0.9654212945427675
J_b = 0.050595589154873825, J_o = 0.9733532928752031
J_b = 0.05105725628994164, J_o = 0.9550030886484118
J_b = 0.05204784004057775, J_o = 0.9435895913534753
J_b = 0.052190980608972634, J_o = 0.9349860267430893
J_b = 0.05277957808363286, J_o = 0.9066016880628505
J_b = 0.05431611644034149, J_o = 0.8248717427011745
J_b = 0.055604391194674654, J_o = 0.7841754684806677
J_b = 0.05271386564876383, J_o = 2.337203639387969
J_b = 0.055493844503123786, J_o = 0.7825633719572409
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
W_opt:  [-0.06722707 -0.06514638 -0.06317721 -0.06099493 -0.05860888 -0.0564455
 -0.05499433 -0.05414706 -0.05366381 -0.05339587]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1709 s, v_trunc (Latent to Reduced) = 0.0018, dec (Reduced to Full) = 0.3869, add (DA)= 0.0001decode = 0.3907 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5616 s, inc stats = 0.5737, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.46423502e-11 3.15916177e-10 3.81235317e-10 9.75610792e-11
 1.36269157e-09]
u_DA:    [2.59846433e-09 4.87092689e-09 6.57865124e-09 3.62681751e-09
 8.85146607e-09]
ref_MAE: [6.92178464e-09 1.01757794e-08 1.26786976e-08 8.44660116e-09
 1.91012981e-08]
da_MAE:  [2.52382198e-09 4.55501071e-09 6.19741592e-09 3.52925643e-09
 7.48877450e-09]
% 6.087215834638907 da_MAE 0.11670414411716196 ref_MAE 0.12426864473708922
u_c taken from control states: [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
u_c before reduction of space:  [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
data[u_c] post encoding of state:  [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
J_b = 0.0, J_o = 13218.53956746845
J_b = 0.4999999999999999, J_o = 836588.4905681829
J_b = 0.006136054245021427, J_o = 238.1113110123945
J_b = 0.0061385731967541135, J_o = 234.57671309527586
J_b = 0.006165442015236124, J_o = 220.79543564695754
J_b = 0.006541605473984473, J_o = 171.38415337618898
J_b = 0.02161709468982551, J_o = 22.611360757687393
J_b = 0.02078602029962505, J_o = 17.52999016026933
J_b = 0.020685843390069777, J_o = 15.182548130320558
J_b = 0.023118721546900724, J_o = 9.014121860195557
J_b = 0.026536422537279378, J_o = 6.700520653382698
J_b = 0.030364595193459337, J_o = 5.86445368909269
J_b = 0.03149626462920597, J_o = 4.491972999722526
J_b = 0.03198860104708942, J_o = 4.09315626167509
J_b = 0.03433276091790863, J_o = 3.266168112413406
J_b = 0.038221726148888004, J_o = 2.469931353844669
J_b = 0.04882366939746529, J_o = 1.4129922922480236
J_b = 0.054488494402438775, J_o = 1.6391800347383503
J_b = 0.05091851106902336, J_o = 1.2561070998904833
J_b = 0.051592422371277855, J_o = 1.118342766351515
J_b = 0.05059201540875648, J_o = 1.0906141085662306
J_b = 0.05031743417302508, J_o = 1.0808010937071892
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
W_opt:  [-0.06618467 -0.06414108 -0.06228472 -0.06030326 -0.05817098 -0.05622661
 -0.05487586 -0.054025   -0.05348776 -0.05314113]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1307 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.3897, add (DA)= 0.0001decode = 0.3949 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5257 s, inc stats = 0.5318, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.37268865e-11 3.14506198e-10 3.77931506e-10 9.59198611e-11
 1.35017899e-09]
u_DA:    [2.59293830e-09 4.87626787e-09 6.57888622e-09 3.62545118e-09
 8.84778308e-09]
ref_MAE: [6.92270011e-09 1.01771894e-08 1.26820014e-08 8.44824238e-09
 1.91138107e-08]
da_MAE:  [2.51921141e-09 4.56176167e-09 6.20095471e-09 3.52953132e-09
 7.49760409e-09]
% 6.050104003766682 da_MAE 0.1174945404358629 ref_MAE 0.12506085205307044
u_c taken from control states: [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
u_c before reduction of space:  [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
data[u_c] post encoding of state:  [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
J_b = 0.0, J_o = 13216.214040770808
J_b = 0.5000000000000001, J_o = 836626.7737405602
J_b = 0.006133885222432682, J_o = 240.38704582600602
J_b = 0.0061364213787558665, J_o = 236.8282539664952
J_b = 0.006163473712869871, J_o = 222.95152055124856
J_b = 0.006542206390465946, J_o = 173.1795312550115
J_b = 0.021801407942019867, J_o = 23.252135298105006
J_b = 0.02093063329718575, J_o = 18.041174493816193
J_b = 0.020802448803161334, J_o = 15.647792621296674
J_b = 0.022859320876232787, J_o = 9.771324360889583
J_b = 0.026374743343556988, J_o = 7.157401425894677
J_b = 0.03087048783746974, J_o = 6.513550015794277
J_b = 0.031565216325718015, J_o = 4.795242604609583
J_b = 0.03189316954619189, J_o = 4.422042564474184
J_b = 0.03414350559062548, J_o = 3.508426127457478
J_b = 0.037879605551019116, J_o = 2.7321058139208754
J_b = 0.04924385211295345, J_o = 1.5585310756570883
J_b = 0.05536681175001307, J_o = 3.3886565037482246
J_b = 0.05021680788802562, J_o = 1.477462674617211
J_b = 0.05067861470651848, J_o = 1.2455416579843728
J_b = 0.05112786102327322, J_o = 1.2098973528219812
J_b = 0.051239199647179906, J_o = 1.1949385736401295
J_b = 0.05160476596055144, J_o = 1.1541902801273636
J_b = 0.05179578972386193, J_o = 1.1279477975685475
J_b = 0.05128517951430629, J_o = 1.4397522567728869
J_b = 0.051556704902297704, J_o = 1.0869157760416532
J_b = 0.056463218361348794, J_o = 1.0552998613843703
J_b = 0.05354576286665241, J_o = 1.0210487069816372
J_b = 0.053312313647895786, J_o = 1.0182053262144628
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
W_opt:  [-0.06649035 -0.06442979 -0.06252524 -0.06045126 -0.05819769 -0.05615045
 -0.0547608  -0.05392738 -0.05343853 -0.05315751]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.2539 s, v_trunc (Latent to Reduced) = 0.0039, dec (Reduced to Full) = 0.3251, add (DA)= 0.0001decode = 0.3309 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5849 s, inc stats = 0.5962, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.27541800e-11 3.12988373e-10 3.74806320e-10 9.43931489e-11
 1.33775832e-09]
u_DA:    [2.59839621e-09 4.87810419e-09 6.57773122e-09 3.62431846e-09
 8.84999479e-09]
ref_MAE: [6.92367281e-09 1.01787072e-08 1.26851266e-08 8.44976909e-09
 1.91262313e-08]
da_MAE:  [2.52564203e-09 4.56511582e-09 6.20292490e-09 3.52992531e-09
 7.51223647e-09]
% 6.0036816239893165 da_MAE 0.11840215729218553 ref_MAE 0.12596467535945918
u_c taken from control states: [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
u_c before reduction of space:  [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
data[u_c] post encoding of state:  [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
J_b = 0.0, J_o = 13211.91236389212
J_b = 0.49999999999999967, J_o = 836686.9262495493
J_b = 0.006130456213157899, J_o = 243.35569105366739
J_b = 0.00613301419479826, J_o = 239.76620248104027
J_b = 0.0061602993322954795, J_o = 225.76825639051793
J_b = 0.006542291257256692, J_o = 175.53660322821167
J_b = 0.02204197373436828, J_o = 24.140569534096944
J_b = 0.02111942506875078, J_o = 18.751992541103956
J_b = 0.02095432681792378, J_o = 16.283198153486108
J_b = 0.022600551661539132, J_o = 10.81860965860082
J_b = 0.02616563882852389, J_o = 7.788353361218038
J_b = 0.030967593182760333, J_o = 6.420810836802795
J_b = 0.03200655560725026, J_o = 5.11505339982398
J_b = 0.03244131330933012, J_o = 4.706520339883722
J_b = 0.034392425656366195, J_o = 3.8931488933172
J_b = 0.03793609616563665, J_o = 3.0868340259197646
J_b = 0.048831163275358476, J_o = 1.693701695391613
J_b = 0.056579787249440884, J_o = 7.619358654261333
J_b = 0.04937098577527599, J_o = 1.6509927803501374
J_b = 0.05188637743238513, J_o = 1.3847317450889463
J_b = 0.05269617658334609, J_o = 1.2983839794235417
J_b = 0.05255749920302811, J_o = 1.2744740074735033
J_b = 0.0531245708449948, J_o = 1.184416410024168
J_b = 0.05393149754869784, J_o = 1.1376150857516856
J_b = 0.054645955197681916, J_o = 1.1140114677531618
J_b = 0.05502569522707711, J_o = 1.1029480647499676
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
W_opt:  [-0.06737931 -0.06526939 -0.06331765 -0.06118353 -0.05886025 -0.05675395
 -0.05533703 -0.05450363 -0.05403151 -0.05377749]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1392 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.4201, add (DA)= 0.0001decode = 0.4230 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5623 s, inc stats = 0.5704, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.17604764e-11 3.11438678e-10 3.71864079e-10 9.29865188e-11
 1.32545093e-09]
u_DA:    [2.60047161e-09 4.88101955e-09 6.57974704e-09 3.62479881e-09
 8.85159449e-09]
ref_MAE: [6.92466652e-09 1.01802569e-08 1.26880689e-08 8.45117572e-09
 1.91385387e-08]
da_MAE:  [2.52871113e-09 4.56958088e-09 6.20788296e-09 3.53181229e-09
 7.52614355e-09]
% 5.95681436387983 da_MAE 0.11935911839714336 ref_MAE 0.12691947597243008
u_c taken from control states: [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
u_c before reduction of space:  [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
data[u_c] post encoding of state:  [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
J_b = 0.0, J_o = 13208.3470594912
J_b = 0.5, J_o = 836736.6343014904
J_b = 0.006127623644450336, J_o = 245.79583626934118
J_b = 0.006130199268998355, J_o = 242.18153181026565
J_b = 0.0061576725975105735, J_o = 228.08556101445907
J_b = 0.006542299196681794, J_o = 177.48163047916103
J_b = 0.022239262858355813, J_o = 24.897702138078124
J_b = 0.021275583374748018, J_o = 19.358750428726907
J_b = 0.021080561189250318, J_o = 16.816031459799486
J_b = 0.02246450550494585, J_o = 11.68056643682446
J_b = 0.026020286681813654, J_o = 8.320395314128396
J_b = 0.03081433517418697, J_o = 6.334997306372601
J_b = 0.03245647400628209, J_o = 5.3689326253925245
J_b = 0.03327205474934327, J_o = 4.9097592662797025
J_b = 0.035242317924584286, J_o = 4.17342897089576
J_b = 0.03860390632439231, J_o = 3.3447918136485737
J_b = 0.04816728711884058, J_o = 1.9110751299927764
J_b = 0.054722331062414864, J_o = 58.93730259032834
J_b = 0.048220834076636195, J_o = 1.905814431305533
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
W_opt:  [-0.0650433  -0.06303232 -0.06123333 -0.05933176 -0.05729636 -0.05544303
 -0.0541558  -0.05334452 -0.05283433 -0.05250925]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1215 s, v_trunc (Latent to Reduced) = 0.0019, dec (Reduced to Full) = 0.4693, add (DA)= 0.0001decode = 0.4734 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.5952 s, inc stats = 0.6014, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.07771313e-11 3.09921827e-10 3.69104428e-10 9.17043647e-11
 1.31327160e-09]
u_DA:    [2.60529300e-09 4.87704130e-09 6.59369370e-09 3.63104458e-09
 8.85989352e-09]
ref_MAE: [6.92564986e-09 1.01817738e-08 1.26908285e-08 8.45245788e-09
 1.91507181e-08]
da_MAE:  [2.53451587e-09 4.56711948e-09 6.22458928e-09 3.53934022e-09
 7.54662192e-09]
% 5.9088417580142405 da_MAE 0.12022338407585784 ref_MAE 0.12777330657006541
u_c taken from control states: [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
u_c before reduction of space:  [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
data[u_c] post encoding of state:  [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
J_b = 0.0, J_o = 13208.002282764504
J_b = 0.5, J_o = 836747.0259377186
J_b = 0.006127046061270346, J_o = 246.67763076573718
J_b = 0.0061296281211055525, J_o = 243.05427587449628
J_b = 0.006157170092681119, J_o = 228.9225799872516
J_b = 0.006542757694739217, J_o = 178.18337528177182
J_b = 0.02231030812275164, J_o = 25.164837394960323
J_b = 0.021333146337563304, J_o = 19.571627278991343
J_b = 0.021128098469546164, J_o = 17.000390640015112
J_b = 0.02243810560182852, J_o = 11.968452453205643
J_b = 0.025985247921733207, J_o = 8.501707774845318
J_b = 0.030770897918575006, J_o = 6.3652432050169905
J_b = 0.032601463462284465, J_o = 5.458934521582124
J_b = 0.03355653637265903, J_o = 4.988324102064524
J_b = 0.035561719536759046, J_o = 4.263092180723566
J_b = 0.03888956873196165, J_o = 3.4261704632279817
J_b = 0.048152690997235154, J_o = 1.994248858265724
J_b = 0.05461910916638322, J_o = 34.22173722828649
J_b = 0.04824346282104325, J_o = 1.9855224915894283
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
W_opt:  [-0.06495138 -0.0629403  -0.06114355 -0.05924497 -0.05721313 -0.05536378
 -0.05408097 -0.05327463 -0.05276976 -0.05245045]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1324 s, v_trunc (Latent to Reduced) = 0.0051, dec (Reduced to Full) = 0.2869, add (DA)= 0.0001decode = 0.2939 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.4264 s, inc stats = 0.4401, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.98256739e-11 3.08469494e-10 3.66519370e-10 9.05507017e-11
 1.30122465e-09]
u_DA:    [2.60614215e-09 4.87793121e-09 6.59540315e-09 3.63114270e-09
 8.86149048e-09]
ref_MAE: [6.92660132e-09 1.01832261e-08 1.26934136e-08 8.45361154e-09
 1.91627650e-08]
da_MAE:  [2.53631648e-09 4.56946172e-09 6.22888378e-09 3.54059200e-09
 7.56026584e-09]
% 5.879231208520379 da_MAE 0.12081227394459136 ref_MAE 0.12835878360943437
u_c taken from control states: [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
u_c before reduction of space:  [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
data[u_c] post encoding of state:  [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
J_b = 0.0, J_o = 13210.119855331075
J_b = 0.49999999999999994, J_o = 836727.1387336871
J_b = 0.0061282039991768815, J_o = 246.34374530726618
J_b = 0.006130783831262198, J_o = 242.72352644177474
J_b = 0.006158302040172194, J_o = 228.6042707112412
J_b = 0.006543556964912012, J_o = 177.91316349202262
J_b = 0.022282984861266456, J_o = 25.040756817068125
J_b = 0.02131326755900801, J_o = 19.46959866352308
J_b = 0.02111362526974085, J_o = 16.910477804450633
J_b = 0.022465730122092863, J_o = 11.816572116901437
J_b = 0.026020536293928843, J_o = 8.405967802681896
J_b = 0.03081622949367214, J_o = 6.3485462538403254
J_b = 0.03254208807383979, J_o = 5.410859117857059
J_b = 0.03341640089981492, J_o = 4.947090465626947
J_b = 0.03539732927723064, J_o = 4.216571982701
J_b = 0.03873532815767503, J_o = 3.3853167239513136
J_b = 0.04815116920107632, J_o = 1.951312557621142
J_b = 0.05463942892244517, J_o = 46.901378560179516
J_b = 0.04821757388701584, J_o = 1.9448302829067177
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
W_opt:  [-0.06493349 -0.06292271 -0.06112714 -0.05923089 -0.05720208 -0.05535534
 -0.05407342 -0.05326649 -0.05276009 -0.05243869]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1106 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.1319, add (DA)= 0.0001decode = 0.1351 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2457 s, inc stats = 0.2516, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.89246333e-11 3.07089287e-10 3.64100188e-10 8.95247745e-11
 1.28932368e-09]
u_DA:    [2.60547088e-09 4.87701094e-09 6.59432678e-09 3.63095754e-09
 8.86015581e-09]
ref_MAE: [6.92750236e-09 1.01846063e-08 1.26958328e-08 8.45463747e-09
 1.91746660e-08]
da_MAE:  [2.53654625e-09 4.56992165e-09 6.23022659e-09 3.54143277e-09
 7.57083212e-09]
% 5.858079010912731 da_MAE 0.1211284740114218 ref_MAE 0.12866581937016427
u_c taken from control states: [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
u_c before reduction of space:  [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
data[u_c] post encoding of state:  [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
J_b = 0.0, J_o = 13213.960926229947
J_b = 0.5, J_o = 836685.7574721342
J_b = 0.006130593430015272, J_o = 245.1233651835273
J_b = 0.006133164699445519, J_o = 241.5151938177408
J_b = 0.006160591573368088, J_o = 227.44360023286833
J_b = 0.0065445678082837, J_o = 176.93469594575564
J_b = 0.022183631658622496, J_o = 24.63478004780106
J_b = 0.021236823316117117, J_o = 19.141366363253315
J_b = 0.021053928126391546, J_o = 16.622427724546522
J_b = 0.0225435059370418, J_o = 11.341817300144108
J_b = 0.026112614639595598, J_o = 8.110632590802728
J_b = 0.030930723767756855, J_o = 6.351069050344396
J_b = 0.03231454120604516, J_o = 5.268326252661394
J_b = 0.0329392800843636, J_o = 4.830941661030162
J_b = 0.034866640420218864, J_o = 4.070638029667221
J_b = 0.03828101549271558, J_o = 3.2538362576091773
J_b = 0.04841213203038011, J_o = 1.812352175034198
J_b = 0.05600213748575356, J_o = 62.13774328991394
J_b = 0.048475358681200016, J_o = 1.8065015961961906
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
W_opt:  [-0.06521467 -0.06319522 -0.0613904  -0.05948432 -0.05744482 -0.05558784
 -0.05429703 -0.05348226 -0.05296851 -0.05263978]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1157 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.2974, add (DA)= 0.0001decode = 0.3013 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4171 s, inc stats = 0.4248, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.80774283e-11 3.05789178e-10 3.61819366e-10 8.86181819e-11
 1.27756112e-09]
u_DA:    [2.60456599e-09 4.87648891e-09 6.59131820e-09 3.63142681e-09
 8.85769410e-09]
ref_MAE: [6.92834957e-09 1.01859064e-08 1.26981136e-08 8.45554406e-09
 1.91864285e-08]
da_MAE:  [2.53648856e-09 4.57069973e-09 6.22949883e-09 3.54280863e-09
 7.58013298e-09]
% 5.849969083291845 da_MAE 0.12117577811814116 ref_MAE 0.12870497963547342
u_c taken from control states: [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
u_c before reduction of space:  [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
data[u_c] post encoding of state:  [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
J_b = 0.0, J_o = 13220.695047572337
J_b = 0.5000000000000001, J_o = 836609.8626954355
J_b = 0.006134965894689492, J_o = 242.59382970697652
J_b = 0.006137519222540167, J_o = 239.01089978651726
J_b = 0.006164754719614076, J_o = 225.0391234061612
J_b = 0.006546051678648873, J_o = 174.9111107084336
J_b = 0.021977554825113804, J_o = 23.81946862198058
J_b = 0.021077653769618645, J_o = 18.48604548092632
J_b = 0.020928748642822688, J_o = 16.041537536985956
J_b = 0.02275130652501449, J_o = 10.379263547693647
J_b = 0.026309985840109018, J_o = 7.526699575216411
J_b = 0.03106566269423518, J_o = 6.55658924509188
J_b = 0.031839185068984824, J_o = 4.9931878932673195
J_b = 0.032173553840448635, J_o = 4.610243206209869
J_b = 0.034226549935701685, J_o = 3.736402504196211
J_b = 0.0378531468878166, J_o = 2.946773943273464
J_b = 0.049176112081516586, J_o = 1.6396480749331657
J_b = 0.056302647584623694, J_o = 1.74372161820936
J_b = 0.052230059096416426, J_o = 1.4077144971901057
J_b = 0.05441930062890766, J_o = 1.357817693469251
J_b = 0.05224852852031612, J_o = 1.2293703066003698
J_b = 0.052008719482951694, J_o = 1.2251638291072362
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
W_opt:  [-0.06709157 -0.06498783 -0.06308575 -0.06105377 -0.05886613 -0.05687658
 -0.05550705 -0.05466021 -0.05414109 -0.05382181]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1367 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1610, add (DA)= 0.0001decode = 0.1638 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3006 s, inc stats = 0.3148, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.72769746e-11 3.04559496e-10 3.59649731e-10 8.78252262e-11
 1.26593486e-09]
u_DA:    [2.59405720e-09 4.87894374e-09 6.58007103e-09 3.62615733e-09
 8.84774210e-09]
ref_MAE: [6.92915002e-09 1.01871361e-08 1.27002832e-08 8.45633702e-09
 1.91980548e-08]
da_MAE:  [2.52678022e-09 4.57438425e-09 6.22042130e-09 3.53833211e-09
 7.58180723e-09]
% 5.86763249217902 da_MAE 0.1209006135596523 ref_MAE 0.1284368137767355
u_c taken from control states: [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
u_c before reduction of space:  [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
data[u_c] post encoding of state:  [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
J_b = 0.0, J_o = 13229.549582905987
J_b = 0.5000000000000001, J_o = 836508.4267697753
J_b = 0.006140807551594147, J_o = 239.07110447740124
J_b = 0.006143335609919998, J_o = 235.52372451108027
J_b = 0.006170301565395729, J_o = 221.69250876012669
J_b = 0.006547824942055965, J_o = 172.1005115855936
J_b = 0.02168882140210646, J_o = 22.723065780449005
J_b = 0.020856327408408995, J_o = 17.6100533296533
J_b = 0.020755863305663005, J_o = 15.249227098834833
J_b = 0.023189161514512044, J_o = 9.076201338267452
J_b = 0.02661028522130311, J_o = 6.747538981720645
J_b = 0.03046984482392449, J_o = 5.93764890719307
J_b = 0.031576907893287695, J_o = 4.526620941539223
J_b = 0.032043939536660584, J_o = 4.134997533906275
J_b = 0.03438224574060978, J_o = 3.2974507932039074
J_b = 0.03824010690401992, J_o = 2.5077983078922674
J_b = 0.048933258814534406, J_o = 1.44375559581438
J_b = 0.05467984025430528, J_o = 2.245828607165264
J_b = 0.05030121108018275, J_o = 1.3388461291300422
J_b = 0.050610632366852475, J_o = 1.1497060500496592
J_b = 0.05052951263044226, J_o = 1.1320541668136856
J_b = 0.05071698225485578, J_o = 1.1108205431026148
J_b = 0.05117723197259155, J_o = 1.0729040104072893
J_b = 0.05159656110605829, J_o = 1.0470732566617056
J_b = 0.04962741868982925, J_o = 1.3360832814913577
J_b = 0.05108677748923889, J_o = 1.0226631070582817
J_b = 0.061579183309738994, J_o = 1.2794236633817524
J_b = 0.053062446729084764, J_o = 1.0025972536553243
J_b = 0.05278196239186188, J_o = 0.9920639767306403
J_b = 0.05258079476516659, J_o = 0.9902390414636386
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
W_opt:  [-0.06586192 -0.06382308 -0.06195743 -0.05994397 -0.05776465 -0.05578306
 -0.05442791 -0.05360239 -0.05310538 -0.05280723]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1265 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.1643, add (DA)= 0.0001decode = 0.1683 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2949 s, inc stats = 0.3020, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.65253747e-11 3.03375980e-10 3.57566291e-10 8.71478571e-11
 1.25444566e-09]
u_DA:    [2.59647563e-09 4.87441656e-09 6.57600913e-09 3.62368169e-09
 8.84571071e-09]
ref_MAE: [6.92990162e-09 1.01883196e-08 1.27023667e-08 8.45701438e-09
 1.92095440e-08]
da_MAE:  [2.52995026e-09 4.57104058e-09 6.21844284e-09 3.53653383e-09
 7.59126505e-09]
% 5.893048184099557 da_MAE 0.12035069591661927 ref_MAE 0.12788714711752533
\% improve_point: 6.87, mse_ref_points: 1.4787280748403315e-05, mse_da_points: 1.3823225270567126e-05, % improve_overlap: 7.59, mse_ref_overlap: 0.23285, mse_da_overlap: 0.21638
DA - - L2: 2899.75, L1: 2921.10, % Improve: 8.37%, DA_MAE: 0.09, mse_ref: 0.24, mse_DA: 0.224, time(s): 0.7617s,
u_c taken from control states: [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
u_c before reduction of space:  [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
data[u_c] post encoding of state:  [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
J_b = 0.0, J_o = 13240.769863772763
J_b = 0.5000000000000001, J_o = 836378.6303906832
J_b = 0.006148283872790507, J_o = 234.44961707363427
J_b = 0.0061507781929442396, J_o = 230.94969859719498
J_b = 0.006177384274584039, J_o = 217.30608769144675
J_b = 0.00654986941754111, J_o = 168.42865206859884
J_b = 0.0213079338128155, J_o = 21.351717611249423
J_b = 0.02056806340986078, J_o = 16.520816822779135
J_b = 0.020534980227526912, J_o = 14.231031752912864
J_b = 0.023986469034080835, J_o = 7.574808940733307
J_b = 0.026984808626564088, J_o = 5.7830388306512575
J_b = 0.029777009471653383, J_o = 4.389405797844753
J_b = 0.0323676497891719, J_o = 3.706747452382049
J_b = 0.035110259789368804, J_o = 3.04543927817283
J_b = 0.039930794084546584, J_o = 2.067266902394182
J_b = 0.05112429667024917, J_o = 1.1914168246698018
J_b = 0.050810332205179415, J_o = 1.0944933609885363
J_b = 0.04928020109230631, J_o = 1.6682002146757284
J_b = 0.05054523919723448, J_o = 1.0708608311040289
J_b = 0.04916766980143067, J_o = 0.9529978414794225
J_b = 0.04892046877123286, J_o = 0.940824499908087
J_b = 0.04883075019186021, J_o = 0.9244191420584351
J_b = 0.049018949820061705, J_o = 0.9126223993974472
J_b = 0.05020264177008258, J_o = 0.89508860700729
J_b = 0.05049525556564715, J_o = 0.8726706554720551
J_b = 0.050559326804457114, J_o = 0.8646736557939227
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
W_opt:  [-0.06443279 -0.062473   -0.06067747 -0.05874931 -0.05666649 -0.05476531
 -0.0534454  -0.05261633 -0.05209125 -0.05174974]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1797 s, v_trunc (Latent to Reduced) = 0.0033, dec (Reduced to Full) = 0.1518, add (DA)= 0.0001decode = 0.1569 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3368 s, inc stats = 0.3456, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.58272224e-11 3.02208783e-10 3.55542598e-10 8.65820966e-11
 1.24309012e-09]
u_DA:    [2.59502815e-09 4.86700515e-09 6.57336205e-09 3.62224064e-09
 8.84469843e-09]
ref_MAE: [6.93059977e-09 1.01894868e-08 1.27043903e-08 8.45758015e-09
 1.92208995e-08]
da_MAE:  [2.52920093e-09 4.56479636e-09 6.21781945e-09 3.53565854e-09
 7.60160832e-09]
% 5.944874133414619 da_MAE 0.11950164548168148 ref_MAE 0.1270548993270088
u_c taken from control states: [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
u_c before reduction of space:  [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
data[u_c] post encoding of state:  [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
J_b = 0.0, J_o = 13253.567485726808
J_b = 0.5000000000000002, J_o = 836230.1739275776
J_b = 0.00615684076778767, J_o = 229.1151296649284
J_b = 0.0061592955037694215, J_o = 225.67089828971476
J_b = 0.006185479354241425, J_o = 212.24743463780896
J_b = 0.00655205326084952, J_o = 164.20896961336436
J_b = 0.02086054000966366, J_o = 19.862949851068986
J_b = 0.020236633570768114, J_o = 15.349691305404654
J_b = 0.020294141782315415, J_o = 13.077287784337594
J_b = 0.02484872391055755, J_o = 6.191461495848348
J_b = 0.027347990662762237, J_o = 4.828169126483962
J_b = 0.029502742069097865, J_o = 4.067733615236012
J_b = 0.0319869684243655, J_o = 3.284914677053756
J_b = 0.034873037288157806, J_o = 2.529300727117901
J_b = 0.0435698735644953, J_o = 1.3371919105312502
J_b = 0.049418924379828075, J_o = 1.1583655776495285
J_b = 0.0466853382192449, J_o = 0.8822626287641071
J_b = 0.04618313470747786, J_o = 0.8598415865821651
J_b = 0.04547387204068047, J_o = 0.8395996999538999
J_b = 0.04607483784505625, J_o = 0.8155612430196723
J_b = 0.047193933755932144, J_o = 0.7937472718951915
J_b = 0.0476301705240752, J_o = 0.7890391492106658
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
W_opt:  [-0.06288385 -0.06101762 -0.05931678 -0.0575142  -0.055579   -0.05380217
 -0.05253673 -0.05170114 -0.05113382 -0.05072891]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1140 s, v_trunc (Latent to Reduced) = 0.0032, dec (Reduced to Full) = 0.2848, add (DA)= 0.0001decode = 0.2899 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4039 s, inc stats = 0.4100, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.51930975e-11 3.01014996e-10 3.53557529e-10 8.61298304e-11
 1.23186955e-09]
u_DA:    [2.59066987e-09 4.86064356e-09 6.56941989e-09 3.62056927e-09
 8.83970945e-09]
ref_MAE: [6.93123390e-09 1.01906806e-08 1.27063754e-08 8.45803241e-09
 1.92321201e-08]
da_MAE:  [2.52547677e-09 4.55962856e-09 6.21586236e-09 3.53443944e-09
 7.60783990e-09]
% 6.010935879673102 da_MAE 0.11842108370127283 ref_MAE 0.12599453437441138
u_c taken from control states: [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
u_c before reduction of space:  [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
data[u_c] post encoding of state:  [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
J_b = 0.0, J_o = 13266.637161436947
J_b = 0.5, J_o = 836079.4912276616
J_b = 0.0061655357159206845, J_o = 223.76026427864497
J_b = 0.006167950367860103, J_o = 220.3724286680128
J_b = 0.0061937066552138955, J_o = 207.17201720110387
J_b = 0.0065542946781671305, J_o = 159.98526694338483
J_b = 0.020402222099796717, J_o = 18.45618915237111
J_b = 0.019905689286051576, J_o = 14.254728761250878
J_b = 0.020079371179294522, J_o = 11.912658904926639
J_b = 0.02525961075565824, J_o = 4.973381460386497
J_b = 0.02753467118739766, J_o = 4.042655807604871
J_b = 0.029788337530302474, J_o = 3.3677446478383057
J_b = 0.03219058417087797, J_o = 2.6800151673862023
J_b = 0.03692763472800265, J_o = 1.6911651838259378
J_b = 0.04457157846151812, J_o = 1.3943513968180623
J_b = 0.04393885586002145, J_o = 0.8805674292377477
J_b = 0.04329962594186716, J_o = 0.846834763038756
J_b = 0.04316341017437349, J_o = 0.8291167662944893
J_b = 0.04302138359542638, J_o = 0.787300699275052
J_b = 0.04349914286050041, J_o = 0.7562170634668461
J_b = 0.04491303631218081, J_o = 0.7179431929255933
J_b = 0.04538920494690123, J_o = 0.7104109507508716
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
W_opt:  [-0.0613214  -0.0595585  -0.05794905 -0.05625698 -0.05444673 -0.05277399
 -0.05155471 -0.05071481 -0.05011237 -0.04965339]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1239 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.1781, add (DA)= 0.0001decode = 0.1822 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3062 s, inc stats = 0.3215, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.46212947e-11 2.99757235e-10 3.51590572e-10 8.57939021e-11
 1.22077790e-09]
u_DA:    [2.58850157e-09 4.85401211e-09 6.56562233e-09 3.61921074e-09
 8.83671224e-09]
ref_MAE: [6.93180570e-09 1.01919384e-08 1.27083424e-08 8.45836834e-09
 1.92432118e-08]
da_MAE:  [2.52388028e-09 4.55425488e-09 6.21403176e-09 3.53341684e-09
 7.61593434e-09]
% 6.07642270113756 da_MAE 0.1172352978089035 ref_MAE 0.12481988141897934
u_c taken from control states: [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
u_c before reduction of space:  [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
data[u_c] post encoding of state:  [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
J_b = 0.0, J_o = 13279.188146904904
J_b = 0.4999999999999999, J_o = 835936.0046915747
J_b = 0.006173827164002012, J_o = 218.74152019387617
J_b = 0.006176203312107258, J_o = 215.40785323001137
J_b = 0.0062015488918965595, J_o = 202.42160247055233
J_b = 0.006556387008946809, J_o = 156.05127296871584
J_b = 0.01997039772020314, J_o = 17.242859332805857
J_b = 0.019599662924585388, J_o = 13.315783406256617
J_b = 0.019916966637033157, J_o = 10.815988908282941
J_b = 0.024889295242475466, J_o = 4.5578054049664525
J_b = 0.027355231753576972, J_o = 3.4950647752664143
J_b = 0.029193547421528875, J_o = 3.0046578684807486
J_b = 0.030890212077577455, J_o = 2.5270128911295076
J_b = 0.033987412595463, J_o = 1.813050332171472
J_b = 0.04069553440097458, J_o = 1.152746208163287
J_b = 0.04192373951506266, J_o = 0.8560447101222481
J_b = 0.041154732646082416, J_o = 0.8084523900948859
J_b = 0.0407850747717421, J_o = 0.9921324402401945
J_b = 0.041109967755534875, J_o = 0.8052099227157319
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
W_opt:  [-0.05931119 -0.05764565 -0.05614944 -0.05461407 -0.05299391 -0.0514871
 -0.05035049 -0.04952021 -0.04888527 -0.04836947]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1046 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.1574, add (DA)= 0.0001decode = 0.1604 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2651 s, inc stats = 0.2711, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.41035184e-11 2.98405115e-10 3.49620668e-10 8.55653261e-11
 1.20981499e-09]
u_DA:    [2.58176924e-09 4.84738451e-09 6.56653151e-09 3.62074868e-09
 8.83388852e-09]
ref_MAE: [6.93232348e-09 1.01932905e-08 1.27103123e-08 8.45859692e-09
 1.92541747e-08]
da_MAE:  [2.51766572e-09 4.54897940e-09 6.21691084e-09 3.53518335e-09
 7.62407352e-09]
% 6.138338047911734 da_MAE 0.1160484451408005 ref_MAE 0.12363774807230399
u_c taken from control states: [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
u_c before reduction of space:  [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
data[u_c] post encoding of state:  [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
J_b = 0.0, J_o = 13289.787912437001
J_b = 0.49999999999999994, J_o = 835817.0760982516
J_b = 0.006180711618122901, J_o = 214.75372358976242
J_b = 0.006183056815678615, J_o = 211.46359850637043
J_b = 0.00620807225627284, J_o = 198.64948057104638
J_b = 0.006558288424591944, J_o = 152.935127201651
J_b = 0.019626567986513094, J_o = 16.329487307562193
J_b = 0.01936043343818027, J_o = 12.609908387082783
J_b = 0.01983079197041378, J_o = 9.914905956220323
J_b = 0.02410519069996139, J_o = 4.455802692737716
J_b = 0.02673759638609532, J_o = 3.2940928372488107
J_b = 0.028496598459198167, J_o = 2.8506592027761046
J_b = 0.029961203448896787, J_o = 2.4218574539697384
J_b = 0.03305405578815032, J_o = 1.71384346836442
J_b = 0.040336370585307875, J_o = 1.5639882056241166
J_b = 0.038795271604570476, J_o = 0.9128276103356021
J_b = 0.03862318282530717, J_o = 0.845699287056224
J_b = 0.03890279670090525, J_o = 0.8030029523871473
J_b = 0.039989001090288086, J_o = 1.3479269139510803
J_b = 0.039003912988668045, J_o = 0.7957716330408654
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
W_opt:  [-0.05757083 -0.05598872 -0.05456973 -0.05312675 -0.05161184 -0.05019608
 -0.0491075  -0.04828791 -0.04764078 -0.0470987 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1611 s, v_trunc (Latent to Reduced) = 0.0090, dec (Reduced to Full) = 0.2407, add (DA)= 0.0001decode = 0.2519 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4131 s, inc stats = 0.4282, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.36409648e-11 2.96932273e-10 3.47629308e-10 8.54366600e-11
 1.19898251e-09]
u_DA:    [2.57912751e-09 4.84245946e-09 6.56342532e-09 3.61927068e-09
 8.83108939e-09]
ref_MAE: [6.93278603e-09 1.01947633e-08 1.27123036e-08 8.45872558e-09
 1.92650072e-08]
da_MAE:  [2.51548654e-09 4.54552719e-09 6.21579601e-09 3.53383402e-09
 7.63210688e-09]
% 6.195396930135086 da_MAE 0.11496877387655625 ref_MAE 0.12256197469427853
u_c taken from control states: [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
u_c before reduction of space:  [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
data[u_c] post encoding of state:  [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
J_b = 0.0, J_o = 13297.362573335547
J_b = 0.5000000000000001, J_o = 835735.7168333237
J_b = 0.006185434774610655, J_o = 212.32216779023366
J_b = 0.0061877611929984505, J_o = 209.058465224459
J_b = 0.006212576322468216, J_o = 196.3488736754593
J_b = 0.006559988135044758, J_o = 151.03400690503875
J_b = 0.01941478289963557, J_o = 15.782839115708516
J_b = 0.019216781797699364, J_o = 12.188042247478347
J_b = 0.019809433436922954, J_o = 9.336546781756878
J_b = 0.0236888217969994, J_o = 4.386307249666464
J_b = 0.026365217489726592, J_o = 3.1823000133713055
J_b = 0.028126572399202132, J_o = 2.743361524990282
J_b = 0.02948949831217637, J_o = 2.335965350382235
J_b = 0.033161072978156285, J_o = 1.5155742659065066
J_b = 0.04072855684111522, J_o = 2.4878722663870034
J_b = 0.03505982240669181, J_o = 1.2643259620318303
J_b = 0.03753704789886311, J_o = 0.9192948301794329
J_b = 0.038255040214926254, J_o = 0.8050907032824878
J_b = 0.03856398499290731, J_o = 1.7058162545509288
J_b = 0.038269764796919084, J_o = 0.80203789133127
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
W_opt:  [-0.0568776  -0.05532819 -0.05394065 -0.05253902 -0.05107314 -0.04969839
 -0.0486269  -0.04780342 -0.04713975 -0.0465734 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0580 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.2447, add (DA)= 0.0001decode = 0.2489 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3071 s, inc stats = 0.3173, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.32409512e-11 2.95341986e-10 3.45597553e-10 8.53975892e-11
 1.18828746e-09]
u_DA:    [2.58051375e-09 4.84101178e-09 6.56620751e-09 3.61982165e-09
 8.83452102e-09]
ref_MAE: [6.93318604e-09 1.01963536e-08 1.27143354e-08 8.45876465e-09
 1.92757022e-08]
da_MAE:  [2.51727280e-09 4.54566979e-09 6.22060996e-09 3.53442406e-09
 7.64623356e-09]
% 6.23794521484587 da_MAE 0.11411178710706889 ref_MAE 0.1217035904007693
u_c taken from control states: [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
u_c before reduction of space:  [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
data[u_c] post encoding of state:  [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
J_b = 0.0, J_o = 13301.8517237698
J_b = 0.5000000000000001, J_o = 835692.6688425583
J_b = 0.006187950586569889, J_o = 211.48431463178076
J_b = 0.006190271022551095, J_o = 208.2290371079955
J_b = 0.006215022339683961, J_o = 195.55293052033625
J_b = 0.006561540779544054, J_o = 150.36856028940807
J_b = 0.01933825080841342, J_o = 15.573136271509046
J_b = 0.019168771590940457, J_o = 12.027476589544762
J_b = 0.019819009333232718, J_o = 9.104986371614546
J_b = 0.023561375344645027, J_o = 4.355048054553795
J_b = 0.02624721873948496, J_o = 3.140804183845219
J_b = 0.027981962244387197, J_o = 2.707227023562666
J_b = 0.029359723150853664, J_o = 2.2945825795004477
J_b = 0.03310356491469519, J_o = 1.4557827403228583
J_b = 0.03824825946869938, J_o = 0.9961946103051398
J_b = 0.03894532583455306, J_o = 0.7580955328827712
J_b = 0.03856982979348657, J_o = 0.7211586208965561
J_b = 0.03849343940553598, J_o = 1.0944044906341563
J_b = 0.038564397536852035, J_o = 0.7195919440464676
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
W_opt:  [-0.05697483 -0.05543446 -0.05404568 -0.0526395  -0.05116639 -0.04978209
 -0.04869913 -0.04786241 -0.04718394 -0.0466012 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1237 s, v_trunc (Latent to Reduced) = 0.0032, dec (Reduced to Full) = 0.1865, add (DA)= 0.0001decode = 0.1916 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3155 s, inc stats = 0.3242, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.29058441e-11 2.93658618e-10 3.43502080e-10 8.54270316e-11
 1.17773562e-09]
u_DA:    [2.57794358e-09 4.83817714e-09 6.56102631e-09 3.61759233e-09
 8.82875473e-09]
ref_MAE: [6.93352115e-09 1.01980370e-08 1.27164309e-08 8.45873521e-09
 1.92862540e-08]
da_MAE:  [2.51503773e-09 4.54451853e-09 6.21752423e-09 3.53216530e-09
 7.65101911e-09]
% 6.252193170392713 da_MAE 0.11354386477452968 ref_MAE 0.12111628913186526
u_c taken from control states: [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
u_c before reduction of space:  [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
data[u_c] post encoding of state:  [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
J_b = 0.0, J_o = 13304.065545866542
J_b = 0.49999999999999983, J_o = 835677.8371429134
J_b = 0.006188839482318981, J_o = 211.81998904294574
J_b = 0.006191163447812869, J_o = 208.55975897495097
J_b = 0.006215952413081031, J_o = 195.86433387524244
J_b = 0.006562997926835392, J_o = 150.61055623273734
J_b = 0.019361736043905366, J_o = 15.599294455993123
J_b = 0.01919072942641154, J_o = 12.04942944729564
J_b = 0.019837880537597274, J_o = 9.132010092017625
J_b = 0.023584659701335966, J_o = 4.371815539163162
J_b = 0.02627900547199307, J_o = 3.1512811377418934
J_b = 0.028022474441959332, J_o = 2.7158899018479636
J_b = 0.029405227177428127, J_o = 2.3019229015509484
J_b = 0.033168237620307156, J_o = 1.4606327344940138
J_b = 0.038357498241833425, J_o = 1.0321810324535827
J_b = 0.0388232540627513, J_o = 0.7725462132036207
J_b = 0.038518901667675555, J_o = 0.7329166062774589
J_b = 0.038580370536504635, J_o = 0.9596838650607964
J_b = 0.038523438182925834, J_o = 0.7305090502182511
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
W_opt:  [-0.05696683 -0.05542794 -0.05403905 -0.0526331  -0.0511608  -0.04977666
 -0.04869185 -0.0478515  -0.04716841 -0.04658036]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1120 s, v_trunc (Latent to Reduced) = 0.0029, dec (Reduced to Full) = 0.4285, add (DA)= 0.0001decode = 0.4327 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5447 s, inc stats = 0.5640, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.26349464e-11 2.91916614e-10 3.41322793e-10 8.54937984e-11
 1.16733163e-09]
u_DA:    [2.57753999e-09 4.83767203e-09 6.56107602e-09 3.61742729e-09
 8.82838998e-09]
ref_MAE: [6.93379205e-09 1.01997790e-08 1.27186102e-08 8.45866844e-09
 1.92966580e-08]
da_MAE:  [2.51490504e-09 4.54575542e-09 6.21975323e-09 3.53193349e-09
 7.66105835e-09]
% 6.246152030155933 da_MAE 0.11323506579636108 ref_MAE 0.12077911280269067
u_c taken from control states: [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
u_c before reduction of space:  [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
data[u_c] post encoding of state:  [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
J_b = 0.0, J_o = 13304.171875634296
J_b = 0.5000000000000001, J_o = 835688.710666764
J_b = 0.006188244792018298, J_o = 213.19297162036884
J_b = 0.006190580660322792, J_o = 209.91601228349882
J_b = 0.006215496588904057, J_o = 197.1547737471921
J_b = 0.006564319589041723, J_o = 151.65540058073978
J_b = 0.019473912085724476, J_o = 15.835660765438401
J_b = 0.019274499967583836, J_o = 12.233856800376097
J_b = 0.019864946473069477, J_o = 9.388387212279588
J_b = 0.023743705829907133, J_o = 4.429661554381715
J_b = 0.02644376573550251, J_o = 3.207980301811669
J_b = 0.028226355643970535, J_o = 2.7644015658465193
J_b = 0.029605905251018368, J_o = 2.352489329490773
J_b = 0.03332461331334099, J_o = 1.5264449908162443
J_b = 0.04078083832133998, J_o = 2.4759247233899946
J_b = 0.03520923982768055, J_o = 1.2761365258581314
J_b = 0.03765846423603649, J_o = 0.9357595726939018
J_b = 0.03837238731126493, J_o = 0.821358014383527
J_b = 0.038708303501743264, J_o = 1.7928577679787836
J_b = 0.038387897184237366, J_o = 0.8182932043944988
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
W_opt:  [-0.05700441 -0.05545525 -0.05406237 -0.05265538 -0.05118462 -0.04980333
 -0.04872121 -0.04788343 -0.04720332 -0.04661895]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1484 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.3587, add (DA)= 0.0001decode = 0.3629 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5114 s, inc stats = 0.5174, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.24210683e-11 2.90154077e-10 3.39043554e-10 8.55566732e-11
 1.15707926e-09]
u_DA:    [2.58016452e-09 4.84026256e-09 6.56608099e-09 3.61983561e-09
 8.83379562e-09]
ref_MAE: [6.93400593e-09 1.02015415e-08 1.27208894e-08 8.45860557e-09
 1.93069104e-08]
da_MAE:  [2.51774345e-09 4.55010849e-09 6.22703743e-09 3.53427893e-09
 7.67671636e-09]
% 6.228617201324449 da_MAE 0.11316675815214874 ref_MAE 0.12068368277677477
u_c taken from control states: [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
u_c before reduction of space:  [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
data[u_c] post encoding of state:  [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
J_b = 0.0, J_o = 13303.389538368056
J_b = 0.4999999999999999, J_o = 835710.6234548821
J_b = 0.00618701383656671, J_o = 215.02602002966745
J_b = 0.0061893652319628175, J_o = 211.72723362271762
J_b = 0.00621444678285466, J_o = 198.88004692612722
J_b = 0.006565588495340651, J_o = 153.0586430391117
J_b = 0.01962530983065667, J_o = 16.173915320579876
J_b = 0.019385993968692616, J_o = 12.496933836970907
J_b = 0.019903421772553782, J_o = 9.744790230812459
J_b = 0.023997685489339546, J_o = 4.493408934496157
J_b = 0.02668784882281552, J_o = 3.284427385655524
J_b = 0.028499005883672608, J_o = 2.833026995797135
J_b = 0.029915700461713726, J_o = 2.414033523838055
J_b = 0.03335864765313561, J_o = 1.6480585861728896
J_b = 0.04141276836893516, J_o = 2.3070759559370617
J_b = 0.035758060995055393, J_o = 1.3237220657650695
J_b = 0.03809687184490095, J_o = 0.9728178623209149
J_b = 0.03885912415380859, J_o = 0.852616863942492
J_b = 0.03913835864493354, J_o = 0.7885274495895915
J_b = 0.04021754405238608, J_o = 1.5476957447448454
J_b = 0.039235956820492655, J_o = 0.7776514530718233
J_b = 0.03952342420968037, J_o = 0.736109472068594
J_b = 0.04005598679591206, J_o = 0.6994623672033506
J_b = 0.04089702611061522, J_o = 0.6597853284513324
J_b = 0.04130770717357644, J_o = 0.6630964685053998
J_b = 0.04108452656559762, J_o = 0.6375619305627271
J_b = 0.04158963529442225, J_o = 0.6260949465321533
J_b = 0.04166000563078737, J_o = 0.6245970373565418
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
W_opt:  [-0.05875619 -0.05716313 -0.05569265 -0.05417565 -0.05256873 -0.0510586
 -0.04989039 -0.04900376 -0.04829564 -0.047694  ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1372 s, v_trunc (Latent to Reduced) = 0.0013, dec (Reduced to Full) = 0.1401, add (DA)= 0.0001decode = 0.1433 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2806 s, inc stats = 0.2901, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.22334304e-11 2.88419153e-10 3.36642896e-10 8.55646771e-11
 1.14696986e-09]
u_DA:    [2.58305949e-09 4.83900016e-09 6.55985867e-09 3.61584132e-09
 8.82985717e-09]
ref_MAE: [6.93419356e-09 1.02032765e-08 1.27232900e-08 8.45859756e-09
 1.93170198e-08]
da_MAE:  [2.52082606e-09 4.55058101e-09 6.22321577e-09 3.53027664e-09
 7.68288731e-09]
% 6.215698306856309 da_MAE 0.11325719042747591 ref_MAE 0.12076348427484834
\% improve_point: 6.49, mse_ref_points: 1.5246252234944407e-05, mse_da_points: 1.4318925706668022e-05, % improve_overlap: 7.26, mse_ref_overlap: 0.24054, mse_da_overlap: 0.22441
DA - - L2: 3247.59, L1: 3088.41, % Improve: 8.15%, DA_MAE: 0.10, mse_ref: 0.25, mse_DA: 0.232, time(s): 0.7242s,
u_c taken from control states: [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
u_c before reduction of space:  [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
data[u_c] post encoding of state:  [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
J_b = 0.0, J_o = 13302.95651870706
J_b = 0.5, J_o = 835728.3918156892
J_b = 0.00618602272267459, J_o = 216.6999650469216
J_b = 0.006188388261665444, J_o = 213.38129674294015
J_b = 0.006213620677567878, J_o = 200.45582758068832
J_b = 0.006566874500201941, J_o = 154.3412157904577
J_b = 0.01976327151906334, J_o = 16.487591623430173
J_b = 0.019488445759630393, J_o = 12.74061850160605
J_b = 0.019946784858212028, J_o = 10.064359645425313
J_b = 0.0242588039260066, J_o = 4.543243697879279
J_b = 0.02692780287458004, J_o = 3.3556309400409794
J_b = 0.028731709633847, J_o = 2.900539118543693
J_b = 0.030234768247166612, J_o = 2.4619854293696743
J_b = 0.033366499704529894, J_o = 1.750294259679309
J_b = 0.04029242937290291, J_o = 1.4774126830597538
J_b = 0.03922438016813219, J_o = 0.9400569605119948
J_b = 0.039010518413758154, J_o = 0.8758296873136586
J_b = 0.03924255440575747, J_o = 0.8385253602479377
J_b = 0.03982811468500711, J_o = 0.8265093844318255
J_b = 0.03996898502373644, J_o = 0.7747900898559315
J_b = 0.040421690325937926, J_o = 0.729977047808815
J_b = 0.04146212704451328, J_o = 0.6784228352565592
J_b = 0.04198404266650611, J_o = 0.6509987415297238
J_b = 0.04221233707591612, J_o = 0.6461249662719121
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
W_opt:  [-0.0592813  -0.057659   -0.05616193 -0.05461497 -0.05297549 -0.05143709
 -0.05025185 -0.04935822 -0.04864966 -0.04805186]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.2023 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.1753, add (DA)= 0.0001decode = 0.1793 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3816 s, inc stats = 0.3908, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.20436798e-11 2.86740432e-10 3.34107798e-10 8.54715932e-11
 1.13699976e-09]
u_DA:    [2.58307119e-09 4.83985163e-09 6.56066210e-09 3.61614677e-09
 8.82975471e-09]
ref_MAE: [6.93438331e-09 1.02049552e-08 1.27258251e-08 8.45869065e-09
 1.93269899e-08]
da_MAE:  [2.52102751e-09 4.55311120e-09 6.22655431e-09 3.53067518e-09
 7.69275495e-09]
% 6.2041947373056345 da_MAE 0.11342331159072308 ref_MAE 0.12092578263287773
u_c taken from control states: [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
u_c before reduction of space:  [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
data[u_c] post encoding of state:  [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
J_b = 0.0, J_o = 13302.158924259369
J_b = 0.5, J_o = 835749.586134524
J_b = 0.00618483156422717, J_o = 218.43276974315646
J_b = 0.006187211524406661, J_o = 215.09382701307504
J_b = 0.0062125977663212185, J_o = 202.08848259061656
J_b = 0.006568005153125067, J_o = 155.6739288666564
J_b = 0.019907235567446613, J_o = 16.826196924182312
J_b = 0.01959480635484253, J_o = 13.00300775125037
J_b = 0.01999576701455353, J_o = 10.40002852931178
J_b = 0.024555779355873813, J_o = 4.590362413557724
J_b = 0.027186438862944605, J_o = 3.432747467887643
J_b = 0.02897872537615847, J_o = 2.970936092125841
J_b = 0.03059442573779378, J_o = 2.50631361462145
J_b = 0.033560480126078235, J_o = 1.8216142535083475
J_b = 0.039532360260770213, J_o = 1.1654420003317028
J_b = 0.04077289887488869, J_o = 0.9013958815575722
J_b = 0.040289970957242585, J_o = 0.8493571219668918
J_b = 0.040084256568523546, J_o = 1.3006135993439645
J_b = 0.04027737898445513, J_o = 0.8476663231415535
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
W_opt:  [-0.05874686 -0.05711795 -0.05564592 -0.05414623 -0.05257167 -0.05109797
 -0.0499581  -0.04909309 -0.04840493 -0.04782427]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1051 s, v_trunc (Latent to Reduced) = 0.0036, dec (Reduced to Full) = 0.1755, add (DA)= 0.0001decode = 0.1811 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2863 s, inc stats = 0.2929, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.18477810e-11 2.85125332e-10 3.31441124e-10 8.52521067e-11
 1.12717006e-09]
u_DA:    [2.57976885e-09 4.84273278e-09 6.56549852e-09 3.62028393e-09
 8.83087901e-09]
ref_MAE: [6.93457921e-09 1.02065703e-08 1.27284918e-08 8.45891014e-09
 1.93368196e-08]
da_MAE:  [2.51792107e-09 4.55760745e-09 6.23405740e-09 3.53503183e-09
 7.70370895e-09]
% 6.196371153136174 da_MAE 0.1136297821726541 ref_MAE 0.12113580633235078
u_c taken from control states: [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
u_c before reduction of space:  [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
data[u_c] post encoding of state:  [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
J_b = 0.0, J_o = 13300.784587821749
J_b = 0.49999999999999994, J_o = 835776.6110079887
J_b = 0.0061833010758861025, J_o = 220.30745680118025
J_b = 0.006185696438878684, J_o = 216.94685780289095
J_b = 0.0062112469774662, J_o = 203.8561568893434
J_b = 0.006568954517691389, J_o = 157.12047450890697
J_b = 0.020063472514541787, J_o = 17.2086171666869
J_b = 0.01970989439840166, J_o = 13.299085562075884
J_b = 0.020053652416072532, J_o = 10.76694163396622
J_b = 0.02488263730792053, J_o = 4.644037517218314
J_b = 0.02744594221488798, J_o = 3.52137847827518
J_b = 0.029328162768922895, J_o = 3.0279173762077733
J_b = 0.03099600965113508, J_o = 2.555714123493175
J_b = 0.03411146380778576, J_o = 1.8433169472288424
J_b = 0.04053601276644277, J_o = 1.2066894318546189
J_b = 0.04159780206025843, J_o = 0.9107012610442697
J_b = 0.04100315750262053, J_o = 0.8592259647001698
J_b = 0.04077043921600905, J_o = 1.11147629072894
J_b = 0.040979383236220086, J_o = 0.856320292149463
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
W_opt:  [-0.05935287 -0.05769358 -0.05619211 -0.05465767 -0.05304388 -0.0515355
 -0.05037486 -0.04950138 -0.04881244 -0.04823578]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1241 s, v_trunc (Latent to Reduced) = 0.0021, dec (Reduced to Full) = 0.1827, add (DA)= 0.0001decode = 0.1891 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3133 s, inc stats = 0.3242, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.16386456e-11 2.83581874e-10 3.28654135e-10 8.48834021e-11
 1.11748309e-09]
u_DA:    [2.58027462e-09 4.84395827e-09 6.56596892e-09 3.62050317e-09
 8.83116452e-09]
ref_MAE: [6.93478835e-09 1.02081137e-08 1.27312788e-08 8.45927884e-09
 1.93465066e-08]
da_MAE:  [2.51863598e-09 4.56037640e-09 6.23731479e-09 3.53561977e-09
 7.71368143e-09]
% 6.188381587579761 da_MAE 0.11384910316193826 ref_MAE 0.12135927840134687
u_c taken from control states: [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
u_c before reduction of space:  [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
data[u_c] post encoding of state:  [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
J_b = 0.0, J_o = 13299.57302338594
J_b = 0.5000000000000002, J_o = 835800.8702495269
J_b = 0.006181928463664912, J_o = 222.00979175511384
J_b = 0.006184337678797595, J_o = 218.62971563276778
J_b = 0.006210035973546244, J_o = 205.46222456757224
J_b = 0.006569812100027556, J_o = 158.4372750938034
J_b = 0.020205881758041683, J_o = 17.56559086688625
J_b = 0.019815075726101795, J_o = 13.574885401054983
J_b = 0.02011139705794788, J_o = 11.098942584344462
J_b = 0.025143645607540024, J_o = 4.703756839870979
J_b = 0.027620312214170977, J_o = 3.615945305639905
J_b = 0.02978447272416518, J_o = 3.046966707958894
J_b = 0.031365951420364836, J_o = 2.599451761467777
J_b = 0.035263773737346814, J_o = 1.7658645774129593
J_b = 0.044687758558002486, J_o = 2.5988549978626163
J_b = 0.03797075686930899, J_o = 1.4013082115631539
J_b = 0.0410150542107394, J_o = 1.005153168285965
J_b = 0.04167235355756171, J_o = 0.8901291814970425
J_b = 0.041961329533541585, J_o = 0.8290868421727638
J_b = 0.04265065825327703, J_o = 0.8708863396657657
J_b = 0.042205929250153165, J_o = 0.7969894569224573
J_b = 0.042532598407042724, J_o = 0.7581490663070216
J_b = 0.04357956422640318, J_o = 0.7087505255364959
J_b = 0.04393986220155098, J_o = 0.6997128097146308
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
W_opt:  [-0.06065559 -0.05895349 -0.05737932 -0.0557404  -0.05399741 -0.05236874
 -0.05113109 -0.0502191  -0.0495135  -0.04893207]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1734 s, v_trunc (Latent to Reduced) = 0.0016, dec (Reduced to Full) = 0.1699, add (DA)= 0.0001decode = 0.1734 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3469 s, inc stats = 0.3528, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.13993232e-11 2.82119422e-10 3.25760680e-10 8.43427983e-11
 1.10793581e-09]
u_DA:    [2.58486377e-09 4.84519261e-09 6.56237652e-09 3.61751925e-09
 8.83086535e-09]
ref_MAE: [6.93502767e-09 1.02095762e-08 1.27341723e-08 8.45981944e-09
 1.93560539e-08]
da_MAE:  [2.52346444e-09 4.56307319e-09 6.23661584e-09 3.53317646e-09
 7.72292954e-09]
% 6.178807001430997 da_MAE 0.11404261191405299 ref_MAE 0.12155314622336172
u_c taken from control states: [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
u_c before reduction of space:  [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
data[u_c] post encoding of state:  [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
J_b = 0.0, J_o = 13299.204830892906
J_b = 0.5000000000000002, J_o = 835814.1339753055
J_b = 0.006181188357308036, J_o = 223.21439651306125
J_b = 0.006183607347494455, J_o = 219.82057607587132
J_b = 0.006209409909482935, J_o = 206.5988994254019
J_b = 0.006570645777321569, J_o = 159.36987439616763
J_b = 0.020306784800817598, J_o = 17.8193128371383
J_b = 0.01989043157950852, J_o = 13.770082801364437
J_b = 0.020156348374485596, J_o = 11.32806209428669
J_b = 0.02528440089211172, J_o = 4.7594146685928
J_b = 0.02769759582977636, J_o = 3.703673052756395
J_b = 0.030098015342018797, J_o = 3.0666891101106097
J_b = 0.03163973690258969, J_o = 2.625409914033577
J_b = 0.03686529024741449, J_o = 1.5969985110444211
J_b = 0.04586882463304902, J_o = 2.9167503819355707
J_b = 0.03896686569658488, J_o = 1.3301672536434062
J_b = 0.04158726855029653, J_o = 1.0099909739115154
J_b = 0.04198189704570416, J_o = 0.9083370979610697
J_b = 0.042375834581900994, J_o = 0.95614344317256
J_b = 0.04211170788715494, J_o = 0.8846602767825267
J_b = 0.04239801885384709, J_o = 0.8167930032245191
J_b = 0.04287613229446501, J_o = 0.7727410793953737
J_b = 0.04405359610077773, J_o = 0.72604675561743
J_b = 0.04450102223214578, J_o = 0.7175629734222924
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
W_opt:  [-0.06110397 -0.05937393 -0.05777625 -0.05611162 -0.05434069 -0.05268783
 -0.05143585 -0.05051841 -0.04981317 -0.04923593]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0609 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1202, add (DA)= 0.0001decode = 0.1232 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1842 s, inc stats = 0.1979, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.11176580e-11 2.80730245e-10 3.22777729e-10 8.36223777e-11
 1.09852522e-09]
u_DA:    [2.58541152e-09 4.84639158e-09 6.56278772e-09 3.61795732e-09
 8.83117272e-09]
ref_MAE: [6.93530934e-09 1.02109654e-08 1.27371552e-08 8.46053986e-09
 1.93654644e-08]
da_MAE:  [2.52429386e-09 4.56566134e-09 6.24000999e-09 3.53433494e-09
 7.73264749e-09]
% 6.17257314923872 da_MAE 0.1141649923206037 ref_MAE 0.1216755016656171
u_c taken from control states: [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
u_c before reduction of space:  [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
data[u_c] post encoding of state:  [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
J_b = 0.0, J_o = 13299.867733471652
J_b = 0.5000000000000001, J_o = 835814.111143986
J_b = 0.0061812126041039025, J_o = 223.8295738214419
J_b = 0.006183636631975123, J_o = 220.42867119254868
J_b = 0.006209492929268078, J_o = 207.17909617549913
J_b = 0.006571481091368985, J_o = 159.84536408367845
J_b = 0.02035799638504834, J_o = 17.943949748350597
J_b = 0.019929918757606104, J_o = 13.865239056892895
J_b = 0.020182491252549308, J_o = 11.437023601354223
J_b = 0.025338406529543493, J_o = 4.7942084325080465
J_b = 0.027727322745337776, J_o = 3.755602092968381
J_b = 0.030180883310748217, J_o = 3.0951090449467076
J_b = 0.031779127414047266, J_o = 2.6410546474930263
J_b = 0.03737317155857418, J_o = 1.5335772623252102
J_b = 0.04449053509481335, J_o = 2.2869528296757053
J_b = 0.03928248844639973, J_o = 1.2886504253754665
J_b = 0.042315340259973716, J_o = 0.9468734665512699
J_b = 0.04299137664269686, J_o = 0.8319741143078454
J_b = 0.043542440153948966, J_o = 2.6888952961227037
J_b = 0.043006261654183434, J_o = 0.8300353747602296
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
W_opt:  [-0.06084613 -0.0591083  -0.05752864 -0.05590188 -0.0541832  -0.0525802
 -0.05135901 -0.05045531 -0.04975502 -0.04917862]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0498 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1369, add (DA)= 0.0001decode = 0.1398 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1898 s, inc stats = 0.2020, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.07792919e-11 2.79393319e-10 3.19724815e-10 8.27122445e-11
 1.08924213e-09]
u_DA:    [2.58442577e-09 4.84898058e-09 6.56838058e-09 3.62179067e-09
 8.83596908e-09]
ref_MAE: [6.93564770e-09 1.02123023e-08 1.27402081e-08 8.46145000e-09
 1.93747475e-08]
da_MAE:  [2.52364648e-09 4.56958726e-09 6.24865576e-09 3.53907842e-09
 7.74672695e-09]
% 6.172237187775166 da_MAE 0.11419563407463848 ref_MAE 0.12170772344127544
\% improve_point: 6.35, mse_ref_points: 1.545633447968094e-05, mse_da_points: 1.4539591671551745e-05, % improve_overlap: 7.11, mse_ref_overlap: 0.24419, mse_da_overlap: 0.22817
DA - - L2: 3459.92, L1: 3183.28, % Improve: 8.04%, DA_MAE: 0.10, mse_ref: 0.25, mse_DA: 0.236, time(s): 0.7004s,
Results of DA at 2020-08-29 15:22:52.005689. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0               9.814794      0.078882  ...  22.005387     0.242923
1               9.884911      0.078878  ...   0.199019     0.181991
2               9.966590      0.078977  ...   0.185834     0.173859
3              10.057514      0.079162  ...   0.218057     0.199255
4              10.115166      0.079379  ...   0.213730     0.201437
..                   ...           ...  ...        ...          ...
102             6.196371      0.121136  ...   0.300203     0.286278
103             6.188382      0.121359  ...   0.328912     0.313283
104             6.178807      0.121553  ...   0.357443     0.346934
105             6.172573      0.121676  ...   0.202318     0.184160
106             6.172237      0.121708  ...   0.206793     0.189768

[107 rows x 20 columns]
data fp  /home/mredstone/unstructuredCAE/data/subdomain_6/
domain, other, pickle, dim 6 ['8'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_80P_150E_1D2L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_6/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
91, 85, 32, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
89, 83, 30, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
87, 81, 28, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
85, 79, 26, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
83, 77, 24, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
81, 75, 22, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
79, 73, 20, stride=(2, 2, 2, )  kernel_size=(3, 3, 2, )  padding=(0, 1, 1, )  
39, 37, 11, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 1, 0, )  
19, 19, 5, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 1, )  
9, 9, 3, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
5, 5, 2, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
OUT: 3, 3, 1, Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
When creating TucodecEncode1D, inputSize =  26032 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
Number of parameters: 27513777
------------------------------ Training subdomain 6 at 2020-08-29 15:23:01.454215. ------------------------------
Loading data started 2020-08-29 15:23:01.454311
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fed56339710>
Loading data finished 2020-08-29 15:23:21.473764
Loop AE Train begins at  15:23:21.478144
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [1/150], TRAIN: -loss:12486.43, av_diff: 0.32, time taken (m): 0.02m
epoch [1/150], TEST: -loss:14601.8979, time taken(m): 0.00m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [6/150], TRAIN: -loss:4936.49, av_diff: 0.03, time taken (m): 0.01m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [11/150], TRAIN: -loss:3292.91, av_diff: 0.02, time taken (m): 0.01m
epoch [11/150], TEST: -loss:11087.0881, time taken(m): 0.00m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [16/150], TRAIN: -loss:2859.57, av_diff: 0.03, time taken (m): 0.01m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [21/150], TRAIN: -loss:2708.44, av_diff: 0.03, time taken (m): 0.01m
epoch [21/150], TEST: -loss:10556.4326, time taken(m): 0.00m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [26/150], TRAIN: -loss:2594.27, av_diff: 0.03, time taken (m): 0.01m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [31/150], TRAIN: -loss:2515.77, av_diff: 0.02, time taken (m): 0.01m
epoch [31/150], TEST: -loss:10333.0530, time taken(m): 0.00m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [36/150], TRAIN: -loss:2216.33, av_diff: 0.02, time taken (m): 0.01m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [41/150], TRAIN: -loss:1873.90, av_diff: 0.01, time taken (m): 0.02m
epoch [41/150], TEST: -loss:10098.9368, time taken(m): 0.01m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [46/150], TRAIN: -loss:1830.38, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [51/150], TRAIN: -loss:1636.64, av_diff: 0.01, time taken (m): 0.02m
epoch [51/150], TEST: -loss:10098.8828, time taken(m): 0.01m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [56/150], TRAIN: -loss:1561.43, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [61/150], TRAIN: -loss:1501.82, av_diff: 0.01, time taken (m): 0.02m
epoch [61/150], TEST: -loss:10075.9429, time taken(m): 0.00m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [66/150], TRAIN: -loss:1430.76, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [71/150], TRAIN: -loss:1537.46, av_diff: 0.01, time taken (m): 0.02m
epoch [71/150], TEST: -loss:10066.3350, time taken(m): 0.00m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [76/150], TRAIN: -loss:1386.84, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [81/150], TRAIN: -loss:1252.43, av_diff: 0.01, time taken (m): 0.02m
epoch [81/150], TEST: -loss:9934.2837, time taken(m): 0.01m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [86/150], TRAIN: -loss:1303.46, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [91/150], TRAIN: -loss:1142.52, av_diff: 0.01, time taken (m): 0.02m
epoch [91/150], TEST: -loss:9790.5969, time taken(m): 0.01m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [96/150], TRAIN: -loss:1241.00, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [101/150], TRAIN: -loss:1158.76, av_diff: 0.01, time taken (m): 0.02m
epoch [101/150], TEST: -loss:9814.8916, time taken(m): 0.01m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [106/150], TRAIN: -loss:1150.47, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [111/150], TRAIN: -loss:1128.40, av_diff: 0.01, time taken (m): 0.02m
epoch [111/150], TEST: -loss:9875.9937, time taken(m): 0.00m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [116/150], TRAIN: -loss:977.91, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [121/150], TRAIN: -loss:1043.41, av_diff: 0.01, time taken (m): 0.03m
epoch [121/150], TEST: -loss:9911.7014, time taken(m): 0.01m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [126/150], TRAIN: -loss:1096.89, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [131/150], TRAIN: -loss:1108.12, av_diff: 0.02, time taken (m): 0.02m
epoch [131/150], TEST: -loss:9861.2943, time taken(m): 0.01m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [136/150], TRAIN: -loss:866.93, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [141/150], TRAIN: -loss:885.16, av_diff: 0.01, time taken (m): 0.02m
epoch [141/150], TEST: -loss:9922.5093, time taken(m): 0.01m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [146/150], TRAIN: -loss:954.99, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [150/150], TRAIN: -loss:1005.67, av_diff: 0.01, time taken (m): 0.02m
epoch [150/150], TEST: -loss:9858.9705, time taken(m): 0.01m
Loop AE Train Ends at  15:26:49.062119
------------------------------ DA subdomain 6 at 2020-08-29 15:26:49.154754. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 26032) , test_X = (107, 26032), X = (537, 26032)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
u_c before reduction of space:  [-0.8531082  -0.80088433  0.03712867 -0.14295814 -0.99493482 -0.66263901
 -0.84611558  0.09697116 -0.648397   -1.36865512]
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
u_c taken from control states: [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
u_c before reduction of space:  [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
data[u_c] post encoding of state:  [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
Shape of w_0 =  (429,)
J_b = 0.0, J_o = 3220.539670955343
J_b = 0.49999999999999994, J_o = 225613.30063766357
J_b = 0.004681839041987066, J_o = 638.387378183662
J_b = 0.005593533270044242, J_o = 545.6879066488325
J_b = 0.005323552490612578, J_o = 501.9027859072699
J_b = 0.005384009071402504, J_o = 469.8682221116418
J_b = 0.0072821237670299115, J_o = 350.34934295742175
J_b = 0.013991088725757569, J_o = 221.72192718782213
J_b = 0.025751212643784185, J_o = 115.8180951700207
J_b = 0.028453302155817414, J_o = 104.50214403126097
J_b = 0.028416338001125266, J_o = 102.92700450015252
J_b = 0.02830334168553741, J_o = 100.71929127224678
J_b = 0.02858725798724531, J_o = 95.80908649659521
J_b = 0.0303062956231435, J_o = 87.59232082030066
J_b = 0.03476863633113938, J_o = 75.69377297881061
J_b = 0.04027818153267357, J_o = 67.36487073645515
J_b = 0.04455959478127273, J_o = 63.02118704161507
J_b = 0.04598737695231995, J_o = 59.3705518988045
J_b = 0.05320524090737549, J_o = 48.725075513583135
J_b = 0.06187122149839118, J_o = 41.29241392880299
J_b = 0.07001990176516351, J_o = 38.2795530052002
J_b = 0.06962123976457714, J_o = 37.65645246652693
J_b = 0.06927818145834327, J_o = 37.4104439186706
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
W_opt:  [-0.0049181   0.00679168  0.00483248  0.00261389  0.00072686 -0.00185461
 -0.00555689 -0.01050403 -0.01751797 -0.02758374]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1070 s, v_trunc (Latent to Reduced) = 0.0042, dec (Reduced to Full) = 0.2284, add (DA)= 0.0001decode = 0.2347 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3418 s, inc stats = 48.1657, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95971306 2.8606017  3.44302222 3.07860686 2.45294002]
u_DA:    [3.84807397 2.06681255 2.62291788 1.87489538 2.18649058]
ref_MAE: [0.11925866 0.69882131 0.90408743 1.22605341 0.07630631]
da_MAE:  [0.11163909 0.79378915 0.82010433 1.20371148 0.26644944]
% 18.491489129191525 da_MAE 0.006126570466311897 ref_MAE 0.007516479445959393
u_c taken from control states: [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
u_c before reduction of space:  [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
data[u_c] post encoding of state:  [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
J_b = 0.0, J_o = 3126.587923739958
J_b = 0.5, J_o = 217816.78214930545
J_b = 0.004701988507964805, J_o = 621.8479448838856
J_b = 0.005333620592727825, J_o = 561.808581978284
J_b = 0.005178025319437896, J_o = 521.6681640736862
J_b = 0.005328498860213304, J_o = 477.0821199294597
J_b = 0.007498668194478354, J_o = 353.85381568045153
J_b = 0.015095748280498672, J_o = 213.85500058531758
J_b = 0.02694661274007583, J_o = 109.28141570381936
J_b = 0.028877390929519915, J_o = 102.04321118580248
J_b = 0.02883212986847148, J_o = 100.93576241644715
J_b = 0.028741340601987474, J_o = 98.82774952388203
J_b = 0.029030611670358534, J_o = 94.5286311216239
J_b = 0.03058344768652449, J_o = 87.48227937685368
J_b = 0.03421930292508653, J_o = 78.02157022505101
J_b = 0.03899283871673548, J_o = 70.86543815365523
J_b = 0.04120924895387042, J_o = 67.88686069403899
J_b = 0.04362951048322744, J_o = 63.863847946091816
J_b = 0.048517102433107986, J_o = 57.4892053280011
J_b = 0.05748044910568864, J_o = 49.72914095490939
J_b = 0.0672692518810761, J_o = 46.16704809678198
J_b = 0.06631551889848375, J_o = 44.888203077569145
J_b = 0.06494480355106709, J_o = 44.65173149338067
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
W_opt:  [-0.00839957  0.00337748  0.00353173  0.00215708  0.00073346 -0.00147821
 -0.00491613 -0.00947535 -0.01573797 -0.02479293]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0588 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1234, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1854 s, inc stats = 0.1990, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95948174 2.86219835 3.44235992 3.07760999 2.45160571]
u_DA:    [3.8480275  2.07142342 2.62404013 1.87589866 2.19081564]
ref_MAE: [0.11902734 0.70041795 0.90342514 1.22505654 0.074972  ]
da_MAE:  [0.11145425 0.79077493 0.81831979 1.20171133 0.26079007]
% 18.24781215362317 da_MAE 0.006147414889608841 ref_MAE 0.007519572321612537
u_c taken from control states: [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
u_c before reduction of space:  [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
data[u_c] post encoding of state:  [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
J_b = 0.0, J_o = 2888.7498831448306
J_b = 0.5, J_o = 219217.8429664442
J_b = 0.004352586216573224, J_o = 573.5335578257881
J_b = 0.004931293411022143, J_o = 517.45922684473
J_b = 0.004797769441942333, J_o = 479.9777900480408
J_b = 0.004963470215153918, J_o = 434.46755151776216
J_b = 0.00710362523971214, J_o = 316.6705609749154
J_b = 0.014495032595397219, J_o = 183.13640272609518
J_b = 0.02555196219746896, J_o = 87.25168418404505
J_b = 0.0268911939967777, J_o = 82.55473811026778
J_b = 0.02688145900126171, J_o = 81.6719358677729
J_b = 0.026855861537403318, J_o = 79.89090086422469
J_b = 0.027141033555997816, J_o = 76.49747391336392
J_b = 0.02828666492137738, J_o = 71.45419305109994
J_b = 0.031058981653544523, J_o = 64.52637692327484
J_b = 0.03379354432543843, J_o = 60.35644968025149
J_b = 0.035179039456895975, J_o = 58.210704739736556
J_b = 0.03548942606956707, J_o = 56.613854165754525
J_b = 0.036835497198486354, J_o = 52.60859822343265
J_b = 0.04044195287188759, J_o = 47.33250347379483
J_b = 0.060143359977418286, J_o = 41.6453664332698
J_b = 0.054451299767630953, J_o = 39.32225465986298
J_b = 0.05348090501835694, J_o = 38.4697676283849
J_b = 0.05408207598845338, J_o = 38.05608620178231
J_b = 0.05558954967628207, J_o = 37.54485675705157
J_b = 0.0576875129153774, J_o = 36.77208017392278
J_b = 0.06478988772217022, J_o = 35.28685640857159
J_b = 0.07109840203010619, J_o = 33.95394696331836
J_b = 0.06821950591120993, J_o = 32.78671988681311
J_b = 0.06704645850578445, J_o = 32.39207564054242
J_b = 0.06678552845396356, J_o = 32.03340206729608
J_b = 0.06816512984369236, J_o = 30.152549192885445
J_b = 0.07496471840622784, J_o = 28.63765629355879
J_b = 0.08118678023120832, J_o = 27.972709127978327
J_b = 0.0835319549540442, J_o = 27.710987383295567
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
W_opt:  [-0.01292177  0.00177226  0.00137619  0.00087525 -0.0002808  -0.00315107
 -0.00847904 -0.01636    -0.02677908 -0.03966321]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0892 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1208, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2129 s, inc stats = 0.2244, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95925042 2.86385592 3.44170924 3.07663321 2.45090041]
u_DA:    [3.84795045 2.07257814 2.62624989 1.87650587 2.19226861]
ref_MAE: [0.11879602 0.70207552 0.90277445 1.22407976 0.0742667 ]
da_MAE:  [0.11129998 0.79127778 0.81545935 1.20012734 0.25863181]
% 18.110606159933678 da_MAE 0.0061604426352367325 ref_MAE 0.0075228822028752034
u_c taken from control states: [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
u_c before reduction of space:  [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
data[u_c] post encoding of state:  [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
J_b = 0.0, J_o = 2523.7999314844014
J_b = 0.5000000000000001, J_o = 225571.3170243738
J_b = 0.0037320131628012097, J_o = 511.20611014868416
J_b = 0.004334629309855936, J_o = 451.6596684503936
J_b = 0.004180408485087302, J_o = 416.5266663626232
J_b = 0.004290725720047848, J_o = 380.1878585073345
J_b = 0.006089061891041763, J_o = 275.46352022218235
J_b = 0.012320043509042552, J_o = 158.7517915244479
J_b = 0.022069620038664715, J_o = 72.23578124448164
J_b = 0.023377996483787383, J_o = 67.31631649631643
J_b = 0.02330437088710771, J_o = 66.6337344660035
J_b = 0.02317917636093847, J_o = 65.4780403998278
J_b = 0.02322402942414491, J_o = 63.067290810222765
J_b = 0.023915979087041517, J_o = 59.23835552029158
J_b = 0.02570842391870301, J_o = 54.41567655664868
J_b = 0.02778155701152557, J_o = 51.14729025770747
J_b = 0.029050232070103134, J_o = 49.73401334179683
J_b = 0.02908238510556504, J_o = 48.909301048701565
J_b = 0.02941413661341537, J_o = 46.53354860606446
J_b = 0.03067494715181784, J_o = 43.33961945396673
J_b = 0.04376579098219808, J_o = 37.40308979829329
J_b = 0.04620407192858824, J_o = 37.12739401755863
J_b = 0.0448515703779305, J_o = 34.87035201100237
J_b = 0.04383157459119775, J_o = 33.4249670167937
J_b = 0.04409621265584824, J_o = 33.08167368868729
J_b = 0.044312132777479626, J_o = 32.92317331420868
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
W_opt:  [-0.01006416 -0.00332671 -0.00334662 -0.00286314 -0.00331593 -0.005654
 -0.01018284 -0.01674351 -0.02437322 -0.03253289]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0718 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1240, add (DA)= 0.0001decode = 0.1270 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1989 s, inc stats = 0.2116, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95902457 2.86543938 3.44108005 3.07580368 2.45092479]
u_DA:    [3.84702207 2.07354386 2.62977282 1.87827652 2.20053765]
ref_MAE: [0.11857017 0.70365898 0.90214526 1.22325023 0.07429108]
da_MAE:  [0.11200249 0.79189552 0.81130722 1.19752716 0.25038713]
% 18.155737076239262 da_MAE 0.006159570639695793 ref_MAE 0.007525965070311078
u_c taken from control states: [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
u_c before reduction of space:  [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
data[u_c] post encoding of state:  [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
J_b = 0.0, J_o = 2062.7450662013375
J_b = 0.5000000000000001, J_o = 231389.19999098754
J_b = 0.0029389370384893206, J_o = 470.66697380181887
J_b = 0.0034573550587456, J_o = 415.8300858829232
J_b = 0.0033414374741304515, J_o = 385.73561084245483
J_b = 0.0034746677741871214, J_o = 347.8297070204893
J_b = 0.005218327213183679, J_o = 252.44573159397794
J_b = 0.011185528200023033, J_o = 145.1210742642459
J_b = 0.019756650054403527, J_o = 71.63855992458623
J_b = 0.020408752950532905, J_o = 69.35381584060603
J_b = 0.020426322543353255, J_o = 68.71073964699914
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
W_opt:  [-0.00735069 -0.00408652 -0.00260132 -0.00265107 -0.0031537  -0.00402617
 -0.00523747 -0.00689759 -0.00924091 -0.01277754]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0332 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1219, add (DA)= 0.0001decode = 0.1248 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1581 s, inc stats = 0.1715, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95880786 2.86683621 3.4404808  3.07524578 2.4516614 ]
u_DA:    [3.84672935 2.07630919 2.63751694 1.87636147 2.21065259]
ref_MAE: [0.11835346 0.70505581 0.90154602 1.22269233 0.07502769]
da_MAE:  [0.11207851 0.79052702 0.80296387 1.19888431 0.24100881]
% 17.908480258803092 da_MAE 0.006180404939608861 ref_MAE 0.007528676480948712
u_c taken from control states: [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
u_c before reduction of space:  [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
data[u_c] post encoding of state:  [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
J_b = 0.0, J_o = 1432.688223738698
J_b = 0.5, J_o = 232315.62174350908
J_b = 0.0017668299318583161, J_o = 506.7376286852204
J_b = 0.002044529172289052, J_o = 466.43065189005733
J_b = 0.0021113047376456473, J_o = 438.3990947470087
J_b = 0.007298968309301287, J_o = 205.69665104196005
J_b = 0.015325939467600885, J_o = 121.82886881274058
J_b = 0.020253657783772968, J_o = 96.72790397532648
J_b = 0.020611131506726287, J_o = 95.92788084388324
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
W_opt:  [-0.00510719 -0.00470248 -0.00356544 -0.00350342 -0.0039348  -0.00472934
 -0.00580573 -0.00733095 -0.00962219 -0.01328168]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0231 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1346, add (DA)= 0.0001decode = 0.1374 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1607 s, inc stats = 0.1652, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95860674 2.86790726 3.43992101 3.07506961 2.45312898]
u_DA:    [3.84621057 2.08964567 2.64236052 1.88112897 2.23264493]
ref_MAE: [0.11815234 0.70612686 0.90098623 1.22251616 0.07649527]
da_MAE:  [0.11239617 0.77826159 0.79756049 1.19394065 0.22048404]
% 17.215190705330595 da_MAE 0.00623437894320084 ref_MAE 0.00753082479300013
u_c taken from control states: [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
u_c before reduction of space:  [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
data[u_c] post encoding of state:  [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
J_b = 0.0, J_o = 737.3819272448286
J_b = 0.5, J_o = 165529.86829376162
J_b = 0.00022831012276974206, J_o = 658.7744182649085
J_b = 0.0005623473947586692, J_o = 594.3415185539127
J_b = 0.004685292537006477, J_o = 390.5697800830063
J_b = 0.018188683755919387, J_o = 200.35518975023425
J_b = 0.022079097647721355, J_o = 179.48792014079186
J_b = 0.022626129142515567, J_o = 178.3850046582808
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
W_opt:  [-0.00059623 -0.00236509 -0.00184737 -0.00193518 -0.00240356 -0.00311169
 -0.00396146 -0.00520275 -0.0074328  -0.01173526]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0210 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1324, add (DA)= 0.0001decode = 0.1353 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1565 s, inc stats = 0.1691, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95842699 2.86857279 3.43940488 3.07534712 2.45528936]
u_DA:    [3.84470858 2.10486741 2.63239856 1.89489342 2.26868973]
ref_MAE: [0.11797259 0.70679239 0.9004701  1.22279367 0.07865565]
da_MAE:  [0.11371842 0.76370538 0.80700632 1.1804537  0.18659963]
% 15.643443287367914 da_MAE 0.006353903327593375 ref_MAE 0.007532198533468474
u_c taken from control states: [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
u_c before reduction of space:  [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
data[u_c] post encoding of state:  [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
J_b = 0.0, J_o = 1292.534367500009
J_b = 0.5, J_o = 285661.75923451735
J_b = 0.0010983362392856136, J_o = 603.2550062309941
J_b = 0.0014952965392587658, J_o = 519.7555319801164
J_b = 0.001581174665375112, J_o = 498.9249078931615
J_b = 0.0022324177431623984, J_o = 422.99219408726697
J_b = 0.02132253486670807, J_o = 216.77199090131396
J_b = 0.022822320684057835, J_o = 207.06164470003523
J_b = 0.01970460851363171, J_o = 182.8473917602969
J_b = 0.0199015039665135, J_o = 181.0246161125429
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
W_opt:  [ 0.00860184  0.00918811  0.0059656   0.00408091  0.00281927  0.00148571
  0.00010539 -0.00148925 -0.00429687 -0.01028549]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0330 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1322, add (DA)= 0.0001decode = 0.1352 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1683 s, inc stats = 0.1799, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95827183 2.86878598 3.43893538 3.07613228 2.45807752]
u_DA:    [3.846636   2.11442404 2.61356295 1.87840743 2.29993124]
ref_MAE: [0.11781743 0.70700558 0.9000006  1.22357883 0.08144381]
da_MAE:  [0.11163583 0.75436194 0.82537243 1.19772485 0.15814627]
% 14.046357057790702 da_MAE 0.006474566732161069 ref_MAE 0.007532626321044038
u_c taken from control states: [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
u_c before reduction of space:  [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
data[u_c] post encoding of state:  [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
J_b = 0.0, J_o = 1901.2892938667956
J_b = 0.4999999999999999, J_o = 245376.79355998102
J_b = 0.002495019022197026, J_o = 486.44250280808654
J_b = 0.0030775131805650395, J_o = 419.05145466035606
J_b = 0.002913435716012532, J_o = 396.8153398776184
J_b = 0.0029329552428552634, J_o = 381.07965346370145
J_b = 0.0038636594965887967, J_o = 321.52743077856513
J_b = 0.0071765973379582055, J_o = 257.7330820343923
J_b = 0.014214441992778477, J_o = 192.91081671171787
J_b = 0.01691506325518118, J_o = 180.7092915795657
J_b = 0.01719161956050641, J_o = 178.6540045015329
J_b = 0.01733622932450043, J_o = 176.6038412705164
J_b = 0.01798539174017733, J_o = 172.09221567913588
J_b = 0.01970423066017608, J_o = 166.00041077124845
J_b = 0.022778045275604796, J_o = 158.1114185438119
J_b = 0.026775652131892192, J_o = 152.21702932492047
J_b = 0.0297067996196527, J_o = 149.1034569175415
J_b = 0.033612728182923705, J_o = 144.38160185193698
J_b = 0.047838582633699965, J_o = 139.66103580455433
J_b = 0.07808027063620458, J_o = 152.7137093967179
J_b = 0.05617954010858013, J_o = 134.74235022010672
J_b = 0.052185729000434666, J_o = 132.30119273944925
J_b = 0.050870710587064674, J_o = 130.34588518931957
J_b = 0.05181371644405593, J_o = 129.02474062566267
J_b = 0.06622628966375674, J_o = 127.12089571908083
J_b = 0.06897654437985867, J_o = 123.73898752586358
J_b = 0.07048008269241862, J_o = 122.56420448062596
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
W_opt:  [ 0.02105923  0.03775442  0.01992197  0.01443771  0.01124916  0.00584784
 -0.00124717 -0.01011583 -0.02333898 -0.04583537]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0751 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2017 s, inc stats = 0.2155, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95814197 2.86844629 3.43851228 3.07743919 2.46136035]
u_DA:    [3.84813652 2.11265529 2.60706706 1.87069188 2.30072733]
ref_MAE: [0.11768757 0.70666589 0.8995775  1.22488574 0.08472664]
da_MAE:  [0.11000545 0.755791   0.83144522 1.20674732 0.16063302]
% 13.493609886196195 da_MAE 0.0065157769488468666 ref_MAE 0.007532133684315126
u_c taken from control states: [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
u_c before reduction of space:  [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
data[u_c] post encoding of state:  [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
J_b = 0.0, J_o = 2066.5183359578004
J_b = 0.49999999999999983, J_o = 222365.11057546115
J_b = 0.0031324215349378816, J_o = 426.8077791748811
J_b = 0.00337130418526698, J_o = 408.0219557643186
J_b = 0.0033003818439309605, J_o = 391.47093565679756
J_b = 0.0033414273645159935, J_o = 377.5260748298106
J_b = 0.004139521013995306, J_o = 329.1355937622343
J_b = 0.007147507677593397, J_o = 271.6820407776596
J_b = 0.01366530436189708, J_o = 212.57528031804398
J_b = 0.017654842276766624, J_o = 193.47911695293234
J_b = 0.018216376925284484, J_o = 190.0243880092033
J_b = 0.018339260499870252, J_o = 187.6745213357405
J_b = 0.018914359975034635, J_o = 183.04560119816674
J_b = 0.021565903634831282, J_o = 172.89944759140283
J_b = 0.028139727067657293, J_o = 160.46735611026466
J_b = 0.032326874694325027, J_o = 153.88730272973035
J_b = 0.03920338782946496, J_o = 145.66173071380462
J_b = 0.0465908092529633, J_o = 143.9077701688336
J_b = 0.05335012789133512, J_o = 135.0667732754352
J_b = 0.05701086710196225, J_o = 131.57070504775416
J_b = 0.05929502495776115, J_o = 130.1358363020022
J_b = 0.06100097231572505, J_o = 128.98283213040227
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
W_opt:  [ 0.01957711  0.04054031  0.02379588  0.01645646  0.01238665  0.00729008
  0.00105651 -0.00625781 -0.01703126 -0.03520516]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0642 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1213, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1887 s, inc stats = 0.1948, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95803318 2.86753935 3.43812562 3.07919254 2.46480604]
u_DA:    [3.84840841 2.10720298 2.6065904  1.86848825 2.30155105]
ref_MAE: [0.11757878 0.70575895 0.89919084 1.22663909 0.08817233]
da_MAE:  [0.10962477 0.76033636 0.83153522 1.21070429 0.16325499]
% 13.558767616547183 da_MAE 0.006509514340652431 ref_MAE 0.007530566329476033
u_c taken from control states: [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
u_c before reduction of space:  [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
data[u_c] post encoding of state:  [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
J_b = 0.0, J_o = 2006.219323626826
J_b = 0.5000000000000001, J_o = 217402.96586376673
J_b = 0.0031405560735543714, J_o = 398.4379152437159
J_b = 0.003187480013281283, J_o = 385.5792414788568
J_b = 0.003619799885527558, J_o = 347.78682724741304
J_b = 0.007061272370706379, J_o = 268.0806482633242
J_b = 0.01459979178260298, J_o = 201.60600784741249
J_b = 0.016393628858455914, J_o = 195.48284916331525
J_b = 0.01752101341726961, J_o = 191.19947689161972
J_b = 0.018645039003913226, J_o = 185.99767863013085
J_b = 0.020514913027192997, J_o = 176.87721164825416
J_b = 0.02390892768096041, J_o = 166.003780992111
J_b = 0.02605417643010526, J_o = 160.79307921531594
J_b = 0.030233298876878933, J_o = 153.1200114911437
J_b = 0.03889813222048089, J_o = 142.24053960673365
J_b = 0.0571836919188102, J_o = 128.89780650816925
J_b = 0.10489000932045096, J_o = 144.5840108955621
J_b = 0.07091136062517432, J_o = 124.0389321135283
J_b = 0.07187506876308504, J_o = 120.94348991905949
J_b = 0.0695948272710635, J_o = 119.86207826208634
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
W_opt:  [ 0.00994978  0.04058891  0.02961023  0.02293173  0.01894935  0.01387524
  0.00724028 -0.00077939 -0.01306942 -0.03398541]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0491 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1218, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1738 s, inc stats = 0.1876, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95793666 2.86609556 3.43775667 3.08119687 2.46791533]
u_DA:    [3.84723855 2.1029224  2.60697216 1.87001837 2.29356993]
ref_MAE: [0.11748226 0.70431517 0.89882188 1.22864342 0.09128162]
da_MAE:  [0.11069811 0.76317316 0.83078451 1.2111785  0.17434541]
% 13.858016601167362 da_MAE 0.006484537865784003 ref_MAE 0.007527732250789896
\% improve_point: 14.41, mse_ref_points: 3.515884780171926e-05, mse_da_points: 3.009018025052192e-05, % improve_overlap: 14.41, mse_ref_overlap: 0.91577, mse_da_overlap: 0.78376
DA - - L2: 200320.11, L1: 12010.84, % Improve: 16.25%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.783, time(s): 4.7556s,
u_c taken from control states: [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
u_c before reduction of space:  [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
data[u_c] post encoding of state:  [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
J_b = 0.0, J_o = 1807.9712642329855
J_b = 0.5000000000000001, J_o = 238173.39377008763
J_b = 0.0025643356166798873, J_o = 393.07044662425415
J_b = 0.0030298921262158817, J_o = 351.8687482780103
J_b = 0.002857335224360288, J_o = 330.76125482856924
J_b = 0.002863022835836161, J_o = 323.42967119593106
J_b = 0.0037160795588608033, J_o = 272.5351296126377
J_b = 0.006735307961099098, J_o = 223.25852292426453
J_b = 0.012939317731108946, J_o = 176.67732615349814
J_b = 0.015341484629255442, J_o = 167.17377392192049
J_b = 0.01551061992743784, J_o = 165.4845873703764
J_b = 0.01553834545895178, J_o = 163.87540974215608
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
W_opt:  [ 0.00659804  0.01797414  0.01682046  0.0145485   0.01294453  0.01114638
  0.00900152  0.00662771  0.00312094 -0.00342157]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0530 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1242, add (DA)= 0.0001decode = 0.1271 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1803 s, inc stats = 0.1928, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95784129 2.86437295 3.43738685 3.08325985 2.47020013]
u_DA:    [3.84793266 2.10278347 2.61245008 1.87808928 2.28843216]
ref_MAE: [0.11738689 0.70259255 0.89845206 1.2307064  0.09356642]
da_MAE:  [0.10990863 0.76158948 0.82493676 1.20517057 0.18176797]
% 14.283418931710194 da_MAE 0.006449088542569996 ref_MAE 0.007523735153916198
u_c taken from control states: [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
u_c before reduction of space:  [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
data[u_c] post encoding of state:  [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
J_b = 0.0, J_o = 1607.7894519863278
J_b = 0.5, J_o = 310973.01578477933
J_b = 0.0017033183904110805, J_o = 414.60785390143513
J_b = 0.002264151453921282, J_o = 273.8431114975775
J_b = 0.002347090600704843, J_o = 267.3386414085315
J_b = 0.002935213982769081, J_o = 237.58869794246158
J_b = 0.004667197778449174, J_o = 200.95661106792122
J_b = 0.008434933431979406, J_o = 164.06239460577206
J_b = 0.010375989954818424, J_o = 152.1483378486045
J_b = 0.010796445254931489, J_o = 149.12788149958135
J_b = 0.010941508356825495, J_o = 147.20266795108063
J_b = 0.011675237023966157, J_o = 142.42068704999838
J_b = 0.013707900800383923, J_o = 135.8906060253573
J_b = 0.020628559251809467, J_o = 120.48120297036021
J_b = 0.05592055885914755, J_o = 100.17085205736174
J_b = 0.05848394214170428, J_o = 89.05995848034675
J_b = 0.06352833561925904, J_o = 127.09997402644316
J_b = 0.05913460784596693, J_o = 88.00223526419165
J_b = 0.06145430495011598, J_o = 86.28935608543892
J_b = 0.06224045700976583, J_o = 85.61403683394751
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
W_opt:  [-0.00416632  0.01241545  0.02870753  0.03462018  0.03554042  0.03291103
  0.02688639  0.01737299  0.00187823 -0.02410257]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0567 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1251, add (DA)= 0.0001decode = 0.1280 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1849 s, inc stats = 0.1974, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95774023 2.86262327 3.43700345 3.08521932 2.47138718]
u_DA:    [3.84777959 2.09367102 2.6239329  1.88455223 2.26104723]
ref_MAE: [0.11728582 0.70084287 0.89806867 1.23266587 0.09475347]
da_MAE:  [0.10996063 0.76895225 0.81307055 1.20066709 0.21033995]
% 15.231065623997297 da_MAE 0.006373611363202555 ref_MAE 0.007518805574376626
u_c taken from control states: [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
u_c before reduction of space:  [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
data[u_c] post encoding of state:  [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
J_b = 0.0, J_o = 1571.4609713578825
J_b = 0.5000000000000001, J_o = 400658.0387823729
J_b = 0.001377902713821008, J_o = 342.63732642544255
J_b = 0.001614602711351077, J_o = 243.99352511339623
J_b = 0.0018903322153057728, J_o = 217.9114248789936
J_b = 0.001999122290487433, J_o = 209.5598993825948
J_b = 0.003540016355295717, J_o = 163.34241221674344
J_b = 0.005843929234502703, J_o = 137.15559850986278
J_b = 0.007416037139530785, J_o = 125.84677001265061
J_b = 0.007944890683221191, J_o = 122.95042908860768
J_b = 0.008357702301039289, J_o = 120.50379523484743
J_b = 0.00991871680143832, J_o = 114.29853635068064
J_b = 0.013800736002067838, J_o = 105.5005430788155
J_b = 0.023882469668109044, J_o = 90.93002925707466
J_b = 0.04352845757022028, J_o = 77.8507040401894
J_b = 0.04463594497902809, J_o = 73.60838400002581
J_b = 0.04554719036625998, J_o = 76.8225698399882
J_b = 0.044877641702034815, J_o = 72.83052446015947
J_b = 0.04520026976740796, J_o = 71.47892059259165
J_b = 0.04616285776500385, J_o = 70.8435065370487
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
W_opt:  [-0.00221121 -0.00063981  0.01173986  0.01984089  0.02277681  0.02229038
  0.01864517  0.01106765 -0.00231597 -0.02477335]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0517 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1215, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1762 s, inc stats = 0.1898, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95762796 2.86095799 3.43659404 3.08690017 2.47128244]
u_DA:    [3.84961516 2.08122158 2.64001232 1.89121099 2.2382256 ]
ref_MAE: [0.11717356 0.6991776  0.89765926 1.23434672 0.09464873]
da_MAE:  [0.10801281 0.77973641 0.79658172 1.19568918 0.23305683]
% 16.753103188934286 da_MAE 0.006254275351518716 ref_MAE 0.007512923113174061
u_c taken from control states: [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
u_c before reduction of space:  [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
data[u_c] post encoding of state:  [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
J_b = 0.0, J_o = 1683.9512629855162
J_b = 0.5, J_o = 448616.18017649313
J_b = 0.0014638206230253488, J_o = 216.7136096060418
J_b = 0.001498665995483334, J_o = 198.06539535258366
J_b = 0.0016553200841710736, J_o = 175.2307279302102
J_b = 0.0019659560353295206, J_o = 155.37827322951486
J_b = 0.00399851095253772, J_o = 107.87583026985445
J_b = 0.006968549652133269, J_o = 77.38186517318414
J_b = 0.007672732804689608, J_o = 74.04325889281203
J_b = 0.007772674582539018, J_o = 73.19530931169011
J_b = 0.00798420481847118, J_o = 71.44571148919732
J_b = 0.008716295148434241, J_o = 67.90972298371031
J_b = 0.011014765514070927, J_o = 61.91954864479274
J_b = 0.016107475345611452, J_o = 53.479153785098376
J_b = 0.023770806309928498, J_o = 46.42493808703851
J_b = 0.0256639021137909, J_o = 44.512058862520206
J_b = 0.02612442117138558, J_o = 43.76786086084171
J_b = 0.02631337048514084, J_o = 43.127076034062725
J_b = 0.02659013450056101, J_o = 42.70963380605893
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
W_opt:  [-0.00251288 -0.00397279 -0.00090038  0.00169429  0.0025746   0.00219134
  0.00027942 -0.00401699 -0.01201473 -0.02566834]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0479 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1377, add (DA)= 0.0001decode = 0.1407 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1887 s, inc stats = 0.2012, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9574981  2.85944181 3.43614634 3.08813201 2.46974923]
u_DA:    [3.84912695 2.05861865 2.63859432 1.89471276 2.20934146]
ref_MAE: [0.1170437  0.69766141 0.89721156 1.23557856 0.09311552]
da_MAE:  [0.10837115 0.80082316 0.79755202 1.19341926 0.26040777]
% 18.83491776448952 da_MAE 0.006092847429583548 ref_MAE 0.007506734745742511
u_c taken from control states: [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
u_c before reduction of space:  [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
data[u_c] post encoding of state:  [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
J_b = 0.0, J_o = 1783.0485589932168
J_b = 0.4999999999999999, J_o = 447343.4825563587
J_b = 0.0015729448783785383, J_o = 204.25849813870366
J_b = 0.0016064107695246315, J_o = 186.43250218483598
J_b = 0.0017452919205947829, J_o = 166.1974104245438
J_b = 0.00200655611347248, J_o = 148.9111835331398
J_b = 0.003965787876725126, J_o = 102.20134919184623
J_b = 0.007477263547726942, J_o = 66.74274021619578
J_b = 0.009276392449569508, J_o = 56.66309984222414
J_b = 0.009670268336553841, J_o = 54.269794780641874
J_b = 0.00998499245101277, J_o = 51.963875862810056
J_b = 0.010910297863116123, J_o = 47.717656456089834
J_b = 0.012729019752567305, J_o = 42.8633481200434
J_b = 0.01415035059162644, J_o = 40.24169545550351
J_b = 0.014772047237040195, J_o = 39.14702937288492
J_b = 0.015263825309187861, J_o = 38.083657799125135
J_b = 0.016544937132178576, J_o = 35.79389051794338
J_b = 0.019558182888283475, J_o = 32.358124707441156
J_b = 0.02852325717742452, J_o = 51.944488200385265
J_b = 0.02068299003809758, J_o = 31.772907494986207
J_b = 0.02466235850522866, J_o = 28.885442507618286
J_b = 0.026775104267107025, J_o = 27.527446842692008
J_b = 0.02729791928133342, J_o = 26.975912229318876
J_b = 0.02772074475586099, J_o = 26.555077013250727
J_b = 0.029225607498015112, J_o = 25.673704779236537
J_b = 0.032066497774702864, J_o = 24.294683947193274
J_b = 0.037852200526403576, J_o = 21.99082039428108
J_b = 0.04466025645128343, J_o = 19.866095807697675
J_b = 0.05585253927094244, J_o = 17.383018725834944
J_b = 0.04642887298369135, J_o = 26.174185436846287
J_b = 0.05410630768134179, J_o = 17.144214384778703
J_b = 0.060338541703510586, J_o = 16.279949259505578
J_b = 0.06651412751754943, J_o = 16.303836394903506
J_b = 0.06331931391923036, J_o = 15.920500184554536
J_b = 0.06098074814447931, J_o = 15.787391074670758
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
W_opt:  [-0.01004438 -0.00372693 -0.0003838   0.00088119 -0.00046235 -0.00389458
 -0.0102764  -0.02171044 -0.04062198 -0.06855111]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0920 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1328, add (DA)= 0.0001decode = 0.1356 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2277 s, inc stats = 0.2411, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95734745 2.8581581  3.43565384 3.08878952 2.46688677]
u_DA:    [3.84907486 2.05011609 2.64497976 1.89628098 2.19110006]
ref_MAE: [0.11689305 0.6963777  0.89671906 1.23623607 0.09025305]
da_MAE:  [0.10827259 0.80804201 0.79067408 1.19250854 0.27578671]
% 19.584694098085706 da_MAE 0.006031685533001911 ref_MAE 0.007500668517457354
u_c taken from control states: [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
u_c before reduction of space:  [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
data[u_c] post encoding of state:  [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
J_b = 0.0, J_o = 1905.5919969317708
J_b = 0.5000000000000002, J_o = 414864.2870584003
J_b = 0.0017403269369450217, J_o = 275.9321371602773
J_b = 0.00193873105415931, J_o = 186.41597466789747
J_b = 0.0022200184428204767, J_o = 157.71359945892476
J_b = 0.002313943071062676, J_o = 150.27012892695296
J_b = 0.004134897032788873, J_o = 100.00731277720362
J_b = 0.007189782665555843, J_o = 69.13582344267704
J_b = 0.01142491756324459, J_o = 45.904661951716065
J_b = 0.012630503091529242, J_o = 40.38161904717727
J_b = 0.013486531198008207, J_o = 36.89332929990329
J_b = 0.014318839006867342, J_o = 34.32358433179046
J_b = 0.016113001413903982, J_o = 30.069562838978143
J_b = 0.01845077119600815, J_o = 26.562395393198575
J_b = 0.020093412259255424, J_o = 24.492649879828512
J_b = 0.022983871379154728, J_o = 21.418688368971527
J_b = 0.025534142307294453, J_o = 19.801420189859684
J_b = 0.028019924533701925, J_o = 19.023548607878343
J_b = 0.026798758780545773, J_o = 18.120320732484117
J_b = 0.026623131005995875, J_o = 18.048614534319167
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
W_opt:  [ 0.00408758 -0.00122833 -0.00228584 -0.00274379 -0.00374771 -0.00618199
 -0.01011015 -0.01568008 -0.02326615 -0.03303782]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1032 s, v_trunc (Latent to Reduced) = 0.0038, dec (Reduced to Full) = 0.1121, add (DA)= 0.0001decode = 0.1178 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2211 s, inc stats = 0.2349, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95717471 2.85714928 3.43511298 3.08877384 2.46294677]
u_DA:    [3.84740939 2.0479324  2.6419208  1.89745208 2.18520226]
ref_MAE: [0.11672031 0.69536889 0.89617819 1.23622039 0.08631306]
da_MAE:  [0.10976532 0.80921688 0.79319217 1.19132176 0.2777445 ]
% 19.727802219429464 da_MAE 0.006016828457867444 ref_MAE 0.007495532231862954
u_c taken from control states: [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
u_c before reduction of space:  [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
data[u_c] post encoding of state:  [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
J_b = 0.0, J_o = 2047.3361391400338
J_b = 0.5000000000000002, J_o = 384305.78023446887
J_b = 0.0019489192513370932, J_o = 344.7577704181099
J_b = 0.0023237532172110656, J_o = 194.87136162871354
J_b = 0.002691051804980259, J_o = 164.0939030164924
J_b = 0.0027881404354588276, J_o = 156.8271703495767
J_b = 0.004548219389233849, J_o = 106.33976126587442
J_b = 0.007317716453952534, J_o = 75.63165664672911
J_b = 0.012240828599439665, J_o = 48.67780489533965
J_b = 0.013556992233051587, J_o = 41.150248796248114
J_b = 0.01455988846020519, J_o = 36.737794542901476
J_b = 0.015541836346504537, J_o = 33.86476122659806
J_b = 0.01845032533262544, J_o = 27.066106449937557
J_b = 0.0235352826737652, J_o = 20.739550584977664
J_b = 0.02617064891352666, J_o = 18.321053836910387
J_b = 0.028792059392180144, J_o = 15.990394915331708
J_b = 0.030719645064008497, J_o = 17.34288922857276
J_b = 0.02933843001370318, J_o = 15.708553036124705
J_b = 0.03011125453708277, J_o = 15.08398908221059
J_b = 0.030176992094021374, J_o = 14.772845155312071
J_b = 0.030570512949222906, J_o = 14.099819014020344
J_b = 0.03127303527221056, J_o = 13.506873812020759
J_b = 0.03391920803241799, J_o = 13.299221006624208
J_b = 0.03444480434635303, J_o = 12.831881588327661
J_b = 0.03378957315994223, J_o = 12.316969025040283
J_b = 0.03380122248841321, J_o = 11.830540151734635
J_b = 0.03500204321532015, J_o = 10.642860376819687
J_b = 0.03814934804799413, J_o = 9.67956519614004
J_b = 0.04289496991433128, J_o = 9.126129924974599
J_b = 0.05037717286964305, J_o = 9.287995554084985
J_b = 0.04614693574384835, J_o = 8.74693957493103
J_b = 0.045961881098860416, J_o = 8.637353842054182
J_b = 0.04631990360168798, J_o = 8.459392688027883
J_b = 0.047847319802603615, J_o = 8.190231036113753
J_b = 0.050729733369336116, J_o = 7.7774729833301475
J_b = 0.0552050809189978, J_o = 7.435667621623374
J_b = 0.0559270718692904, J_o = 7.022203070583888
J_b = 0.056342826857314204, J_o = 6.7563316875649715
J_b = 0.05644653727787534, J_o = 6.545374028567195
J_b = 0.05726291799588011, J_o = 6.289999075580203
J_b = 0.05741219714897968, J_o = 6.179456763802971
J_b = 0.05691998445942766, J_o = 6.089517953059126
J_b = 0.056557300765997714, J_o = 5.97784991678187
J_b = 0.055993426728844116, J_o = 5.903164145469557
J_b = 0.05516114994116557, J_o = 5.80568115375117
J_b = 0.055057270403431474, J_o = 5.763662895602614
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
W_opt:  [-0.01157417 -0.00716166 -0.00094292  0.00106172  0.00135953 -0.00210391
 -0.00975227 -0.02217846 -0.04162313 -0.07084579]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1158 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1218, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2409 s, inc stats = 0.2479, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95697784 2.85640887 3.43452062 3.08803483 2.45821844]
u_DA:    [3.84646338 2.04604495 2.63806712 1.88931786 2.18208719]
ref_MAE: [0.11652344 0.69462848 0.89558584 1.23548138 0.08158473]
da_MAE:  [0.11051445 0.81036392 0.7964535  1.19871696 0.27613125]
% 19.73377866398917 da_MAE 0.006013473650341534 ref_MAE 0.007491910731873004
u_c taken from control states: [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
u_c before reduction of space:  [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
data[u_c] post encoding of state:  [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
J_b = 0.0, J_o = 2137.9338465928854
J_b = 0.5, J_o = 363081.37429012475
J_b = 0.002105592985721829, J_o = 391.2299716391496
J_b = 0.0026125832677767634, J_o = 206.66495488480405
J_b = 0.002990275463927276, J_o = 178.74632590215623
J_b = 0.003112831483030634, J_o = 170.09606747570672
J_b = 0.004754925144155696, J_o = 119.08111925742453
J_b = 0.0075499795393190895, J_o = 84.0655220450785
J_b = 0.012946611535204211, J_o = 52.838599124149646
J_b = 0.014012521783739258, J_o = 43.96840702618778
J_b = 0.014716582953088973, J_o = 39.66711411255461
J_b = 0.01562869114995098, J_o = 36.51807814973637
J_b = 0.018164856106892585, J_o = 30.74472459274585
J_b = 0.0212794371009657, J_o = 26.185489613720385
J_b = 0.02385770799224498, J_o = 23.269163519170796
J_b = 0.026437165869200332, J_o = 20.365826373378123
J_b = 0.029867071625507807, J_o = 16.825245854849037
J_b = 0.03713982316640511, J_o = 48.19539960018082
J_b = 0.0305623913831071, J_o = 16.321705266603075
J_b = 0.031638144153720724, J_o = 15.059334611428966
J_b = 0.03139651958577703, J_o = 14.733976300914865
J_b = 0.03113781945612107, J_o = 14.524793994186682
J_b = 0.030923247465897783, J_o = 14.17089667257368
J_b = 0.031199671721031927, J_o = 13.500067804049403
J_b = 0.032441159706449584, J_o = 12.63076493614812
J_b = 0.03511319678339894, J_o = 11.909938580281239
J_b = 0.038361529398688796, J_o = 11.470178163072354
J_b = 0.039075900912376914, J_o = 11.155917186831044
J_b = 0.0405177595921991, J_o = 10.466372859524366
J_b = 0.04342034243029607, J_o = 9.397295273845845
J_b = 0.058938296965232014, J_o = 39.71796688392003
J_b = 0.04415545280701336, J_o = 9.284880175826281
J_b = 0.0456056354064549, J_o = 8.78785733962393
J_b = 0.04540195508168519, J_o = 8.492854673844509
J_b = 0.04444050688288915, J_o = 8.193705544751605
J_b = 0.05242060572830949, J_o = 11.070779439947591
J_b = 0.045305916208109025, J_o = 8.140365842487425
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
W_opt:  [ 0.00544213  0.00015476  0.00025353  0.00094583  0.00038657 -0.00293379
 -0.00921107 -0.01901009 -0.03313831 -0.05278672]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0964 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1200, add (DA)= 0.0001decode = 0.1228 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2193 s, inc stats = 0.2319, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95675496 2.85585573 3.43387888 3.08659972 2.45306202]
u_DA:    [3.84642358 2.04668892 2.63585157 1.88492044 2.1815033 ]
ref_MAE: [0.11630056 0.69407533 0.8949441  1.23404627 0.07642831]
da_MAE:  [0.11033137 0.8091668  0.79802731 1.20167927 0.27155872]
% 19.66284259694991 da_MAE 0.006016802233881969 ref_MAE 0.007489438795669331
u_c taken from control states: [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
u_c before reduction of space:  [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
data[u_c] post encoding of state:  [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
J_b = 0.0, J_o = 2202.781335836604
J_b = 0.4999999999999999, J_o = 347132.3922918637
J_b = 0.0022304692450982877, J_o = 426.83565666613276
J_b = 0.0028392451501344502, J_o = 221.91922623750747
J_b = 0.0031970659111897957, J_o = 197.40427289518354
J_b = 0.0033641355425128947, J_o = 186.1890267692246
J_b = 0.004943639084815139, J_o = 133.8345372936756
J_b = 0.00800651701322421, J_o = 91.21875356111822
J_b = 0.014160736871746085, J_o = 55.21599857761736
J_b = 0.014571376494406171, J_o = 45.38384864074956
J_b = 0.014863530731278786, J_o = 41.647402714550395
J_b = 0.01542068029940879, J_o = 38.901064452117204
J_b = 0.017543491538207855, J_o = 33.548099021818444
J_b = 0.021114165320978266, J_o = 25.865073981796467
J_b = 0.02939836118761618, J_o = 17.236286054987062
J_b = 0.031554449693023554, J_o = 15.488187992057117
J_b = 0.03396684948429598, J_o = 14.358026073973528
J_b = 0.034512236851747154, J_o = 12.975602574050274
J_b = 0.034134561101111904, J_o = 12.623220837070068
J_b = 0.03442111153743029, J_o = 12.082966445475652
J_b = 0.03534471905765261, J_o = 11.74321811535286
J_b = 0.037203727858220174, J_o = 12.811387458034789
J_b = 0.035920922679206664, J_o = 11.25060465466812
J_b = 0.03864570600573077, J_o = 10.615856848152095
J_b = 0.04181370048073565, J_o = 9.919975360838354
J_b = 0.04542825023633819, J_o = 9.271230578580067
J_b = 0.04391257473972296, J_o = 8.862581512957032
J_b = 0.043849883812438165, J_o = 8.471771034447688
J_b = 0.04336011551351616, J_o = 8.358919833367555
J_b = 0.04324355158821793, J_o = 8.330187238140361
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
W_opt:  [ 0.00792662  0.00128219 -0.00091449 -0.00068692 -0.00134827 -0.00442493
 -0.0101469  -0.01914485 -0.03192048 -0.04937231]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0840 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1229, add (DA)= 0.0001decode = 0.1259 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2099 s, inc stats = 0.2232, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95651069 2.85540571 3.43319822 3.08457918 2.44799337]
u_DA:    [3.84643295 2.04800476 2.63772669 1.88328177 2.18170426]
ref_MAE: [0.11605629 0.69362532 0.89426344 1.23202573 0.07135966]
da_MAE:  [0.11007775 0.80740095 0.79547154 1.20129741 0.26628912]
% 19.605743254573852 da_MAE 0.006020433856751427 ref_MAE 0.00748863675152261
u_c taken from control states: [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
u_c before reduction of space:  [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
data[u_c] post encoding of state:  [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
J_b = 0.0, J_o = 2236.5710556817453
J_b = 0.49999999999999994, J_o = 335716.67442277644
J_b = 0.0023134545465725888, J_o = 450.61870932014557
J_b = 0.0029921056454114917, J_o = 235.8951895346625
J_b = 0.0033192493099821717, J_o = 214.1007099293543
J_b = 0.003545941574312252, J_o = 199.41719658465564
J_b = 0.005125372651165713, J_o = 145.59888469838543
J_b = 0.008547196648219256, J_o = 95.01109408894473
J_b = 0.015078770448718287, J_o = 54.6650392143428
J_b = 0.015026043753457638, J_o = 45.652198003786694
J_b = 0.01518853225953082, J_o = 41.891537428631565
J_b = 0.015531673420512836, J_o = 39.81141507092441
J_b = 0.017474221762447013, J_o = 34.02692096384493
J_b = 0.020786021209367345, J_o = 26.345282343129668
J_b = 0.02823933335722416, J_o = 18.06227309307034
J_b = 0.030457845936812264, J_o = 16.160162186196672
J_b = 0.033042814318757975, J_o = 17.24837675694858
J_b = 0.031365685989626475, J_o = 15.57235862582013
J_b = 0.03238120509750338, J_o = 14.484076472576374
J_b = 0.032507049224965286, J_o = 14.07306323004267
J_b = 0.03251207399341214, J_o = 13.665794369569255
J_b = 0.032576826013428754, J_o = 13.310782627970521
J_b = 0.03268702856835316, J_o = 12.60914542679497
J_b = 0.035624312114757715, J_o = 12.402682451212835
J_b = 0.03500801085796407, J_o = 11.628261399329515
J_b = 0.035290139265372666, J_o = 11.336931741266408
J_b = 0.03663805741054095, J_o = 10.791077055002045
J_b = 0.03947264663082723, J_o = 9.955024988523336
J_b = 0.04296559579442284, J_o = 10.248777236595274
J_b = 0.040845625748059285, J_o = 9.610973119313975
J_b = 0.04381880801531469, J_o = 9.028558072792201
J_b = 0.04535043273964272, J_o = 8.710991680485341
J_b = 0.04550331011538657, J_o = 8.570478645832218
J_b = 0.04485326462287116, J_o = 8.486855696756187
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
W_opt:  [ 0.00788701  0.00073316 -0.0023053  -0.00201941 -0.00260005 -0.0056097
 -0.01126858 -0.02030544 -0.03311633 -0.05047236]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0980 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1210, add (DA)= 0.0001decode = 0.1240 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2221 s, inc stats = 0.2357, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95625104 2.8549381  3.43248729 3.0820369  2.44344662]
u_DA:    [3.84647246 2.04915709 2.64106301 1.88297311 2.18193789]
ref_MAE: [0.11579664 0.6931577  0.8935525  1.22948345 0.06681291]
da_MAE:  [0.10977858 0.80578101 0.79142428 1.19906379 0.26150873]
% 19.573963244841732 da_MAE 0.006023153777946842 ref_MAE 0.007489059539615492
\% improve_point: 15.28, mse_ref_points: 3.486536501664882e-05, mse_da_points: 2.954217386331877e-05, % improve_overlap: 15.28, mse_ref_overlap: 0.90811, mse_da_overlap: 0.76947
DA - - L2: 168640.85, L1: 10613.07, % Improve: 17.22%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.769, time(s): 2.5976s,
u_c taken from control states: [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
u_c before reduction of space:  [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
data[u_c] post encoding of state:  [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
J_b = 0.0, J_o = 2217.160956250494
J_b = 0.49999999999999994, J_o = 333625.65527337906
J_b = 0.002291883477152001, J_o = 460.145045871254
J_b = 0.0029747589704675905, J_o = 246.84259456985674
J_b = 0.003294906312516058, J_o = 224.91686871343393
J_b = 0.0035606004359723217, J_o = 207.68304902046722
J_b = 0.00523842364459018, J_o = 150.49416490450432
J_b = 0.008995195889464099, J_o = 94.64472725375806
J_b = 0.015464725648988912, J_o = 52.59416339972111
J_b = 0.015309820610177377, J_o = 45.13311046483972
J_b = 0.015454844435913046, J_o = 41.132425759508486
J_b = 0.015759734466924625, J_o = 39.302453877101705
J_b = 0.017777940792991626, J_o = 33.15084653633766
J_b = 0.020785492203639636, J_o = 26.13676079669527
J_b = 0.02730188472841909, J_o = 18.59787173141892
J_b = 0.029470404601047696, J_o = 16.620711226543072
J_b = 0.03210967109948837, J_o = 16.53120348114754
J_b = 0.03076308369945124, J_o = 15.759039072896794
J_b = 0.0320062448979634, J_o = 14.513017881730459
J_b = 0.031955652011430115, J_o = 14.162296038882038
J_b = 0.031834999492050556, J_o = 13.871071107879139
J_b = 0.03186347221122465, J_o = 13.62534054853668
J_b = 0.03213108107787944, J_o = 12.962868715439239
J_b = 0.037690064973501164, J_o = 14.469119610094392
J_b = 0.03361532549785779, J_o = 12.6771315126479
J_b = 0.03402717239633101, J_o = 11.987072397130387
J_b = 0.034638013371003175, J_o = 11.655044775694332
J_b = 0.03548563560120272, J_o = 11.402163128548178
J_b = 0.03648712442663361, J_o = 11.13125674788936
J_b = 0.03828981808015868, J_o = 10.599149221367796
J_b = 0.04111454602302484, J_o = 10.505358640661742
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
W_opt:  [ 0.00779751  0.0016628  -0.00225169 -0.00248066 -0.00330027 -0.00616128
 -0.01123319 -0.0190858  -0.0300154  -0.04472568]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0945 s, v_trunc (Latent to Reduced) = 0.0097, dec (Reduced to Full) = 0.1143, add (DA)= 0.0001decode = 0.1258 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2205 s, inc stats = 0.2273, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9559738  2.85430624 3.43174682 3.07902499 2.43950125]
u_DA:    [3.84624932 2.05046328 2.64407966 1.88303694 2.18446957]
ref_MAE: [0.1155194  0.69252584 0.89281204 1.22647154 0.06286754]
da_MAE:  [0.10972448 0.80384296 0.78766716 1.19598805 0.25503168]
% 19.47810906074951 da_MAE 0.006031583523614109 ref_MAE 0.007490613363966601
u_c taken from control states: [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
u_c before reduction of space:  [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
data[u_c] post encoding of state:  [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
J_b = 0.0, J_o = 2137.2524638331734
J_b = 0.49999999999999994, J_o = 343484.3125751367
J_b = 0.0021491897135703987, J_o = 448.58424241073135
J_b = 0.002758360552750748, J_o = 247.99652451633253
J_b = 0.003106740259408291, J_o = 222.631089894584
J_b = 0.003348178450124933, J_o = 206.3120063769059
J_b = 0.005154722042287511, J_o = 145.07830279408284
J_b = 0.008987325849262146, J_o = 89.86921327758607
J_b = 0.015007654152960332, J_o = 50.04889151490089
J_b = 0.014980437973536018, J_o = 43.81379058395346
J_b = 0.015172243457084341, J_o = 39.67635577419283
J_b = 0.015530633318685485, J_o = 37.78003949800032
J_b = 0.01777056284109806, J_o = 31.446359627905245
J_b = 0.020886631070133162, J_o = 24.171215308043188
J_b = 0.027826392252433746, J_o = 16.700075672470497
J_b = 0.029468405042301405, J_o = 15.341901084269534
J_b = 0.03186947094327201, J_o = 19.411521593796117
J_b = 0.029928374151646644, J_o = 15.04189890834269
J_b = 0.03084170813424051, J_o = 14.1997103280997
J_b = 0.031447308315452414, J_o = 13.461220291748283
J_b = 0.032204609733217295, J_o = 12.56120500597051
J_b = 0.032793995652297236, J_o = 12.166096271694219
J_b = 0.033051291829335874, J_o = 19.12350283997813
J_b = 0.032762298253511075, J_o = 11.969764553111752
J_b = 0.034192920538454685, J_o = 11.467576116144311
J_b = 0.03731269073461368, J_o = 10.722165375376013
J_b = 0.03966491712541519, J_o = 9.76454649870283
J_b = 0.040577829630995085, J_o = 8.776422709507637
J_b = 0.0508839432190649, J_o = 10.122402265325936
J_b = 0.04292864637446942, J_o = 8.612294360358357
J_b = 0.04257450795720419, J_o = 8.556454316686624
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
W_opt:  [ 0.00552765 -0.0010429  -0.00356549 -0.002699   -0.00299874 -0.00575322
 -0.0111137  -0.01979936 -0.03229361 -0.04972151]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0749 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1155, add (DA)= 0.0001decode = 0.1184 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1934 s, inc stats = 0.2007, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95567803 2.85347245 3.4309813  3.07562723 2.43622151]
u_DA:    [3.84621799 2.04878708 2.64125969 1.8834235  2.18290405]
ref_MAE: [0.11522363 0.69169206 0.89204652 1.22307378 0.0595878 ]
da_MAE:  [0.10946005 0.80468537 0.78972161 1.19220373 0.25331747]
% 19.54609992110777 da_MAE 0.006028909514276153 ref_MAE 0.007493619959211759
u_c taken from control states: [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
u_c before reduction of space:  [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
data[u_c] post encoding of state:  [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
J_b = 0.0, J_o = 2033.8670765030427
J_b = 0.5000000000000002, J_o = 361461.3470865366
J_b = 0.0019650175015071096, J_o = 418.80426878715576
J_b = 0.002457011364469648, J_o = 241.6762940017108
J_b = 0.002833923230452279, J_o = 211.4212922086384
J_b = 0.0030331069560464306, J_o = 197.16623643314472
J_b = 0.005001935740365506, J_o = 132.6025037622293
J_b = 0.00876944917793201, J_o = 82.28909982701082
J_b = 0.013867377129846602, J_o = 47.83720942976315
J_b = 0.014247401983358408, J_o = 42.85820251579003
J_b = 0.014605059677729175, J_o = 38.68004291826948
J_b = 0.01511217040459413, J_o = 36.28831123992307
J_b = 0.017282258403519355, J_o = 30.517929919420446
J_b = 0.019838227054163344, J_o = 25.233564505953137
J_b = 0.023627443422352946, J_o = 20.35405540384637
J_b = 0.02540653466240693, J_o = 18.27818495015729
J_b = 0.02777366278551958, J_o = 15.768316979797392
J_b = 0.03352694100273964, J_o = 41.91592723979207
J_b = 0.02825863342555541, J_o = 15.464041283948355
J_b = 0.029102050557220545, J_o = 14.61242635768443
J_b = 0.029172201673414923, J_o = 14.35039116595644
J_b = 0.029182599439336203, J_o = 14.203366302859912
J_b = 0.029271833609347618, J_o = 13.907145597806512
J_b = 0.030144100220839323, J_o = 13.332578823336036
J_b = 0.029535774930344823, J_o = 13.367975289965969
J_b = 0.02979596554615596, J_o = 12.895555233114958
J_b = 0.032448483960004125, J_o = 12.437308534201508
J_b = 0.03435976170355304, J_o = 11.658907207377212
J_b = 0.03353691911292866, J_o = 11.412110592915369
J_b = 0.03294288547217148, J_o = 11.039018151855753
J_b = 0.033056361602430334, J_o = 10.493236173549132
J_b = 0.03719848054582531, J_o = 18.86856745931852
J_b = 0.03344058835762729, J_o = 10.302167946941015
J_b = 0.03522205552015612, J_o = 9.55414611761846
J_b = 0.03772411844861544, J_o = 9.065930027042594
J_b = 0.03951385129393052, J_o = 8.785718585534187
J_b = 0.040942314730540906, J_o = 8.528273400842444
J_b = 0.04212276906204226, J_o = 9.11619288453333
J_b = 0.0412032914177554, J_o = 8.469606427991572
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
W_opt:  [ 0.00370392 -0.00208965 -0.00348309 -0.00222515 -0.00234815 -0.00509773
 -0.010547   -0.01935119 -0.0321159  -0.05011548]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0989 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1214, add (DA)= 0.0001decode = 0.1244 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2234 s, inc stats = 0.2300, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95536993 2.85230978 3.43020345 3.07199115 2.43379607]
u_DA:    [3.84609746 2.04867203 2.63799802 1.88538846 2.18429391]
ref_MAE: [0.11491553 0.69052938 0.89126866 1.2194377  0.05716236]
da_MAE:  [0.10927247 0.80363775 0.79220543 1.18660269 0.24950217]
% 19.517168008968152 da_MAE 0.006034224050139356 ref_MAE 0.0074975294741265385
u_c taken from control states: [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
u_c before reduction of space:  [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
data[u_c] post encoding of state:  [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
J_b = 0.0, J_o = 1955.2044910921131
J_b = 0.49999999999999983, J_o = 381042.67136429483
J_b = 0.0018203616948591476, J_o = 385.63820282914
J_b = 0.002197754858790325, J_o = 237.13229615580374
J_b = 0.0025771138346812107, J_o = 203.05630298101426
J_b = 0.002752728741883247, J_o = 189.87520423438085
J_b = 0.004880468329079427, J_o = 123.18460873367493
J_b = 0.008636888846590897, J_o = 76.87603194840305
J_b = 0.01299645357394506, J_o = 47.26031193161739
J_b = 0.013766823410081131, J_o = 42.552101168459515
J_b = 0.014277998668217886, J_o = 39.15083684079199
J_b = 0.015087483982860752, J_o = 35.45233586304946
J_b = 0.016961409172108064, J_o = 30.36254432505806
J_b = 0.01935134436850215, J_o = 25.449522260847175
J_b = 0.022131381328116623, J_o = 21.59447450051423
J_b = 0.02340189873865591, J_o = 19.757928378860157
J_b = 0.025633817894949732, J_o = 16.816415781655735
J_b = 0.03235313757553553, J_o = 21.20228413749537
J_b = 0.027312371384468348, J_o = 16.119417351172796
J_b = 0.029355899825981777, J_o = 14.441826596936822
J_b = 0.029980721185322502, J_o = 13.859322473835089
J_b = 0.030124664971573227, J_o = 13.638632387332091
J_b = 0.030307512004399826, J_o = 13.367888050062447
J_b = 0.030883912059155888, J_o = 12.86707719728371
J_b = 0.030496775539281193, J_o = 14.666486601684788
J_b = 0.030698453326503852, J_o = 12.58233072021695
J_b = 0.031185105472437618, J_o = 12.069302672929943
J_b = 0.03199395442972024, J_o = 11.603134350173425
J_b = 0.03264805077310074, J_o = 11.141707186889235
J_b = 0.03518069694418012, J_o = 10.450048230839188
J_b = 0.03935956274723434, J_o = 14.93467752076147
J_b = 0.035794352547725616, J_o = 10.192642386809796
J_b = 0.03937492405590477, J_o = 9.387828128729094
J_b = 0.041524796045022065, J_o = 8.768104576646849
J_b = 0.04167684405777562, J_o = 8.529915639355304
J_b = 0.04157042009997417, J_o = 8.517657755759725
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
W_opt:  [ 0.00222553 -0.00239172 -0.00261532 -0.00100909 -0.00109368 -0.0040502
 -0.00981929 -0.01902384 -0.03248209 -0.05163489]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0993 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1215, add (DA)= 0.0001decode = 0.1245 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2239 s, inc stats = 0.2375, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95505368 2.85072188 3.42942295 3.06825367 2.43221142]
u_DA:    [3.84624808 2.0484227  2.63675459 1.88803407 2.18569836]
ref_MAE: [0.11459928 0.68894149 0.89048816 1.21570022 0.05557771]
da_MAE:  [0.10880559 0.80229918 0.79266836 1.1802196  0.24651306]
% 19.554504579319076 da_MAE 0.006034750706921576 ref_MAE 0.007501663922092228
u_c taken from control states: [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
u_c before reduction of space:  [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
data[u_c] post encoding of state:  [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
J_b = 0.0, J_o = 1917.8671726665368
J_b = 0.5, J_o = 398434.02615864924
J_b = 0.0017343638211791673, J_o = 358.81360483538856
J_b = 0.0020183605391817386, J_o = 238.41870073845786
J_b = 0.0023780400407148786, J_o = 202.4467213604098
J_b = 0.0025515160591849393, J_o = 189.03066512863845
J_b = 0.0048121352345113465, J_o = 120.43997310225228
J_b = 0.008711705858529982, J_o = 74.72414382634034
J_b = 0.012793820699791675, J_o = 47.25998777424291
J_b = 0.01379011120889152, J_o = 42.30493834119713
J_b = 0.014329383066804311, J_o = 39.243413167736676
J_b = 0.015430070481691052, J_o = 34.67165459557789
J_b = 0.017505032745807895, J_o = 29.254610130495955
J_b = 0.019379843917531975, J_o = 25.560064752827323
J_b = 0.02106074496594374, J_o = 23.011640769096818
J_b = 0.022107374487882653, J_o = 21.303566726005776
J_b = 0.024430289651150537, J_o = 18.067881784055935
J_b = 0.0285431694129956, J_o = 27.23211051655134
J_b = 0.025099357517840027, J_o = 17.591159331864237
J_b = 0.027638310332764877, J_o = 15.42312704465748
J_b = 0.028697373257586267, J_o = 14.588615822964295
J_b = 0.028633201512556074, J_o = 14.407607319606313
J_b = 0.028517038592499946, J_o = 14.266500738042382
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
W_opt:  [ 0.00679111 -0.00048056 -0.00381262 -0.00457102 -0.00564771 -0.00811402
 -0.01195132 -0.01735234 -0.02454153 -0.03381631]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0590 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1346, add (DA)= 0.0001decode = 0.1376 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1967 s, inc stats = 0.2082, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95473103 2.84870643 3.42864671 3.06454671 2.43135803]
u_DA:    [3.8466672  2.04837584 2.63929771 1.8942021  2.18654865]
ref_MAE: [0.11427663 0.68692603 0.88971193 1.21199326 0.05472432]
da_MAE:  [0.10806383 0.80033059 0.78934901 1.17034461 0.24480938]
% 19.655236037453683 da_MAE 0.0060304384192765475 ref_MAE 0.0075057018302869235
u_c taken from control states: [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
u_c before reduction of space:  [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
data[u_c] post encoding of state:  [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
J_b = 0.0, J_o = 1914.337843536101
J_b = 0.4999999999999999, J_o = 413266.4926997287
J_b = 0.0016925739782631178, J_o = 338.47270072103635
J_b = 0.0019004934928327926, J_o = 244.62891652726222
J_b = 0.0022277075511486126, J_o = 208.33656200607578
J_b = 0.0024183456639779743, J_o = 193.40911763039688
J_b = 0.004802688875996854, J_o = 122.5272338641024
J_b = 0.009008249046972401, J_o = 74.3369840716649
J_b = 0.013034737307836781, J_o = 47.19923559660296
J_b = 0.014174665032368241, J_o = 41.9468386914
J_b = 0.01471297919489662, J_o = 38.997039645123635
J_b = 0.015998448388889502, J_o = 33.88273263948007
J_b = 0.018278430715368003, J_o = 28.21138557663867
J_b = 0.019844524121205805, J_o = 25.287448255919788
J_b = 0.02094887484747542, J_o = 23.495160345589404
J_b = 0.021796840708270277, J_o = 22.006265708319283
J_b = 0.023949109145128145, J_o = 18.888414228202297
J_b = 0.027651800475860456, J_o = 20.40784365228312
J_b = 0.025246400074654212, J_o = 17.93365950692628
J_b = 0.028083028861000548, J_o = 15.540714440260084
J_b = 0.028990072890311688, J_o = 14.786805011664143
J_b = 0.028879939958658736, J_o = 14.658539729952022
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
W_opt:  [ 0.00617593 -0.00065768 -0.00356543 -0.00432797 -0.00546782 -0.00801224
 -0.01191686 -0.01738877 -0.02472662 -0.03426735]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0563 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1215, add (DA)= 0.0001decode = 0.1245 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1809 s, inc stats = 0.1943, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95440808 2.84627661 3.42788343 3.0610232  2.43125483]
u_DA:    [3.8472703  2.04925398 2.64149389 1.89698454 2.18642183]
ref_MAE: [0.11395368 0.68449621 0.88894865 1.20846975 0.05462112]
da_MAE:  [0.10713778 0.79702263 0.78638954 1.16403866 0.244833  ]
% 19.713344093698765 da_MAE 0.006028999690006784 ref_MAE 0.007509342146524255
u_c taken from control states: [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
u_c before reduction of space:  [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
data[u_c] post encoding of state:  [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
J_b = 0.0, J_o = 1931.414035982832
J_b = 0.49999999999999983, J_o = 425895.83201877936
J_b = 0.001677246145051004, J_o = 322.9019680712639
J_b = 0.0018206675256801682, J_o = 254.42025205731372
J_b = 0.0021096327640705405, J_o = 218.73795533193743
J_b = 0.002345058724644258, J_o = 200.52064551803454
J_b = 0.004893461557949426, J_o = 126.74771641178475
J_b = 0.009559237946349797, J_o = 73.85988449570826
J_b = 0.013450580316752956, J_o = 47.51636927279477
J_b = 0.014580443854717112, J_o = 42.214960696204855
J_b = 0.015072487879572027, J_o = 39.30749990396674
J_b = 0.01641547049900896, J_o = 33.83327349048761
J_b = 0.01893185433716859, J_o = 28.052924252850477
J_b = 0.02019069104473819, J_o = 25.424744937359325
J_b = 0.021050868588943897, J_o = 23.833230105411438
J_b = 0.02173803828423666, J_o = 22.530651021276782
J_b = 0.02393828584869725, J_o = 19.372581697919795
J_b = 0.02767749501773661, J_o = 19.015045931675985
J_b = 0.02891805891405676, J_o = 15.727856807366623
J_b = 0.028942777443886042, J_o = 15.169972669859977
J_b = 0.029139363727860784, J_o = 15.027539870107368
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
W_opt:  [ 0.00490113 -0.00076964 -0.00314361 -0.00383023 -0.00498606 -0.00756479
 -0.01149848 -0.01702759 -0.02451249 -0.03442004]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0536 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1225, add (DA)= 0.0001decode = 0.1254 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1791 s, inc stats = 0.1847, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9540897  2.84349198 3.42713651 3.05779888 2.43187065]
u_DA:    [3.8479278  2.04943089 2.64441559 1.89869324 2.18727341]
ref_MAE: [0.1136353  0.68171159 0.88820173 1.20524543 0.05523694]
da_MAE:  [0.10616191 0.7940611  0.78272092 1.15910564 0.24459724]
% 19.753985146754694 da_MAE 0.006027966031132607 ref_MAE 0.007511857183383636
u_c taken from control states: [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
u_c before reduction of space:  [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
data[u_c] post encoding of state:  [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
J_b = 0.0, J_o = 1960.50187736303
J_b = 0.49999999999999994, J_o = 435730.8058776336
J_b = 0.001681057980965099, J_o = 310.8009332081828
J_b = 0.001773030197637139, J_o = 264.4948034634928
J_b = 0.0020299927005141094, J_o = 229.32764898408664
J_b = 0.0023579627996787385, J_o = 205.34500910814828
J_b = 0.005227161467680734, J_o = 127.90199939070956
J_b = 0.010483174873647494, J_o = 70.27454583324662
J_b = 0.01382784054738151, J_o = 48.8242988503485
J_b = 0.014593022632584893, J_o = 44.495233594341016
J_b = 0.01496848505288768, J_o = 41.57671777747289
J_b = 0.01614942546376073, J_o = 35.8744454412589
J_b = 0.018467964337832196, J_o = 29.736409962555275
J_b = 0.019929460166289475, J_o = 27.05034804146117
J_b = 0.020478384789888986, J_o = 26.05516731476982
J_b = 0.02085992835576171, J_o = 25.14419984283764
J_b = 0.02194608380632762, J_o = 22.97448453024718
J_b = 0.02449885295620482, J_o = 19.686896115976015
J_b = 0.03122414919586014, J_o = 33.961623620889554
J_b = 0.02542097588976536, J_o = 19.185455812682587
J_b = 0.029091859285435034, J_o = 16.399287375031406
J_b = 0.03054633230809551, J_o = 15.502779693596555
J_b = 0.030371795395709767, J_o = 15.355100624507418
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
W_opt:  [ 0.00291513 -0.00121258 -0.00301603 -0.00346261 -0.00454766 -0.00714914
 -0.01117608 -0.01692915 -0.0248045  -0.03544026]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0634 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1204, add (DA)= 0.0001decode = 0.1233 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1869 s, inc stats = 0.2004, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95377645 2.84046469 3.42640554 3.05495551 2.43305632]
u_DA:    [3.84866675 2.05032663 2.64586122 1.89894505 2.1888802 ]
ref_MAE: [0.11332205 0.67868429 0.88747075 1.20240206 0.05642261]
da_MAE:  [0.1051097  0.79013805 0.78054432 1.15601046 0.24417612]
% 19.77922912294831 da_MAE 0.006027230557747374 ref_MAE 0.007513304212676857
u_c taken from control states: [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
u_c before reduction of space:  [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
data[u_c] post encoding of state:  [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
J_b = 0.0, J_o = 1990.09151708399
J_b = 0.5000000000000001, J_o = 441820.5434117925
J_b = 0.0016951820778770665, J_o = 302.36045370362115
J_b = 0.0017538786356044442, J_o = 271.3071733062713
J_b = 0.00200507919146249, J_o = 234.76308302692118
J_b = 0.0025034091478333756, J_o = 202.44650964503649
J_b = 0.006005848106296928, J_o = 120.08692313649686
J_b = 0.01184210843021534, J_o = 60.83420988472515
J_b = 0.014118783288390975, J_o = 48.77344733606415
J_b = 0.014449209875925132, J_o = 46.20564942635269
J_b = 0.01479137280251173, J_o = 43.057825216102486
J_b = 0.015884602422658264, J_o = 37.4499157295288
J_b = 0.018203084575662894, J_o = 30.999454034847147
J_b = 0.019800154845790775, J_o = 27.98744838059553
J_b = 0.020333028996600687, J_o = 26.98850418646935
J_b = 0.02059173162884685, J_o = 26.226981770199163
J_b = 0.021344260725495653, J_o = 24.38247053220962
J_b = 0.02342493188689837, J_o = 21.294383564430518
J_b = 0.027785513589492536, J_o = 17.52760339946535
J_b = 0.032918562828479346, J_o = 26.546871782847248
J_b = 0.028558059863365362, J_o = 17.169841571443072
J_b = 0.03071169842051823, J_o = 15.838063281118217
J_b = 0.030591014166170404, J_o = 15.630219452403086
J_b = 0.03034655948557698, J_o = 15.525367604205664
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
W_opt:  [ 0.00087399 -0.00186613 -0.00317417 -0.00337115 -0.00430399 -0.0067736
 -0.01068376 -0.0163997  -0.024348   -0.03523896]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0905 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1348, add (DA)= 0.0001decode = 0.1380 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2286 s, inc stats = 0.2519, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95347048 2.83729307 3.42569139 3.05255973 2.43470276]
u_DA:    [3.84910846 2.05140001 2.64550988 1.89897412 2.19009731]
ref_MAE: [0.11301608 0.67551267 0.8867566  1.20000628 0.05806905]
da_MAE:  [0.10436202 0.78589306 0.78018151 1.15358561 0.24460546]
% 19.778935095447597 da_MAE 0.006027503042416069 ref_MAE 0.007513616342026418
u_c taken from control states: [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
u_c before reduction of space:  [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
data[u_c] post encoding of state:  [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
J_b = 0.0, J_o = 2012.296972895391
J_b = 0.5000000000000001, J_o = 444997.1174453359
J_b = 0.0017081070760070164, J_o = 298.6419992261266
J_b = 0.001748702875295513, J_o = 276.15982148336093
J_b = 0.0020342787269586656, J_o = 235.0066124918141
J_b = 0.002817673883025689, J_o = 192.38209731921324
J_b = 0.007318307530354845, J_o = 104.54757262748936
J_b = 0.013446898298948646, J_o = 48.57023634248269
J_b = 0.014461479346505357, J_o = 45.39458781043198
J_b = 0.015137848702416681, J_o = 42.87893368836238
J_b = 0.016588529326457734, J_o = 37.79263567665205
J_b = 0.01858064553402192, J_o = 32.18830267442681
J_b = 0.02006881262705694, J_o = 28.153840346253247
J_b = 0.020857037527756205, J_o = 26.082402751941522
J_b = 0.021273662826408687, J_o = 24.81367484642216
J_b = 0.022829464603870416, J_o = 21.97333461535819
J_b = 0.026052247975979256, J_o = 18.749673479672957
J_b = 0.03559067743769748, J_o = 47.28939775446841
J_b = 0.02689014833345959, J_o = 18.379205282755198
J_b = 0.02957613365342165, J_o = 16.747857541587877
J_b = 0.0301251682238652, J_o = 16.358317017206836
J_b = 0.030269484209574468, J_o = 16.19000371552698
J_b = 0.03066346377730287, J_o = 15.930044298745031
J_b = 0.032044938351317956, J_o = 15.251721536257794
J_b = 0.0370965101316993, J_o = 14.643422885239374
J_b = 0.03568623635132614, J_o = 13.614312425759971
J_b = 0.035372707699264525, J_o = 12.93060823405657
J_b = 0.03575870771072595, J_o = 12.255909369383184
J_b = 0.03865054730952636, J_o = 11.000862606675872
J_b = 0.04413584824450082, J_o = 10.139265887343472
J_b = 0.04519105290567102, J_o = 18.862623112455672
J_b = 0.04424441119266267, J_o = 9.845240851733513
J_b = 0.0445694602852201, J_o = 9.191151854907222
J_b = 0.046491582088261464, J_o = 9.032355530755504
J_b = 0.048719159567325684, J_o = 8.670630344328966
J_b = 0.04966764139325812, J_o = 8.60331092499911
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
W_opt:  [-0.00803725 -0.00137443 -0.00027832  0.00075865 -0.00012605 -0.00387964
 -0.01026138 -0.02024023 -0.03537836 -0.05754519]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0874 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1259 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2135 s, inc stats = 0.2271, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95317354 2.83404184 3.42498917 3.0505911  2.43667811]
u_DA:    [3.84927047 2.05103736 2.64395206 1.89882483 2.19017565]
ref_MAE: [0.11271914 0.67226144 0.88605439 1.19803765 0.0600444 ]
da_MAE:  [0.10390307 0.78300448 0.78103711 1.15176626 0.24650246]
% 19.819557746750228 da_MAE 0.0060235022641802515 ref_MAE 0.007512433325267814
\% improve_point: 16.04, mse_ref_points: 3.467014939660186e-05, mse_da_points: 2.9116043181135283e-05, % improve_overlap: 16.03, mse_ref_overlap: 0.90303, mse_da_overlap: 0.75838
DA - - L2: 116880.63, L1: 9608.72, % Improve: 18.01%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.758, time(s): 1.8308s,
u_c taken from control states: [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
u_c before reduction of space:  [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
data[u_c] post encoding of state:  [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
J_b = 0.0, J_o = 2027.9513857834672
J_b = 0.5000000000000001, J_o = 446625.52496450127
J_b = 0.001716047913845377, J_o = 299.53077335595367
J_b = 0.0017472265877589792, J_o = 281.5509417744108
J_b = 0.00211830770865935, J_o = 232.02192170879383
J_b = 0.0033535513827643738, J_o = 177.54456529716174
J_b = 0.009135313266537413, J_o = 85.80877561923285
J_b = 0.01429680614282168, J_o = 43.900648851259376
J_b = 0.014988390521589932, J_o = 42.134613669705196
J_b = 0.019413694654584174, J_o = 29.15037607293662
J_b = 0.02169706224654787, J_o = 25.674928070592927
J_b = 0.023947917692649087, J_o = 22.675931807440612
J_b = 0.029032924610898507, J_o = 18.279800182496075
J_b = 0.0338548669282059, J_o = 15.414736343435397
J_b = 0.034103928276824506, J_o = 14.40588409626094
J_b = 0.034390300855525406, J_o = 13.620119774890092
J_b = 0.03609444096380834, J_o = 15.64440672543542
J_b = 0.03478059277700882, J_o = 13.277792307285566
J_b = 0.03628237704782567, J_o = 12.344702651840326
J_b = 0.04073557426604773, J_o = 10.886281535523255
J_b = 0.045433408062126424, J_o = 9.982672682309806
J_b = 0.057628264527616276, J_o = 48.44180623273875
J_b = 0.045890394536258115, J_o = 9.89883174349652
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
W_opt:  [-0.00699558 -0.00262579 -0.00172787 -0.00072781 -0.00146771 -0.00479696
 -0.01047674 -0.01939632 -0.03286736 -0.05252563]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0670 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1348, add (DA)= 0.0001decode = 0.1378 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2049 s, inc stats = 0.2187, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95288051 2.83074972 3.42428479 3.04890962 2.43870025]
u_DA:    [3.84936565 2.05040487 2.64247207 1.89923944 2.18991894]
ref_MAE: [0.11242611 0.66896932 0.88535    1.19635617 0.06206654]
da_MAE:  [0.10351486 0.78034485 0.78181272 1.14967018 0.24878131]
% 19.877648125162764 da_MAE 0.006017293987849757 ref_MAE 0.007510131501443748
u_c taken from control states: [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
u_c before reduction of space:  [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
data[u_c] post encoding of state:  [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
J_b = 0.0, J_o = 2036.5522072709314
J_b = 0.4999999999999998, J_o = 447377.93670705927
J_b = 0.0017183699430940442, J_o = 302.741642266055
J_b = 0.001745372196828384, J_o = 286.74247179467415
J_b = 0.002232187185475593, J_o = 227.7347028411755
J_b = 0.003985735618140461, J_o = 163.08523562073546
J_b = 0.01083391687823584, J_o = 71.32680419509907
J_b = 0.014099781995446113, J_o = 48.58570087587979
J_b = 0.01495193774552048, J_o = 45.356738581212014
J_b = 0.01577901724130941, J_o = 41.97659870457167
J_b = 0.017613903423699187, J_o = 36.080631604048335
J_b = 0.0203094373118097, J_o = 28.987059777953277
J_b = 0.02225068571278353, J_o = 25.38724598537151
J_b = 0.0230146635626882, J_o = 23.888246810213126
J_b = 0.02535999012491496, J_o = 20.865129524952337
J_b = 0.02925070192905933, J_o = 17.681858540858894
J_b = 0.03602309683733785, J_o = 19.79124465697059
J_b = 0.03149437496675399, J_o = 16.761548942559813
J_b = 0.032522651450054355, J_o = 15.959025491116307
J_b = 0.03256500950784957, J_o = 15.725992321245235
J_b = 0.03294105516744098, J_o = 15.339365794582562
J_b = 0.03413189549761742, J_o = 14.751496247823876
J_b = 0.03703642165281377, J_o = 18.91299712007124
J_b = 0.03459945277984459, J_o = 14.27773506634647
J_b = 0.03635055243888912, J_o = 13.424589701413062
J_b = 0.03896401414740302, J_o = 11.739127442771089
J_b = 0.05450141539517325, J_o = 10.936352483089324
J_b = 0.05042230714598005, J_o = 10.142740380825686
J_b = 0.04880826752142057, J_o = 9.236411915353717
J_b = 0.04904181003185365, J_o = 9.139775327174378
J_b = 0.05038727086746407, J_o = 9.01852787770796
J_b = 0.05171198307640943, J_o = 9.824539050273023
J_b = 0.050647971109611424, J_o = 8.957005385119935
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
W_opt:  [-0.0088515  -0.00295802 -0.00150473 -0.00021038 -0.00081979 -0.00428259
 -0.01034268 -0.01994436 -0.03458704 -0.05623204]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1166 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1343, add (DA)= 0.0001decode = 0.1375 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2541 s, inc stats = 0.2678, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95258008 2.82745615 3.42355969 3.04730262 2.44038488]
u_DA:    [3.84931688 2.05112187 2.64258684 1.89923105 2.1904063 ]
ref_MAE: [0.11212568 0.66567576 0.88462491 1.19474917 0.06375117]
da_MAE:  [0.1032632  0.77633428 0.78097285 1.14807157 0.24997859]
% 19.86897394224018 da_MAE 0.006015414745029396 ref_MAE 0.0075069733172933315
u_c taken from control states: [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
u_c before reduction of space:  [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
data[u_c] post encoding of state:  [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
J_b = 0.0, J_o = 2031.4035685434033
J_b = 0.5, J_o = 447179.20016977
J_b = 0.0017128526431606373, J_o = 304.2797049323027
J_b = 0.0017414208835921283, J_o = 287.5083145925307
J_b = 0.002186061915753192, J_o = 231.57739959832696
J_b = 0.0037526101700898077, J_o = 169.97559165904474
J_b = 0.010285129196103941, J_o = 76.97414188384406
J_b = 0.014202166073827318, J_o = 47.05942346604159
J_b = 0.015091014167764406, J_o = 44.351146584519
J_b = 0.016326783271408508, J_o = 40.47726322527569
J_b = 0.018376700890146834, J_o = 34.97095700766779
J_b = 0.021060201963469805, J_o = 27.578181165818908
J_b = 0.02431670491096448, J_o = 22.578188565958037
J_b = 0.025855706349936235, J_o = 20.821294318082096
J_b = 0.029722950887351614, J_o = 17.757774484281722
J_b = 0.03273609551860751, J_o = 16.649837801214815
J_b = 0.035142972198678915, J_o = 16.717162078627897
J_b = 0.03387123577348576, J_o = 16.17903355532154
J_b = 0.03360942274773481, J_o = 15.935361929297784
J_b = 0.03353046020940524, J_o = 15.338563410353682
J_b = 0.0346527226701955, J_o = 14.421900006907338
J_b = 0.03644275069622947, J_o = 13.649678255589508
J_b = 0.03825993660695112, J_o = 12.398829998307598
J_b = 0.04064495874946625, J_o = 11.55592489969882
J_b = 0.043898598082354946, J_o = 10.270829287134994
J_b = 0.05360502288055381, J_o = 9.829292026708876
J_b = 0.05072529596625103, J_o = 9.426029727641833
J_b = 0.05024504316711603, J_o = 9.348591491041617
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
W_opt:  [-8.71923889e-03 -3.20623281e-03 -1.44746150e-03 -5.24340255e-05
 -5.78182067e-04 -3.92548139e-03 -9.83317261e-03 -1.92171978e-02
 -3.35477754e-02 -5.49310029e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0709 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1224, add (DA)= 0.0001decode = 0.1253 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1962 s, inc stats = 0.2097, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95226516 2.82420282 3.42280081 3.04558442 2.44160603]
u_DA:    [3.84935376 2.05109209 2.64264315 1.89929098 2.19040829]
ref_MAE: [0.11181076 0.66242242 0.88386603 1.19303096 0.06497232]
da_MAE:  [0.10291141 0.77311073 0.78015767 1.14629344 0.25119773]
% 19.884005515330713 da_MAE 0.006011482262746578 ref_MAE 0.00750347330943625
u_c taken from control states: [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
u_c before reduction of space:  [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
data[u_c] post encoding of state:  [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
J_b = 0.0, J_o = 2005.6139975288036
J_b = 0.49999999999999983, J_o = 445177.9059832769
J_b = 0.0016977723469191412, J_o = 302.2896146309488
J_b = 0.0017382274290368516, J_o = 279.83821478668966
J_b = 0.0020310591994028783, J_o = 237.76032601297203
J_b = 0.00284533915313349, J_o = 193.95036456995072
J_b = 0.007459906403844524, J_o = 104.8736399872189
J_b = 0.013630404013180813, J_o = 49.002550678013996
J_b = 0.014558627837263527, J_o = 46.22554480097509
J_b = 0.015363918356862542, J_o = 43.43226983654196
J_b = 0.01693675663361527, J_o = 38.268069145145354
J_b = 0.0189587720016778, J_o = 32.674315659978845
J_b = 0.020131548131038284, J_o = 29.437515307516648
J_b = 0.020496546054461294, J_o = 28.001575265878024
J_b = 0.020701695295298052, J_o = 26.94445748968956
J_b = 0.021690146522573808, J_o = 24.533388850937705
J_b = 0.024456705150034907, J_o = 21.148537482470935
J_b = 0.044129900599912605, J_o = 224.38036309886525
J_b = 0.024890443192144368, J_o = 20.975949054196647
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
W_opt:  [ 0.00011713 -0.00316683 -0.00424126 -0.00424126 -0.00478138 -0.00647303
 -0.0092304  -0.01334441 -0.01918854 -0.02770242]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0985 s, v_trunc (Latent to Reduced) = 0.0038, dec (Reduced to Full) = 0.1049, add (DA)= 0.0001decode = 0.1106 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2092 s, inc stats = 0.2158, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95193239 2.82102874 3.42200182 3.04362282 2.44248364]
u_DA:    [3.84927423 2.05153875 2.64611929 1.89800958 2.19080515]
ref_MAE: [0.11147799 0.65924834 0.88306704 1.19106937 0.06584993]
da_MAE:  [0.10265816 0.76948998 0.77588253 1.14561324 0.25167849]
% 19.84602934606401 da_MAE 0.006011957880767663 ref_MAE 0.007500511617477111
u_c taken from control states: [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
u_c before reduction of space:  [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
data[u_c] post encoding of state:  [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
J_b = 0.0, J_o = 1978.9861823732078
J_b = 0.5, J_o = 440646.99762100517
J_b = 0.0016863047199435276, J_o = 305.10907565836385
J_b = 0.0017518295122215847, J_o = 270.8701603956587
J_b = 0.002001252449708949, J_o = 234.9284069525804
J_b = 0.002447060623564965, J_o = 204.9448020583074
J_b = 0.005746922246144412, J_o = 124.07368888988444
J_b = 0.01143201320218683, J_o = 64.94071402252891
J_b = 0.014006608555573032, J_o = 50.39702582107849
J_b = 0.014404176929194537, J_o = 47.4699119099084
J_b = 0.01471009917219158, J_o = 44.52246404380226
J_b = 0.015740110119155118, J_o = 39.00863627638258
J_b = 0.01796870831661473, J_o = 32.67107546490402
J_b = 0.019606042441236576, J_o = 29.550705202446736
J_b = 0.02020987959755782, J_o = 28.488311985455013
J_b = 0.020503395898001053, J_o = 27.70955631132321
J_b = 0.021338682583346973, J_o = 25.803741825687858
J_b = 0.023530267467225603, J_o = 22.701101972965496
J_b = 0.028128065865397855, J_o = 19.02135440443856
J_b = 0.03674454690160533, J_o = 33.225643479034034
J_b = 0.029397371586316452, J_o = 18.42613380643553
J_b = 0.030997777469014248, J_o = 17.335962934492677
J_b = 0.030817539961410026, J_o = 17.14252423818372
J_b = 0.03060376135371665, J_o = 17.038192576653188
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
W_opt:  [-2.45598655e-05 -3.39827628e-03 -3.91962292e-03 -3.62416335e-03
 -4.25558418e-03 -6.50801073e-03 -1.02382744e-02 -1.57823841e-02
 -2.35548497e-02 -3.46720078e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1034 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1283, add (DA)= 0.0001decode = 0.1314 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2349 s, inc stats = 0.2475, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95157343 2.81802471 3.42115443 3.04130215 2.44305344]
u_DA:    [3.84901704 2.05127823 2.64550481 1.89847584 2.19009245]
ref_MAE: [0.11111903 0.65624432 0.88221965 1.1887487  0.06641973]
da_MAE:  [0.10255639 0.76674648 0.77564962 1.14282631 0.25296099]
% 19.835011045745144 da_MAE 0.006011574644673 ref_MAE 0.007499002648280074
u_c taken from control states: [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
u_c before reduction of space:  [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
data[u_c] post encoding of state:  [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
J_b = 0.0, J_o = 1975.9913890247735
J_b = 0.5000000000000001, J_o = 434630.69596247637
J_b = 0.001696276200756891, J_o = 314.65307210433315
J_b = 0.0017936252428481115, J_o = 265.91789442922965
J_b = 0.0020540460083790387, J_o = 230.66085886747612
J_b = 0.0023678941638573406, J_o = 207.4826904880308
J_b = 0.005186781077713771, J_o = 130.47607692339605
J_b = 0.010375194447250897, J_o = 73.15418643991671
J_b = 0.013863022592276942, J_o = 50.57236798108734
J_b = 0.014694116351113673, J_o = 46.050256086711634
J_b = 0.015081175530830262, J_o = 43.16176744566629
J_b = 0.016264448855509452, J_o = 37.5791920444112
J_b = 0.018625752107824228, J_o = 31.513853046091924
J_b = 0.019968117298830995, J_o = 28.96803395600696
J_b = 0.020558377141566102, J_o = 27.889512779958533
J_b = 0.02098107647790589, J_o = 26.93538468227022
J_b = 0.022272843559538274, J_o = 24.55064215023029
J_b = 0.02512931703100914, J_o = 21.188036863309577
J_b = 0.040869363098989975, J_o = 245.10097888215694
J_b = 0.02541628850250339, J_o = 21.06219622386729
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
W_opt:  [ 0.00294077 -0.0018422  -0.0037197  -0.00413022 -0.00493991 -0.00689357
 -0.00989475 -0.01418467 -0.02016537 -0.02888162]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0511 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1338, add (DA)= 0.0001decode = 0.1369 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1882 s, inc stats = 0.2002, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95118557 2.81525519 3.42025215 3.03859826 2.44359222]
u_DA:    [3.84847295 2.05020593 2.6462177  1.89779419 2.18784961]
ref_MAE: [0.11073117 0.6534748  0.88131737 1.18604481 0.06695851]
da_MAE:  [0.10271262 0.76504926 0.77403445 1.14080407 0.25574261]
% 19.866114295417532 da_MAE 0.00600939230226627 ref_MAE 0.0074991899487068326
u_c taken from control states: [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
u_c before reduction of space:  [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
data[u_c] post encoding of state:  [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
J_b = 0.0, J_o = 1993.5111745800205
J_b = 0.5000000000000001, J_o = 425034.9072910792
J_b = 0.00173673241616039, J_o = 327.7404012243264
J_b = 0.0018846305154153573, J_o = 257.204209507958
J_b = 0.0021774110722164947, J_o = 221.342496844969
J_b = 0.0024053230877827403, J_o = 203.64521286183162
J_b = 0.004942493284049629, J_o = 130.0760801721971
J_b = 0.009606372687647852, J_o = 77.25481325919728
J_b = 0.013778910644420026, J_o = 49.350081748791965
J_b = 0.014983947279001274, J_o = 43.844153914554155
J_b = 0.01549948368159727, J_o = 40.90327640664701
J_b = 0.016811197120437996, J_o = 35.62113792442873
J_b = 0.01919773286021271, J_o = 30.082112699056808
J_b = 0.020388057842271406, J_o = 27.622206664024453
J_b = 0.021305365164069615, J_o = 25.984735538071334
J_b = 0.02206363752644531, J_o = 24.620205290738003
J_b = 0.024440663446989884, J_o = 21.350128211344035
J_b = 0.028533357820244774, J_o = 22.43744048755716
J_b = 0.025976055441848927, J_o = 20.33849236174115
J_b = 0.02911587691934788, J_o = 17.888783308206488
J_b = 0.030088272981777776, J_o = 17.11794249601059
J_b = 0.02993730298303582, J_o = 16.9990463876306
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
W_opt:  [ 0.00402618 -0.00192179 -0.00357212 -0.00378187 -0.00462138 -0.00697115
 -0.01071682 -0.01609268 -0.02348899 -0.03394637]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0677 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1212, add (DA)= 0.0001decode = 0.1240 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1918 s, inc stats = 0.2058, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95077111 2.81273131 3.41929737 3.03554934 2.44458092]
u_DA:    [3.84799099 2.04926963 2.64386088 1.89854011 2.185652  ]
ref_MAE: [0.11031671 0.65095091 0.88036258 1.18299589 0.06794721]
da_MAE:  [0.10278012 0.76346167 0.77543649 1.13700924 0.25892893]
% 19.872519390638185 da_MAE 0.006010691834309609 ref_MAE 0.007501411236942523
u_c taken from control states: [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
u_c before reduction of space:  [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
data[u_c] post encoding of state:  [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
J_b = 0.0, J_o = 2039.2349588666739
J_b = 0.4999999999999998, J_o = 409483.12828811933
J_b = 0.001821112059569652, J_o = 351.51945824255307
J_b = 0.0020542452007979665, J_o = 247.41566625579088
J_b = 0.0023990912599803097, J_o = 210.50726837052412
J_b = 0.00257232947804961, J_o = 196.91583305651307
J_b = 0.004943487815790517, J_o = 126.77953266461415
J_b = 0.009101750629248746, J_o = 79.70367715966177
J_b = 0.013769666570716583, J_o = 49.791468767461865
J_b = 0.015004528374637182, J_o = 43.970453837060326
J_b = 0.01569525586501469, J_o = 40.456562202504514
J_b = 0.016863926243133754, J_o = 35.99386711776332
J_b = 0.018878136046698444, J_o = 30.953575861625445
J_b = 0.020295665698913605, J_o = 28.316302864537626
J_b = 0.02132826328720029, J_o = 26.63129882421515
J_b = 0.02226475140361211, J_o = 25.01781140798937
J_b = 0.024492060652374043, J_o = 21.790462124980408
J_b = 0.027953435998333772, J_o = 19.402951194076486
J_b = 0.03191960162691317, J_o = 17.393194598404964
J_b = 0.030208848984676285, J_o = 16.627007911949946
J_b = 0.02991879575099646, J_o = 16.479512025757334
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
W_opt:  [ 0.00634264 -0.00098404 -0.00334159 -0.00380409 -0.00471365 -0.007072
 -0.01081722 -0.01613133 -0.0233435  -0.03327389]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0534 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1299, add (DA)= 0.0001decode = 0.1328 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1863 s, inc stats = 0.2071, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95032256 2.81042572 3.41828653 3.03219616 2.44637526]
u_DA:    [3.84725979 2.04814885 2.64049264 1.89688472 2.1822205 ]
ref_MAE: [0.10986816 0.64864532 0.87935174 1.17964271 0.06974155]
da_MAE:  [0.10306277 0.76227686 0.77779388 1.13531144 0.26415476]
% 19.885147846545866 da_MAE 0.0060133711758553945 ref_MAE 0.007505938055452218
u_c taken from control states: [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
u_c before reduction of space:  [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
data[u_c] post encoding of state:  [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
J_b = 0.0, J_o = 2107.2544981104825
J_b = 0.49999999999999994, J_o = 393906.2582969168
J_b = 0.0019266956422773396, J_o = 383.4880319349577
J_b = 0.0022511546931909703, J_o = 247.43091304957235
J_b = 0.002638481207241595, J_o = 210.23535260110953
J_b = 0.0027980693287362026, J_o = 197.93343343215207
J_b = 0.005097077816380184, J_o = 129.0300824199595
J_b = 0.009045045264872705, J_o = 83.58914453775711
J_b = 0.014086197363445404, J_o = 52.12133144951159
J_b = 0.015217560909625477, J_o = 45.90475178300235
J_b = 0.016028542025729536, J_o = 41.5966504613177
J_b = 0.017050198041125206, J_o = 37.71398942489529
J_b = 0.019166584933179125, J_o = 32.57273291057694
J_b = 0.02084620022800211, J_o = 29.529853910365944
J_b = 0.022150090396493065, J_o = 27.527637317929674
J_b = 0.023231181624323822, J_o = 25.727275679743475
J_b = 0.0257013117631026, J_o = 22.17416474872033
J_b = 0.029349975368373207, J_o = 19.857798326972613
J_b = 0.033018821204602325, J_o = 17.247145748520282
J_b = 0.03161517131562293, J_o = 16.582549342189807
J_b = 0.03135717434827622, J_o = 16.399810109592824
J_b = 0.03140796692311638, J_o = 16.297327690828418
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
W_opt:  [ 8.23407453e-03 -5.14333747e-06 -3.02004671e-03 -3.63454229e-03
 -4.59055659e-03 -6.98687834e-03 -1.08040870e-02 -1.62275060e-02
 -2.35316339e-02 -3.34063992e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0638 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1197, add (DA)= 0.0001decode = 0.1227 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1866 s, inc stats = 0.2007, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94983413 2.80829687 3.41722299 3.02859144 2.4491964 ]
u_DA:    [3.8468181  2.04667771 2.6380806  1.89396898 2.18049735]
ref_MAE: [0.10937972 0.64651647 0.87828821 1.17603799 0.07256269]
da_MAE:  [0.10301603 0.76161917 0.77914238 1.13462246 0.26869905]
% 19.870101278708113 da_MAE 0.006019629477694377 ref_MAE 0.007512338807056122
u_c taken from control states: [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
u_c before reduction of space:  [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
data[u_c] post encoding of state:  [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
J_b = 0.0, J_o = 2158.644307111787
J_b = 0.49999999999999983, J_o = 386008.7012991448
J_b = 0.0019930232562555567, J_o = 407.47584245422604
J_b = 0.0023672622938956654, J_o = 255.43880466406424
J_b = 0.0027738593446505716, J_o = 218.06303881516646
J_b = 0.002940600988760119, J_o = 205.37696635898257
J_b = 0.005249440264726586, J_o = 135.10259182259668
J_b = 0.009265421027571654, J_o = 87.77934788466759
J_b = 0.014617663372490411, J_o = 54.302629259615465
J_b = 0.015664378503458618, J_o = 47.82669259762814
J_b = 0.01647268612286936, J_o = 43.14892670034213
J_b = 0.017418198472256653, J_o = 39.478667757221054
J_b = 0.019673352991203975, J_o = 34.05198631458957
J_b = 0.021540639845678528, J_o = 30.71072337639038
J_b = 0.023104729220267895, J_o = 28.414517330154034
J_b = 0.024307264299649713, J_o = 26.484902956783422
J_b = 0.02699302328504569, J_o = 22.701110595614523
J_b = 0.030731603276426333, J_o = 20.76483380385671
J_b = 0.03378291343419514, J_o = 17.667001709896535
J_b = 0.032698589499975186, J_o = 17.071684379033062
J_b = 0.03247402880559841, J_o = 16.86238887086341
J_b = 0.03250761375703062, J_o = 16.72198701489636
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
W_opt:  [ 0.00908271  0.00031304 -0.00301004 -0.00365021 -0.00461444 -0.00701511
 -0.0108432  -0.01630684 -0.0236468  -0.03351248]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1161 s, v_trunc (Latent to Reduced) = 0.0039, dec (Reduced to Full) = 0.1185, add (DA)= 0.0001decode = 0.1242 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2405 s, inc stats = 0.2496, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94930238 2.80626043 3.41611379 3.02479853 2.45284428]
u_DA:    [3.84675544 2.04637826 2.63701499 1.89251698 2.18050707]
ref_MAE: [0.10884798 0.64448003 0.87717901 1.17224508 0.07621056]
da_MAE:  [0.10254694 0.75988217 0.7790988  1.13228155 0.2723372 ]
% 19.84224376136557 da_MAE 0.006028106280010713 ref_MAE 0.007520303165753143
\% improve_point: 16.48, mse_ref_points: 3.462635133254889e-05, mse_da_points: 2.892488084049864e-05, % improve_overlap: 16.48, mse_ref_overlap: 0.90190, mse_da_overlap: 0.75341
DA - - L2: 90520.66, L1: 8880.72, % Improve: 18.46%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.753, time(s): 1.4395s,
u_c taken from control states: [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
u_c before reduction of space:  [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
data[u_c] post encoding of state:  [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
J_b = 0.0, J_o = 2180.920600776199
J_b = 0.5, J_o = 386630.45987485413
J_b = 0.0020051269359286587, J_o = 415.59222587546503
J_b = 0.002377708352284219, J_o = 263.6124647695491
J_b = 0.0027895721729598393, J_o = 225.3202571938831
J_b = 0.0029641240370827013, J_o = 212.01090660559657
J_b = 0.005345350736110657, J_o = 139.4110717604185
J_b = 0.009520685949795302, J_o = 90.11728954362101
J_b = 0.015017350813208378, J_o = 55.55130774321967
J_b = 0.01608650640935594, J_o = 48.994017543157256
J_b = 0.01689775705900603, J_o = 44.274130878433496
J_b = 0.01785967638576573, J_o = 40.49831062067305
J_b = 0.020123511177130213, J_o = 35.01035679771918
J_b = 0.022008376209371742, J_o = 31.603702444926682
J_b = 0.023597040225134015, J_o = 29.26059656188866
J_b = 0.02478037306634543, J_o = 27.342123351779897
J_b = 0.027454136279503986, J_o = 23.522161085480935
J_b = 0.03120286616385171, J_o = 21.13008095547389
J_b = 0.034929950730905775, J_o = 18.360881296200056
J_b = 0.03340999155743724, J_o = 17.67263690494655
J_b = 0.03311152725182362, J_o = 17.46086028344793
J_b = 0.0331617386918471, J_o = 17.321215669174613
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
W_opt:  [ 0.00920012  0.00017168 -0.00307852 -0.00364208 -0.00459389 -0.00699974
 -0.01084144 -0.01633595 -0.02371236 -0.03361029]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0531 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1402, add (DA)= 0.0001decode = 0.1432 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1965 s, inc stats = 0.2098, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94871461 2.80424376 3.41496207 3.02085712 2.45680241]
u_DA:    [3.84678763 2.04630365 2.63704755 1.89274692 2.1798409 ]
ref_MAE: [0.1082602  0.64246336 0.87602729 1.16830367 0.08016869]
da_MAE:  [0.10192698 0.75794011 0.77791452 1.1281102  0.2769615 ]
% 19.84927164100985 da_MAE 0.006035054062286252 ref_MAE 0.007529630966365794
u_c taken from control states: [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
u_c before reduction of space:  [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
data[u_c] post encoding of state:  [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
J_b = 0.0, J_o = 2181.8155872449843
J_b = 0.49999999999999994, J_o = 392231.58556244476
J_b = 0.0019853770762155195, J_o = 409.6819469554324
J_b = 0.002325226308430996, J_o = 267.61302666440685
J_b = 0.002731013754567422, J_o = 228.43378025331717
J_b = 0.0029079804734765693, J_o = 214.80335690805276
J_b = 0.005361849254844835, J_o = 140.69113205273493
J_b = 0.009667615854231999, J_o = 90.59987113603732
J_b = 0.015203849170453148, J_o = 55.85934205365703
J_b = 0.016379123463556595, J_o = 49.1976467606444
J_b = 0.01722612691398635, J_o = 44.55426462081803
J_b = 0.018264746422353952, J_o = 40.545947438748165
J_b = 0.020496862624033142, J_o = 35.12112867341255
J_b = 0.022285575275627075, J_o = 31.889272850865694
J_b = 0.023685097416251678, J_o = 29.764384673436766
J_b = 0.024793757977008574, J_o = 27.911299078608547
J_b = 0.027342450210518995, J_o = 24.17467307464606
J_b = 0.031122354722348245, J_o = 21.087806784056117
J_b = 0.03649035611356052, J_o = 19.37771651376924
J_b = 0.033794127501244164, J_o = 18.000841891587083
J_b = 0.033378114438412966, J_o = 17.810336828351726
J_b = 0.03343662756553307, J_o = 17.694826363033265
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
W_opt:  [ 8.96372056e-03 -8.55786463e-05 -3.07002907e-03 -3.55872756e-03
 -4.52045965e-03 -6.96354013e-03 -1.08576875e-02 -1.64220334e-02
 -2.38856645e-02 -3.38493740e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0559 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1201, add (DA)= 0.0001decode = 0.1230 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1791 s, inc stats = 0.1838, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94805628 2.80220795 3.41376748 3.01678332 2.460672  ]
u_DA:    [3.84688185 2.04634749 2.63768964 1.89397774 2.17911907]
ref_MAE: [0.10760188 0.64042755 0.87483269 1.16422987 0.08403829]
da_MAE:  [0.10117443 0.75586046 0.77607784 1.12280559 0.28155293]
% 19.864580001744766 da_MAE 0.006041979151702546 ref_MAE 0.007539711093838525
u_c taken from control states: [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
u_c before reduction of space:  [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
data[u_c] post encoding of state:  [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
J_b = 0.0, J_o = 2173.067169820868
J_b = 0.4999999999999999, J_o = 399521.00106051366
J_b = 0.0019556358367851805, J_o = 396.744814420407
J_b = 0.0022522338854060664, J_o = 268.89570896112446
J_b = 0.0026422600324114876, J_o = 229.4497164893609
J_b = 0.002820456337721227, J_o = 215.57968029084327
J_b = 0.005322578480747833, J_o = 140.87776339745895
J_b = 0.00973770840865432, J_o = 90.37215396434763
J_b = 0.015308890647970743, J_o = 55.610269063665356
J_b = 0.01660594901857725, J_o = 48.80213335236505
J_b = 0.017489275411413412, J_o = 44.25578784053698
J_b = 0.018607436076323407, J_o = 40.05865802126914
J_b = 0.020811735090003298, J_o = 34.70961819717124
J_b = 0.022494454446413556, J_o = 31.700998288549727
J_b = 0.023698629465083956, J_o = 29.816313833460903
J_b = 0.02478142080344831, J_o = 27.97547733888303
J_b = 0.027264253634100816, J_o = 24.315281156471453
J_b = 0.031127138191618473, J_o = 20.9797560758242
J_b = 0.03741674021040154, J_o = 20.141794426693703
J_b = 0.03398521979574311, J_o = 18.023391339276568
J_b = 0.033544638371637535, J_o = 17.840162647826535
J_b = 0.033581377698023676, J_o = 17.733690532183996
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
W_opt:  [ 0.00856227 -0.00020115 -0.00288161 -0.00335801 -0.00437469 -0.00690069
 -0.01089105 -0.01657099 -0.02417516 -0.03425467]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0575 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1290, add (DA)= 0.0001decode = 0.1319 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1896 s, inc stats = 0.2034, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94733038 2.80007076 3.41253993 3.01265139 2.46425221]
u_DA:    [3.84707709 2.04677796 2.63854852 1.89571301 2.17904811]
ref_MAE: [0.10687598 0.63829036 0.87360515 1.16009794 0.0876185 ]
da_MAE:  [0.10025329 0.75329279 0.77399141 1.11693838 0.2852041 ]
% 19.888958098354053 da_MAE 0.006049362694261063 ref_MAE 0.007551222092065655
u_c taken from control states: [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
u_c before reduction of space:  [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
data[u_c] post encoding of state:  [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
J_b = 0.0, J_o = 2162.5943527517297
J_b = 0.49999999999999983, J_o = 406516.11324321217
J_b = 0.001927845730742029, J_o = 382.4557045117915
J_b = 0.0021830694176811862, J_o = 269.21864798986985
J_b = 0.002552258879844281, J_o = 230.12297854801324
J_b = 0.002733944939276607, J_o = 215.87741665243837
J_b = 0.005262294564193287, J_o = 141.06652506040825
J_b = 0.00978576739077274, J_o = 89.91775908959025
J_b = 0.015391740138369667, J_o = 55.01240410640803
J_b = 0.016789537413072986, J_o = 48.10663307470438
J_b = 0.01768371840192713, J_o = 43.702216421570185
J_b = 0.01885848767820058, J_o = 39.38079567602223
J_b = 0.02102210223978756, J_o = 34.125324890489104
J_b = 0.02261977084553806, J_o = 31.29052937892935
J_b = 0.023703780638259547, J_o = 29.55650911525412
J_b = 0.02480428395489131, J_o = 27.686229398240272
J_b = 0.02729051759407887, J_o = 24.066625981020977
J_b = 0.0312178502574862, J_o = 20.752954883212674
J_b = 0.037478472894194835, J_o = 19.977251666673887
J_b = 0.03400262377372636, J_o = 17.878782279081246
J_b = 0.0335556880638332, J_o = 17.709639622855168
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
W_opt:  [ 0.00800307 -0.00030074 -0.00269777 -0.00320124 -0.0042825  -0.00688387
 -0.01094785 -0.01670089 -0.02438906 -0.03452458]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0542 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1308, add (DA)= 0.0001decode = 0.1338 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1881 s, inc stats = 0.2019, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94656003 2.79769652 3.41130549 3.00860393 2.46767119]
u_DA:    [3.84738025 2.04732839 2.63973641 1.89748341 2.17951903]
ref_MAE: [0.10610563 0.63591612 0.87237071 1.15605048 0.09103748]
da_MAE:  [0.09917978 0.75036812 0.77156909 1.11112053 0.28815216]
% 19.88799724291476 da_MAE 0.00605845509901205 ref_MAE 0.007562481139539643
u_c taken from control states: [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
u_c before reduction of space:  [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
data[u_c] post encoding of state:  [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
J_b = 0.0, J_o = 2155.0621154789856
J_b = 0.49999999999999994, J_o = 412575.5968028394
J_b = 0.001906426897192906, J_o = 369.6986972775959
J_b = 0.002126091681412255, J_o = 269.76521402935373
J_b = 0.0024737081461416455, J_o = 231.33069644189698
J_b = 0.0026625109037971004, J_o = 216.47662277665182
J_b = 0.0052098360882432025, J_o = 141.58421172757622
J_b = 0.009853880083571246, J_o = 89.38289805076238
J_b = 0.015462451594661966, J_o = 54.29190806180057
J_b = 0.016937304591513946, J_o = 47.376392845091964
J_b = 0.01780736171808558, J_o = 43.194748864571594
J_b = 0.01902881106165911, J_o = 38.73956709148906
J_b = 0.021144240591410804, J_o = 33.57311739377528
J_b = 0.022663263907297962, J_o = 30.874538779370575
J_b = 0.023682475052836806, J_o = 29.21959876565274
J_b = 0.024809097868794695, J_o = 27.32176638385246
J_b = 0.027318910303299814, J_o = 23.73613775285645
J_b = 0.031249269683658643, J_o = 20.528863450180886
J_b = 0.037203291368873535, J_o = 19.668813469283457
J_b = 0.033852567712741505, J_o = 17.76875717124795
J_b = 0.033409792319054214, J_o = 17.61407756621914
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
W_opt:  [ 0.00735764 -0.00026775 -0.00240641 -0.00295105 -0.00408978 -0.00675003
 -0.0108625  -0.01665437 -0.02439513 -0.03460133]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0619 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1320, add (DA)= 0.0001decode = 0.1350 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1970 s, inc stats = 0.2107, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94575895 2.79501179 3.4100744  3.0047426  2.47092416]
u_DA:    [3.84765491 2.04779768 2.6408439  1.89831418 2.18068969]
ref_MAE: [0.10530455 0.63323139 0.87113961 1.15218915 0.09429045]
da_MAE:  [0.09810404 0.74721411 0.76923049 1.10642842 0.29023447]
% 19.87176487593428 da_MAE 0.006068106823311494 ref_MAE 0.00757299448055483
u_c taken from control states: [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
u_c before reduction of space:  [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
data[u_c] post encoding of state:  [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
J_b = 0.0, J_o = 2152.4669232164547
J_b = 0.5, J_o = 418266.26979890256
J_b = 0.001890600749048202, J_o = 358.41550367534796
J_b = 0.002077109774217609, J_o = 271.48942038793155
J_b = 0.0024024133725621534, J_o = 233.84445302788532
J_b = 0.0026043359195379594, J_o = 217.97102965856553
J_b = 0.005181850505369379, J_o = 142.6730562084844
J_b = 0.009987567863433964, J_o = 88.79182189557967
J_b = 0.015531161688136792, J_o = 53.6299121845324
J_b = 0.017078713124447194, J_o = 46.76196544081243
J_b = 0.01788705506157031, J_o = 42.905444729618964
J_b = 0.019180740803322816, J_o = 38.18813652989484
J_b = 0.021283906666182992, J_o = 33.01375311328093
J_b = 0.022725941833294055, J_o = 30.432744457400386
J_b = 0.023734472149843963, J_o = 28.784732605858725
J_b = 0.024930043856381645, J_o = 26.827615429242506
J_b = 0.027537606117716957, J_o = 23.24998760330331
J_b = 0.03143970093410804, J_o = 20.54740659634777
J_b = 0.03594714494544145, J_o = 18.675948479748786
J_b = 0.03359356083873394, J_o = 17.735224643189316
J_b = 0.03320316605143103, J_o = 17.59403018544789
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
W_opt:  [ 0.00663105 -0.00019483 -0.00213845 -0.00274597 -0.00394298 -0.00664682
 -0.01078004 -0.01657223 -0.02431895 -0.03457525]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0519 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1259 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1778 s, inc stats = 0.1906, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94493466 2.7920876  3.40884207 3.00116618 2.47389692]
u_DA:    [3.84792764 2.04805027 2.6422388  1.89924334 2.18200987]
ref_MAE: [0.10448026 0.6303072  0.86990729 1.14861273 0.09726321]
da_MAE:  [0.09700702 0.74403733 0.76660327 1.10192284 0.29188705]
% 19.894171409920112 da_MAE 0.006077939749694338 ref_MAE 0.0075873876553934246
u_c taken from control states: [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
u_c before reduction of space:  [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
data[u_c] post encoding of state:  [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
J_b = 0.0, J_o = 2155.9201079509303
J_b = 0.4999999999999999, J_o = 423647.0778004745
J_b = 0.001880939715176078, J_o = 348.6190714285678
J_b = 0.002036134984920365, J_o = 274.5217844675212
J_b = 0.0023388593737714977, J_o = 237.72828859200754
J_b = 0.0025619013673970075, J_o = 220.31562131199732
J_b = 0.005191750376708609, J_o = 144.26069081653856
J_b = 0.010208488229659477, J_o = 88.1337754939317
J_b = 0.015595706928111033, J_o = 53.31539099719765
J_b = 0.017211028860937488, J_o = 46.459134000851954
J_b = 0.017939019800049475, J_o = 42.92272091088029
J_b = 0.019347142998694188, J_o = 37.76554328740372
J_b = 0.021579038843589773, J_o = 32.321369042613064
J_b = 0.022974244936094276, J_o = 29.77868575295538
J_b = 0.02415664273777724, J_o = 27.895202620924728
J_b = 0.02556087772317133, J_o = 25.78015190425222
J_b = 0.02849894748457323, J_o = 22.10899982276625
J_b = 0.03323650894487504, J_o = 26.296267389537302
J_b = 0.02974234271013827, J_o = 21.259341619062624
J_b = 0.033190877301418176, J_o = 18.534473361936275
J_b = 0.03403423170430988, J_o = 17.72465392637546
J_b = 0.033745835347232876, J_o = 17.590898464191472
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
W_opt:  [ 0.00567826 -0.00031209 -0.00199117 -0.00259515 -0.00383169 -0.00660102
 -0.01082245 -0.01673728 -0.02464938 -0.03515215]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0561 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1254, add (DA)= 0.0001decode = 0.1283 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1845 s, inc stats = 0.1982, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94410183 2.78901632 3.40762096 2.99799387 2.47655864]
u_DA:    [3.84818473 2.04762253 2.64376949 1.89925098 2.18252212]
ref_MAE: [0.10364743 0.62723592 0.86868618 1.14544042 0.09992493]
da_MAE:  [0.0959171  0.74139379 0.76385147 1.09874289 0.29403652]
% 19.952280985301186 da_MAE 0.006086678620270361 ref_MAE 0.007603812694716124
u_c taken from control states: [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
u_c before reduction of space:  [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
data[u_c] post encoding of state:  [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
J_b = 0.0, J_o = 2162.266952742697
J_b = 0.4999999999999999, J_o = 427853.1709821975
J_b = 0.0018774728958189132, J_o = 340.557098223056
J_b = 0.0020080020020858892, J_o = 276.9600834413138
J_b = 0.0022917358766622836, J_o = 240.97747531669887
J_b = 0.0025389912710983694, J_o = 221.91247512059178
J_b = 0.005229005406702237, J_o = 145.26845165806026
J_b = 0.010440975576876121, J_o = 87.22950168717207
J_b = 0.015611013682252522, J_o = 53.44140043559365
J_b = 0.01723761018309448, J_o = 46.58303422548025
J_b = 0.01790692808877875, J_o = 43.19281260560273
J_b = 0.01940808882467623, J_o = 37.62586706577882
J_b = 0.021915433949181187, J_o = 31.80385345725147
J_b = 0.023248045133039064, J_o = 29.185094958839333
J_b = 0.0247540618639795, J_o = 26.81499664666422
J_b = 0.026207278796178905, J_o = 24.733353397836446
J_b = 0.02954320232650136, J_o = 20.89715486725941
J_b = 0.04472598957730868, J_o = 134.90909426459316
J_b = 0.030056772992334654, J_o = 20.700244763200576
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
W_opt:  [ 5.40250275e-03 -3.32855650e-05 -2.34544159e-03 -3.27529350e-03
 -4.52479666e-03 -6.97953939e-03 -1.05883020e-02 -1.55608877e-02
 -2.21900954e-02 -3.10613826e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0480 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1212, add (DA)= 0.0001decode = 0.1241 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1723 s, inc stats = 0.1857, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94328189 2.78588968 3.40643176 2.99535641 2.4789957 ]
u_DA:    [3.84842575 2.04753131 2.64442796 1.89914767 2.18198998]
ref_MAE: [0.10282749 0.62410929 0.86749698 1.14280296 0.10236199]
da_MAE:  [0.09485614 0.73835838 0.7620038  1.09620874 0.29700572]
% 20.005386785533336 da_MAE 0.006093388242464193 ref_MAE 0.007617248209110949
u_c taken from control states: [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
u_c before reduction of space:  [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
data[u_c] post encoding of state:  [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
J_b = 0.0, J_o = 2165.6168817833363
J_b = 0.4999999999999999, J_o = 430578.7631367879
J_b = 0.0018765996310215615, J_o = 333.1697135372704
J_b = 0.0019909197615542384, J_o = 276.6906804931053
J_b = 0.002260501859063913, J_o = 241.52557751182565
J_b = 0.002525389797997947, J_o = 221.35306802001833
J_b = 0.005247810521316735, J_o = 144.93448693247754
J_b = 0.01056170406444028, J_o = 86.14215471409524
J_b = 0.015529468498859686, J_o = 53.67177781676479
J_b = 0.017117208357851223, J_o = 46.88212952944092
J_b = 0.017757165100117118, J_o = 43.51592482328542
J_b = 0.019294443545447605, J_o = 37.728895507910124
J_b = 0.022027631052931207, J_o = 31.723919133170956
J_b = 0.02328301269575, J_o = 28.99407288465369
J_b = 0.024824890099313216, J_o = 26.44505667232277
J_b = 0.026182289163437795, J_o = 24.460627363371227
J_b = 0.029787864845852503, J_o = 20.495987287930117
J_b = 0.04707456008129411, J_o = 143.89583150589473
J_b = 0.030377993035695237, J_o = 20.269374792132023
J_b = 0.03293591114478472, J_o = 18.459184231934678
J_b = 0.03377977310581412, J_o = 17.886259082635895
J_b = 0.0337979141939035, J_o = 17.77337527454581
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
W_opt:  [ 0.00414009 -0.00062888 -0.00208732 -0.00266396 -0.00390311 -0.00668132
 -0.01092367 -0.01688058 -0.02481771 -0.03528008]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0538 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1214, add (DA)= 0.0001decode = 0.1245 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1785 s, inc stats = 0.1918, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94249599 2.78278491 3.40529443 2.99336342 2.48133689]
u_DA:    [3.84873942 2.0479858  2.64500283 1.8982603  2.18369027]
ref_MAE: [0.10204159 0.62100451 0.86635964 1.14080997 0.10470317]
da_MAE:  [0.09375656 0.73479911 0.7602916  1.09510312 0.29764662]
% 19.959206085327903 da_MAE 0.006105376418957009 ref_MAE 0.007627830910155235
u_c taken from control states: [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
u_c before reduction of space:  [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
data[u_c] post encoding of state:  [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
J_b = 0.0, J_o = 2160.9061139965547
J_b = 0.49999999999999994, J_o = 431969.532050718
J_b = 0.0018739020266897333, J_o = 325.31709465973506
J_b = 0.0019798402317460825, J_o = 272.6293657394934
J_b = 0.0022392226877833207, J_o = 238.39339358957744
J_b = 0.002507028369283188, J_o = 218.1216789836455
J_b = 0.005200918848693762, J_o = 143.1013768080502
J_b = 0.010478577105537358, J_o = 84.97086592480285
J_b = 0.015322989158886635, J_o = 53.41529866410209
J_b = 0.016882785428451532, J_o = 46.71367230288454
J_b = 0.017513025124786842, J_o = 43.368966707693524
J_b = 0.0190487242936795, J_o = 37.57157294202794
J_b = 0.02184146078622685, J_o = 31.540046298253607
J_b = 0.023093999879146072, J_o = 28.743692868677545
J_b = 0.024631265163287914, J_o = 26.166340865024917
J_b = 0.025989889970249504, J_o = 24.180573359211994
J_b = 0.029609212036532565, J_o = 20.25014448136308
J_b = 0.047706209585530894, J_o = 143.33313397837122
J_b = 0.0302237665124416, J_o = 20.027369005832828
J_b = 0.032672836983592426, J_o = 18.321578665008214
J_b = 0.03348085831795531, J_o = 17.78719292697882
J_b = 0.03353369644117443, J_o = 17.67337476563029
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
W_opt:  [ 0.00367241 -0.00080532 -0.00222399 -0.00278055 -0.00400468 -0.00678933
 -0.01106222 -0.01706491 -0.02502013 -0.03540681]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0694 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1206, add (DA)= 0.0001decode = 0.1235 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1931 s, inc stats = 0.2209, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94176834 2.77972456 3.4042264  2.99210838 2.48381561]
u_DA:    [3.8488476  2.0480427  2.64503101 1.89809446 2.18416438]
ref_MAE: [0.10131394 0.61794416 0.86529161 1.13955493 0.10718189]
da_MAE:  [0.09292073 0.73168186 0.75919539 1.09401391 0.29965122]
% 19.89782710453682 da_MAE 0.006116122011528544 ref_MAE 0.0076354008767157274
\% improve_point: 16.77, mse_ref_points: 3.47766175949086e-05, mse_da_points: 2.8947902130798533e-05, % improve_overlap: 16.77, mse_ref_overlap: 0.90583, mse_da_overlap: 0.75402
DA - - L2: 74148.56, L1: 8357.75, % Improve: 18.75%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.754, time(s): 1.1973s,
u_c taken from control states: [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
u_c before reduction of space:  [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
data[u_c] post encoding of state:  [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
J_b = 0.0, J_o = 2146.451201060577
J_b = 0.5, J_o = 432248.8391354491
J_b = 0.001867262173369264, J_o = 316.5688753500898
J_b = 0.001971469642072934, J_o = 264.7607013880724
J_b = 0.0022236115811674873, J_o = 231.61320442311597
J_b = 0.0024770798543818913, J_o = 212.36165444561095
J_b = 0.0050705993926610056, J_o = 139.9652446147346
J_b = 0.010168527172108697, J_o = 83.83406294714848
J_b = 0.01501061259850234, J_o = 52.40091192698786
J_b = 0.016584866311104632, J_o = 45.74699624694724
J_b = 0.017222454501312188, J_o = 42.46133334277931
J_b = 0.018725804991373732, J_o = 36.87687406087439
J_b = 0.021390961434301255, J_o = 30.953158209868977
J_b = 0.022748204528325697, J_o = 28.147179795372228
J_b = 0.02441165690964428, J_o = 25.524226574668248
J_b = 0.02591130266428836, J_o = 23.43879476568885
J_b = 0.029431385958688366, J_o = 19.685111602313082
J_b = 0.046787499677930236, J_o = 106.5956257843561
J_b = 0.030201241243828024, J_o = 19.417723321462084
J_b = 0.03231416145419023, J_o = 17.88917387863566
J_b = 0.03294578496654744, J_o = 17.434423547840947
J_b = 0.033005790007330615, J_o = 17.334965994572396
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
W_opt:  [ 0.00339135 -0.00098386 -0.00236915 -0.00291234 -0.00411946 -0.00690904
 -0.01121058 -0.01724477 -0.02518182 -0.03541317]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0558 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1200, add (DA)= 0.0001decode = 0.1228 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1787 s, inc stats = 0.1918, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94111966 2.77670414 3.40322547 2.99163227 2.48666347]
u_DA:    [3.84884907 2.04794874 2.64512702 1.89815564 2.18433527]
ref_MAE: [0.10066526 0.61492374 0.86429069 1.13907882 0.11002975]
da_MAE:  [0.09227059 0.7287554  0.75809845 1.09347662 0.3023282 ]
% 19.820337966022674 da_MAE 0.006126655868324405 ref_MAE 0.00764115950716797
u_c taken from control states: [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
u_c before reduction of space:  [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
data[u_c] post encoding of state:  [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
J_b = 0.0, J_o = 2122.5888647492293
J_b = 0.49999999999999994, J_o = 431141.082415603
J_b = 0.0018574670504070917, J_o = 307.5565664691806
J_b = 0.001968122923512112, J_o = 253.02506849695536
J_b = 0.002217606745608206, J_o = 221.01902376737945
J_b = 0.002438939242664738, J_o = 203.97378078611786
J_b = 0.0048639506746178335, J_o = 135.41328935129388
J_b = 0.009632989852899081, J_o = 82.7707773089742
J_b = 0.01464409383583682, J_o = 50.628336020015254
J_b = 0.01624551713317531, J_o = 44.02837663649259
J_b = 0.016926321710721885, J_o = 40.76275437385512
J_b = 0.018319525700438093, J_o = 35.75519130581017
J_b = 0.02058763453880323, J_o = 30.320866484144815
J_b = 0.022098146390328494, J_o = 27.597474986526112
J_b = 0.023597695612411766, J_o = 25.366471923424882
J_b = 0.025373175121632754, J_o = 22.999684870084632
J_b = 0.02857583458263979, J_o = 19.465998699142133
J_b = 0.04976994804837634, J_o = 140.10336518611507
J_b = 0.029262517149287993, J_o = 19.27118898486547
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
W_opt:  [ 0.00392384 -0.00081591 -0.00278771 -0.00358211 -0.00477019 -0.00729651
 -0.01111398 -0.01638025 -0.02322088 -0.03191712]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0468 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1718 s, inc stats = 0.1857, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94054796 2.77375261 3.40228196 2.99187276 2.48984431]
u_DA:    [3.84861881 2.04748303 2.6449995  1.89881638 2.18289405]
ref_MAE: [0.10009356 0.61197221 0.86334717 1.13931931 0.1132106 ]
da_MAE:  [0.09192914 0.72626958 0.75728245 1.09305638 0.30695025]
% 19.81300463091578 da_MAE 0.006134838797793749 ref_MAE 0.007650665509483613
u_c taken from control states: [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
u_c before reduction of space:  [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
data[u_c] post encoding of state:  [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
J_b = 0.0, J_o = 2092.820361878332
J_b = 0.49999999999999994, J_o = 428214.87635690166
J_b = 0.0018467353571603863, J_o = 301.1771565105074
J_b = 0.001974280411093976, J_o = 239.42126385329075
J_b = 0.002229794696460843, J_o = 208.15711895472003
J_b = 0.002411287877185005, J_o = 193.93235985813567
J_b = 0.004656194492239594, J_o = 129.60174128863454
J_b = 0.00900898375041458, J_o = 81.64130441870766
J_b = 0.014303763283657154, J_o = 49.028886485263996
J_b = 0.015829999108137885, J_o = 42.45758114224576
J_b = 0.016640462573360687, J_o = 38.83535545572247
J_b = 0.01778253217183162, J_o = 34.86839330777396
J_b = 0.01967694364323823, J_o = 30.275090389040024
J_b = 0.0211962040072702, J_o = 27.68006490816216
J_b = 0.022255273299973958, J_o = 26.03189353933577
J_b = 0.023783194987231096, J_o = 23.760267446013444
J_b = 0.026649176482885156, J_o = 20.218557549140304
J_b = 0.03244219045441418, J_o = 25.63947202504326
J_b = 0.028030629782666856, J_o = 19.4507884170975
J_b = 0.03127267321998859, J_o = 16.86549438691694
J_b = 0.031942197740600274, J_o = 16.11472452946583
J_b = 0.03165444330651006, J_o = 15.970998535692367
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
W_opt:  [ 0.00352869 -0.00111412 -0.00239921 -0.0029424  -0.00412824 -0.00697255
 -0.01141065 -0.01758294 -0.02556653 -0.03548546]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0565 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1340, add (DA)= 0.0001decode = 0.1369 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1935 s, inc stats = 0.2073, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94003601 2.77092732 3.40138429 2.99270336 2.49308591]
u_DA:    [3.84841899 2.04726326 2.64499247 1.89915294 2.18380217]
ref_MAE: [0.09958161 0.60914692 0.86244951 1.14014991 0.1164522 ]
da_MAE:  [0.09161703 0.72366406 0.75639182 1.09355042 0.30928374]
% 19.724910676779597 da_MAE 0.006149141428686207 ref_MAE 0.007660086685082646
u_c taken from control states: [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
u_c before reduction of space:  [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
data[u_c] post encoding of state:  [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
J_b = 0.0, J_o = 2065.442099333931
J_b = 0.49999999999999983, J_o = 423736.7592643918
J_b = 0.0018387615420409383, J_o = 300.6949897801811
J_b = 0.001991774697554819, J_o = 228.26738983740358
J_b = 0.002262683633022604, J_o = 196.97256120148353
J_b = 0.0024131890791215136, J_o = 185.05466725508185
J_b = 0.0045381804114923395, J_o = 123.96942083148042
J_b = 0.00851962927044237, J_o = 80.49946203463037
J_b = 0.014008041882782464, J_o = 48.57726915586879
J_b = 0.015420418426249168, J_o = 41.667774790274024
J_b = 0.016365945597358326, J_o = 37.43299504529069
J_b = 0.017305928522034823, J_o = 34.31843797799885
J_b = 0.019333210749238775, J_o = 29.63925155338928
J_b = 0.021208381064040664, J_o = 26.728344975111924
J_b = 0.022427833741326526, J_o = 24.977584767722256
J_b = 0.02449211929325618, J_o = 22.201113621348156
J_b = 0.027748811401465068, J_o = 18.578344057298505
J_b = 0.04500300458340919, J_o = 142.47897530946852
J_b = 0.02827312592359467, J_o = 18.40754784463078
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
W_opt:  [ 0.00474479 -0.00060017 -0.00271437 -0.00360602 -0.00480422 -0.00737673
 -0.01129261 -0.01662884 -0.02345381 -0.03181744]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0481 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1748 s, inc stats = 0.1885, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93957172 2.76828194 3.40052114 2.99399729 2.4961908 ]
u_DA:    [3.8481083  2.04723748 2.64323105 1.90012659 2.1827555 ]
ref_MAE: [0.09911732 0.60650154 0.86158636 1.14144384 0.11955709]
da_MAE:  [0.09146342 0.72104445 0.75729009 1.0938707  0.3134353 ]
% 19.66331593992713 da_MAE 0.006161724149182698 ref_MAE 0.007669876123559174
u_c taken from control states: [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
u_c before reduction of space:  [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
data[u_c] post encoding of state:  [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
J_b = 0.0, J_o = 2046.621905258662
J_b = 0.49999999999999994, J_o = 418064.10134353384
J_b = 0.0018377486379115911, J_o = 306.5620177947093
J_b = 0.0020225886311991646, J_o = 221.2737595397129
J_b = 0.0023151076381343508, J_o = 189.36287013299057
J_b = 0.002446581041442885, J_o = 178.9375714920193
J_b = 0.0045113940887720055, J_o = 119.80039951561444
J_b = 0.008214862069427908, J_o = 79.73392926706116
J_b = 0.013734289936858227, J_o = 48.878087151277185
J_b = 0.015122738736038777, J_o = 41.534757953531674
J_b = 0.016124751330381694, J_o = 37.03606293109865
J_b = 0.017037165372755333, J_o = 34.178564008815904
J_b = 0.01939619793519192, J_o = 28.783131056774593
J_b = 0.022077869246372527, J_o = 24.92253948955198
J_b = 0.023911374669071506, J_o = 22.63473844300013
J_b = 0.02713438130439996, J_o = 19.159317195859142
J_b = 0.02999956686945183, J_o = 16.46106668829666
J_b = 0.033729687430825335, J_o = 16.019617075359083
J_b = 0.03241082198921368, J_o = 15.354357213310916
J_b = 0.0317518335492644, J_o = 15.197056002561064
J_b = 0.03146590492103884, J_o = 15.14378843547997
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
W_opt:  [ 0.00520108 -0.00053402 -0.00219045 -0.00286551 -0.00405473 -0.00693538
 -0.01147625 -0.01775902 -0.0258558  -0.0357428 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0552 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1200, add (DA)= 0.0001decode = 0.1229 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1783 s, inc stats = 0.1840, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93914523 2.7658555  3.39968518 2.99564192 2.49916722]
u_DA:    [3.84784076 2.04757185 2.64234103 1.89965014 2.18314493]
ref_MAE: [0.09869083 0.6040751  0.8607504  1.14308847 0.12253351]
da_MAE:  [0.09130447 0.71828364 0.75734415 1.09599178 0.3160223 ]
% 19.572628294582586 da_MAE 0.006176439089643689 ref_MAE 0.007679523722677683
u_c taken from control states: [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
u_c before reduction of space:  [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
data[u_c] post encoding of state:  [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
J_b = 0.0, J_o = 2043.8141885620757
J_b = 0.5000000000000001, J_o = 410995.3217312867
J_b = 0.0018521702853383523, J_o = 318.9536617435561
J_b = 0.002076640144290214, J_o = 218.38943272975314
J_b = 0.002395406295863247, J_o = 185.54081806631137
J_b = 0.0025168861293359125, J_o = 175.96070788216815
J_b = 0.00455984057535541, J_o = 117.60646621613277
J_b = 0.008073821306926349, J_o = 79.67615178989809
J_b = 0.013522017491044074, J_o = 49.60153921352951
J_b = 0.014928140777580125, J_o = 42.03489058341493
J_b = 0.01597923089373541, J_o = 37.388369830018135
J_b = 0.016939101645200686, J_o = 34.46497022634412
J_b = 0.01953071951324902, J_o = 28.481717099435127
J_b = 0.0229307397271098, J_o = 23.772384341391223
J_b = 0.025195197682097166, J_o = 21.19173851466001
J_b = 0.02880976279771719, J_o = 17.696027910772006
J_b = 0.030755329602792533, J_o = 17.54172559088031
J_b = 0.029676858266304007, J_o = 16.254603746493693
J_b = 0.03302922995988929, J_o = 14.85359559957465
J_b = 0.034336483550777806, J_o = 16.167302852584335
J_b = 0.033400224330587716, J_o = 14.594556310305702
J_b = 0.03248254607668995, J_o = 14.440414496777713
J_b = 0.03120205052765128, J_o = 14.018760196412568
J_b = 0.03477373002103773, J_o = 26.88737576951312
J_b = 0.03146520910597256, J_o = 13.725452505130693
J_b = 0.031538818442686585, J_o = 12.684582736679324
J_b = 0.035848348198990555, J_o = 10.66941561101654
J_b = 0.0422812153830952, J_o = 9.603816699599609
J_b = 0.04584326323735348, J_o = 9.123525562937292
J_b = 0.048573826848556656, J_o = 8.32438053391951
J_b = 0.05168831835314616, J_o = 9.071738327793247
J_b = 0.0495373204144284, J_o = 8.02464660538733
J_b = 0.051406077671615036, J_o = 7.354700759421789
J_b = 0.052214171776503976, J_o = 7.080080387545213
J_b = 0.05278191510556357, J_o = 6.662923767531188
J_b = 0.05531621410502077, J_o = 6.204095786835046
J_b = 0.05923417497558357, J_o = 5.985572974089884
J_b = 0.06225463087024562, J_o = 5.899483403054151
J_b = 0.06294967015681195, J_o = 5.815287812094281
J_b = 0.06331116198233618, J_o = 5.7626957602480156
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
W_opt:  [-0.01475932 -0.00647488  0.0002494   0.00289653  0.00330936 -0.00068269
 -0.009053   -0.0222428  -0.04233151 -0.07234835]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1000 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1316, add (DA)= 0.0001decode = 0.1345 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2346 s, inc stats = 0.2484, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93874457 2.76368301 3.398866   2.99749349 2.50195261]
u_DA:    [3.84714112 2.04717835 2.64141078 1.89604593 2.18052936]
ref_MAE: [0.09829017 0.60190261 0.85993122 1.14494004 0.12531889]
da_MAE:  [0.09160345 0.71650465 0.75745522 1.10144755 0.32142325]
% 19.493877931267683 da_MAE 0.006189884417369016 ref_MAE 0.007688712682104332
u_c taken from control states: [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
u_c before reduction of space:  [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
data[u_c] post encoding of state:  [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
J_b = 0.0, J_o = 2059.477738115113
J_b = 0.49999999999999994, J_o = 402878.950525681
J_b = 0.0018852593966820614, J_o = 336.5906279090923
J_b = 0.0021560820224307367, J_o = 219.16353042655578
J_b = 0.0025020009135012875, J_o = 185.42989945294187
J_b = 0.002620729323247549, J_o = 176.1652637258319
J_b = 0.004664815254505819, J_o = 117.55705457475102
J_b = 0.00808255462664191, J_o = 80.38873061691396
J_b = 0.013436170664457438, J_o = 50.59526390853132
J_b = 0.014829261331973808, J_o = 43.00440962000607
J_b = 0.015917460214040346, J_o = 38.18396613286276
J_b = 0.016931749887907733, J_o = 35.09065805712624
J_b = 0.019648555419642624, J_o = 28.809610711612997
J_b = 0.023183792450642338, J_o = 23.914518348488627
J_b = 0.025473514100033, J_o = 21.29532770453935
J_b = 0.02903180253833986, J_o = 17.7977658840378
J_b = 0.03141959477709269, J_o = 17.730123601030336
J_b = 0.030106932965902253, J_o = 16.343449316995322
J_b = 0.03321449639959334, J_o = 15.031854643727643
J_b = 0.03305788378670554, J_o = 14.468388089878921
J_b = 0.03260804021373997, J_o = 14.350053783196097
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
W_opt:  [ 0.00720153  0.00044417 -0.00172205 -0.00242341 -0.00363092 -0.00656714
 -0.01122381 -0.01771727 -0.02618691 -0.03667524]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0533 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1208, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1771 s, inc stats = 0.1887, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93835657 2.76179847 3.39805086 2.99939743 2.50437555]
u_DA:    [3.84702326 2.04653213 2.63918912 1.89592071 2.18098713]
ref_MAE: [0.09790217 0.60001807 0.85911608 1.14684398 0.12774184]
da_MAE:  [0.09133331 0.71526633 0.75886174 1.10347672 0.32338842]
% 19.452538995667574 da_MAE 0.006200838876505582 ref_MAE 0.007698366651398305
u_c taken from control states: [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
u_c before reduction of space:  [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
data[u_c] post encoding of state:  [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
J_b = 0.0, J_o = 2088.0677194371897
J_b = 0.5, J_o = 395073.53120842087
J_b = 0.0019294615698193201, J_o = 356.4230691401886
J_b = 0.002246368159865634, J_o = 223.23122033068913
J_b = 0.0026152653766672554, J_o = 188.87881834201377
J_b = 0.0027376833257740795, J_o = 179.44582997591885
J_b = 0.004796926605217483, J_o = 119.6734725055656
J_b = 0.008213924344045928, J_o = 81.82784246094094
J_b = 0.013550291530723343, J_o = 51.58080830597271
J_b = 0.014882474864780977, J_o = 44.00569648543778
J_b = 0.015956891371158983, J_o = 39.04343225223355
J_b = 0.016990669814724222, J_o = 35.806986883708106
J_b = 0.019723330189244218, J_o = 29.51836087151888
J_b = 0.022886357092877625, J_o = 25.02326604250392
J_b = 0.024935579914272244, J_o = 22.52655379903526
J_b = 0.02814780885296329, J_o = 19.050298250491547
J_b = 0.031193243761775975, J_o = 16.80008051575172
J_b = 0.03416943509287942, J_o = 16.450440744288514
J_b = 0.03253167303350346, J_o = 15.011095185947292
J_b = 0.03218709700404492, J_o = 14.919612856447223
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
W_opt:  [ 0.0081298   0.00047718 -0.00238125 -0.00320117 -0.00439547 -0.00718068
 -0.011562   -0.01765766 -0.02559403 -0.03544141]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0786 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1229, add (DA)= 0.0001decode = 0.1259 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2046 s, inc stats = 0.2156, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93797206 2.76025246 3.39722972 3.00122915 2.50634349]
u_DA:    [3.84687809 2.0462004  2.6382973  1.89442617 2.18102573]
ref_MAE: [0.09751765 0.59847207 0.85829493 1.1486757  0.12970978]
da_MAE:  [0.09109396 0.71405207 0.75893242 1.10680298 0.32531776]
% 19.413137248927715 da_MAE 0.006212477915881404 ref_MAE 0.007709045499229018
u_c taken from control states: [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
u_c before reduction of space:  [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
data[u_c] post encoding of state:  [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
J_b = 0.0, J_o = 2115.1285082964005
J_b = 0.4999999999999997, J_o = 390022.3984125242
J_b = 0.0019649379616794266, J_o = 372.169656907633
J_b = 0.002312899610174084, J_o = 228.8242373104647
J_b = 0.0026961382788032824, J_o = 194.01230400953744
J_b = 0.0028258179404681756, J_o = 184.10722626219206
J_b = 0.0049120624392525215, J_o = 122.6894772718395
J_b = 0.00839505986417143, J_o = 83.33051188526701
J_b = 0.013770722975089349, J_o = 52.26228845218087
J_b = 0.015026675705797639, J_o = 44.74426643364866
J_b = 0.01605222534707886, J_o = 39.72120163337436
J_b = 0.01707052748982564, J_o = 36.41138758792651
J_b = 0.019746950331306475, J_o = 30.28284494735425
J_b = 0.02243983964757389, J_o = 26.327817788880104
J_b = 0.024208898631957427, J_o = 24.033900257979298
J_b = 0.026836510396658367, J_o = 20.84547065395668
J_b = 0.030240897640560198, J_o = 17.39821101625771
J_b = 0.03735865519727451, J_o = 35.27251825422133
J_b = 0.03119298743907653, J_o = 16.81615146720407
J_b = 0.03257898906257337, J_o = 15.601015597702927
J_b = 0.0324792154758311, J_o = 15.325967960116603
J_b = 0.03231772442315175, J_o = 15.1835180102896
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
W_opt:  [ 0.0084157   0.00044818 -0.00268872 -0.00349554 -0.00463713 -0.00732167
 -0.01156233 -0.01748631 -0.02522008 -0.03491025]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0565 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1812 s, inc stats = 0.1952, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9375834  2.75909416 3.39639638 3.00289321 2.50781074]
u_DA:    [3.84679997 2.04598336 2.63771735 1.89348959 2.18074705]
ref_MAE: [0.097129   0.59731376 0.8574616  1.15033976 0.13117703]
da_MAE:  [0.09078343 0.7131108  0.75867903 1.10940362 0.32706368]
% 19.37875522520505 da_MAE 0.006223853222168364 ref_MAE 0.007719867436373496
u_c taken from control states: [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
u_c before reduction of space:  [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
data[u_c] post encoding of state:  [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
J_b = 0.0, J_o = 2130.1058097046334
J_b = 0.5, J_o = 389138.72485404264
J_b = 0.001977433844102254, J_o = 379.329493821939
J_b = 0.0023317419610307368, J_o = 233.78376619361876
J_b = 0.002720369219742209, J_o = 198.45263831360074
J_b = 0.0028560125986976125, J_o = 188.10241178277812
J_b = 0.004979326087921151, J_o = 125.179207548977
J_b = 0.008546892730462517, J_o = 84.49225387980414
J_b = 0.013976163343300806, J_o = 52.75374815081088
J_b = 0.015207266881725353, J_o = 45.26511404989271
J_b = 0.016212062607699078, J_o = 40.206651204042814
J_b = 0.017225365434487442, J_o = 36.837033904165565
J_b = 0.01986121930329719, J_o = 30.80851868342419
J_b = 0.022314289921251403, J_o = 27.12724630855338
J_b = 0.023935941033453846, J_o = 24.95390303353154
J_b = 0.026218410931913037, J_o = 22.000035011043888
J_b = 0.02963001848639921, J_o = 18.28229388526197
J_b = 0.03904508600371302, J_o = 81.15787490004118
J_b = 0.03017544670088877, J_o = 17.933379501989933
J_b = 0.03254631426516708, J_o = 16.07122251689099
J_b = 0.03273574381073904, J_o = 15.590762606309898
J_b = 0.03250182549306135, J_o = 15.43306594288244
J_b = 0.03225166175125343, J_o = 15.206861417660793
J_b = 0.032211707409653505, J_o = 14.658986464864835
J_b = 0.03305188603497439, J_o = 13.904519455247915
J_b = 0.03555978515916068, J_o = 12.57000911429542
J_b = 0.042189868517875075, J_o = 10.737982476648288
J_b = 0.044211820758315944, J_o = 10.1454545234709
J_b = 0.051368847968121946, J_o = 10.100290259182465
J_b = 0.047764228636362385, J_o = 9.79225754414069
J_b = 0.04763172972219453, J_o = 9.68450509717121
J_b = 0.046722145392508616, J_o = 9.416737279948805
J_b = 0.04615105283960953, J_o = 9.308323157382416
J_b = 0.04561939752276411, J_o = 9.187021339653988
J_b = 0.04456406091157099, J_o = 8.95881297904664
J_b = 0.04806896661097505, J_o = 9.145530747678595
J_b = 0.04580177794731856, J_o = 8.840559590283814
J_b = 0.04600034012200244, J_o = 8.641626676635868
J_b = 0.04723803084591862, J_o = 8.404464264626878
J_b = 0.04841669405289386, J_o = 8.223412793963076
J_b = 0.05013984162456999, J_o = 7.8444728801496
J_b = 0.054672598445201025, J_o = 7.45002273714654
J_b = 0.052760097965141174, J_o = 7.027863246379191
J_b = 0.0517969488077751, J_o = 6.885865530329492
J_b = 0.05196828360518383, J_o = 6.794225922935175
J_b = 0.05298784464201261, J_o = 6.660930125466594
J_b = 0.055997821764396175, J_o = 6.427742554879645
J_b = 0.059083174477373525, J_o = 6.769204570317074
J_b = 0.05700322160541017, J_o = 6.311869966306971
J_b = 0.06134292928444341, J_o = 6.085024584714489
J_b = 0.06464686752781927, J_o = 5.963995356933902
J_b = 0.06484803583595336, J_o = 5.923292570969318
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
W_opt:  [-1.56140618e-02 -1.07360275e-02 -3.40898851e-03 -2.26594656e-05
  9.23207804e-04 -2.31182801e-03 -9.91916507e-03 -2.27085547e-02
 -4.30017152e-02 -7.43143144e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1325 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1388, add (DA)= 0.0001decode = 0.1418 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2744 s, inc stats = 58.3697, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9371823  2.75836606 3.39554487 3.00430921 2.50870118]
u_DA:    [3.84659848 2.04625271 2.6380334  1.89078968 2.17906698]
ref_MAE: [0.0967279  0.59658566 0.85661009 1.15175576 0.13206747]
da_MAE:  [0.09058382 0.71211335 0.75751147 1.11351953 0.3296342 ]
% 19.324193427235336 da_MAE 0.006237183989242345 ref_MAE 0.007731170290335783
\% improve_point: 16.93, mse_ref_points: 3.49696078940064e-05, mse_da_points: 2.9050847323970253e-05, % improve_overlap: 16.93, mse_ref_overlap: 0.91087, mse_da_overlap: 0.75671
DA - - L2: 63277.57, L1: 8037.58, % Improve: 18.88%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.756, time(s): 1.9882s,
u_c taken from control states: [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
u_c before reduction of space:  [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
data[u_c] post encoding of state:  [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
J_b = 0.0, J_o = 2132.9722771218558
J_b = 0.5, J_o = 391238.3745113079
J_b = 0.0019713377426451187, J_o = 378.52638256232933
J_b = 0.002313692426093018, J_o = 236.57796827990396
J_b = 0.0027005390188247686, J_o = 200.84679023766375
J_b = 0.0028380305383869024, J_o = 190.3099649442156
J_b = 0.004989652924787635, J_o = 126.66321482911388
J_b = 0.008613869063618317, J_o = 85.42873382156272
J_b = 0.014124625331171148, J_o = 53.26810737775222
J_b = 0.015395225293805352, J_o = 45.65428355476544
J_b = 0.01642332034841071, J_o = 40.54405366345736
J_b = 0.017453263441651892, J_o = 37.136563931590594
J_b = 0.02011114487835159, J_o = 31.05535542873814
J_b = 0.022596797548018976, J_o = 27.340488588284117
J_b = 0.024219935684670346, J_o = 25.162146743724296
J_b = 0.02659433987382811, J_o = 22.11644916531595
J_b = 0.03006522194102118, J_o = 18.389221015844072
J_b = 0.03941770584381537, J_o = 72.63778850731978
J_b = 0.030669499711658908, J_o = 18.016910085146506
J_b = 0.03295011785397727, J_o = 16.235618518013894
J_b = 0.03308298255251874, J_o = 15.796055253065084
J_b = 0.03285635304895589, J_o = 15.648545989199224
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
W_opt:  [ 0.00794801 -0.000275   -0.00314489 -0.00376206 -0.00479078 -0.00741987
 -0.01167555 -0.01768808 -0.02547023 -0.03511791]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0571 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1235, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1838 s, inc stats = 0.1972, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93676869 2.75806816 3.39467217 3.00543937 2.509108  ]
u_DA:    [3.84685926 2.04607203 2.63774085 1.89378889 2.18030181]
ref_MAE: [0.09631429 0.59628776 0.85573739 1.15288592 0.13247429]
da_MAE:  [0.08990943 0.71199613 0.75693132 1.11165048 0.32880618]
% 19.345658010442232 da_MAE 0.006244913232181043 ref_MAE 0.007742810961112999
u_c taken from control states: [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
u_c before reduction of space:  [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
data[u_c] post encoding of state:  [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
J_b = 0.0, J_o = 2132.604192921911
J_b = 0.5, J_o = 394044.1466542104
J_b = 0.001961952470113275, J_o = 374.520332723228
J_b = 0.0022879935393450056, J_o = 237.7174638317717
J_b = 0.0026695701207076587, J_o = 201.87073559586986
J_b = 0.0028057844323782256, J_o = 191.3779714571874
J_b = 0.004969109732398135, J_o = 127.74626150385208
J_b = 0.008620908582620119, J_o = 86.51867834794976
J_b = 0.014266325551441703, J_o = 53.98087039273803
J_b = 0.015605594699602144, J_o = 46.07924434198162
J_b = 0.01667573682029755, J_o = 40.9013089201143
J_b = 0.017724668382128474, J_o = 37.51413187805676
J_b = 0.020481350699945736, J_o = 31.198892672924217
J_b = 0.023282441772972756, J_o = 27.1187491210385
J_b = 0.02510578317069652, J_o = 24.763916925544827
J_b = 0.027976216236936396, J_o = 21.35802926568754
J_b = 0.03150791114280084, J_o = 17.883457739543406
J_b = 0.03819655706603819, J_o = 30.691301850750712
J_b = 0.032583542126510184, J_o = 17.25426317423675
J_b = 0.03377921532058373, J_o = 16.1576546240995
J_b = 0.03362662303649963, J_o = 15.920700297783103
J_b = 0.033472785626439856, J_o = 15.777882948220705
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
W_opt:  [ 0.00780257 -0.00034592 -0.00294288 -0.00352482 -0.0045782  -0.00729342
 -0.01168337 -0.01788799 -0.02590121 -0.03576147]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0563 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1256, add (DA)= 0.0001decode = 0.1285 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1849 s, inc stats = 0.1967, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93634497 2.75813076 3.3937798  3.0062726  2.50919532]
u_DA:    [3.84692528 2.0461981  2.63803536 1.89435643 2.18024218]
ref_MAE: [0.09589057 0.59635037 0.85484501 1.15371915 0.13256161]
da_MAE:  [0.08941969 0.71193266 0.75574443 1.11191618 0.32895315]
% 19.336191543140075 da_MAE 0.006255073157380343 ref_MAE 0.007754497682471364
u_c taken from control states: [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
u_c before reduction of space:  [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
data[u_c] post encoding of state:  [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
J_b = 0.0, J_o = 2137.39736096022
J_b = 0.4999999999999999, J_o = 396115.322977587
J_b = 0.0019591087189152674, J_o = 372.7888143106543
J_b = 0.002273430444110195, J_o = 239.72334236578376
J_b = 0.0026510629163569825, J_o = 203.79577257426436
J_b = 0.0027865194749142866, J_o = 193.3220840010597
J_b = 0.004963744963253687, J_o = 129.56691128916543
J_b = 0.008656945052296978, J_o = 88.14741202109417
J_b = 0.01447500806156761, J_o = 55.063507153532754
J_b = 0.015873961624944553, J_o = 46.835697832276125
J_b = 0.01697391557787517, J_o = 41.598699762916766
J_b = 0.018033765938589495, J_o = 38.24890160462011
J_b = 0.020908480200430388, J_o = 31.64619578591838
J_b = 0.024131103313917827, J_o = 27.071069343161174
J_b = 0.026247085079958224, J_o = 24.478450551571154
J_b = 0.029640145115852345, J_o = 20.778213938759116
J_b = 0.03301642464831099, J_o = 17.8630148506276
J_b = 0.0371482658672798, J_o = 19.60902109489444
J_b = 0.03448472885259574, J_o = 16.92159168375762
J_b = 0.034635180243939204, J_o = 16.278555292567674
J_b = 0.034534734123012355, J_o = 16.065234046671165
J_b = 0.03444744604717054, J_o = 15.694702793473777
J_b = 0.03479395044948476, J_o = 15.025965926953004
J_b = 0.03686584773269435, J_o = 14.079007659960507
J_b = 0.04062660490779793, J_o = 26.206472082283703
J_b = 0.037147715206310404, J_o = 13.714854950754757
J_b = 0.03913732986311361, J_o = 12.992269458350197
J_b = 0.040666898306727824, J_o = 12.053662300495596
J_b = 0.04879076641016882, J_o = 10.832850123500442
J_b = 0.04873510447492788, J_o = 10.281108840986269
J_b = 0.04867069208555392, J_o = 10.026863278294897
J_b = 0.0482989490617879, J_o = 9.699262463129896
J_b = 0.04837923264718927, J_o = 9.66433715075242
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
W_opt:  [ 0.00078118 -0.00215842  0.00091657  0.00256886  0.00223142 -0.00126911
 -0.00782604 -0.01799627 -0.03265529 -0.05315224]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0757 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1226, add (DA)= 0.0001decode = 0.1254 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2013 s, inc stats = 0.2149, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93590339 2.75847828 3.3928678  3.00678617 2.50894246]
u_DA:    [3.84673377 2.04578552 2.63785866 1.89274953 2.1777969 ]
ref_MAE: [0.09544899 0.59669788 0.85393301 1.15423272 0.13230875]
da_MAE:  [0.08916963 0.71269276 0.75500913 1.11403664 0.33114556]
% 19.307036242524006 da_MAE 0.006266555787748509 ref_MAE 0.007765925919616416
u_c taken from control states: [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
u_c before reduction of space:  [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
data[u_c] post encoding of state:  [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
J_b = 0.0, J_o = 2149.456948703803
J_b = 0.5000000000000001, J_o = 397833.8053906568
J_b = 0.001962524320089665, J_o = 373.8942028788693
J_b = 0.0022676111901572386, J_o = 243.723507618799
J_b = 0.0026433778996664196, J_o = 207.5059303248279
J_b = 0.002780611655125454, J_o = 196.86017987134
J_b = 0.004990345096022286, J_o = 132.29197552600309
J_b = 0.008768107031842163, J_o = 90.09586980585635
J_b = 0.014763285349663273, J_o = 56.2879494986319
J_b = 0.016197820399286973, J_o = 47.821461057318416
J_b = 0.017306124639111277, J_o = 42.549751247248096
J_b = 0.018365255918812367, J_o = 39.2289834110195
J_b = 0.021298527728411214, J_o = 32.47846076057352
J_b = 0.024749623676296503, J_o = 27.63601749176559
J_b = 0.02704056691107599, J_o = 24.90527371754231
J_b = 0.030719908040611466, J_o = 21.055471780621854
J_b = 0.03399349397971159, J_o = 18.48953147236855
J_b = 0.03732450464960196, J_o = 18.70772703244092
J_b = 0.03554223301855324, J_o = 17.38874694021184
J_b = 0.03541306283281357, J_o = 16.786600357252837
J_b = 0.03537893532576039, J_o = 16.471803916240138
J_b = 0.03573071073652041, J_o = 15.639127639397437
J_b = 0.03698732918439935, J_o = 14.812606814605756
J_b = 0.0387497271492737, J_o = 13.884115202214202
J_b = 0.04222915585775898, J_o = 12.224308382249305
J_b = 0.04481823216233307, J_o = 11.223596650228703
J_b = 0.04796339507447833, J_o = 10.40227134411449
J_b = 0.05766276740853376, J_o = 11.43780017991907
J_b = 0.05070736670886368, J_o = 10.177897023224496
J_b = 0.05151834015487262, J_o = 10.00041520073423
J_b = 0.0527234448424711, J_o = 9.948853009751513
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
W_opt:  [-0.00076659 -0.00307467  0.00101004  0.00301581  0.00277318 -0.0008782
 -0.0077834  -0.0185466  -0.0342595  -0.05658851]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0795 s, v_trunc (Latent to Reduced) = 0.0039, dec (Reduced to Full) = 0.1133, add (DA)= 0.0001decode = 0.1192 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1988 s, inc stats = 0.2055, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93543533 2.7590151  3.39193568 3.00696751 2.50828746]
u_DA:    [3.84684316 2.045723   2.63806828 1.89366286 2.17657038]
ref_MAE: [0.09498093 0.5972347  0.85300089 1.15441406 0.13165375]
da_MAE:  [0.08859217 0.7132921  0.7538674  1.11330465 0.33171708]
% 19.32538343138262 da_MAE 0.0062742807925230334 ref_MAE 0.0077772675711281205
u_c taken from control states: [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
u_c before reduction of space:  [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
data[u_c] post encoding of state:  [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
J_b = 0.0, J_o = 2166.1320207459726
J_b = 0.5, J_o = 399676.3717100272
J_b = 0.001969518327112919, J_o = 375.56237249112644
J_b = 0.002264861657748222, J_o = 248.45603664459924
J_b = 0.00263921311059078, J_o = 211.8132425901632
J_b = 0.0027799194869359417, J_o = 200.86071752619802
J_b = 0.005036444582929815, J_o = 135.01133594843932
J_b = 0.008931803358963831, J_o = 91.65433240175742
J_b = 0.015086663403532914, J_o = 57.10115796245405
J_b = 0.016532474130392178, J_o = 48.52785151083867
J_b = 0.017629856394135585, J_o = 43.262203545230484
J_b = 0.018672128679617712, J_o = 39.9873258040681
J_b = 0.021587497898843507, J_o = 33.273347677775845
J_b = 0.02501810890869186, J_o = 28.458689613607447
J_b = 0.027327488648374646, J_o = 25.707902323695635
J_b = 0.031100108637986953, J_o = 21.783842301443947
J_b = 0.03442417944060827, J_o = 19.082486605657873
J_b = 0.037928064806982936, J_o = 19.604169550517312
J_b = 0.03595092253767415, J_o = 18.075684229950745
J_b = 0.0359083157535435, J_o = 17.459191100018813
J_b = 0.035831844244919774, J_o = 17.194478667584605
J_b = 0.035920052275389754, J_o = 16.51352080805032
J_b = 0.036835198702740594, J_o = 15.745574446504788
J_b = 0.03911559202223307, J_o = 14.289530631912076
J_b = 0.046298008227829854, J_o = 13.481825591021323
J_b = 0.04749530395415907, J_o = 12.139508257412588
J_b = 0.04809680186971436, J_o = 11.593754068833476
J_b = 0.04825254127073304, J_o = 11.037092317827707
J_b = 0.0516347043384637, J_o = 10.696112607833985
J_b = 0.061004484237304514, J_o = 13.736417501627912
J_b = 0.053379439093994466, J_o = 10.465848461079064
J_b = 0.053766428447167815, J_o = 10.286887367844045
J_b = 0.05440067545778536, J_o = 10.150404027796935
J_b = 0.0575903258980651, J_o = 9.619922721798668
J_b = 0.06432314906204163, J_o = 8.568939587246655
J_b = 0.07241562083006495, J_o = 8.200477839727867
J_b = 0.0683583651824384, J_o = 7.353200345360724
J_b = 0.0677682418927248, J_o = 7.220497665471076
J_b = 0.06769908989127962, J_o = 7.156397521420103
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
W_opt:  [-0.01449989 -0.00984379 -0.00150591  0.00198452  0.00269152 -0.00093364
 -0.00880769 -0.02164789 -0.04159618 -0.07213047]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0977 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1200, add (DA)= 0.0001decode = 0.1229 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2207 s, inc stats = 0.2418, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93494478 2.75961269 3.39098855 3.00684171 2.50730475]
u_DA:    [3.8468346  2.04642353 2.63964025 1.89330817 2.1774058 ]
ref_MAE: [0.09449038 0.5978323  0.85205377 1.15428826 0.13067104]
da_MAE:  [0.08811018 0.71318917 0.75134831 1.11353353 0.32989895]
% 19.27365231039746 da_MAE 0.006287507987593653 ref_MAE 0.007788668963161177
u_c taken from control states: [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
u_c before reduction of space:  [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
data[u_c] post encoding of state:  [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
J_b = 0.0, J_o = 2180.7406732407526
J_b = 0.49999999999999994, J_o = 401289.94924255135
J_b = 0.001976706920087458, J_o = 375.93446430113954
J_b = 0.0022634234546707968, J_o = 251.6048466152676
J_b = 0.0026360495828543057, J_o = 214.64425478658697
J_b = 0.002779619021772023, J_o = 203.4377056355322
J_b = 0.005074386601694567, J_o = 136.56212694151083
J_b = 0.009068240566333473, J_o = 92.25470896681765
J_b = 0.015345867428953351, J_o = 57.15413973959875
J_b = 0.01678826203788171, J_o = 48.55109945519541
J_b = 0.017862043415723318, J_o = 43.33887966585836
J_b = 0.018876834882300818, J_o = 40.13756264830201
J_b = 0.021739726717767832, J_o = 33.53970732109834
J_b = 0.025082919024778803, J_o = 28.841297494077587
J_b = 0.02736017406989323, J_o = 26.120362091486633
J_b = 0.031150064103158473, J_o = 22.180519484692496
J_b = 0.03449392230747378, J_o = 19.360573640570475
J_b = 0.03815920243623167, J_o = 20.20164739722361
J_b = 0.03598441324411468, J_o = 18.450633451504768
J_b = 0.03603848275199003, J_o = 17.828077458407318
J_b = 0.03592136517793366, J_o = 17.60827589156179
J_b = 0.035819429015309934, J_o = 17.078720492386697
J_b = 0.03639059095523677, J_o = 16.385861714961564
J_b = 0.03890533014734249, J_o = 15.09733254244031
J_b = 0.04532310015602622, J_o = 24.727681930278813
J_b = 0.03966829439776286, J_o = 14.664217234760972
J_b = 0.042310302701312044, J_o = 13.566309941873753
J_b = 0.04497930034851084, J_o = 12.460769669651363
J_b = 0.052955699530591704, J_o = 11.645203113699655
J_b = 0.053964789715965834, J_o = 11.575180061746435
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
W_opt:  [-0.00040531 -0.00277434  0.00152102  0.00354931  0.00328863 -0.00035994
 -0.00724719 -0.01792654 -0.03355812 -0.05601207]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0796 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1223, add (DA)= 0.0001decode = 0.1253 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2051 s, inc stats = 0.2191, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93443316 2.76013066 3.3900313  3.00642704 2.50599876]
u_DA:    [3.84696953 2.04665965 2.63850393 1.89416551 2.17681805]
ref_MAE: [0.09397876 0.59835026 0.85109651 1.15387359 0.12936505]
da_MAE:  [0.08746362 0.71347101 0.75152737 1.11226153 0.3291807 ]
% 19.2467856417506 da_MAE 0.006299113836857924 ref_MAE 0.00780044966249004
u_c taken from control states: [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
u_c before reduction of space:  [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
data[u_c] post encoding of state:  [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
J_b = 0.0, J_o = 2187.7374486836407
J_b = 0.5000000000000001, J_o = 402064.26938667893
J_b = 0.0019818005743307385, J_o = 374.46587856777336
J_b = 0.0022643629649403666, J_o = 251.49956310571156
J_b = 0.002635431232715191, J_o = 214.5150618356901
J_b = 0.0027787648958478755, J_o = 203.3132774957757
J_b = 0.005078368558355967, J_o = 136.41009256657904
J_b = 0.009088608206142023, J_o = 92.01930693543102
J_b = 0.015445944723810959, J_o = 56.736278658771575
J_b = 0.0168879555624676, J_o = 48.05233634318913
J_b = 0.017936533698080796, J_o = 42.92486425483513
J_b = 0.018928209745374996, J_o = 39.80662485327762
J_b = 0.021772745758138493, J_o = 33.22848947227703
J_b = 0.02521594974319832, J_o = 28.434617823041112
J_b = 0.027569111442414782, J_o = 25.68265513033782
J_b = 0.031466808355319655, J_o = 21.75107787288737
J_b = 0.03454451305512038, J_o = 19.34810624438217
J_b = 0.037589466040199596, J_o = 19.069439433581053
J_b = 0.036041442604372476, J_o = 17.662465863102767
J_b = 0.035678368692063166, J_o = 17.576842249879885
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
W_opt:  [ 0.00798366 -0.00017161 -0.00221107 -0.00271451 -0.00379032 -0.00660207
 -0.01113625 -0.0175157  -0.02587749 -0.03650514]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0506 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1367, add (DA)= 0.0001decode = 0.1396 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1903 s, inc stats = 0.2038, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93389619 2.76047015 3.38906364 3.0057245  2.50425932]
u_DA:    [3.84725453 2.04643085 2.63863757 1.89640202 2.17851375]
ref_MAE: [0.09344178 0.59868976 0.85012886 1.15317105 0.12762561]
da_MAE:  [0.08664165 0.7140393  0.75042607 1.10932248 0.32574557]
% 19.24590197135767 da_MAE 0.006308967046719317 ref_MAE 0.00781256580252016
u_c taken from control states: [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
u_c before reduction of space:  [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
data[u_c] post encoding of state:  [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
J_b = 0.0, J_o = 2189.238835217809
J_b = 0.4999999999999999, J_o = 401506.75402775453
J_b = 0.0019874779724499843, J_o = 372.9403208128899
J_b = 0.0022734772577319142, J_o = 248.77873116894074
J_b = 0.002644886783657913, J_o = 212.02889416185556
J_b = 0.0027842870920383716, J_o = 201.14384593872506
J_b = 0.005054654152545194, J_o = 135.24096160282068
J_b = 0.008993710727055343, J_o = 91.70390321287158
J_b = 0.01541655315873474, J_o = 56.52136794599093
J_b = 0.01687607340572797, J_o = 47.610610169997294
J_b = 0.01790274905527284, J_o = 42.586746148095436
J_b = 0.018886791650785596, J_o = 39.53172845654079
J_b = 0.021779677853395962, J_o = 32.78763731763413
J_b = 0.025676689976338367, J_o = 27.49251056375138
J_b = 0.028300777401670214, J_o = 24.6019829978168
J_b = 0.03238992775765522, J_o = 20.747281553299295
J_b = 0.03492044781953766, J_o = 20.421318753520215
J_b = 0.033546627647100535, J_o = 19.002089547109673
J_b = 0.03723031511191152, J_o = 17.182070250201033
J_b = 0.036898979618438334, J_o = 16.741282198371223
J_b = 0.03643533865362157, J_o = 16.04098641223265
J_b = 0.03690997877802129, J_o = 17.14645732727954
J_b = 0.03654292882749372, J_o = 15.726018108740636
J_b = 0.03738826745533495, J_o = 15.287570022515569
J_b = 0.040678375398186535, J_o = 14.615753674364132
J_b = 0.04180901253494785, J_o = 14.378762013561982
J_b = 0.04682216325220737, J_o = 13.092556652779702
J_b = 0.060535631151181504, J_o = 15.670670494493471
J_b = 0.050452426055005495, J_o = 12.505631993913545
J_b = 0.052536295598725295, J_o = 11.291233932016155
J_b = 0.05173517482328171, J_o = 10.919557724696983
J_b = 0.050277393967780006, J_o = 10.797714044419182
J_b = 0.05173760516992729, J_o = 11.274051743398763
J_b = 0.05070222392950934, J_o = 10.660176346484182
J_b = 0.0504236055815725, J_o = 10.39364389807702
J_b = 0.0545881585359554, J_o = 8.604428765799279
J_b = 0.069133849406246, J_o = 22.940020742734042
J_b = 0.055530253143990765, J_o = 8.51098354112527
J_b = 0.06180214072927589, J_o = 7.961691180110755
J_b = 0.06699175619334764, J_o = 7.746921144989739
J_b = 0.06857437632158586, J_o = 7.656272249636627
J_b = 0.07454688274563284, J_o = 7.420765347010234
J_b = 0.0787265467242757, J_o = 7.12009333926067
J_b = 0.07727467844906684, J_o = 6.847502707617325
J_b = 0.07682430106583628, J_o = 6.581053333871623
J_b = 0.07792218710493648, J_o = 6.420654026010954
J_b = 0.07745598051121637, J_o = 8.840242038905677
J_b = 0.07779554607861275, J_o = 6.36855762897304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
W_opt:  [-0.02154767 -0.01090883 -0.00165627  0.00137274  0.00222459 -0.00134726
 -0.00963547 -0.02346258 -0.04592113 -0.08182485]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1252 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1209, add (DA)= 0.0001decode = 0.1241 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2496 s, inc stats = 0.2562, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93333252 2.76055827 3.38808597 3.00474399 2.50200569]
u_DA:    [3.84704974 2.04701317 2.63978262 1.89429823 2.17680114]
ref_MAE: [0.09287812 0.59877787 0.84915119 1.15219054 0.12537198]
da_MAE:  [0.08628279 0.7135451  0.74830335 1.11044576 0.32520456]
% 19.187000015249296 da_MAE 0.0063234063294851485 ref_MAE 0.007824739003227657
u_c taken from control states: [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
u_c before reduction of space:  [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
data[u_c] post encoding of state:  [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
J_b = 0.0, J_o = 2188.102267011009
J_b = 0.5, J_o = 399265.52528458467
J_b = 0.0019957998570563564, J_o = 373.88287251978
J_b = 0.002295115638331112, J_o = 245.18441862936285
J_b = 0.0026708205213215146, J_o = 208.71711124001928
J_b = 0.0028053164996193077, J_o = 198.25333219212908
J_b = 0.005030413705376859, J_o = 133.7116795961331
J_b = 0.008848885771616598, J_o = 91.43018868114982
J_b = 0.015272084785463604, J_o = 56.556725205496406
J_b = 0.016755104173338236, J_o = 47.4343086100386
J_b = 0.01776950202677616, J_o = 42.491603824358855
J_b = 0.018764430339023273, J_o = 39.43414138172706
J_b = 0.021723140117730293, J_o = 32.484119621021954
J_b = 0.026138879404348427, J_o = 26.62086375355246
J_b = 0.02900718165878331, J_o = 23.636288500270997
J_b = 0.0331032910699778, J_o = 19.960089403314825
J_b = 0.03582284509297507, J_o = 23.88712262692886
J_b = 0.03379799242650683, J_o = 18.870065246183657
J_b = 0.036651838387240454, J_o = 17.070703617316163
J_b = 0.03675749776579441, J_o = 16.702617303703484
J_b = 0.03615758421561, J_o = 16.292662755768703
J_b = 0.03640011523716487, J_o = 15.71455893988807
J_b = 0.03945845693578282, J_o = 15.094294971288118
J_b = 0.04578136860107623, J_o = 19.165427997974
J_b = 0.04074544018839639, J_o = 14.4087031605666
J_b = 0.04260542309642131, J_o = 13.64817691213914
J_b = 0.046479651447877045, J_o = 12.24075536393595
J_b = 0.05268800882375689, J_o = 11.164184164494682
J_b = 0.05002203590781274, J_o = 10.883535516878633
J_b = 0.04874092017698593, J_o = 10.742495727909535
J_b = 0.048363011090166864, J_o = 10.427902097717014
J_b = 0.05027216860634108, J_o = 9.264323767652145
J_b = 0.05578880502754256, J_o = 8.4292018154988
J_b = 0.06757864740330402, J_o = 8.554937557447213
J_b = 0.06077510543508466, J_o = 8.157102531806997
J_b = 0.06512708014690112, J_o = 7.8515668085011034
J_b = 0.06663272098457898, J_o = 7.775584810013948
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
W_opt:  [-1.23545738e-02 -7.74793580e-03  4.14351926e-04  3.42184552e-03
  3.81970890e-03  2.39831405e-05 -7.97582802e-03 -2.07045008e-02
 -4.03320559e-02 -7.02893636e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0987 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1270, add (DA)= 0.0001decode = 0.1302 s, unnorm = 0.0008 s, TOTAL = unnormalising + decoding + minimising = 0.2296 s, inc stats = 0.2362, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93274409 2.76029769 3.38710393 3.00351568 2.49922582]
u_DA:    [3.84681932 2.04640806 2.63955957 1.89271746 2.17688218]
ref_MAE: [0.09228969 0.59851729 0.84816915 1.15096223 0.12259211]
da_MAE:  [0.08592477 0.71388963 0.74754436 1.11079822 0.32234364]
% 19.14743527782789 da_MAE 0.006336218676965021 ref_MAE 0.007836756568870408
u_c taken from control states: [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
u_c before reduction of space:  [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
data[u_c] post encoding of state:  [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
J_b = 0.0, J_o = 2187.5639318644057
J_b = 0.5, J_o = 394749.8659161163
J_b = 0.0020095947724829365, J_o = 380.6748959965301
J_b = 0.00233577938775154, J_o = 243.07310065484495
J_b = 0.002721725778542584, J_o = 206.72973889041938
J_b = 0.002855137290730763, J_o = 196.43158176766235
J_b = 0.005044446103188904, J_o = 132.53749009319577
J_b = 0.00875701610960099, J_o = 90.97337497417274
J_b = 0.01500672328545894, J_o = 56.57518654273044
J_b = 0.01645409942925781, J_o = 47.605797344724614
J_b = 0.017479418662457374, J_o = 42.59076146742682
J_b = 0.01849320165302801, J_o = 39.45087117999179
J_b = 0.021470186185632893, J_o = 32.477275894955575
J_b = 0.02568896371305689, J_o = 26.81407925548787
J_b = 0.028420647869178597, J_o = 23.887937056254785
J_b = 0.03240046581228073, J_o = 20.18510647347628
J_b = 0.03528888117215088, J_o = 20.802150273832893
J_b = 0.033527913952049924, J_o = 18.526037561614608
J_b = 0.03705622257580818, J_o = 16.939151322732123
J_b = 0.03727687493436199, J_o = 16.491500083213396
J_b = 0.03651182050381906, J_o = 16.265804624796672
J_b = 0.036042026668781015, J_o = 16.000737861181136
J_b = 0.03620682846848573, J_o = 15.61476039647551
J_b = 0.037676281753219215, J_o = 15.184695496756186
J_b = 0.04191187321291886, J_o = 14.857370066544778
J_b = 0.04171982985412844, J_o = 13.789654209388233
J_b = 0.042688864908294856, J_o = 12.776743938348334
J_b = 0.04521536207769822, J_o = 11.678837555098763
J_b = 0.04769951226047826, J_o = 11.096990299181126
J_b = 0.05060613732193411, J_o = 11.10601698847471
J_b = 0.04906489865149832, J_o = 10.966744508069265
J_b = 0.05085289875339056, J_o = 10.867164239950693
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
W_opt:  [ 0.00144015 -0.0018608   0.0017856   0.00350468  0.00311534 -0.00043714
 -0.00706419 -0.01725059 -0.03214745 -0.05349329]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0808 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.0450, add (DA)= 0.0001decode = 0.0480 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1289 s, inc stats = 0.1434, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93212621 2.7596687  3.38611754 3.00204374 2.49577772]
u_DA:    [3.84676901 2.04564844 2.63781501 1.89200056 2.17652772]
ref_MAE: [0.09167181 0.59788831 0.84718276 1.14949029 0.11914401]
da_MAE:  [0.0853572  0.71402026 0.74830253 1.11004317 0.31925   ]
% 19.10674269968042 da_MAE 0.006349155590004195 ref_MAE 0.007848806936321888
\% improve_point: 17.02, mse_ref_points: 3.519515298370806e-05, mse_da_points: 2.9203369640931292e-05, % improve_overlap: 17.02, mse_ref_overlap: 0.91676, mse_da_overlap: 0.76069
DA - - L2: 55318.65, L1: 7816.48, % Improve: 18.93%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.760, time(s): 1.7386s,
u_c taken from control states: [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
u_c before reduction of space:  [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
data[u_c] post encoding of state:  [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
J_b = 0.0, J_o = 2189.1704070432743
J_b = 0.5000000000000003, J_o = 388698.87983652414
J_b = 0.002026462417216896, J_o = 394.1162309329517
J_b = 0.002388598821596292, J_o = 245.2008595781723
J_b = 0.0027877545324693893, J_o = 208.78458276927597
J_b = 0.002928869999101943, J_o = 198.01104631254987
J_b = 0.005118399615984131, J_o = 132.99217949141422
J_b = 0.0088315918400522, J_o = 90.41972495761618
J_b = 0.014763330982493496, J_o = 56.378720212086506
J_b = 0.016050330371501637, J_o = 48.10933644549185
J_b = 0.017044116660704208, J_o = 42.96292899135597
J_b = 0.018041819352646263, J_o = 39.69616430399003
J_b = 0.020840436586427678, J_o = 33.25139675490058
J_b = 0.023755019192576183, J_o = 29.054646743599754
J_b = 0.025716598784708933, J_o = 26.59679859725322
J_b = 0.028728019745498063, J_o = 23.118716176013187
J_b = 0.03239630683337977, J_o = 19.560459623616204
J_b = 0.039166749424525485, J_o = 33.10355522223784
J_b = 0.03347029960500379, J_o = 18.90896933475814
J_b = 0.03460488674546022, J_o = 17.80088585341005
J_b = 0.034393598698119074, J_o = 17.546916087956998
J_b = 0.03419050240078154, J_o = 17.360433556171394
J_b = 0.033981769629422204, J_o = 16.873861402738434
J_b = 0.03468797842954391, J_o = 16.130631069456722
J_b = 0.03562772465113673, J_o = 15.583654300432155
J_b = 0.03613928015895489, J_o = 14.971987641299464
J_b = 0.03819020572646085, J_o = 14.335471394909103
J_b = 0.04021177412091131, J_o = 13.14531654383353
J_b = 0.04510032227863479, J_o = 11.788583474005083
J_b = 0.0517786046723839, J_o = 12.563633642300376
J_b = 0.04728700822421346, J_o = 11.475896368604015
J_b = 0.05036716364406517, J_o = 10.75265789070485
J_b = 0.049644370667557405, J_o = 10.627644021014127
J_b = 0.04914086215163473, J_o = 10.42932900132219
J_b = 0.048763648541855775, J_o = 10.162791839264575
J_b = 0.050104734378832234, J_o = 9.586862280838405
J_b = 0.053865727173155964, J_o = 8.911735833491957
J_b = 0.06002573978904237, J_o = 8.260448257796023
J_b = 0.06345887935499213, J_o = 8.023445235039086
J_b = 0.06550072948951716, J_o = 7.580585127990261
J_b = 0.06516480498118334, J_o = 7.488697841860475
J_b = 0.0650384877333855, J_o = 7.339329448877004
J_b = 0.06522601602226527, J_o = 7.249843862332344
J_b = 0.06606893236883299, J_o = 7.120397557574955
J_b = 0.06686815585784393, J_o = 7.043962233057792
J_b = 0.06752529773272334, J_o = 6.999327049149868
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
W_opt:  [-0.01542962 -0.01012674 -0.00088773  0.00255679  0.0031559  -0.00038399
 -0.00823053 -0.0212081  -0.04181895 -0.07406165]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1243 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1260 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2504 s, inc stats = 0.2644, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93148284 2.75868746 3.38513012 3.00036735 2.49167953]
u_DA:    [3.84664476 2.04606681 2.6381546  1.89039777 2.17797639]
ref_MAE: [0.09102844 0.59690706 0.84619533 1.1478139  0.11504582]
da_MAE:  [0.08483808 0.71262065 0.74697552 1.10996958 0.31370314]
% 19.01817973257572 da_MAE 0.006365656684205001 ref_MAE 0.007860599654569197
u_c taken from control states: [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
u_c before reduction of space:  [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
data[u_c] post encoding of state:  [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
J_b = 0.0, J_o = 2186.6536764248895
J_b = 0.49999999999999994, J_o = 383899.7395058976
J_b = 0.002031129905800117, J_o = 409.4946250229741
J_b = 0.0024209320339314455, J_o = 252.44768461221668
J_b = 0.0028305341979455467, J_o = 215.59803027675235
J_b = 0.0029891797517879034, J_o = 203.58767902686344
J_b = 0.005229385561298256, J_o = 135.5052120115445
J_b = 0.009089112144934346, J_o = 89.86375955731287
J_b = 0.014717818462274782, J_o = 55.71418053057896
J_b = 0.01579159728199805, J_o = 48.481765950250534
J_b = 0.016651349382091202, J_o = 43.47397251447687
J_b = 0.01757774994094186, J_o = 40.07957426472977
J_b = 0.020068626986047937, J_o = 34.3092256163075
J_b = 0.022050613542230306, J_o = 31.08020145328783
J_b = 0.02352784788368558, J_o = 29.001632920888287
J_b = 0.02500477486603227, J_o = 26.7946714285088
J_b = 0.027996361021826878, J_o = 22.91359246595107
J_b = 0.03221944850713874, J_o = 26.476934979118795
J_b = 0.02922259452986172, J_o = 21.824793684250974
J_b = 0.03284868860556309, J_o = 18.786873386396785
J_b = 0.03360350151001587, J_o = 17.82031776817879
J_b = 0.03325672665800222, J_o = 17.586081808705735
J_b = 0.03295587602106095, J_o = 17.423851336104796
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
W_opt:  [ 0.00843114 -0.00016625 -0.00296319 -0.0033937  -0.00434063 -0.00682692
 -0.01085036 -0.01657118 -0.02413879 -0.03406804]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0657 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1259 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1917 s, inc stats = 0.2043, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93082942 2.7573624  3.38415054 2.9985557  2.48715691]
u_DA:    [3.84676894 2.04605178 2.63664268 1.8920439  2.18001073]
ref_MAE: [0.09037502 0.595582   0.84521576 1.14600225 0.1105232 ]
da_MAE:  [0.08406048 0.71131062 0.74750786 1.1065118  0.30714618]
% 18.987892409059242 da_MAE 0.00637715115554562 ref_MAE 0.007871849461991716
u_c taken from control states: [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
u_c before reduction of space:  [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
data[u_c] post encoding of state:  [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
J_b = 0.0, J_o = 2168.773013149492
J_b = 0.5000000000000001, J_o = 384135.72846959974
J_b = 0.002001483449299414, J_o = 418.26200794484015
J_b = 0.0023873275634271477, J_o = 262.6417622125602
J_b = 0.002801304530430547, J_o = 224.5863289191999
J_b = 0.002980963681139566, J_o = 210.95905114655295
J_b = 0.005330647832999429, J_o = 138.5923883243301
J_b = 0.00944194580663815, J_o = 89.10769028647452
J_b = 0.01482127660189378, J_o = 54.82472075839516
J_b = 0.015783992720672668, J_o = 48.55378233520994
J_b = 0.01649909005743146, J_o = 44.03430750771239
J_b = 0.017378421686776502, J_o = 40.405465587185176
J_b = 0.0195568657801001, J_o = 35.015386489550515
J_b = 0.021431264987542175, J_o = 31.51590960842649
J_b = 0.02315012439098854, J_o = 28.996957846296965
J_b = 0.024288818142353837, J_o = 27.161373844056715
J_b = 0.026888949891043394, J_o = 23.48220976338057
J_b = 0.03034980558948214, J_o = 22.01192771171875
J_b = 0.032841702629650735, J_o = 18.86875998407675
J_b = 0.032098725953430864, J_o = 18.320302609829206
J_b = 0.03195317480965978, J_o = 18.11251406388689
J_b = 0.03198354713591006, J_o = 17.960287646306224
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
W_opt:  [ 0.00773694 -0.00056565 -0.00354422 -0.00389319 -0.00475296 -0.00708213
 -0.01085216 -0.01623087 -0.02337478 -0.03297964]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0555 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1336, add (DA)= 0.0001decode = 0.1365 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1921 s, inc stats = 0.2057, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93017055 2.7557472  3.38318099 2.99664174 2.4822923 ]
u_DA:    [3.84675259 2.0465197  2.63656636 1.89198166 2.18094601]
ref_MAE: [0.08971615 0.59396681 0.8442462  1.14408829 0.10565859]
da_MAE:  [0.08341796 0.7092275  0.74661463 1.10466007 0.30134629]
% 18.94357658576051 da_MAE 0.0063892527692575645 ref_MAE 0.00788247556471279
u_c taken from control states: [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
u_c before reduction of space:  [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
data[u_c] post encoding of state:  [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
J_b = 0.0, J_o = 2134.2744527361665
J_b = 0.49999999999999994, J_o = 391298.0290908303
J_b = 0.0019345366014768004, J_o = 414.63862555803814
J_b = 0.0022753006702355186, J_o = 272.9247239199483
J_b = 0.0026838963106534447, J_o = 232.9852905456179
J_b = 0.0028823948743348015, J_o = 217.73577869997
J_b = 0.005390442263156795, J_o = 140.7804055275796
J_b = 0.009801681204340827, J_o = 87.99249156814415
J_b = 0.014922917834756464, J_o = 54.26424056579918
J_b = 0.015930828255035348, J_o = 48.54384340183698
J_b = 0.016547084960240176, J_o = 44.71806221834689
J_b = 0.01750621941177447, J_o = 40.529078546569906
J_b = 0.019537412230687275, J_o = 35.18827268709002
J_b = 0.02143109724608361, J_o = 31.397032300716052
J_b = 0.023234999526503305, J_o = 28.674546939376356
J_b = 0.024283176963983, J_o = 26.94003998864637
J_b = 0.026759090451447334, J_o = 23.39845187820988
J_b = 0.030078609659131353, J_o = 22.7482861227292
J_b = 0.03185385328934117, J_o = 19.352950273658895
J_b = 0.03163937067693269, J_o = 18.804531263387773
J_b = 0.031692214702588525, J_o = 18.604991497466248
J_b = 0.031753495822477315, J_o = 18.47259792633515
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
W_opt:  [ 0.00675119 -0.00122429 -0.00404881 -0.00421966 -0.00497856 -0.00722315
 -0.01089493 -0.01616293 -0.02319646 -0.03283117]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0538 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1368 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1907 s, inc stats = 0.2044, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92951115 2.75393726 3.38222197 2.994665   2.47720928]
u_DA:    [3.84678783 2.04729475 2.63741826 1.89361843 2.18122781]
ref_MAE: [0.08905675 0.59215686 0.84328719 1.14211155 0.10057557]
da_MAE:  [0.08272332 0.70664251 0.74480372 1.10104657 0.29598148]
% 18.94349726683427 da_MAE 0.0063971326356394055 ref_MAE 0.007892189299973219
u_c taken from control states: [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
u_c before reduction of space:  [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
data[u_c] post encoding of state:  [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
J_b = 0.0, J_o = 2100.1691336921094
J_b = 0.5000000000000001, J_o = 403883.1297616957
J_b = 0.0018570571542448845, J_o = 400.76205792844735
J_b = 0.0021242145569367104, J_o = 283.608669786353
J_b = 0.002510724572586471, J_o = 242.15306363244514
J_b = 0.0027326196519379562, J_o = 224.87987103337005
J_b = 0.005423407433693749, J_o = 143.58815962586198
J_b = 0.010205731668476959, J_o = 87.34795553423112
J_b = 0.015099330447523067, J_o = 54.50469211768358
J_b = 0.016231074063056097, J_o = 48.855292130728465
J_b = 0.016781094380413333, J_o = 45.540258305545024
J_b = 0.017930555030065586, J_o = 40.55664442549002
J_b = 0.02008796586442187, J_o = 34.85552756025642
J_b = 0.021796276439085202, J_o = 31.529291023763765
J_b = 0.023104123923331974, J_o = 29.463694230720474
J_b = 0.023964660787795012, J_o = 27.933587794960513
J_b = 0.026141700008037748, J_o = 24.621429975010514
J_b = 0.02948950031376371, J_o = 21.860921904162296
J_b = 0.03449377773892821, J_o = 20.6589055730009
J_b = 0.032131953417699165, J_o = 19.31327047945344
J_b = 0.03179424927195584, J_o = 19.15641143401119
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
W_opt:  [ 0.00556089 -0.00201011 -0.00447487 -0.00448397 -0.00519678 -0.00743394
 -0.0111077  -0.01639044 -0.02346991 -0.03325124]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0511 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1209, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1749 s, inc stats = 0.1882, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92885948 2.75202884 3.38127572 2.99267812 2.47212177]
u_DA:    [3.84708634 2.04827064 2.63881862 1.89611278 2.18157896]
ref_MAE: [0.08840508 0.59024844 0.84234093 1.14012467 0.09548806]
da_MAE:  [0.08177314 0.7037582  0.7424571  1.09656534 0.29054282]
% 18.986377724342155 da_MAE 0.006400820411551394 ref_MAE 0.007900918674851857
u_c taken from control states: [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
u_c before reduction of space:  [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
data[u_c] post encoding of state:  [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
J_b = 0.0, J_o = 2089.1166111177877
J_b = 0.4999999999999999, J_o = 417747.1756717424
J_b = 0.0018062019925804214, J_o = 382.43394216621095
J_b = 0.001995919978111545, J_o = 294.1513932926307
J_b = 0.0023437105053826755, J_o = 252.68440348901106
J_b = 0.002605771926858863, J_o = 232.33568075959525
J_b = 0.005482489748065205, J_o = 147.6516582095083
J_b = 0.010729662403575712, J_o = 87.03619234469826
J_b = 0.015420565220032972, J_o = 55.314156377663544
J_b = 0.016636739151391532, J_o = 49.50547446743456
J_b = 0.017147138195772637, J_o = 46.34959119358706
J_b = 0.018476040023237616, J_o = 40.62488914950719
J_b = 0.020969745676282393, J_o = 34.38684970621602
J_b = 0.022482263616172532, J_o = 31.526315963961746
J_b = 0.023393753637751133, J_o = 29.963936076055482
J_b = 0.024080081422103987, J_o = 28.632633373814734
J_b = 0.02607586191412103, J_o = 25.48172127602156
J_b = 0.02965660954514937, J_o = 22.37265143167268
J_b = 0.036426783630074, J_o = 23.304050602971135
J_b = 0.03240756995061465, J_o = 20.85601777470096
J_b = 0.03271427478992701, J_o = 19.923395276956963
J_b = 0.032434515054539696, J_o = 19.715143080153265
J_b = 0.03244884830930448, J_o = 19.658880801202155
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
W_opt:  [ 0.00421476 -0.00244108 -0.00447041 -0.00438813 -0.00514388 -0.00746617
 -0.01123961 -0.016669   -0.02397218 -0.03410205]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0667 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1218, add (DA)= 0.0001decode = 0.1247 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1916 s, inc stats = 0.2053, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92821768 2.75013289 3.38034302 2.99072603 2.46717717]
u_DA:    [3.84775754 2.04914471 2.64137147 1.897717   2.18390944]
ref_MAE: [0.08776328 0.58835249 0.84140823 1.13817258 0.09054346]
da_MAE:  [0.08046013 0.70098818 0.73897155 1.09300902 0.28326774]
% 19.002431888057345 da_MAE 0.006405842277517505 ref_MAE 0.007908684701081782
u_c taken from control states: [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
u_c before reduction of space:  [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
data[u_c] post encoding of state:  [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
J_b = 0.0, J_o = 2110.695694999571
J_b = 0.5000000000000001, J_o = 428957.7007530549
J_b = 0.0017995328882387796, J_o = 364.98359538503644
J_b = 0.0019267566097053558, J_o = 302.52837879917246
J_b = 0.002233057929809041, J_o = 262.243179876668
J_b = 0.0025619725348166246, J_o = 237.50918320287795
J_b = 0.005668929893283007, J_o = 150.4779557476777
J_b = 0.01145416102320907, J_o = 85.53086795965501
J_b = 0.015782774724783667, J_o = 56.880473099331695
J_b = 0.016901084908978386, J_o = 51.20758569880681
J_b = 0.017381373177137494, J_o = 47.917934684275316
J_b = 0.01878115193591584, J_o = 41.6337846793094
J_b = 0.021584361045954473, J_o = 34.89624060642916
J_b = 0.022970316226021314, J_o = 32.0857593571068
J_b = 0.023669799869836788, J_o = 30.725937545319574
J_b = 0.02421022466934809, J_o = 29.546224012259955
J_b = 0.02604193261694895, J_o = 26.475931232121532
J_b = 0.02963593160546534, J_o = 22.91382738899098
J_b = 0.040957205179285056, J_o = 51.98033343695638
J_b = 0.030828241565425817, J_o = 22.27676879746696
J_b = 0.03325415226803349, J_o = 20.486169093208222
J_b = 0.033457436806725804, J_o = 20.088332185474414
J_b = 0.033250527409753386, J_o = 20.02019943139583
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
W_opt:  [ 0.00264888 -0.00248333 -0.00412074 -0.00409277 -0.00496518 -0.00740395
 -0.01129541 -0.0168836  -0.02439417 -0.03476888]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0648 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1234, add (DA)= 0.0001decode = 0.1263 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1912 s, inc stats = 0.1965, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92757809 2.74838944 3.37941998 2.98883206 2.46234823]
u_DA:    [3.84843785 2.04921083 2.64426539 1.89857452 2.18536505]
ref_MAE: [0.08712369 0.58660904 0.8404852  1.13627861 0.08571452]
da_MAE:  [0.07914024 0.69917861 0.73515459 1.09025754 0.27698318]
% 19.050744179161953 da_MAE 0.006407610353341317 ref_MAE 0.00791558895553412
u_c taken from control states: [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
u_c before reduction of space:  [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
data[u_c] post encoding of state:  [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
J_b = 0.0, J_o = 2153.005085039101
J_b = 0.5, J_o = 435299.28145683516
J_b = 0.0018274943295842532, J_o = 352.10463960892577
J_b = 0.0019172082714508333, J_o = 306.31985760634296
J_b = 0.0021976205011109916, J_o = 267.02224354285084
J_b = 0.002609070841035762, J_o = 237.76491237450344
J_b = 0.005999634543515781, J_o = 149.27515293453055
J_b = 0.01224532031743794, J_o = 82.11971145210619
J_b = 0.016060559786094712, J_o = 58.4823595815838
J_b = 0.016912232070563915, J_o = 53.57184037958868
J_b = 0.017359853706159962, J_o = 50.05907934033871
J_b = 0.01873808073696854, J_o = 43.380142409710274
J_b = 0.021499235092976292, J_o = 36.10013282103837
J_b = 0.02309086108838529, J_o = 33.14359371732565
J_b = 0.02367727448273604, J_o = 32.041088478253464
J_b = 0.02409917516541662, J_o = 31.008970135771065
J_b = 0.025336493313410178, J_o = 28.518529934479155
J_b = 0.0282595926511526, J_o = 24.757708694098586
J_b = 0.035784434557233416, J_o = 29.182576090563032
J_b = 0.03037184790568328, J_o = 23.639394978277075
J_b = 0.03497765789762192, J_o = 20.422230366946906
J_b = 0.035852362517261274, J_o = 19.65248856601443
J_b = 0.0355947767407411, J_o = 19.503296499721102
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
W_opt:  [ 0.00160847 -0.00226323 -0.00356857 -0.00359637 -0.00459686 -0.007225
 -0.01137202 -0.01734861 -0.02539162 -0.03637177]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0595 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1248 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1844 s, inc stats = 0.1966, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92694327 2.74689826 3.3785102  2.98706884 2.45774389]
u_DA:    [3.84901746 2.04986247 2.64441231 1.89859636 2.18664845]
ref_MAE: [0.08648887 0.58511786 0.83957541 1.13451539 0.08111018]
da_MAE:  [0.07792581 0.69703579 0.73409788 1.08847248 0.27109545]
% 19.08681401677024 da_MAE 0.00640959190391861 ref_MAE 0.007921566585262229
u_c taken from control states: [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
u_c before reduction of space:  [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
data[u_c] post encoding of state:  [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
J_b = 0.0, J_o = 2199.453049766131
J_b = 0.5, J_o = 437610.76147942466
J_b = 0.0018697813877484295, J_o = 344.3103800911292
J_b = 0.0019433908313715121, J_o = 305.99177087869174
J_b = 0.0022121339805510286, J_o = 267.41654885329206
J_b = 0.0026743163006793884, J_o = 235.88408774972015
J_b = 0.006235371740967371, J_o = 147.4883444977682
J_b = 0.012698228224141482, J_o = 80.199908008287
J_b = 0.01622129357324655, J_o = 59.5789644881599
J_b = 0.01694729467810044, J_o = 55.13037322564883
J_b = 0.017410953413683847, J_o = 51.4083563990523
J_b = 0.018826648992016113, J_o = 44.50725571483919
J_b = 0.02165791863789586, J_o = 36.92116504724992
J_b = 0.02334180850837949, J_o = 33.83222841550226
J_b = 0.023877859428027778, J_o = 32.77983750755246
J_b = 0.02426688176348032, J_o = 31.744233672065256
J_b = 0.02538830998236085, J_o = 29.317454731402144
J_b = 0.028259697142984156, J_o = 25.44609255506161
J_b = 0.03413603493885519, J_o = 20.982978885383044
J_b = 0.040674917565887446, J_o = 27.40720773934527
J_b = 0.03555164408750866, J_o = 20.329599130769882
J_b = 0.037144902188364436, J_o = 19.248283793745085
J_b = 0.03675611459595676, J_o = 19.056634599575315
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
W_opt:  [ 0.00094783 -0.00200453 -0.00294101 -0.00303535 -0.00413921 -0.00692729
 -0.01130491 -0.01762347 -0.02611043 -0.03743708]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0563 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1209, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1801 s, inc stats = 0.1938, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92632745 2.74568866 3.37762437 2.98554036 2.45361818]
u_DA:    [3.84934137 2.05026557 2.64388084 1.89911465 2.18703634]
ref_MAE: [0.08587305 0.58390826 0.83868959 1.13298691 0.07698447]
da_MAE:  [0.07698608 0.69542309 0.73374353 1.08642572 0.26658184]
% 19.113298608835173 da_MAE 0.0064116969586349385 ref_MAE 0.007926762803230448
u_c taken from control states: [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
u_c before reduction of space:  [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
data[u_c] post encoding of state:  [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
J_b = 0.0, J_o = 2240.3863337224316
J_b = 0.5000000000000001, J_o = 437419.20997228706
J_b = 0.001912276875060468, J_o = 341.1033131116709
J_b = 0.0019843090447173852, J_o = 303.5868020126319
J_b = 0.0022449725102674407, J_o = 266.1922595926763
J_b = 0.0026876653145598843, J_o = 235.85620788535226
J_b = 0.006156465540136579, J_o = 149.50352777373962
J_b = 0.01258666441246204, J_o = 82.69434663902854
J_b = 0.016353861093723263, J_o = 60.42841792544495
J_b = 0.01721919590682379, J_o = 55.47581296596823
J_b = 0.01773578567081517, J_o = 51.6275314619873
J_b = 0.019251884154065133, J_o = 44.56366905586299
J_b = 0.022216917031460042, J_o = 36.88342173256262
J_b = 0.023816029161366537, J_o = 33.94815091398405
J_b = 0.024377554682155102, J_o = 32.82956077680808
J_b = 0.024881837142524364, J_o = 31.60183254229488
J_b = 0.02630157421450676, J_o = 28.844578358696644
J_b = 0.029581836071367964, J_o = 24.773435836429186
J_b = 0.03931444965979243, J_o = 21.1301475659796
J_b = 0.043274500596820045, J_o = 27.85039795869404
J_b = 0.040202053753214076, J_o = 20.447083112853637
J_b = 0.038324534797321855, J_o = 19.479873202211568
J_b = 0.03794642477184647, J_o = 18.794841304244603
J_b = 0.038145573671676584, J_o = 18.641832509915638
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
W_opt:  [ 0.00130066 -0.00149352 -0.0023101  -0.00257183 -0.00379889 -0.0067174
 -0.01125045 -0.01778069 -0.02654274 -0.03807923]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0952 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1205, add (DA)= 0.0001decode = 0.1234 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2187 s, inc stats = 0.2309, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92572808 2.74479837 3.37676221 2.98428214 2.4499543 ]
u_DA:    [3.84943238 2.04987534 2.64396457 1.89908476 2.1865962 ]
ref_MAE: [0.08527367 0.58301797 0.83782743 1.13172869 0.07332059]
da_MAE:  [0.0762957  0.69492303 0.73279764 1.08519738 0.2633581 ]
% 19.15331329007386 da_MAE 0.0064122998095500665 ref_MAE 0.007931431788363915
\% improve_point: 17.06, mse_ref_points: 3.548769883269102e-05, mse_da_points: 2.942983836772835e-05, % improve_overlap: 17.06, mse_ref_overlap: 0.92439, mse_da_overlap: 0.76660
DA - - L2: 49689.04, L1: 7749.84, % Improve: 18.94%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.766, time(s): 1.5503s,
u_c taken from control states: [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
u_c before reduction of space:  [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
data[u_c] post encoding of state:  [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
J_b = 0.0, J_o = 2266.7560106655264
J_b = 0.5000000000000002, J_o = 435740.2445185068
J_b = 0.0019453632822275177, J_o = 339.8401356252887
J_b = 0.0020255967476673783, J_o = 298.5958833589986
J_b = 0.0022805616171135117, J_o = 262.71948161812253
J_b = 0.0026548012683957774, J_o = 236.066418211
J_b = 0.00584082406170638, J_o = 153.37514592913098
J_b = 0.012022751475010841, J_o = 87.87196968571116
J_b = 0.016478164581049518, J_o = 60.150747841006904
J_b = 0.017765981171130624, J_o = 53.83657897410707
J_b = 0.018375766065237723, J_o = 49.98114248861697
J_b = 0.020035270158375397, J_o = 43.034063972219016
J_b = 0.023280597647959398, J_o = 35.66944746281266
J_b = 0.02453565259981631, J_o = 32.90496648182538
J_b = 0.02555741346258224, J_o = 30.93935080640697
J_b = 0.026438213925860883, J_o = 29.306903038091612
J_b = 0.029197379064745437, J_o = 25.355147668135647
J_b = 0.03443217462554059, J_o = 23.188969992638043
J_b = 0.03770230173449352, J_o = 20.227601715632865
J_b = 0.036779447362533545, J_o = 19.662248715372503
J_b = 0.036660947303573506, J_o = 19.485958994189666
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
W_opt:  [ 0.00267472 -0.00083631 -0.00197013 -0.00252391 -0.00384134 -0.00672143
 -0.0111169  -0.01734008 -0.0255215  -0.03601719]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0539 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1201, add (DA)= 0.0001decode = 0.1230 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1770 s, inc stats = 0.1851, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92513842 2.7442818  3.37591942 2.98331164 2.44664595]
u_DA:    [3.84934655 2.04915836 2.64415658 1.89839691 2.18503378]
ref_MAE: [0.08468402 0.5825014  0.83698464 1.13075819 0.07001224]
da_MAE:  [0.07579188 0.69512344 0.73176284 1.08491473 0.26161217]
% 19.17950916054533 da_MAE 0.00641387217576667 ref_MAE 0.007935948061126557
u_c taken from control states: [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
u_c before reduction of space:  [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
data[u_c] post encoding of state:  [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
J_b = 0.0, J_o = 2279.9841341549795
J_b = 0.49999999999999994, J_o = 433332.3132926405
J_b = 0.001967674907678011, J_o = 340.2734595635286
J_b = 0.002061567246095498, J_o = 292.8348988711725
J_b = 0.0023176485333116256, J_o = 257.9771201337058
J_b = 0.002625419153129307, J_o = 235.16687810384954
J_b = 0.005545230439445936, J_o = 156.0349107284506
J_b = 0.011413511422793843, J_o = 92.6132563713114
J_b = 0.016703846190765367, J_o = 58.678234684890924
J_b = 0.018473863182755436, J_o = 51.182899479951146
J_b = 0.019171015620764943, J_o = 47.50953582866272
J_b = 0.020878830401518774, J_o = 41.16393477071863
J_b = 0.02408277471016492, J_o = 34.42107588610564
J_b = 0.025539711851970796, J_o = 31.15040819276702
J_b = 0.02758189557849013, J_o = 27.87134761742264
J_b = 0.029382886429094996, J_o = 25.471337524866602
J_b = 0.0334357314233222, J_o = 21.432620443553034
J_b = 0.04746438310745437, J_o = 52.56929940798415
J_b = 0.034782426553664564, J_o = 20.96630681752275
J_b = 0.036359236313278524, J_o = 19.76987858338346
J_b = 0.03680258238216583, J_o = 19.434468402494293
J_b = 0.03692900152956502, J_o = 19.333173318476106
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
W_opt:  [ 0.00370816 -0.00037465 -0.00157142 -0.00225569 -0.00364618 -0.00659678
 -0.01106877 -0.01733902 -0.02550146 -0.03580116]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0654 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1201, add (DA)= 0.0001decode = 0.1231 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1886 s, inc stats = 0.2026, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92455714 2.74415506 3.37509882 2.98265846 2.44365566]
u_DA:    [3.84919952 2.04819509 2.64460193 1.89809198 2.18381149]
ref_MAE: [0.08410274 0.58237467 0.83616403 1.130105   0.06702195]
da_MAE:  [0.07535762 0.69595997 0.73049689 1.08456648 0.25984417]
% 19.187403293821006 da_MAE 0.006416971744810424 ref_MAE 0.007940558782118403
u_c taken from control states: [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
u_c before reduction of space:  [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
data[u_c] post encoding of state:  [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
J_b = 0.0, J_o = 2283.953692423429
J_b = 0.4999999999999999, J_o = 430620.504723015
J_b = 0.001980986377516293, J_o = 342.4836657451265
J_b = 0.002091174115903, J_o = 287.7443770509278
J_b = 0.0023548389120653097, J_o = 253.19884910783412
J_b = 0.002614816165835133, J_o = 233.37684769203477
J_b = 0.005357444196752258, J_o = 156.80998472282954
J_b = 0.010947361412572134, J_o = 95.721604891003
J_b = 0.017005863363479572, J_o = 57.24761195236791
J_b = 0.01896670446249719, J_o = 49.475465769236536
J_b = 0.019745101845657986, J_o = 45.85933151030857
J_b = 0.021281249192191255, J_o = 40.46366883557647
J_b = 0.023743067057550513, J_o = 34.510641334659425
J_b = 0.025645072874258004, J_o = 31.224552191610538
J_b = 0.02749044332168447, J_o = 28.598720336343586
J_b = 0.03011599687139933, J_o = 25.403948349701018
J_b = 0.03391396567687183, J_o = 21.53480455056732
J_b = 0.05154251252199196, J_o = 50.72235015883804
J_b = 0.03565543050270476, J_o = 21.067935835364242
J_b = 0.03789757504207418, J_o = 19.545655881824178
J_b = 0.0374686871553081, J_o = 19.17143265806899
J_b = 0.037175865721820585, J_o = 19.07561002839083
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
W_opt:  [ 4.65000456e-03  4.88499080e-06 -1.23862933e-03 -1.98862762e-03
 -3.41299055e-03 -6.41774318e-03 -1.09701318e-02 -1.73109640e-02
 -2.55164194e-02 -3.57542824e-02]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0544 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1325, add (DA)= 0.0001decode = 0.1354 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1900 s, inc stats = 0.2036, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92397928 2.74441606 3.37430267 2.98233001 2.44083538]
u_DA:    [3.84897045 2.0471757  2.64507218 1.89818988 2.18240659]
ref_MAE: [0.08352488 0.58263566 0.83536788 1.12977656 0.06420167]
da_MAE:  [0.07500883 0.69724036 0.72923049 1.08414014 0.25842879]
% 19.190194229751956 da_MAE 0.0064208295574565005 ref_MAE 0.00794560696719367
u_c taken from control states: [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
u_c before reduction of space:  [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
data[u_c] post encoding of state:  [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
J_b = 0.0, J_o = 2281.2614899512214
J_b = 0.5000000000000001, J_o = 427529.26300011296
J_b = 0.0019885914812189974, J_o = 345.8563528694066
J_b = 0.002117824544179716, J_o = 282.7403880278741
J_b = 0.0023937413341972094, J_o = 248.04214618626887
J_b = 0.002618317384449467, J_o = 230.58809016101202
J_b = 0.005242981811804844, J_o = 155.95439732075366
J_b = 0.010578785368348182, J_o = 97.41231837028572
J_b = 0.01729268709585316, J_o = 56.489755802449494
J_b = 0.019149576644167284, J_o = 48.660682572585934
J_b = 0.020082122648624096, J_o = 44.55093206339404
J_b = 0.02128226237602669, J_o = 40.39584249560537
J_b = 0.02331578190652639, J_o = 35.48969012517708
J_b = 0.025103425212234225, J_o = 32.502157879597505
J_b = 0.026349146460969485, J_o = 30.609520169684878
J_b = 0.028298423863549662, J_o = 27.800276908805877
J_b = 0.03175367783966992, J_o = 23.59226982023356
J_b = 0.0401152419509013, J_o = 27.673370531926267
J_b = 0.03422905915753019, J_o = 22.435253836188423
J_b = 0.038003403828127856, J_o = 19.481729353553558
J_b = 0.03828672795566605, J_o = 18.737745479063534
J_b = 0.03791560645671332, J_o = 18.560063996102304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
W_opt:  [ 0.00543341  0.00028158 -0.00097388 -0.001742   -0.00317792 -0.00623936
 -0.01089762 -0.01736559 -0.02573523 -0.0361668 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0543 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1793 s, inc stats = 0.1932, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92340902 2.74504147 3.37353624 2.98234935 2.43815919]
u_DA:    [3.84875656 2.04680966 2.64482179 1.89861937 2.18155686]
ref_MAE: [0.08295462 0.58326107 0.83460145 1.1297959  0.06152548]
da_MAE:  [0.07465247 0.69823181 0.72871444 1.08372997 0.25660233]
% 19.174367289158713 da_MAE 0.006426378010371458 ref_MAE 0.00795091581078273
u_c taken from control states: [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
u_c before reduction of space:  [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
data[u_c] post encoding of state:  [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
J_b = 0.0, J_o = 2276.4421964157486
J_b = 0.5000000000000001, J_o = 423793.24514703685
J_b = 0.001995705625171572, J_o = 350.6587280964317
J_b = 0.0021480625258811204, J_o = 277.61689715247866
J_b = 0.0024404359903099416, J_o = 242.45815436853866
J_b = 0.0026368090316535547, J_o = 227.00579830537552
J_b = 0.005178145821387063, J_o = 154.0267420330573
J_b = 0.01026344777156841, J_o = 98.32185843913287
J_b = 0.017501292985329712, J_o = 56.7319766055695
J_b = 0.019156624829923766, J_o = 48.35044811137854
J_b = 0.020192468548930694, J_o = 43.499110082385585
J_b = 0.021116071297730847, J_o = 40.405796268307896
J_b = 0.023395570912205024, J_o = 35.23577288426863
J_b = 0.025624218574790206, J_o = 31.866527480469053
J_b = 0.027180207789843033, J_o = 29.73626046098608
J_b = 0.029846363296328362, J_o = 26.322513204719506
J_b = 0.033836626946879375, J_o = 21.996051876953786
J_b = 0.055486776710677733, J_o = 63.74671433269468
J_b = 0.03552782553799238, J_o = 21.57959582973371
J_b = 0.03873963318730702, J_o = 19.337987160738464
J_b = 0.03828420540463288, J_o = 18.890234965990224
J_b = 0.037948456627321776, J_o = 18.73118298122212
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
W_opt:  [ 0.00630373  0.00036795 -0.00102994 -0.00181383 -0.00323218 -0.00627734
 -0.01092704 -0.01734912 -0.02563414 -0.03592686]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0544 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.0471, add (DA)= 0.0001decode = 0.0500 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1045 s, inc stats = 0.1139, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92286238 2.74596868 3.37280446 2.98276285 2.43580646]
u_DA:    [3.84849026 2.04662572 2.64407784 1.89939212 2.18096299]
ref_MAE: [0.08240798 0.58418828 0.83386967 1.1302094  0.05917275]
da_MAE:  [0.07437212 0.69934296 0.72872662 1.08337073 0.25484346]
% 19.145507438280667 da_MAE 0.006433068039170151 ref_MAE 0.00795635200389087
u_c taken from control states: [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
u_c before reduction of space:  [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
data[u_c] post encoding of state:  [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
J_b = 0.0, J_o = 2271.496591877597
J_b = 0.5, J_o = 419046.50092764513
J_b = 0.002005249816903005, J_o = 357.6096304027401
J_b = 0.0021869670674680946, J_o = 272.36122160432814
J_b = 0.002500535565833664, J_o = 236.48892021285087
J_b = 0.002673935792714732, J_o = 222.75776478589557
J_b = 0.005155059329020004, J_o = 151.2890381448169
J_b = 0.009985291925085146, J_o = 98.6509990271174
J_b = 0.017591991025891283, J_o = 57.58106830104478
J_b = 0.019112807135212545, J_o = 48.168423520498976
J_b = 0.020076527673013263, J_o = 43.21540355398657
J_b = 0.02093524583102454, J_o = 40.538921991454295
J_b = 0.023650090281317825, J_o = 34.35353623645894
J_b = 0.02705106968924092, J_o = 29.65355550020937
J_b = 0.029673628079780637, J_o = 26.665247967398955
J_b = 0.03401552218261713, J_o = 22.44853766836583
J_b = 0.036934428018393334, J_o = 21.213938423257588
J_b = 0.03935281741253085, J_o = 19.08104687105208
J_b = 0.03791082141609391, J_o = 18.610147454277598
J_b = 0.037630793133964835, J_o = 18.530423270541494
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
W_opt:  [ 0.00701606  0.00045107 -0.00098654 -0.00170489 -0.00305589 -0.00605155
 -0.01067522 -0.01706824 -0.02535986 -0.03573303]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0495 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1375, add (DA)= 0.0001decode = 0.1403 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1899 s, inc stats = 0.2037, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9223578  2.74708172 3.37210801 2.98360705 2.43400274]
u_DA:    [3.84825009 2.0465465  2.64280663 1.89980868 2.18007867]
ref_MAE: [0.0819034  0.58530132 0.83317322 1.1310536  0.05736903]
da_MAE:  [0.07410771 0.70053521 0.72930138 1.08379837 0.25392407]
% 19.11238050536057 da_MAE 0.0064400984671590285 ref_MAE 0.007961785137694435
u_c taken from control states: [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
u_c before reduction of space:  [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
data[u_c] post encoding of state:  [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
J_b = 0.0, J_o = 2269.111297582092
J_b = 0.4999999999999999, J_o = 412761.3978725017
J_b = 0.0020214126954499387, J_o = 367.7723865197162
J_b = 0.0022419687906359113, J_o = 267.06782397125005
J_b = 0.0025818301764134475, J_o = 230.35773369949254
J_b = 0.002736456665360436, J_o = 218.11426230467163
J_b = 0.00516672440762479, J_o = 148.2170347006948
J_b = 0.009724769659369721, J_o = 98.82369638894548
J_b = 0.017516402304808786, J_o = 58.817556936973915
J_b = 0.01902996427290953, J_o = 48.360651337273865
J_b = 0.019882458111693826, J_o = 43.714590821692134
J_b = 0.020757872981896047, J_o = 40.99191875763011
J_b = 0.023552564493034975, J_o = 34.43713969989793
J_b = 0.028123094719961567, J_o = 28.41392538258738
J_b = 0.03144753990133345, J_o = 25.06387683709418
J_b = 0.03617354960349813, J_o = 20.99582043907041
J_b = 0.03899156302953709, J_o = 83.50433002766482
J_b = 0.03627318474408317, J_o = 20.794718793356147
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
W_opt:  [ 0.00846974  0.00080818 -0.00155612 -0.00248996 -0.00380741 -0.00659826
 -0.01087175 -0.01671548 -0.02424955 -0.03363402]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0442 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1258 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1702 s, inc stats = 0.1834, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92189685 2.7482563  3.3714445  2.98482663 2.43267036]
u_DA:    [3.84798379 2.04639603 2.6406111  1.89933747 2.17811318]
ref_MAE: [0.08144245 0.5864759  0.83250972 1.13227318 0.05603665]
da_MAE:  [0.07391306 0.70186027 0.7308334  1.08548916 0.25455718]
% 19.09899877621768 da_MAE 0.006445565530269715 ref_MAE 0.00796722590915837
u_c taken from control states: [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
u_c before reduction of space:  [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
data[u_c] post encoding of state:  [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
J_b = 0.0, J_o = 2272.7268597031643
J_b = 0.49999999999999994, J_o = 404768.5798015308
J_b = 0.0020491464281661544, J_o = 380.96369532003786
J_b = 0.0023193096747676743, J_o = 261.64853663430495
J_b = 0.0026882602775911155, J_o = 224.26027592162046
J_b = 0.0028294513424946934, J_o = 213.16282627506575
J_b = 0.0052034381388506665, J_o = 144.97771782147316
J_b = 0.00947261808032818, J_o = 98.69496029298358
J_b = 0.017161385053390293, J_o = 59.9085455863748
J_b = 0.018744635469676786, J_o = 48.98145866112823
J_b = 0.019559637932271744, J_o = 44.4806850845351
J_b = 0.020485520359390535, J_o = 41.55464274592742
J_b = 0.023338912436163827, J_o = 34.73784545211259
J_b = 0.02884977681567562, J_o = 27.639989451826352
J_b = 0.03253887417968062, J_o = 24.174143028852395
J_b = 0.037146191211568355, J_o = 20.36392481985942
J_b = 0.04003177520993453, J_o = 50.57475351607689
J_b = 0.03731777288990006, J_o = 20.202317175694695
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
W_opt:  [ 0.00918302  0.00064145 -0.00177035 -0.0025449  -0.00377401 -0.00656391
 -0.01093242 -0.01696894 -0.02480551 -0.03459266]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0462 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1223, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1715 s, inc stats = 0.1838, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9214674  2.74953686 3.37080836 2.98633923 2.43163117]
u_DA:    [3.84760732 2.04584797 2.63843601 1.89724774 2.17711043]
ref_MAE: [0.081013   0.58775646 0.83187358 1.13378578 0.05499746]
da_MAE:  [0.07386009 0.70368889 0.73237235 1.08909149 0.25452074]
% 19.063830386069966 da_MAE 0.006452726017603132 ref_MAE 0.007972611069170915
u_c taken from control states: [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
u_c before reduction of space:  [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
data[u_c] post encoding of state:  [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
J_b = 0.0, J_o = 2279.8641913268984
J_b = 0.5000000000000001, J_o = 395662.7455901435
J_b = 0.0020844835302604287, J_o = 396.6741211470147
J_b = 0.0024115464361126643, J_o = 257.5931020832895
J_b = 0.002806901227994068, J_o = 220.01361920660202
J_b = 0.002942489557693178, J_o = 209.5050312622199
J_b = 0.005249930024905951, J_o = 142.76677900586014
J_b = 0.009262786463325625, J_o = 98.58991987262232
J_b = 0.016621896851472424, J_o = 60.72717877174852
J_b = 0.018229485570756952, J_o = 49.895692433369035
J_b = 0.01910684240222768, J_o = 45.21103179393017
J_b = 0.02011038677051156, J_o = 42.06208504957164
J_b = 0.023128248507685363, J_o = 34.84052495653552
J_b = 0.02896229971741805, J_o = 27.364190898446616
J_b = 0.03265516464570489, J_o = 23.920714402554545
J_b = 0.03707811450616854, J_o = 20.21499793614069
J_b = 0.03979759143348116, J_o = 32.82701921142262
J_b = 0.037393228771316525, J_o = 19.934023801692874
J_b = 0.03895412080857348, J_o = 18.743109271502057
J_b = 0.038838433932755934, J_o = 18.199151331733255
J_b = 0.03846883633187852, J_o = 17.58292796100462
J_b = 0.0383930448431858, J_o = 17.03999910743096
J_b = 0.040625997283598746, J_o = 16.316173887773843
J_b = 0.04794205329307432, J_o = 22.956297260211134
J_b = 0.04198950783429981, J_o = 15.461084516096498
J_b = 0.044687726835451066, J_o = 14.570101336669072
J_b = 0.049301887294824064, J_o = 13.222190258892823
J_b = 0.05307810373886086, J_o = 12.36657530904353
J_b = 0.052186403745414965, J_o = 12.854516506136623
J_b = 0.05243889325484796, J_o = 11.811188159303923
J_b = 0.05393322259626257, J_o = 11.507513668501492
J_b = 0.05456768237181519, J_o = 11.302059018243254
J_b = 0.05404870406626617, J_o = 11.231392097311508
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
W_opt:  [ 0.00140447 -0.0020394   0.0022462   0.00415197  0.00388468  0.00056921
 -0.00576365 -0.01563432 -0.03041457 -0.05201485]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0850 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1222, add (DA)= 0.0001decode = 0.1251 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2102 s, inc stats = 0.2207, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92106759 2.75092824 3.37019613 2.98806585 2.430809  ]
u_DA:    [3.84691091 2.04515837 2.63786954 1.89229046 2.17492436]
ref_MAE: [0.08061318 0.58914785 0.83126135 1.1355124  0.05417529]
da_MAE:  [0.07415667 0.70576987 0.7323266  1.09577539 0.25588465]
% 18.98706488499408 da_MAE 0.006463067087330328 ref_MAE 0.00797782116911992
u_c taken from control states: [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
u_c before reduction of space:  [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
data[u_c] post encoding of state:  [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
J_b = 0.0, J_o = 2287.0003091954663
J_b = 0.49999999999999994, J_o = 386949.82218709256
J_b = 0.0021193411491865284, J_o = 412.4466017753195
J_b = 0.0025010394525150164, J_o = 256.0088755216184
J_b = 0.0029145795154740346, J_o = 218.77742442339084
J_b = 0.0030531035078545433, J_o = 208.22082645900247
J_b = 0.005298480369171626, J_o = 142.08757200132294
J_b = 0.009150833588035732, J_o = 98.3857125182004
J_b = 0.016109506813989125, J_o = 61.01031444048458
J_b = 0.01761419626882741, J_o = 50.63108134519851
J_b = 0.018557913594937046, J_o = 45.6177246722652
J_b = 0.019605404626637547, J_o = 42.30942416236775
J_b = 0.02269788553890711, J_o = 35.01357577414679
J_b = 0.027635411831668656, J_o = 28.467943018120376
J_b = 0.03088279135412102, J_o = 25.144925280543635
J_b = 0.035222106300452256, J_o = 21.18371496660898
J_b = 0.03875463053525255, J_o = 23.58451609425181
J_b = 0.036360487193650766, J_o = 19.619867666153393
J_b = 0.03956971624934632, J_o = 18.134490564219405
J_b = 0.039047760733629415, J_o = 17.396981964815094
J_b = 0.03872271505582252, J_o = 17.201981875788597
J_b = 0.038492646756325764, J_o = 16.37390645267208
J_b = 0.04019931948096944, J_o = 16.5546797998927
J_b = 0.03921303252333412, J_o = 16.062586457399103
J_b = 0.040856312268056756, J_o = 15.12035594488983
J_b = 0.04516951523032317, J_o = 14.134656005909665
J_b = 0.04983938866183243, J_o = 13.147896563298387
J_b = 0.05261545101931339, J_o = 12.038038751554376
J_b = 0.05381866555777227, J_o = 11.529350642537448
J_b = 0.05282095229002685, J_o = 11.405427774056424
J_b = 0.05191753344112325, J_o = 11.344701952132548
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
W_opt:  [ 0.00425819 -0.00128034  0.00160595  0.00324351  0.00296109 -0.00017044
 -0.00615301 -0.01553194 -0.02947372 -0.0497119 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0829 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1191, add (DA)= 0.0001decode = 0.1220 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2050 s, inc stats = 0.2165, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92069404 2.75243413 3.36960224 2.98986908 2.42994432]
u_DA:    [3.8467394  2.04517001 2.6366719  1.88982303 2.17545816]
ref_MAE: [0.08023964 0.59065374 0.83066746 1.13731563 0.05331061]
da_MAE:  [0.07395464 0.70726412 0.73293034 1.10004606 0.25448616]
% 18.915621209837248 da_MAE 0.006473041822377575 ref_MAE 0.007983093561250655
\% improve_point: 17.09, mse_ref_points: 3.580367588735654e-05, mse_da_points: 2.9684179043346835e-05, % improve_overlap: 17.09, mse_ref_overlap: 0.93263, mse_da_overlap: 0.77323
DA - - L2: 44917.31, L1: 7508.37, % Improve: 18.96%, DA_MAE: 0.01, mse_ref: 0.93, mse_DA: 0.773, time(s): 1.4013s,
u_c taken from control states: [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
u_c before reduction of space:  [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
data[u_c] post encoding of state:  [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
J_b = 0.0, J_o = 2290.0151058459996
J_b = 0.49999999999999994, J_o = 380478.4235504379
J_b = 0.0021417796838374956, J_o = 426.0265814397877
J_b = 0.0025636694818845646, J_o = 257.90937526214657
J_b = 0.0029865409851278406, J_o = 221.1047103192035
J_b = 0.003134705271359764, J_o = 209.966477817186
J_b = 0.00535326317015236, J_o = 143.16163644102372
J_b = 0.009183898937256943, J_o = 98.26484594709527
J_b = 0.01583310103710589, J_o = 60.89497768753489
J_b = 0.017144048561828565, J_o = 51.174428225479446
J_b = 0.01807316271855218, J_o = 45.928810345818874
J_b = 0.019095212737669464, J_o = 42.56101623174264
J_b = 0.022101726248157375, J_o = 35.612685367459484
J_b = 0.02566163030695725, J_o = 30.609251651649284
J_b = 0.02820179540294689, J_o = 27.65730295450105
J_b = 0.031720737490160134, J_o = 23.845610988564214
J_b = 0.035724214768668376, J_o = 20.141154793296344
J_b = 0.041801318936107536, J_o = 28.74579612293326
J_b = 0.03700370353621438, J_o = 19.293857316907236
J_b = 0.03738016575805701, J_o = 18.409001977773592
J_b = 0.03704242622677807, J_o = 18.156320093446585
J_b = 0.036794514602324344, J_o = 17.832390457976214
J_b = 0.03684628820778037, J_o = 17.179892042626143
J_b = 0.03868074306756822, J_o = 16.331178067952493
J_b = 0.039700327669327504, J_o = 19.97787629198825
J_b = 0.03880166104172013, J_o = 15.913210693737629
J_b = 0.04058047194123249, J_o = 15.357196817869323
J_b = 0.042390287531902576, J_o = 14.825480735070158
J_b = 0.04430872064049625, J_o = 14.095563201796782
J_b = 0.04679569961714078, J_o = 13.102757500112347
J_b = 0.05238350012626369, J_o = 12.332184421509547
J_b = 0.05530328166519425, J_o = 11.391784243576984
J_b = 0.05339905045334589, J_o = 11.185957470109456
J_b = 0.0527980696673558, J_o = 11.107022011827073
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
W_opt:  [ 0.00510203 -0.00178187  0.00054494  0.00229906  0.00212944 -0.00090655
 -0.00682033 -0.01623279 -0.03019597 -0.05046448]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0931 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1247 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2179 s, inc stats = 0.2256, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92034331 2.75401291 3.36901949 2.9916208  2.42879723]
u_DA:    [3.84677861 2.04531019 2.6357588  1.88845904 2.17602422]
ref_MAE: [0.07988891 0.59223251 0.83008471 1.13906735 0.05216352]
da_MAE:  [0.07356469 0.70870272 0.7332607  1.10316176 0.25277301]
% 18.859230161881698 da_MAE 0.0064819424417857765 ref_MAE 0.007988514842437063
u_c taken from control states: [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
u_c before reduction of space:  [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
data[u_c] post encoding of state:  [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
J_b = 0.0, J_o = 2285.698051801298
J_b = 0.5000000000000001, J_o = 377647.9943949437
J_b = 0.0021423421396069816, J_o = 435.1161943232336
J_b = 0.0025807771137054763, J_o = 262.58621746698134
J_b = 0.0030076943183798095, J_o = 225.69161970687952
J_b = 0.003167990785038157, J_o = 213.70569310823947
J_b = 0.0054118339492515675, J_o = 145.0545014522287
J_b = 0.009337884859311413, J_o = 98.03233237417035
J_b = 0.015784878804895992, J_o = 60.424629525529284
J_b = 0.01692340971531919, J_o = 51.464288412975364
J_b = 0.017803805287880326, J_o = 46.099075088664776
J_b = 0.01877073695032577, J_o = 42.739078219031285
J_b = 0.02168802964107705, J_o = 36.067960459883956
J_b = 0.024411683244877077, J_o = 31.99585457590868
J_b = 0.02652374944203042, J_o = 29.340959422900447
J_b = 0.029012561695316515, J_o = 26.221105308175197
J_b = 0.03297451140649012, J_o = 21.87691186412401
J_b = 0.04287855503590732, J_o = 138.26717159000737
J_b = 0.033348461669207775, J_o = 21.583729771492518
J_b = 0.03633345512810304, J_o = 19.116624898533516
J_b = 0.03662085119912837, J_o = 18.367165882742892
J_b = 0.036229051956232244, J_o = 18.09573080472276
J_b = 0.035858713778627156, J_o = 17.821900005642362
J_b = 0.03564995315771031, J_o = 17.135719708351562
J_b = 0.03664969918208505, J_o = 16.23762918947222
J_b = 0.039369072195945966, J_o = 15.125576034083487
J_b = 0.04427669583636224, J_o = 14.23965577169689
J_b = 0.04621474246109061, J_o = 13.745451814360429
J_b = 0.04950066570567352, J_o = 13.13183717585254
J_b = 0.05356896161692585, J_o = 12.738250522628052
J_b = 0.053158750517106945, J_o = 12.262727892588273
J_b = 0.052354253130412004, J_o = 11.594324677640774
J_b = 0.05209484062803031, J_o = 11.4831137046259
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
W_opt:  [ 0.00608928 -0.00194405 -0.00055102  0.00114057  0.00098455 -0.00195845
 -0.00768917 -0.01683947 -0.03026352 -0.04961136]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0865 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1237, add (DA)= 0.0001decode = 0.1266 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2132 s, inc stats = 0.2269, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92000547 2.75556063 3.36844018 2.99319085 2.42727717]
u_DA:    [3.84678384 2.04570629 2.6352797  1.88830954 2.17679431]
ref_MAE: [0.07955107 0.59378023 0.82950539 1.1406374  0.05064345]
da_MAE:  [0.07322163 0.70985434 0.73316048 1.1048813  0.25048285]
% 18.81659580562654 da_MAE 0.006490564902813018 ref_MAE 0.007994940551239975
u_c taken from control states: [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
u_c before reduction of space:  [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
data[u_c] post encoding of state:  [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
J_b = 0.0, J_o = 2274.1298690352723
J_b = 0.49999999999999983, J_o = 378829.66905311786
J_b = 0.002120543433083062, J_o = 437.9658259813215
J_b = 0.0025499425739577827, J_o = 268.1144086038586
J_b = 0.0029781347889966136, J_o = 230.45303145747877
J_b = 0.003148084350276402, J_o = 217.69540454580763
J_b = 0.005459667411270331, J_o = 146.6525802465682
J_b = 0.00953512638200335, J_o = 97.64940479007888
J_b = 0.01582640719794977, J_o = 59.965611268121805
J_b = 0.01690021242681274, J_o = 51.70183890644735
J_b = 0.01776896831621558, J_o = 46.27140089051264
J_b = 0.01870973005566466, J_o = 42.87353633306486
J_b = 0.02154573251270821, J_o = 36.37081205321849
J_b = 0.023896859634506034, J_o = 32.67033673301961
J_b = 0.025781199755354745, J_o = 30.171104901402725
J_b = 0.027720316791538382, J_o = 27.503057418819363
J_b = 0.03133989888815909, J_o = 23.159025342199193
J_b = 0.03688090205892491, J_o = 50.247061213785535
J_b = 0.03189465028657087, J_o = 22.644754453611515
J_b = 0.03553454718720831, J_o = 19.58618155526038
J_b = 0.03639456870777547, J_o = 18.45532274579385
J_b = 0.035951189875385786, J_o = 18.15166633446137
J_b = 0.035539599719007206, J_o = 17.936016387256362
J_b = 0.03519433668102593, J_o = 17.339692429653212
J_b = 0.03608195458937052, J_o = 16.437896418903627
J_b = 0.039898601295820436, J_o = 15.004343966495878
J_b = 0.05693050775502485, J_o = 16.88349193882079
J_b = 0.045061679729127155, J_o = 14.274717020852485
J_b = 0.04765467569068993, J_o = 13.414512375340406
J_b = 0.04946603978586686, J_o = 12.732833919662312
J_b = 0.051768884214582984, J_o = 12.071642777092846
J_b = 0.052216632869475275, J_o = 11.536686664019475
J_b = 0.05123871055660363, J_o = 11.292110491605092
J_b = 0.05024382194665627, J_o = 11.170648679247822
J_b = 0.0508960235761916, J_o = 10.96933324869936
J_b = 0.052236058248472335, J_o = 10.380370735956042
J_b = 0.05778725525145325, J_o = 9.961871531051152
J_b = 0.057917731071414395, J_o = 9.698398942631135
J_b = 0.06010057448945936, J_o = 9.031210938555228
J_b = 0.06267469635537429, J_o = 8.56021533615046
J_b = 0.06579018317591238, J_o = 8.092614949861218
J_b = 0.06806693480129197, J_o = 7.973851598649117
J_b = 0.06960726935718155, J_o = 7.992085919480405
J_b = 0.06877145200417335, J_o = 7.916841024560527
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
W_opt:  [-0.01138659 -0.01239148 -0.00414434  0.00020469  0.00139572 -0.0013584
 -0.00818183 -0.02017862 -0.03933965 -0.06943497]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.1098 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1222, add (DA)= 0.0001decode = 0.1251 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2351 s, inc stats = 0.2422, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91966918 2.75710264 3.3678523  2.99443614 2.42516509]
u_DA:    [3.84678025 2.04629872 2.63586203 1.88756307 2.17741686]
ref_MAE: [0.07921477 0.59532225 0.82891751 1.14188269 0.04853138]
da_MAE:  [0.07288893 0.71080392 0.73199027 1.10687307 0.24774823]
% 18.789058832460597 da_MAE 0.006497734451006454 ref_MAE 0.008001057933316558
u_c taken from control states: [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
u_c before reduction of space:  [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
data[u_c] post encoding of state:  [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
J_b = 0.0, J_o = 2259.2501470452034
J_b = 0.5000000000000002, J_o = 383691.866176696
J_b = 0.0020833134901865748, J_o = 434.3687693833465
J_b = 0.002481205964751848, J_o = 273.5834218306848
J_b = 0.0029071181355096783, J_o = 234.67545185700408
J_b = 0.0030830234956963814, J_o = 221.32339240121814
J_b = 0.005490570322571295, J_o = 147.76275245130282
J_b = 0.009738825281766087, J_o = 97.27694959294426
J_b = 0.015902913449687396, J_o = 59.76030402155913
J_b = 0.017025019001538202, J_o = 51.99132366693054
J_b = 0.017929718762300657, J_o = 46.57866274154904
J_b = 0.01889668839003192, J_o = 43.00671207479347
J_b = 0.02158078432254214, J_o = 36.79382857746429
J_b = 0.023704872947533293, J_o = 33.32287805220463
J_b = 0.025332220928659662, J_o = 31.047316023528033
J_b = 0.02690461047858895, J_o = 28.69833447967047
J_b = 0.030139554020236006, J_o = 24.482837437894844
J_b = 0.03458898268006024, J_o = 26.13303853017336
J_b = 0.03177073331105144, J_o = 23.045128850109435
J_b = 0.03575835033791922, J_o = 19.743116341047916
J_b = 0.03628788316765078, J_o = 18.8061550537377
J_b = 0.03589937443370761, J_o = 18.564631488318156
J_b = 0.03561856267856247, J_o = 18.39288142070307
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
W_opt:  [ 0.0095199  -0.00011086 -0.00314319 -0.00350341 -0.00440156 -0.00684806
 -0.01084992 -0.01662858 -0.02430517 -0.03441746]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0591 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1842 s, inc stats = 0.1965, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91932592 2.75866795 3.36724538 2.99524076 2.42232338]
u_DA:    [3.84687848 2.04576899 2.6365308  1.89214082 2.17847618]
ref_MAE: [0.07887152 0.59688756 0.8283106  1.14268731 0.04568967]
da_MAE:  [0.07244744 0.71289896 0.73071459 1.10309994 0.24384721]
% 18.82570443665218 da_MAE 0.006499406353318943 ref_MAE 0.008006729603519447
u_c taken from control states: [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
u_c before reduction of space:  [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
data[u_c] post encoding of state:  [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
J_b = 0.0, J_o = 2243.8783841572904
J_b = 0.4999999999999999, J_o = 391874.3139710408
J_b = 0.0020374472826039706, J_o = 423.8029560188156
J_b = 0.0023843619754235212, J_o = 278.59287239910947
J_b = 0.0027997272265016786, J_o = 238.46332023146576
J_b = 0.0029797491173650754, J_o = 224.59056456495966
J_b = 0.005494265113178243, J_o = 148.7418807648537
J_b = 0.009940519526413946, J_o = 97.02271579227431
J_b = 0.016046007603038728, J_o = 59.65543308891128
J_b = 0.01729737745033133, J_o = 52.10258704771405
J_b = 0.018255431922983748, J_o = 46.83530764034258
J_b = 0.01929781917503537, J_o = 42.97778238718173
J_b = 0.021795628139976684, J_o = 37.1223239956584
J_b = 0.023731093129399795, J_o = 33.88006716706342
J_b = 0.025096497917683095, J_o = 31.86659385616988
J_b = 0.02643135092929257, J_o = 29.73338342566887
J_b = 0.029327163352677106, J_o = 25.699322903761374
J_b = 0.033614342762082555, J_o = 23.089728369862172
J_b = 0.037655472904502316, J_o = 20.010807551094565
J_b = 0.03594154840770729, J_o = 19.28076980067404
J_b = 0.03557298571483366, J_o = 19.069668807132715
J_b = 0.03559488178361793, J_o = 18.94436986444217
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
W_opt:  [ 0.00913946 -0.00031768 -0.00309056 -0.00343559 -0.00436978 -0.00684856
 -0.01086352 -0.0166359  -0.02432048 -0.0344949 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0610 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1210, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1851 s, inc stats = 0.1988, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91897064 2.76024014 3.36661658 2.9955774  2.41881164]
u_DA:    [3.8469841  2.04601899 2.63746585 1.89421531 2.17781262]
ref_MAE: [0.07851624 0.59845974 0.82768179 1.14302395 0.04217793]
da_MAE:  [0.07198653 0.71422114 0.72915073 1.10136209 0.24099902]
% 18.852246598454926 da_MAE 0.006501515478278064 ref_MAE 0.00801194759651137
u_c taken from control states: [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
u_c before reduction of space:  [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
data[u_c] post encoding of state:  [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
J_b = 0.0, J_o = 2232.7764244377086
J_b = 0.5, J_o = 401579.16108244983
J_b = 0.001995715826663203, J_o = 408.27270194413563
J_b = 0.002283519363430628, J_o = 282.7793780157652
J_b = 0.00267695423769049, J_o = 242.21249297666017
J_b = 0.002862898405441291, J_o = 227.6916815948204
J_b = 0.005464824677939315, J_o = 150.25503582666101
J_b = 0.010131968679836081, J_o = 97.03834373913352
J_b = 0.016298271318582108, J_o = 59.31707883194381
J_b = 0.017703915659337235, J_o = 51.735276840267936
J_b = 0.01869778588708977, J_o = 46.67149401647044
J_b = 0.019819882683526385, J_o = 42.57905195498175
J_b = 0.02218102757924153, J_o = 36.99297264986238
J_b = 0.023966179820822987, J_o = 33.97679282001874
J_b = 0.02513569418621757, J_o = 32.17768565340275
J_b = 0.02639327073005104, J_o = 30.105159209762725
J_b = 0.02914224836167292, J_o = 26.190346180121864
J_b = 0.033438498142196835, J_o = 22.868020326093912
J_b = 0.039175977781166355, J_o = 20.963672062683454
J_b = 0.0361999689079935, J_o = 19.58019100488373
J_b = 0.03570845350685963, J_o = 19.39996081863036
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
W_opt:  [ 0.00848598 -0.00054672 -0.00300259 -0.00337358 -0.00437653 -0.00693302
 -0.01102133 -0.01685745 -0.02461552 -0.03484974]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0551 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1368 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1921 s, inc stats = 0.2038, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91860107 2.76179185 3.36596814 2.99549997 2.41479181]
u_DA:    [3.84729493 2.04684852 2.63839357 1.89660914 2.17800448]
ref_MAE: [0.07814667 0.60001145 0.82703336 1.14294652 0.0381581 ]
da_MAE:  [0.07130614 0.71494333 0.72757458 1.09889084 0.23678733]
% 18.87423939846437 da_MAE 0.006503284577509368 ref_MAE 0.008016300284013938
u_c taken from control states: [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
u_c before reduction of space:  [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
data[u_c] post encoding of state:  [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
J_b = 0.0, J_o = 2230.1324042712567
J_b = 0.5, J_o = 410217.7320383364
J_b = 0.001969218115546395, J_o = 392.6682316674363
J_b = 0.0022050673534591693, J_o = 286.03402651227793
J_b = 0.0025709658803202006, J_o = 245.92438979808998
J_b = 0.002767242857221241, J_o = 230.4931442026034
J_b = 0.005426521225891662, J_o = 152.13226159038075
J_b = 0.010320369839999935, J_o = 96.96152209702907
J_b = 0.016579071515620686, J_o = 58.51601316633237
J_b = 0.01811825790214768, J_o = 50.892383103892755
J_b = 0.0191060525084489, J_o = 46.10048461010703
J_b = 0.020288511474122407, J_o = 41.828701255416874
J_b = 0.022532517128981133, J_o = 36.466105754479486
J_b = 0.024193746342805352, J_o = 33.63291118364762
J_b = 0.025249825816591364, J_o = 31.96068399874605
J_b = 0.02648597203008827, J_o = 29.904745065884075
J_b = 0.029167088291532774, J_o = 26.079044057825712
J_b = 0.0334134566632767, J_o = 22.55564223263649
J_b = 0.03998122081394088, J_o = 21.805891289200936
J_b = 0.0361849062713301, J_o = 19.59798846712115
J_b = 0.03569120467239746, J_o = 19.431964568505023
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
W_opt:  [ 0.0075838  -0.0006068  -0.00270548 -0.00313707 -0.00422453 -0.00686322
 -0.01102057 -0.01691051 -0.02472167 -0.03498032]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0598 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1216, add (DA)= 0.0001decode = 0.1244 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1844 s, inc stats = 0.1934, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91821823 2.76322836 3.36530777 2.99513916 2.41054747]
u_DA:    [3.84773331 2.04739005 2.64025032 1.89845308 2.17921818]
ref_MAE: [0.07776383 0.60144797 0.82637298 1.14258571 0.03391376]
da_MAE:  [0.07048492 0.71583831 0.72505745 1.09668607 0.2313293 ]
% 18.89071376124562 da_MAE 0.0065042851366216336 ref_MAE 0.008019162093814428
u_c taken from control states: [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
u_c before reduction of space:  [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
data[u_c] post encoding of state:  [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
J_b = 0.0, J_o = 2233.9535232856724
J_b = 0.5000000000000001, J_o = 416702.81139857264
J_b = 0.001956499489462124, J_o = 380.2164114876672
J_b = 0.002153407410640697, J_o = 288.6828778154307
J_b = 0.0024938564869589424, J_o = 249.42419368607008
J_b = 0.0027039162275596185, J_o = 232.90777131420327
J_b = 0.005401965185784689, J_o = 154.0313235769692
J_b = 0.010500587697852651, J_o = 96.8308778970934
J_b = 0.016793597301622682, J_o = 57.77617195463808
J_b = 0.01843958609170016, J_o = 50.16248798672915
J_b = 0.019385726130876902, J_o = 45.69108564722011
J_b = 0.02063375642105885, J_o = 41.191376691399206
J_b = 0.02280449963173843, J_o = 35.940304197761826
J_b = 0.024379185188953538, J_o = 33.215044895339524
J_b = 0.025395477069396977, J_o = 31.576992013040535
J_b = 0.026650111312691634, J_o = 29.502131999587796
J_b = 0.029339839590352752, J_o = 25.71256497613347
J_b = 0.03352047181686593, J_o = 22.198522758896765
J_b = 0.04017872580535527, J_o = 22.079342518495515
J_b = 0.036722915224368935, J_o = 20.312159430533683
J_b = 0.03612682003482686, J_o = 19.480290344853866
J_b = 0.035723022425456684, J_o = 19.274784280899652
J_b = 0.035851953648790486, J_o = 19.205756193330497
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
W_opt:  [ 0.00681829 -0.00045056 -0.00229411 -0.00281346 -0.00398822 -0.00670358
 -0.01091965 -0.01686224 -0.02473767 -0.03505891]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0552 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1201, add (DA)= 0.0001decode = 0.1230 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1783 s, inc stats = 0.1897, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91782988 2.76450396 3.36464846 2.99468599 2.40648166]
u_DA:    [3.84804699 2.04765994 2.64188192 1.89944044 2.18081961]
ref_MAE: [0.07737547 0.60272357 0.82571368 1.14213254 0.02984795]
da_MAE:  [0.06978289 0.71684403 0.72276654 1.09524556 0.22566205]
% 18.895291431520803 da_MAE 0.006504807053734411 ref_MAE 0.008020258217489558
u_c taken from control states: [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
u_c before reduction of space:  [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
data[u_c] post encoding of state:  [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
J_b = 0.0, J_o = 2241.9309337958434
J_b = 0.49999999999999994, J_o = 421399.55981363286
J_b = 0.0019526085435359556, J_o = 371.2174742970376
J_b = 0.0021211417221742392, J_o = 291.2150774622837
J_b = 0.002440709980434935, J_o = 252.83239681023719
J_b = 0.002666243877251857, J_o = 235.1769129365188
J_b = 0.005400672001358817, J_o = 155.91651981051467
J_b = 0.010684729802595858, J_o = 96.85006646407622
J_b = 0.01693394226330153, J_o = 57.54645460624934
J_b = 0.01867962753523754, J_o = 49.936844044007
J_b = 0.01956870667405829, J_o = 45.78624370606386
J_b = 0.020912921176256344, J_o = 40.951691394219765
J_b = 0.023093141164009606, J_o = 35.624102675668674
J_b = 0.0246439146817399, J_o = 32.90797449123065
J_b = 0.025707398853251972, J_o = 31.189933531362545
J_b = 0.027105095979381502, J_o = 28.961028186947292
J_b = 0.030005287977693994, J_o = 25.075998907211996
J_b = 0.03425674525791015, J_o = 22.262195446461853
J_b = 0.03873957444091827, J_o = 20.17084152911589
J_b = 0.03632817857000015, J_o = 19.32448801289388
J_b = 0.0359035093179187, J_o = 19.188565746106292
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
W_opt:  [ 0.00612486 -0.00036277 -0.00201804 -0.00262774 -0.0038783  -0.00665732
 -0.01092748 -0.01692411 -0.02484184 -0.03515102]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0543 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1330, add (DA)= 0.0001decode = 0.1359 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1903 s, inc stats = 0.2026, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91744512 2.76560497 3.36400138 2.99432735 2.40288123]
u_DA:    [3.84825297 2.0472569  2.64319105 1.89941271 2.18118955]
ref_MAE: [0.07699072 0.60382457 0.8250666  1.1417739  0.02624752]
da_MAE:  [0.06919215 0.71834807 0.72081033 1.09491464 0.22169168]
% 18.92028551924633 da_MAE 0.006502161090147603 ref_MAE 0.008019467177195174
u_c taken from control states: [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
u_c before reduction of space:  [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
data[u_c] post encoding of state:  [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
J_b = 0.0, J_o = 2251.464334417312
J_b = 0.5000000000000001, J_o = 424964.9055995133
J_b = 0.0019534512582549436, J_o = 364.0088202993993
J_b = 0.0021001775570944916, J_o = 293.18261586650345
J_b = 0.002402215622469652, J_o = 255.66593036673572
J_b = 0.0026435101307880054, J_o = 236.91363521234143
J_b = 0.005412766280563578, J_o = 157.46496757053666
J_b = 0.010861452425451553, J_o = 96.84409723524664
J_b = 0.017024860932280655, J_o = 57.63436666327916
J_b = 0.01886160654533162, J_o = 49.97083587955915
J_b = 0.019697565256106282, J_o = 46.06841191140711
J_b = 0.021150526108804794, J_o = 40.86753867681275
J_b = 0.023430519387902433, J_o = 35.28852009056399
J_b = 0.025028380933295437, J_o = 32.476342797945506
J_b = 0.026268476593050715, J_o = 30.522519654804974
J_b = 0.02799026873333751, J_o = 27.984347397209113
J_b = 0.03131457907130452, J_o = 23.92772921867937
J_b = 0.036961872577140814, J_o = 28.23721879695369
J_b = 0.03285984308393508, J_o = 22.96011055076289
J_b = 0.03661976444408189, J_o = 20.01072707005129
J_b = 0.037360097076579536, J_o = 19.183048842729168
J_b = 0.03701663312493294, J_o = 19.03318895409569
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
W_opt:  [ 0.00568343 -0.00021394 -0.00168153 -0.00234338 -0.00367593 -0.00657566
 -0.01100237 -0.01720445 -0.02536868 -0.03592437]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0595 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1203, add (DA)= 0.0001decode = 0.1233 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1829 s, inc stats = 0.1967, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91707436 2.76654448 3.36337476 2.99420772 2.39994813]
u_DA:    [3.84848799 2.04705722 2.64406684 1.89915001 2.18153686]
ref_MAE: [0.07661996 0.60476409 0.82443998 1.14165427 0.02331442]
da_MAE:  [0.06858637 0.71948727 0.71930792 1.09505771 0.21841127]
% 18.95254882148024 da_MAE 0.006497359571694262 ref_MAE 0.008016735230060234
\% improve_point: 17.07, mse_ref_points: 3.6146594121086654e-05, mse_da_points: 2.9976481580244618e-05, % improve_overlap: 17.07, mse_ref_overlap: 0.94157, mse_da_overlap: 0.78086
DA - - L2: 41088.95, L1: 7424.65, % Improve: 18.95%, DA_MAE: 0.01, mse_ref: 0.94, mse_DA: 0.780, time(s): 1.2836s,
u_c taken from control states: [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
u_c before reduction of space:  [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
data[u_c] post encoding of state:  [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
J_b = 0.0, J_o = 2263.7222447847907
J_b = 0.5, J_o = 427731.7096942555
J_b = 0.0019594571960526376, J_o = 357.70830583906223
J_b = 0.002088908138156263, J_o = 294.34913894663646
J_b = 0.0023759315838001284, J_o = 257.69114633344094
J_b = 0.0026321653223774625, J_o = 237.95766469624317
J_b = 0.0054328499461255035, J_o = 158.5624183926933
J_b = 0.011023445838867272, J_o = 96.76190377276686
J_b = 0.017086658736247737, J_o = 57.91591322173416
J_b = 0.018996398291329476, J_o = 50.16034411329454
J_b = 0.019791958564320228, J_o = 46.41714989476078
J_b = 0.02134099695470417, J_o = 40.901568276010565
J_b = 0.023787927288137098, J_o = 34.97571811145306
J_b = 0.025486611046590654, J_o = 31.96811679928357
J_b = 0.027071263980602455, J_o = 29.59039097134727
J_b = 0.02923137594587012, J_o = 26.71883610535683
J_b = 0.03297410003229914, J_o = 22.61022055326114
J_b = 0.05463449141994924, J_o = 150.82038544775787
J_b = 0.03368219149045478, J_o = 22.406339109003515
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
W_opt:  [ 0.00599643  0.00028551 -0.00197108 -0.00302581 -0.00441487 -0.00706376
 -0.0109533  -0.0162927  -0.02325863 -0.03223037]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0553 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1215, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1798 s, inc stats = 0.1918, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91672335 2.76734226 3.36277538 2.99444796 2.39784992]
u_DA:    [3.84865029 2.04715752 2.64415349 1.89942853 2.18084166]
ref_MAE: [0.07626895 0.60556186 0.8238406  1.14189451 0.02121621]
da_MAE:  [0.06807306 0.72018474 0.71862189 1.09501943 0.21700826]
% 19.00624565013068 da_MAE 0.006489376110788722 ref_MAE 0.008012193239933681
u_c taken from control states: [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
u_c before reduction of space:  [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
data[u_c] post encoding of state:  [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
J_b = 0.0, J_o = 2279.5827408659106
J_b = 0.5, J_o = 429482.05916784966
J_b = 0.0019713107800532854, J_o = 353.38876279219136
J_b = 0.002089391200250005, J_o = 295.0375161682812
J_b = 0.0023658767559065043, J_o = 259.05557675593974
J_b = 0.0026330224146348426, J_o = 238.64439576665205
J_b = 0.005457414806746579, J_o = 159.4126464181339
J_b = 0.011154985309786761, J_o = 96.84332604240055
J_b = 0.017167290075121334, J_o = 58.26043611603572
J_b = 0.019127669357006865, J_o = 50.40985280726554
J_b = 0.019902565260980228, J_o = 46.74126891928256
J_b = 0.021507301752087475, J_o = 41.05696511023957
J_b = 0.024098943674309214, J_o = 34.86815882136873
J_b = 0.025908411447302337, J_o = 31.651331497655676
J_b = 0.02785040836653073, J_o = 28.86457790671905
J_b = 0.030358425279632992, J_o = 25.79027107725553
J_b = 0.03425714604113582, J_o = 21.824818418182545
J_b = 0.05245971283570512, J_o = 66.86622073735282
J_b = 0.03561079992234412, J_o = 21.436165795997315
J_b = 0.0378760153178723, J_o = 19.764938362694622
J_b = 0.03783579944194616, J_o = 19.378831982928983
J_b = 0.03764188721288184, J_o = 19.28669159071314
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
W_opt:  [ 0.00533262  0.00022754 -0.00116109 -0.00196501 -0.00340672 -0.00640461
 -0.01092155 -0.01721266 -0.02544089 -0.03591576]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0638 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1210, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1878 s, inc stats = 0.2016, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91639489 2.76799759 3.36220782 2.99512792 2.396612  ]
u_DA:    [3.8488643  2.04724752 2.64494985 1.89837109 2.18230831]
ref_MAE: [0.07594049 0.6062172  0.82327303 1.14257447 0.01997829]
da_MAE:  [0.06753059 0.72075007 0.71725797 1.09675683 0.21430369]
% 19.01657651590428 da_MAE 0.006483682544125926 ref_MAE 0.00800618480323847
u_c taken from control states: [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
u_c before reduction of space:  [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
data[u_c] post encoding of state:  [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
J_b = 0.0, J_o = 2297.1447007574097
J_b = 0.5000000000000001, J_o = 429967.9746350292
J_b = 0.0019870704130185205, J_o = 352.30891471241597
J_b = 0.0021014455408117014, J_o = 295.602593189193
J_b = 0.0023737811222301905, J_o = 259.96786219663
J_b = 0.002642567116868327, J_o = 239.47652356657954
J_b = 0.005468115857549785, J_o = 160.50728203960017
J_b = 0.011210436062682726, J_o = 97.66012899415536
J_b = 0.017330130418683976, J_o = 58.56515509388036
J_b = 0.019328115406496243, J_o = 50.63544115844331
J_b = 0.02010909778732093, J_o = 46.97122240565187
J_b = 0.02170319534176262, J_o = 41.356562697333494
J_b = 0.024270932752707954, J_o = 35.19238355682387
J_b = 0.026169830584681565, J_o = 31.87063650874142
J_b = 0.028149953139587455, J_o = 29.06694000912453
J_b = 0.030847977826475814, J_o = 25.83187926850451
J_b = 0.03478007084504647, J_o = 21.902709345468846
J_b = 0.051260583291159345, J_o = 49.187589872452115
J_b = 0.03649823275751552, J_o = 21.417297301219264
J_b = 0.038611342056552325, J_o = 19.91234172157055
J_b = 0.03823655113583429, J_o = 19.57183705371302
J_b = 0.037978398182674344, J_o = 19.488334052608554
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
W_opt:  [ 0.00532467  0.00036166 -0.00096606 -0.0018165  -0.00328851 -0.00631377
 -0.01086052 -0.01718302 -0.0254366  -0.03590351]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0646 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1206, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1884 s, inc stats = 0.2009, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91608823 2.76849594 3.36166969 2.99625791 2.39604189]
u_DA:    [3.84893648 2.04722738 2.64505044 1.89817147 2.18216836]
ref_MAE: [0.07563383 0.60671554 0.82273491 1.14370446 0.01940818]
da_MAE:  [0.06715175 0.72126856 0.71661925 1.09808645 0.21387353]
% 19.05157692039411 da_MAE 0.006475205017919233 ref_MAE 0.007999173759754924
u_c taken from control states: [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
u_c before reduction of space:  [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
data[u_c] post encoding of state:  [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
J_b = 0.0, J_o = 2310.628126283321
J_b = 0.5, J_o = 429320.76283124747
J_b = 0.002001347723642204, J_o = 353.83218945780914
J_b = 0.002119236206652239, J_o = 295.5636368032883
J_b = 0.0023931922193993066, J_o = 260.0110836822319
J_b = 0.002652533520916548, J_o = 240.14264157273863
J_b = 0.0054467169873239005, J_o = 161.70729480116023
J_b = 0.011154224017843602, J_o = 99.2038192734666
J_b = 0.01757234027919753, J_o = 58.70892179502068
J_b = 0.019581105467392654, J_o = 50.73674507976406
J_b = 0.02040326076320678, J_o = 46.98327112573688
J_b = 0.02189740136525576, J_o = 41.751501339312284
J_b = 0.024245945572282112, J_o = 36.012302316223156
J_b = 0.026138345535264885, J_o = 32.771742408517156
J_b = 0.027767206960480108, J_o = 30.379119860577934
J_b = 0.030321360580329408, J_o = 27.108688701700704
J_b = 0.03427509040775939, J_o = 22.921602627040937
J_b = 0.06252568349719954, J_o = 110.45366255707421
J_b = 0.03561245117847773, J_o = 22.60546350723065
J_b = 0.03871875662662201, J_o = 20.43123005730349
J_b = 0.038660760971595876, J_o = 20.01302167505896
J_b = 0.038397338222125155, J_o = 19.77080843568807
J_b = 0.03839245050251416, J_o = 19.67398992261532
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
W_opt:  [ 0.00548711  0.000396   -0.00092855 -0.00180712 -0.00328508 -0.00631344
 -0.01086763 -0.01718661 -0.02541607 -0.03583951]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0589 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1280, add (DA)= 0.0001decode = 0.1308 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1898 s, inc stats = 0.2023, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91580024 2.76887555 3.36115342 2.99777853 2.39585421]
u_DA:    [3.84891454 2.04713503 2.6450623  1.89816243 2.18187907]
ref_MAE: [0.07534584 0.60709516 0.82221863 1.14522508 0.0192205 ]
da_MAE:  [0.0668857  0.72174053 0.71609112 1.0996161  0.21397514]
% 19.086757653322273 da_MAE 0.006466273390873152 ref_MAE 0.007991613243192022
u_c taken from control states: [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
u_c before reduction of space:  [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
data[u_c] post encoding of state:  [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
J_b = 0.0, J_o = 2315.1043381002232
J_b = 0.5000000000000002, J_o = 427801.74026648677
J_b = 0.0020099780076820247, J_o = 356.27066678178466
J_b = 0.0021371661736336958, J_o = 293.9104543398036
J_b = 0.002417080941897592, J_o = 258.2865079196092
J_b = 0.0026589158798303912, J_o = 239.58732491976107
J_b = 0.0053951673185277495, J_o = 162.0853890675069
J_b = 0.010987407538272983, J_o = 100.70411735566431
J_b = 0.017811058376859357, J_o = 58.663768725188746
J_b = 0.019755393874889473, J_o = 50.649898752097755
J_b = 0.020666798358794498, J_o = 46.59329295249684
J_b = 0.021964954568585392, J_o = 42.06258728728406
J_b = 0.024078788478440378, J_o = 36.91889229121277
J_b = 0.02588033785635048, J_o = 33.87357206791042
J_b = 0.027175676792143624, J_o = 31.893527640935638
J_b = 0.029221560630178212, J_o = 28.971030795323742
J_b = 0.03283804203905713, J_o = 24.645174764833556
J_b = 0.0425215734813293, J_o = 30.08199970568146
J_b = 0.035443663238951956, J_o = 23.5379482718864
J_b = 0.03939568061690931, J_o = 20.531107878102524
J_b = 0.03959775453070305, J_o = 19.74280464174848
J_b = 0.03917151170206483, J_o = 19.55504466687377
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
W_opt:  [ 0.00556038  0.00030067 -0.00084652 -0.00165367 -0.0031121  -0.00617882
 -0.01083219 -0.01729674 -0.02570981 -0.03636178]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0569 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1224, add (DA)= 0.0001decode = 0.1253 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1823 s, inc stats = 0.1953, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91552792 2.76915985 3.36065243 2.99959935 2.39582438]
u_DA:    [3.84884575 2.04685226 2.64490413 1.89843006 2.1813037 ]
ref_MAE: [0.07507352 0.60737945 0.82171765 1.1470459  0.01919067]
da_MAE:  [0.06668218 0.72230758 0.7157483  1.10116929 0.21452068]
% 19.11981209178911 da_MAE 0.006457166455353637 ref_MAE 0.007983619502320804
u_c taken from control states: [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
u_c before reduction of space:  [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
data[u_c] post encoding of state:  [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
J_b = 0.0, J_o = 2312.3381931999807
J_b = 0.5000000000000002, J_o = 425338.7755887379
J_b = 0.0020156892258477604, J_o = 358.8941762159776
J_b = 0.0021582567493348102, J_o = 289.8792090731655
J_b = 0.0024483448376252663, J_o = 254.0871979582202
J_b = 0.002666724551983784, J_o = 237.01686222682181
J_b = 0.005324647141763531, J_o = 160.99508060999912
J_b = 0.010719308119706138, J_o = 101.72781804966
J_b = 0.018007197864889666, J_o = 58.667559334803066
J_b = 0.019794914699633768, J_o = 50.36511589869383
J_b = 0.020824384572159224, J_o = 45.68082977659778
J_b = 0.021862823653772488, J_o = 42.09541361779334
J_b = 0.023999652255667202, J_o = 37.11487842010473
J_b = 0.025967241166863005, J_o = 33.992426507333555
J_b = 0.02728874462366572, J_o = 32.06979820816218
J_b = 0.029393935250515982, J_o = 29.09799202395017
J_b = 0.033071537887778495, J_o = 24.669334908434102
J_b = 0.042490448864917305, J_o = 33.19417538345795
J_b = 0.03514072155002747, J_o = 23.725083984832413
J_b = 0.03903702565793624, J_o = 20.611686150692773
J_b = 0.039592687094326943, J_o = 19.77740541326495
J_b = 0.039265024321111626, J_o = 19.588465042485467
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
W_opt:  [ 0.00606356  0.00033089 -0.00087942 -0.00167963 -0.0031219  -0.00618443
 -0.01085289 -0.01732003 -0.02570826 -0.03628256]
----------------------------- DA Assimilate ----------------------
minCostFunction = 0.0648 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1320, add (DA)= 0.0001decode = 0.1349 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1998 s, inc stats = 0.2136, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91526598 2.76939843 3.36015762 3.00159    2.39568216]
u_DA:    [3.84866382 2.04656984 2.64462597 1.89897284 2.18089271]
ref_MAE: [0.07481158 0.60761803 0.82122283 1.14903655 0.01904845]
da_MAE:  [0.06660216 0.72282859 0.71553165 1.10261715 0.21478945]
% 19.139957231132453 da_MAE 0.006449256810459609 ref_MAE 0.007975826613021134
\% improve_point: 17.06, mse_ref_points: 3.635055790904895e-05, mse_da_points: 3.0148855433870762e-05, % improve_overlap: 17.06, mse_ref_overlap: 0.94689, mse_da_overlap: 0.78535
DA - - L2: 39113.89, L1: 7351.33, % Improve: 18.96%, DA_MAE: 0.01, mse_ref: 0.95, mse_DA: 0.785, time(s): 1.2231s,
Results of DA at 2020-08-29 15:30:22.998479. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              18.491489      0.007516  ...  50.349259     0.341800
1              18.247812      0.007520  ...   0.203812     0.185437
2              18.110606      0.007523  ...   0.228340     0.212949
3              18.155737      0.007526  ...   0.215803     0.198937
4              17.908480      0.007529  ...   0.176199     0.158062
..                   ...           ...  ...        ...          ...
102            19.016577      0.008006  ...   0.206119     0.187823
103            19.051577      0.007999  ...   0.205452     0.188393
104            19.086758      0.007992  ...   0.206930     0.189850
105            19.119812      0.007984  ...   0.199815     0.182327
106            19.139957      0.007976  ...   0.218229     0.199850

[107 rows x 20 columns]
------------------------- Ended at 2020-08-29 15:30:24.989702 -------------------- 

