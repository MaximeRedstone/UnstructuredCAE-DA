Path ['/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/mredstone/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/', '/Users/maxime/IndividualProject/code/Data_Assimilation/src/']

------------------------- Simulation Started at 2020-08-27 17:53:39.476622 ------------------- 

data fp  /home/mredstone/unstructuredCAE/data/subdomain_8/
domain, other, pickle, dim 8 ['6'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_40P_150E_1D4L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_8/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 40                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 8957, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  8957
DIM USED  1
When creating TucodecEncode1D, inputSize =  8957 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 8957, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  8957
DIM USED  1
Number of parameters: 20300414
------------------------------ Training subdomain 8 at 2020-08-27 17:53:44.170161. ------------------------------
Loading data started 2020-08-27 17:53:44.170464
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
shape of mean (8957,) and std (8957,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7ff979de73c8>
Loading data finished 2020-08-27 17:53:51.312797
Loop AE Train begins at  17:53:51.316678
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [1/150], TRAIN: -loss:10132.41, av_diff: 0.91, time taken (m): 0.05m
epoch [1/150], TEST: -loss:9926.5371, time taken(m): 0.02m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [6/150], TRAIN: -loss:438.15, av_diff: 0.11, time taken (m): 0.05m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [11/150], TRAIN: -loss:89.34, av_diff: 0.00, time taken (m): 0.05m
epoch [11/150], TEST: -loss:1789.5011, time taken(m): 0.01m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [16/150], TRAIN: -loss:34.50, av_diff: 0.01, time taken (m): 0.05m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [21/150], TRAIN: -loss:20.93, av_diff: 0.01, time taken (m): 0.05m
epoch [21/150], TEST: -loss:256.5701, time taken(m): 0.01m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [26/150], TRAIN: -loss:17.76, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [31/150], TRAIN: -loss:18.15, av_diff: 0.00, time taken (m): 0.06m
epoch [31/150], TEST: -loss:113.6766, time taken(m): 0.01m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [36/150], TRAIN: -loss:18.26, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [41/150], TRAIN: -loss:17.52, av_diff: 0.00, time taken (m): 0.05m
epoch [41/150], TEST: -loss:123.3661, time taken(m): 0.02m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [46/150], TRAIN: -loss:16.71, av_diff: 0.00, time taken (m): 0.05m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [51/150], TRAIN: -loss:16.91, av_diff: 0.00, time taken (m): 0.05m
epoch [51/150], TEST: -loss:182.5506, time taken(m): 0.02m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [56/150], TRAIN: -loss:16.99, av_diff: 0.01, time taken (m): 0.05m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [61/150], TRAIN: -loss:20.30, av_diff: 0.01, time taken (m): 0.05m
epoch [61/150], TEST: -loss:145.2630, time taken(m): 0.02m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [66/150], TRAIN: -loss:18.68, av_diff: 0.01, time taken (m): 0.04m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [71/150], TRAIN: -loss:17.45, av_diff: 0.01, time taken (m): 0.05m
epoch [71/150], TEST: -loss:115.5366, time taken(m): 0.02m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [76/150], TRAIN: -loss:18.11, av_diff: 0.01, time taken (m): 0.04m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [81/150], TRAIN: -loss:18.39, av_diff: 0.01, time taken (m): 0.05m
epoch [81/150], TEST: -loss:116.1239, time taken(m): 0.02m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [86/150], TRAIN: -loss:19.59, av_diff: 0.02, time taken (m): 0.05m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [91/150], TRAIN: -loss:18.56, av_diff: 0.01, time taken (m): 0.05m
epoch [91/150], TEST: -loss:103.1716, time taken(m): 0.01m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [96/150], TRAIN: -loss:22.16, av_diff: 0.02, time taken (m): 0.05m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [101/150], TRAIN: -loss:18.13, av_diff: 0.02, time taken (m): 0.05m
epoch [101/150], TEST: -loss:83.2203, time taken(m): 0.02m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [106/150], TRAIN: -loss:21.21, av_diff: 0.02, time taken (m): 0.05m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [111/150], TRAIN: -loss:12.44, av_diff: 0.01, time taken (m): 0.05m
epoch [111/150], TEST: -loss:76.6313, time taken(m): 0.02m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [116/150], TRAIN: -loss:14.93, av_diff: 0.02, time taken (m): 0.05m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [121/150], TRAIN: -loss:10.60, av_diff: 0.02, time taken (m): 0.03m
epoch [121/150], TEST: -loss:82.5731, time taken(m): 0.01m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [126/150], TRAIN: -loss:9.57, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [131/150], TRAIN: -loss:9.93, av_diff: 0.02, time taken (m): 0.03m
epoch [131/150], TEST: -loss:82.9542, time taken(m): 0.01m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [136/150], TRAIN: -loss:24.64, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [141/150], TRAIN: -loss:22.11, av_diff: 0.03, time taken (m): 0.02m
epoch [141/150], TEST: -loss:71.8415, time taken(m): 0.00m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [146/150], TRAIN: -loss:24.83, av_diff: 0.03, time taken (m): 0.03m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
epoch [150/150], TRAIN: -loss:32.64, av_diff: 0.04, time taken (m): 0.03m
epoch [150/150], TEST: -loss:216.5156, time taken(m): 0.01m
Loop AE Train Ends at  18:01:04.448595
------------------------------ DA subdomain 8 at 2020-08-27 18:01:04.530438. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
shape of mean (8957,) and std (8957,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 8957) , test_X = (107, 8957), X = (537, 8957)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
shape of mean (8957,) and std (8957,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
Shape of w_0 =  (429,)
minCostFunction = 0.1868 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.7069, add (DA)= 0.0001decode = 0.7075 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.8944 s, inc stats = 14.7481, 
minCostFunction = 0.2100 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2845, add (DA)= 0.0001decode = 0.2851 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4951 s, inc stats = 0.4991, 
minCostFunction = 0.2903 s, v_trunc (Latent to Reduced) = 0.0066, dec (Reduced to Full) = 0.2059, add (DA)= 0.0000decode = 0.2126 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.5029 s, inc stats = 0.5067, 
minCostFunction = 0.3206 s, v_trunc (Latent to Reduced) = 0.0063, dec (Reduced to Full) = 0.2782, add (DA)= 0.0001decode = 0.2846 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.6052 s, inc stats = 0.6090, 
minCostFunction = 0.2783 s, v_trunc (Latent to Reduced) = 0.0050, dec (Reduced to Full) = 0.3815, add (DA)= 0.0001decode = 0.3866 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6650 s, inc stats = 0.6689, 
minCostFunction = 0.4347 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.2442, add (DA)= 0.0001decode = 0.2465 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6813 s, inc stats = 0.6852, 
minCostFunction = 0.0972 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.3341, add (DA)= 0.0001decode = 0.3347 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4319 s, inc stats = 0.4358, 
minCostFunction = 0.3037 s, v_trunc (Latent to Reduced) = 0.0071, dec (Reduced to Full) = 0.3974, add (DA)= 0.0018decode = 0.4064 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.7102 s, inc stats = 0.7141, 
minCostFunction = 0.1392 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.2604, add (DA)= 0.0001decode = 0.2609 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4002 s, inc stats = 0.4040, 
minCostFunction = 0.2053 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3214, add (DA)= 0.0001decode = 0.3220 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5274 s, inc stats = 0.5313, 
minCostFunction = 0.2535 s, v_trunc (Latent to Reduced) = 0.0097, dec (Reduced to Full) = 0.3448, add (DA)= 0.0001decode = 0.3545 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6081 s, inc stats = 0.6112, 
DA - - L2: 233.76, L1: 1158.67, % Improve: 10.79%, DA_MAE: 0.13, mse_ref: 0.17, mse_DA: 0.155, time(s): 2.6548s,
\% improve_point: 10.13, mse_ref_points: 1.921800582454184e-05, mse_da_points: 1.7271360872729785e-05, % improve_overlap: 9.79, mse_ref_overlap: 0.16460, mse_da_overlap: 0.14848
minCostFunction = 0.2043 s, v_trunc (Latent to Reduced) = 0.0064, dec (Reduced to Full) = 0.3543, add (DA)= 0.0001decode = 0.3608 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.5652 s, inc stats = 0.5691, 
minCostFunction = 0.2931 s, v_trunc (Latent to Reduced) = 0.0028, dec (Reduced to Full) = 0.3001, add (DA)= 0.0001decode = 0.3029 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5961 s, inc stats = 0.6002, 
minCostFunction = 0.1836 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.5118, add (DA)= 0.0001decode = 0.5132 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6969 s, inc stats = 0.7009, 
minCostFunction = 0.1908 s, v_trunc (Latent to Reduced) = 0.0022, dec (Reduced to Full) = 0.3849, add (DA)= 0.0001decode = 0.3872 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5780 s, inc stats = 0.5812, 
minCostFunction = 0.2354 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2535, add (DA)= 0.0001decode = 0.2541 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4895 s, inc stats = 0.4936, 
minCostFunction = 0.3684 s, v_trunc (Latent to Reduced) = 0.0048, dec (Reduced to Full) = 0.4956, add (DA)= 0.0001decode = 0.5005 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.8689 s, inc stats = 0.8720, 
minCostFunction = 0.1503 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3876, add (DA)= 0.0001decode = 0.3882 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5386 s, inc stats = 0.5427, 
minCostFunction = 0.2483 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.3727, add (DA)= 0.0001decode = 0.3751 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.6236 s, inc stats = 0.6276, 
minCostFunction = 0.1671 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1400, add (DA)= 0.0001decode = 0.1412 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3084 s, inc stats = 0.3127, 
minCostFunction = 0.2906 s, v_trunc (Latent to Reduced) = 0.0021, dec (Reduced to Full) = 0.1506, add (DA)= 0.0001decode = 0.1527 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4434 s, inc stats = 0.4473, 
DA - - L2: 340.51, L1: 1305.33, % Improve: 10.56%, DA_MAE: 0.13, mse_ref: 0.17, mse_DA: 0.156, time(s): 1.6657s,
\% improve_point: 8.99, mse_ref_points: 1.91021360157635e-05, mse_da_points: 1.7383428881786387e-05, % improve_overlap: 6.25, mse_ref_overlap: 0.16240, mse_da_overlap: 0.15217
minCostFunction = 0.0957 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1313, add (DA)= 0.0001decode = 0.1319 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2276 s, inc stats = 0.2308, 
minCostFunction = 0.0696 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1474, add (DA)= 0.0001decode = 0.1479 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2176 s, inc stats = 0.2207, 
minCostFunction = 0.1451 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.1681, add (DA)= 0.0001decode = 0.1705 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.3156 s, inc stats = 0.3187, 
minCostFunction = 0.0704 s, v_trunc (Latent to Reduced) = 0.0031, dec (Reduced to Full) = 0.1342, add (DA)= 0.0001decode = 0.1374 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2078 s, inc stats = 0.2109, 
minCostFunction = 0.0981 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1305, add (DA)= 0.0001decode = 0.1317 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2299 s, inc stats = 0.2338, 
minCostFunction = 0.1951 s, v_trunc (Latent to Reduced) = 0.0048, dec (Reduced to Full) = 0.1409, add (DA)= 0.0001decode = 0.1458 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.3409 s, inc stats = 0.3440, 
minCostFunction = 0.1407 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.4622, add (DA)= 0.0001decode = 0.4634 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6041 s, inc stats = 0.6079, 
minCostFunction = 0.1240 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1495, add (DA)= 0.0001decode = 0.1501 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2741 s, inc stats = 0.2772, 
minCostFunction = 0.1297 s, v_trunc (Latent to Reduced) = 0.0048, dec (Reduced to Full) = 0.1616, add (DA)= 0.0001decode = 0.1664 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2962 s, inc stats = 0.2993, 
minCostFunction = 0.0865 s, v_trunc (Latent to Reduced) = 0.0045, dec (Reduced to Full) = 0.1333, add (DA)= 0.0001decode = 0.1380 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2245 s, inc stats = 0.2276, 
DA - - L2: 408.99, L1: 1370.17, % Improve: 10.44%, DA_MAE: 0.13, mse_ref: 0.17, mse_DA: 0.157, time(s): 1.2251s,
\% improve_point: 8.69, mse_ref_points: 1.923560617214775e-05, mse_da_points: 1.756327945161477e-05, % improve_overlap: 5.85, mse_ref_overlap: 0.16286, mse_da_overlap: 0.15327
minCostFunction = 0.2942 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1420, add (DA)= 0.0001decode = 0.1425 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4368 s, inc stats = 0.4410, 
minCostFunction = 0.1182 s, v_trunc (Latent to Reduced) = 0.0027, dec (Reduced to Full) = 0.1600, add (DA)= 0.0001decode = 0.1628 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2810 s, inc stats = 0.2841, 
minCostFunction = 0.0959 s, v_trunc (Latent to Reduced) = 0.0026, dec (Reduced to Full) = 0.1430, add (DA)= 0.0001decode = 0.1457 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2417 s, inc stats = 0.2448, 
minCostFunction = 0.0315 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1331, add (DA)= 0.0000decode = 0.1337 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1653 s, inc stats = 0.1684, 
minCostFunction = 0.0314 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1321, add (DA)= 0.0000decode = 0.1327 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1641 s, inc stats = 0.1672, 
minCostFunction = 0.0560 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1371, add (DA)= 0.0000decode = 0.1376 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1936 s, inc stats = 0.1959, 
minCostFunction = 0.0324 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1279, add (DA)= 0.0000decode = 0.1285 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1609 s, inc stats = 0.1640, 
minCostFunction = 0.0324 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1331, add (DA)= 0.0001decode = 0.1337 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1661 s, inc stats = 0.1692, 
minCostFunction = 0.0439 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1252, add (DA)= 0.0001decode = 0.1258 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1698 s, inc stats = 0.1729, 
minCostFunction = 0.0389 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1359, add (DA)= 0.0001decode = 0.1364 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1754 s, inc stats = 0.1785, 
DA - - L2: 530.90, L1: 1477.96, % Improve: 10.34%, DA_MAE: 0.13, mse_ref: 0.18, mse_DA: 0.162, time(s): 0.9802s,
\% improve_point: 8.74, mse_ref_points: 1.9784141079882655e-05, mse_da_points: 1.805172054809643e-05, % improve_overlap: 6.70, mse_ref_overlap: 0.16810, mse_da_overlap: 0.15656
minCostFunction = 0.0411 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1224, add (DA)= 0.0001decode = 0.1230 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1642 s, inc stats = 0.1673, 
minCostFunction = 0.0456 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1312, add (DA)= 0.0000decode = 0.1318 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1774 s, inc stats = 0.1806, 
minCostFunction = 0.0316 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1334, add (DA)= 0.0000decode = 0.1340 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1656 s, inc stats = 0.1687, 
minCostFunction = 0.0723 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1330, add (DA)= 0.0001decode = 0.1342 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2066 s, inc stats = 0.2089, 
minCostFunction = 0.0335 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1240, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1581 s, inc stats = 0.1613, 
minCostFunction = 0.0536 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1343, add (DA)= 0.0000decode = 0.1348 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1885 s, inc stats = 0.1917, 
minCostFunction = 0.0425 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1324, add (DA)= 0.0000decode = 0.1330 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1755 s, inc stats = 0.1779, 
minCostFunction = 0.0247 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1245, add (DA)= 0.0000decode = 0.1251 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1499 s, inc stats = 0.1530, 
minCostFunction = 0.0491 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1347, add (DA)= 0.0000decode = 0.1352 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1844 s, inc stats = 0.1866, 
minCostFunction = 0.0308 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1355, add (DA)= 0.0000decode = 0.1361 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1669 s, inc stats = 0.1701, 
DA - - L2: 909.92, L1: 1690.46, % Improve: 10.32%, DA_MAE: 0.14, mse_ref: 0.19, mse_DA: 0.175, time(s): 0.8231s,
\% improve_point: 8.83, mse_ref_points: 2.148904935637146e-05, mse_da_points: 1.9583383091361932e-05, % improve_overlap: 8.02, mse_ref_overlap: 0.18616, mse_da_overlap: 0.17004
minCostFunction = 0.0309 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1352, add (DA)= 0.0000decode = 0.1358 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1668 s, inc stats = 0.1690, 
minCostFunction = 0.0301 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1225 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1527 s, inc stats = 0.1569, 
minCostFunction = 0.0304 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1326, add (DA)= 0.0000decode = 0.1332 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1637 s, inc stats = 0.1659, 
minCostFunction = 0.0292 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1305, add (DA)= 0.0000decode = 0.1310 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1603 s, inc stats = 0.1634, 
minCostFunction = 0.0300 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1347, add (DA)= 0.0000decode = 0.1352 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1653 s, inc stats = 0.1684, 
minCostFunction = 0.0294 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1341, add (DA)= 0.0000decode = 0.1346 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1641 s, inc stats = 0.1672, 
minCostFunction = 0.0291 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1356, add (DA)= 0.0000decode = 0.1362 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1653 s, inc stats = 0.1684, 
minCostFunction = 0.0305 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1361, add (DA)= 0.0000decode = 0.1367 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1673 s, inc stats = 0.1704, 
minCostFunction = 0.0389 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1275, add (DA)= 0.0000decode = 0.1280 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1670 s, inc stats = 0.1701, 
minCostFunction = 0.0307 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1284, add (DA)= 0.0000decode = 0.1289 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1597 s, inc stats = 7.5817, 
DA - - L2: 1205.02, L1: 1863.66, % Improve: 10.12%, DA_MAE: 0.15, mse_ref: 0.21, mse_DA: 0.189, time(s): 0.8375s,
\% improve_point: 8.64, mse_ref_points: 2.3112836228646893e-05, mse_da_points: 2.112658315454418e-05, % improve_overlap: 8.47, mse_ref_overlap: 0.19989, mse_da_overlap: 0.18164
minCostFunction = 0.0312 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1394, add (DA)= 0.0001decode = 0.1400 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1712 s, inc stats = 0.1744, 
minCostFunction = 0.0495 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1325, add (DA)= 0.0001decode = 0.1331 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1826 s, inc stats = 0.1857, 
minCostFunction = 0.0898 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1280, add (DA)= 0.0001decode = 0.1285 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.2184 s, inc stats = 0.2215, 
minCostFunction = 0.0682 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1299, add (DA)= 0.0001decode = 0.1305 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1987 s, inc stats = 0.2013, 
minCostFunction = 0.0836 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1588, add (DA)= 0.0001decode = 0.1594 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2431 s, inc stats = 0.2454, 
minCostFunction = 0.0673 s, v_trunc (Latent to Reduced) = 0.0043, dec (Reduced to Full) = 0.3111, add (DA)= 0.0001decode = 0.3155 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3829 s, inc stats = 0.3860, 
minCostFunction = 0.1041 s, v_trunc (Latent to Reduced) = 0.0024, dec (Reduced to Full) = 0.1455, add (DA)= 0.0001decode = 0.1480 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2522 s, inc stats = 0.2553, 
minCostFunction = 0.0488 s, v_trunc (Latent to Reduced) = 0.0033, dec (Reduced to Full) = 0.1279, add (DA)= 0.0001decode = 0.1312 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.1801 s, inc stats = 0.1832, 
minCostFunction = 0.2417 s, v_trunc (Latent to Reduced) = 0.0043, dec (Reduced to Full) = 0.5624, add (DA)= 0.0001decode = 0.5668 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.8085 s, inc stats = 0.8124, 
minCostFunction = 0.2120 s, v_trunc (Latent to Reduced) = 0.0046, dec (Reduced to Full) = 0.4404, add (DA)= 0.0001decode = 0.4452 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.6572 s, inc stats = 0.6610, 
DA - - L2: 1441.99, L1: 1998.31, % Improve: 9.85%, DA_MAE: 0.16, mse_ref: 0.22, mse_DA: 0.201, time(s): 0.7668s,
\% improve_point: 8.37, mse_ref_points: 2.445691533744615e-05, mse_da_points: 2.244184339916369e-05, % improve_overlap: 8.51, mse_ref_overlap: 0.21106, mse_da_overlap: 0.19195
minCostFunction = 0.2010 s, v_trunc (Latent to Reduced) = 0.0021, dec (Reduced to Full) = 0.2525, add (DA)= 0.0001decode = 0.2548 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4558 s, inc stats = 0.4599, 
minCostFunction = 0.1532 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2589, add (DA)= 0.0001decode = 0.2595 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.4127 s, inc stats = 0.4166, 
minCostFunction = 0.1354 s, v_trunc (Latent to Reduced) = 0.0027, dec (Reduced to Full) = 0.3078, add (DA)= 0.0001decode = 0.3106 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4462 s, inc stats = 0.4493, 
minCostFunction = 0.1786 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2717, add (DA)= 0.0001decode = 0.2723 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.4509 s, inc stats = 0.4548, 
minCostFunction = 0.2241 s, v_trunc (Latent to Reduced) = 0.0090, dec (Reduced to Full) = 0.1943, add (DA)= 0.0000decode = 0.2034 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.4276 s, inc stats = 0.4314, 
minCostFunction = 0.1963 s, v_trunc (Latent to Reduced) = 0.0023, dec (Reduced to Full) = 0.2793, add (DA)= 0.0001decode = 0.2818 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4781 s, inc stats = 0.4890, 
minCostFunction = 0.1254 s, v_trunc (Latent to Reduced) = 0.0021, dec (Reduced to Full) = 0.2699, add (DA)= 0.0001decode = 0.2721 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3975 s, inc stats = 0.4015, 
minCostFunction = 0.1714 s, v_trunc (Latent to Reduced) = 0.0038, dec (Reduced to Full) = 0.3426, add (DA)= 0.0001decode = 0.3466 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5181 s, inc stats = 0.5225, 
minCostFunction = 0.1354 s, v_trunc (Latent to Reduced) = 0.0091, dec (Reduced to Full) = 0.1758, add (DA)= 0.0001decode = 0.1851 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3205 s, inc stats = 0.3237, 
minCostFunction = 0.2027 s, v_trunc (Latent to Reduced) = 0.0028, dec (Reduced to Full) = 0.2745, add (DA)= 0.0001decode = 0.2774 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4802 s, inc stats = 0.4843, 
DA - - L2: 1668.63, L1: 2114.57, % Improve: 9.52%, DA_MAE: 0.16, mse_ref: 0.23, mse_DA: 0.211, time(s): 0.7272s,
\% improve_point: 7.97, mse_ref_points: 2.558745586083833e-05, mse_da_points: 2.3606693327267774e-05, % improve_overlap: 7.96, mse_ref_overlap: 0.22038, mse_da_overlap: 0.20219
minCostFunction = 0.3043 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3262, add (DA)= 0.0001decode = 0.3267 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6311 s, inc stats = 0.6350, 
minCostFunction = 0.2666 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3728, add (DA)= 0.0001decode = 0.3734 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6401 s, inc stats = 0.6440, 
minCostFunction = 0.1294 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.5454, add (DA)= 0.0001decode = 0.5460 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6755 s, inc stats = 0.6795, 
minCostFunction = 0.1969 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.8965, add (DA)= 0.0001decode = 0.8971 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 1.0942 s, inc stats = 1.0982, 
minCostFunction = 0.1906 s, v_trunc (Latent to Reduced) = 0.0035, dec (Reduced to Full) = 0.3723, add (DA)= 0.0001decode = 0.3759 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5665 s, inc stats = 0.5715, 
minCostFunction = 0.2910 s, v_trunc (Latent to Reduced) = 0.0109, dec (Reduced to Full) = 0.5038, add (DA)= 0.0001decode = 0.5148 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.8059 s, inc stats = 0.8098, 
minCostFunction = 0.1411 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1959, add (DA)= 0.0001decode = 0.1965 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3376 s, inc stats = 0.3407, 
minCostFunction = 0.0737 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2075, add (DA)= 0.0001decode = 0.2081 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2819 s, inc stats = 0.2852, 
minCostFunction = 0.1927 s, v_trunc (Latent to Reduced) = 0.0095, dec (Reduced to Full) = 0.2114, add (DA)= 0.0000decode = 0.2210 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.4138 s, inc stats = 0.4176, 
minCostFunction = 0.1345 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3051, add (DA)= 0.0001decode = 0.3057 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4403 s, inc stats = 0.4444, 
DA - - L2: 1914.96, L1: 2227.98, % Improve: 9.22%, DA_MAE: 0.17, mse_ref: 0.24, mse_DA: 0.223, time(s): 0.7128s,
\% improve_point: 7.51, mse_ref_points: 2.675471884515577e-05, mse_da_points: 2.484241845128442e-05, % improve_overlap: 7.17, mse_ref_overlap: 0.23053, mse_da_overlap: 0.21409
minCostFunction = 0.1632 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3931, add (DA)= 0.0001decode = 0.3936 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.5569 s, inc stats = 0.5592, 
minCostFunction = 0.1717 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3037, add (DA)= 0.0001decode = 0.3043 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4761 s, inc stats = 0.4800, 
minCostFunction = 0.1027 s, v_trunc (Latent to Reduced) = 0.0044, dec (Reduced to Full) = 0.3838, add (DA)= 0.0001decode = 0.3884 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4911 s, inc stats = 0.4951, 
minCostFunction = 0.2161 s, v_trunc (Latent to Reduced) = 0.0052, dec (Reduced to Full) = 0.6279, add (DA)= 0.0001decode = 0.6333 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.8495 s, inc stats = 0.8535, 
minCostFunction = 0.2670 s, v_trunc (Latent to Reduced) = 0.0042, dec (Reduced to Full) = 0.3681, add (DA)= 0.0001decode = 0.3725 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6396 s, inc stats = 0.6435, 
minCostFunction = 0.1778 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2104, add (DA)= 0.0001decode = 0.2109 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3888 s, inc stats = 0.3919, 
minCostFunction = 0.1892 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2040, add (DA)= 0.0001decode = 0.2046 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3938 s, inc stats = 0.3976, 
minCostFunction = 0.3275 s, v_trunc (Latent to Reduced) = 0.0044, dec (Reduced to Full) = 0.7873, add (DA)= 0.0001decode = 0.7918 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 1.1193 s, inc stats = 1.1233, 
minCostFunction = 0.1278 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.6359, add (DA)= 0.0001decode = 0.6365 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.7645 s, inc stats = 0.7676, 
minCostFunction = 0.1715 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.3662, add (DA)= 0.0001decode = 0.3668 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5384 s, inc stats = 0.5418, 
DA - - L2: 2085.39, L1: 2311.64, % Improve: 8.99%, DA_MAE: 0.17, mse_ref: 0.25, mse_DA: 0.230, time(s): 0.7044s,
\% improve_point: 7.13, mse_ref_points: 2.7585142189453965e-05, mse_da_points: 2.5733449041999933e-05, % improve_overlap: 6.46, mse_ref_overlap: 0.23812, mse_da_overlap: 0.22331
minCostFunction = 0.1078 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.4249, add (DA)= 0.0001decode = 0.4255 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.5333 s, inc stats = 0.5395, 
minCostFunction = 0.2158 s, v_trunc (Latent to Reduced) = 0.0017, dec (Reduced to Full) = 0.2387, add (DA)= 0.0001decode = 0.2406 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.4564 s, inc stats = 0.4603, 
minCostFunction = 0.1846 s, v_trunc (Latent to Reduced) = 0.0070, dec (Reduced to Full) = 0.1989, add (DA)= 0.0000decode = 0.2060 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 0.3907 s, inc stats = 0.3946, 
minCostFunction = 0.2411 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.4103, add (DA)= 0.0001decode = 0.4109 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.6521 s, inc stats = 0.6579, 
minCostFunction = 0.1348 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.2045, add (DA)= 0.0001decode = 0.2051 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3400 s, inc stats = 0.3439, 
minCostFunction = 0.2839 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1805, add (DA)= 0.0001decode = 0.1810 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4650 s, inc stats = 0.4690, 
DA - - L2: 2189.55, L1: 2359.05, % Improve: 8.88%, DA_MAE: 0.17, mse_ref: 0.25, mse_DA: 0.234, time(s): 0.6919s,
\% improve_point: 6.99, mse_ref_points: 2.7965246871915533e-05, mse_da_points: 2.6130207208334328e-05, % improve_overlap: 6.22, mse_ref_overlap: 0.24141, mse_da_overlap: 0.22709
Results of DA at 2020-08-27 18:03:48.354571. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              10.600035      0.142254  ...  23.506500     0.894409
1              10.652606      0.142248  ...   0.502019     0.495138
2              10.717808      0.142426  ...   0.509787     0.502913
3              10.795207      0.142762  ...   0.612065     0.605178
4              10.923804      0.143154  ...   0.672356     0.664962
..                   ...           ...  ...        ...          ...
102             6.965721      0.218702  ...   0.463385     0.456403
103             6.953707      0.219106  ...   0.398089     0.390685
104             6.944716      0.219457  ...   0.660953     0.652149
105             6.943239      0.219678  ...   0.347028     0.340006
106             6.952287      0.219736  ...   0.471749     0.465003

[107 rows x 20 columns]
data fp  /home/mredstone/unstructuredCAE/data/subdomain_6/
domain, other, pickle, dim 6 ['8'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_40P_150E_1D4L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_6/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 40                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
When creating TucodecEncode1D, inputSize =  26032 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
Number of parameters: 55287089
------------------------------ Training subdomain 6 at 2020-08-27 18:03:58.048667. ------------------------------
Loading data started 2020-08-27 18:03:58.048789
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7ff977d15f28>
Loading data finished 2020-08-27 18:04:12.525159
Loop AE Train begins at  18:04:12.527690
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [1/150], TRAIN: -loss:8514.89, av_diff: 0.33, time taken (m): 0.03m
epoch [1/150], TEST: -loss:98744.1562, time taken(m): 0.01m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [6/150], TRAIN: -loss:2511.36, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [11/150], TRAIN: -loss:1951.13, av_diff: 0.02, time taken (m): 0.06m
epoch [11/150], TEST: -loss:98131.2637, time taken(m): 0.02m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [16/150], TRAIN: -loss:1793.50, av_diff: 0.02, time taken (m): 0.06m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [21/150], TRAIN: -loss:1466.81, av_diff: 0.01, time taken (m): 0.05m
epoch [21/150], TEST: -loss:98114.3604, time taken(m): 0.01m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [26/150], TRAIN: -loss:958.04, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [31/150], TRAIN: -loss:1254.41, av_diff: 0.01, time taken (m): 0.06m
epoch [31/150], TEST: -loss:97675.8008, time taken(m): 0.02m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [36/150], TRAIN: -loss:670.11, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [41/150], TRAIN: -loss:545.99, av_diff: 0.00, time taken (m): 0.05m
epoch [41/150], TEST: -loss:97790.2510, time taken(m): 0.02m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [46/150], TRAIN: -loss:508.43, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [51/150], TRAIN: -loss:452.04, av_diff: 0.00, time taken (m): 0.06m
epoch [51/150], TEST: -loss:97268.3604, time taken(m): 0.02m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [56/150], TRAIN: -loss:330.75, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [61/150], TRAIN: -loss:199.65, av_diff: 0.00, time taken (m): 0.06m
epoch [61/150], TEST: -loss:96976.6133, time taken(m): 0.02m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [66/150], TRAIN: -loss:214.81, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [71/150], TRAIN: -loss:256.06, av_diff: 0.01, time taken (m): 0.06m
epoch [71/150], TEST: -loss:97086.9141, time taken(m): 0.02m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [76/150], TRAIN: -loss:210.88, av_diff: 0.01, time taken (m): 0.05m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [81/150], TRAIN: -loss:235.27, av_diff: 0.01, time taken (m): 0.06m
epoch [81/150], TEST: -loss:96788.1904, time taken(m): 0.01m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [86/150], TRAIN: -loss:217.59, av_diff: 0.01, time taken (m): 0.05m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [91/150], TRAIN: -loss:161.07, av_diff: 0.01, time taken (m): 0.06m
epoch [91/150], TEST: -loss:96867.0532, time taken(m): 0.03m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [96/150], TRAIN: -loss:140.67, av_diff: 0.01, time taken (m): 0.07m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [101/150], TRAIN: -loss:134.44, av_diff: 0.01, time taken (m): 0.06m
epoch [101/150], TEST: -loss:96667.1362, time taken(m): 0.02m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [106/150], TRAIN: -loss:98.50, av_diff: 0.01, time taken (m): 0.04m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [111/150], TRAIN: -loss:94.81, av_diff: 0.01, time taken (m): 0.03m
epoch [111/150], TEST: -loss:96363.2666, time taken(m): 0.00m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [116/150], TRAIN: -loss:63.76, av_diff: 0.00, time taken (m): 0.07m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [121/150], TRAIN: -loss:56.03, av_diff: 0.00, time taken (m): 0.09m
epoch [121/150], TEST: -loss:96337.7500, time taken(m): 0.02m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [126/150], TRAIN: -loss:64.42, av_diff: 0.01, time taken (m): 0.08m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [131/150], TRAIN: -loss:53.51, av_diff: 0.01, time taken (m): 0.07m
epoch [131/150], TEST: -loss:96325.7920, time taken(m): 0.02m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [136/150], TRAIN: -loss:51.15, av_diff: 0.01, time taken (m): 0.08m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [141/150], TRAIN: -loss:46.93, av_diff: 0.01, time taken (m): 0.07m
epoch [141/150], TEST: -loss:96148.3867, time taken(m): 0.02m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [146/150], TRAIN: -loss:46.18, av_diff: 0.00, time taken (m): 0.06m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [150/150], TRAIN: -loss:42.89, av_diff: 0.01, time taken (m): 0.08m
epoch [150/150], TEST: -loss:96277.4805, time taken(m): 0.02m
Loop AE Train Ends at  18:13:42.127711
------------------------------ DA subdomain 6 at 2020-08-27 18:13:42.228533. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 26032) , test_X = (107, 26032), X = (537, 26032)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
Shape of w_0 =  (429,)
minCostFunction = 0.0479 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1338, add (DA)= 0.0001decode = 0.1344 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1824 s, inc stats = 47.2052, 
minCostFunction = 0.0463 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1353, add (DA)= 0.0002decode = 0.1360 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1825 s, inc stats = 0.1882, 
minCostFunction = 0.0544 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1788 s, inc stats = 0.1921, 
minCostFunction = 0.0603 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1242, add (DA)= 0.0001decode = 0.1248 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1853 s, inc stats = 0.1978, 
minCostFunction = 0.0461 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1256, add (DA)= 0.0001decode = 0.1262 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1724 s, inc stats = 0.1860, 
minCostFunction = 0.0719 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1245, add (DA)= 0.0001decode = 0.1251 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1972 s, inc stats = 0.2108, 
minCostFunction = 0.0580 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1244, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1831 s, inc stats = 0.1912, 
minCostFunction = 0.0242 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1242, add (DA)= 0.0001decode = 0.1248 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1491 s, inc stats = 0.1622, 
minCostFunction = 0.0448 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1685 s, inc stats = 0.1818, 
minCostFunction = 0.0293 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1289, add (DA)= 0.0001decode = 0.1295 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1589 s, inc stats = 0.1657, 
minCostFunction = 0.0408 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1320, add (DA)= 0.0001decode = 0.1326 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1736 s, inc stats = 0.1871, 
DA - - L2: 199216.78, L1: 11714.88, % Improve: 15.24%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.790, time(s): 4.5680s,
\% improve_point: 13.70, mse_ref_points: 3.515884780171926e-05, mse_da_points: 3.0341513792347866e-05, % improve_overlap: 13.70, mse_ref_overlap: 0.91577, mse_da_overlap: 0.79030
minCostFunction = 0.0499 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1246, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1752 s, inc stats = 0.1888, 
minCostFunction = 0.0335 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1262, add (DA)= 0.0001decode = 0.1268 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1605 s, inc stats = 0.1741, 
minCostFunction = 0.0595 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.0669, add (DA)= 0.0001decode = 0.0675 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1271 s, inc stats = 0.1362, 
minCostFunction = 0.0450 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1260, add (DA)= 0.0001decode = 0.1266 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1717 s, inc stats = 0.1794, 
minCostFunction = 0.0591 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1258, add (DA)= 0.0001decode = 0.1264 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1857 s, inc stats = 0.1988, 
minCostFunction = 0.0768 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1238, add (DA)= 0.0001decode = 0.1244 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2013 s, inc stats = 0.2110, 
minCostFunction = 0.0447 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1242, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1697 s, inc stats = 0.1752, 
minCostFunction = 0.0573 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1299, add (DA)= 0.0001decode = 0.1306 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1880 s, inc stats = 0.1949, 
minCostFunction = 0.0489 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1196, add (DA)= 0.0001decode = 0.1202 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1692 s, inc stats = 0.1828, 
minCostFunction = 0.0476 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1243, add (DA)= 0.0001decode = 0.1249 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1727 s, inc stats = 0.1794, 
DA - - L2: 168018.91, L1: 10393.44, % Improve: 15.83%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.779, time(s): 2.4806s,
\% improve_point: 14.22, mse_ref_points: 3.486536501664882e-05, mse_da_points: 2.9909611409727403e-05, % improve_overlap: 14.22, mse_ref_overlap: 0.90811, mse_da_overlap: 0.77904
minCostFunction = 0.0399 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1389, add (DA)= 0.0001decode = 0.1396 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1796 s, inc stats = 0.1929, 
minCostFunction = 0.0457 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1258, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1723 s, inc stats = 0.1859, 
minCostFunction = 0.0285 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1362, add (DA)= 0.0001decode = 0.1369 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1655 s, inc stats = 0.1708, 
minCostFunction = 0.0544 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1250, add (DA)= 0.0001decode = 0.1256 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1802 s, inc stats = 0.1917, 
minCostFunction = 0.0483 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1242 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1726 s, inc stats = 0.1814, 
minCostFunction = 0.0450 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1389, add (DA)= 0.0001decode = 0.1395 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1846 s, inc stats = 0.1982, 
minCostFunction = 0.0932 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.0827, add (DA)= 0.0001decode = 0.0840 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1773 s, inc stats = 0.1836, 
minCostFunction = 0.0410 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1235, add (DA)= 0.0001decode = 0.1241 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1653 s, inc stats = 0.1715, 
minCostFunction = 0.0448 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1243, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1699 s, inc stats = 0.1833, 
minCostFunction = 0.0333 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1272, add (DA)= 0.0001decode = 0.1278 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1612 s, inc stats = 0.1746, 
DA - - L2: 116432.25, L1: 9448.45, % Improve: 16.23%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.771, time(s): 1.7404s,
\% improve_point: 14.63, mse_ref_points: 3.467014939660186e-05, mse_da_points: 2.9601454227747944e-05, % improve_overlap: 14.63, mse_ref_overlap: 0.90303, mse_da_overlap: 0.77102
minCostFunction = 0.0659 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1239, add (DA)= 0.0001decode = 0.1245 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1905 s, inc stats = 0.2041, 
minCostFunction = 0.0733 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1237, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1978 s, inc stats = 0.2114, 
minCostFunction = 0.0565 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1250, add (DA)= 0.0001decode = 0.1257 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1824 s, inc stats = 0.1959, 
minCostFunction = 0.0318 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1261, add (DA)= 0.0001decode = 0.1267 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1586 s, inc stats = 0.1705, 
minCostFunction = 0.0973 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1441, add (DA)= 0.0001decode = 0.1447 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2422 s, inc stats = 0.2490, 
minCostFunction = 0.1902 s, v_trunc (Latent to Reduced) = 0.0027, dec (Reduced to Full) = 0.1789, add (DA)= 0.0001decode = 0.1817 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3721 s, inc stats = 0.3856, 
minCostFunction = 0.1382 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1656, add (DA)= 0.0001decode = 0.1662 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3046 s, inc stats = 0.3228, 
minCostFunction = 0.1436 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1805, add (DA)= 0.0001decode = 0.1812 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3250 s, inc stats = 0.3298, 
minCostFunction = 0.1543 s, v_trunc (Latent to Reduced) = 0.0009, dec (Reduced to Full) = 0.1858, add (DA)= 0.0001decode = 0.1868 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.3413 s, inc stats = 0.3530, 
minCostFunction = 0.1172 s, v_trunc (Latent to Reduced) = 0.0046, dec (Reduced to Full) = 0.1588, add (DA)= 0.0001decode = 0.1636 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2809 s, inc stats = 0.2891, 
DA - - L2: 90155.31, L1: 8749.68, % Improve: 16.41%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.768, time(s): 1.3828s,
\% improve_point: 14.82, mse_ref_points: 3.462635133254889e-05, mse_da_points: 2.9498487244069545e-05, % improve_overlap: 14.82, mse_ref_overlap: 0.90190, mse_da_overlap: 0.76835
minCostFunction = 0.1155 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1569, add (DA)= 0.0002decode = 0.1576 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 0.2735 s, inc stats = 0.2781, 
minCostFunction = 0.1670 s, v_trunc (Latent to Reduced) = 0.0048, dec (Reduced to Full) = 0.1177, add (DA)= 0.0001decode = 0.1226 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2898 s, inc stats = 0.2966, 
minCostFunction = 0.0868 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1334, add (DA)= 0.0001decode = 0.1340 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2210 s, inc stats = 0.2320, 
minCostFunction = 0.2533 s, v_trunc (Latent to Reduced) = 0.0021, dec (Reduced to Full) = 0.1789, add (DA)= 0.0001decode = 0.1811 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.4346 s, inc stats = 0.4662, 
minCostFunction = 0.1236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1612, add (DA)= 0.0001decode = 0.1618 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2855 s, inc stats = 0.2964, 
minCostFunction = 0.1240 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1617, add (DA)= 0.0001decode = 0.1623 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2865 s, inc stats = 0.2927, 
minCostFunction = 0.1925 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1401, add (DA)= 0.0001decode = 0.1414 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.3340 s, inc stats = 0.3388, 
minCostFunction = 0.0724 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1675, add (DA)= 0.0001decode = 0.1682 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2407 s, inc stats = 0.2484, 
minCostFunction = 0.2146 s, v_trunc (Latent to Reduced) = 0.0038, dec (Reduced to Full) = 0.1746, add (DA)= 0.0001decode = 0.1785 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.3933 s, inc stats = 0.4069, 
minCostFunction = 0.1587 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1743, add (DA)= 0.0001decode = 0.1749 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.3337 s, inc stats = 0.3417, 
DA - - L2: 73845.91, L1: 8254.40, % Improve: 16.52%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.770, time(s): 1.1750s,
\% improve_point: 14.95, mse_ref_points: 3.47766175949086e-05, mse_da_points: 2.957987117977974e-05, % improve_overlap: 14.95, mse_ref_overlap: 0.90583, mse_da_overlap: 0.77048
minCostFunction = 0.1394 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1527, add (DA)= 0.0001decode = 0.1533 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2929 s, inc stats = 0.3009, 
minCostFunction = 0.1613 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1650, add (DA)= 0.0001decode = 0.1656 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3271 s, inc stats = 0.3340, 
minCostFunction = 0.2436 s, v_trunc (Latent to Reduced) = 0.0050, dec (Reduced to Full) = 0.1439, add (DA)= 0.0001decode = 0.1490 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3928 s, inc stats = 0.4005, 
minCostFunction = 0.1179 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1372, add (DA)= 0.0001decode = 0.1379 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2559 s, inc stats = 0.2635, 
minCostFunction = 0.1092 s, v_trunc (Latent to Reduced) = 0.0065, dec (Reduced to Full) = 0.1408, add (DA)= 0.0001decode = 0.1475 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2569 s, inc stats = 0.2659, 
minCostFunction = 0.2101 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1486, add (DA)= 0.0001decode = 0.1498 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.3601 s, inc stats = 0.3751, 
minCostFunction = 0.3274 s, v_trunc (Latent to Reduced) = 0.0027, dec (Reduced to Full) = 0.1731, add (DA)= 0.0002decode = 0.1760 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 0.5037 s, inc stats = 0.5104, 
minCostFunction = 0.2715 s, v_trunc (Latent to Reduced) = 0.0010, dec (Reduced to Full) = 0.1764, add (DA)= 0.0001decode = 0.1776 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 0.4494 s, inc stats = 0.4567, 
minCostFunction = 0.2035 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1695, add (DA)= 0.0001decode = 0.1701 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.3738 s, inc stats = 0.3841, 
minCostFunction = 0.1221 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1623, add (DA)= 0.0001decode = 0.1630 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2852 s, inc stats = 53.4793, 
DA - - L2: 63011.54, L1: 7946.85, % Improve: 16.55%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.774, time(s): 1.9136s,
\% improve_point: 15.01, mse_ref_points: 3.49696078940064e-05, mse_da_points: 2.9721091029275825e-05, % improve_overlap: 15.01, mse_ref_overlap: 0.91087, mse_da_overlap: 0.77417
minCostFunction = 0.0514 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1352, add (DA)= 0.0002decode = 0.1359 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 0.1875 s, inc stats = 0.2008, 
minCostFunction = 0.0527 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1265, add (DA)= 0.0001decode = 0.1271 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1800 s, inc stats = 0.1844, 
minCostFunction = 0.0461 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1256, add (DA)= 0.0001decode = 0.1263 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1725 s, inc stats = 0.1784, 
minCostFunction = 0.0422 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1251, add (DA)= 0.0001decode = 0.1258 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1681 s, inc stats = 0.1802, 
minCostFunction = 0.0748 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1259, add (DA)= 0.0001decode = 0.1265 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2015 s, inc stats = 0.2140, 
minCostFunction = 0.0535 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1233, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1776 s, inc stats = 0.1828, 
minCostFunction = 0.0530 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1239, add (DA)= 0.0001decode = 0.1245 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1776 s, inc stats = 0.1914, 
minCostFunction = 0.0449 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1244, add (DA)= 0.0002decode = 0.1251 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 0.1703 s, inc stats = 0.1823, 
minCostFunction = 0.1063 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1370, add (DA)= 0.0001decode = 0.1383 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2447 s, inc stats = 0.2563, 
minCostFunction = 0.0439 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1229, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1676 s, inc stats = 0.1816, 
DA - - L2: 55071.14, L1: 7738.07, % Improve: 16.55%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.778, time(s): 1.6719s,
\% improve_point: 15.05, mse_ref_points: 3.519515298370806e-05, mse_da_points: 2.98975717709317e-05, % improve_overlap: 15.05, mse_ref_overlap: 0.91676, mse_da_overlap: 0.77877
minCostFunction = 0.0487 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1232, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1726 s, inc stats = 0.1854, 
minCostFunction = 0.0395 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1255, add (DA)= 0.0001decode = 0.1261 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1658 s, inc stats = 0.1791, 
minCostFunction = 0.0497 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1248, add (DA)= 0.0001decode = 0.1254 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1752 s, inc stats = 0.1888, 
minCostFunction = 0.0446 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1223, add (DA)= 0.0001decode = 0.1229 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1676 s, inc stats = 0.1813, 
minCostFunction = 0.0432 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1265, add (DA)= 0.0001decode = 0.1271 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1704 s, inc stats = 0.1771, 
minCostFunction = 0.0267 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1232, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1507 s, inc stats = 0.1560, 
minCostFunction = 0.0808 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1266, add (DA)= 0.0001decode = 0.1273 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2082 s, inc stats = 0.2161, 
minCostFunction = 0.0406 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1643 s, inc stats = 0.1707, 
minCostFunction = 0.0428 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1270, add (DA)= 0.0001decode = 0.1276 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1706 s, inc stats = 0.1837, 
minCostFunction = 0.0394 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1257, add (DA)= 0.0001decode = 0.1263 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1659 s, inc stats = 0.1789, 
DA - - L2: 49472.24, L1: 7672.80, % Improve: 16.52%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.785, time(s): 1.4882s,
\% improve_point: 15.05, mse_ref_points: 3.548769883269102e-05, mse_da_points: 3.0147964575786626e-05, % improve_overlap: 15.05, mse_ref_overlap: 0.92439, mse_da_overlap: 0.78531
minCostFunction = 0.0408 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1229, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1645 s, inc stats = 0.1751, 
minCostFunction = 0.0579 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1239, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1826 s, inc stats = 0.1959, 
minCostFunction = 0.0533 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1238 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1771 s, inc stats = 0.1830, 
minCostFunction = 0.0806 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1240, add (DA)= 0.0001decode = 0.1247 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2054 s, inc stats = 0.2173, 
minCostFunction = 0.0531 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1267, add (DA)= 0.0001decode = 0.1273 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1805 s, inc stats = 0.1842, 
minCostFunction = 0.0487 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.0693, add (DA)= 0.0001decode = 0.0699 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1187 s, inc stats = 0.1279, 
minCostFunction = 0.0396 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1250, add (DA)= 0.0001decode = 0.1256 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1653 s, inc stats = 0.1794, 
minCostFunction = 0.0265 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1273, add (DA)= 0.0001decode = 0.1279 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1545 s, inc stats = 0.1679, 
minCostFunction = 0.0421 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1394, add (DA)= 0.0001decode = 0.1400 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1823 s, inc stats = 0.1878, 
minCostFunction = 0.0548 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1233, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1788 s, inc stats = 0.1837, 
DA - - L2: 44734.58, L1: 7450.12, % Improve: 16.49%, DA_MAE: 0.01, mse_ref: 0.93, mse_DA: 0.792, time(s): 1.3448s,
\% improve_point: 15.03, mse_ref_points: 3.580367588735654e-05, mse_da_points: 3.0424074057029198e-05, % improve_overlap: 15.03, mse_ref_overlap: 0.93263, mse_da_overlap: 0.79251
minCostFunction = 0.0353 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1240, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1600 s, inc stats = 0.1732, 
minCostFunction = 0.0479 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1331, add (DA)= 0.0001decode = 0.1338 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1817 s, inc stats = 0.1955, 
minCostFunction = 0.0356 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1271, add (DA)= 0.0001decode = 0.1277 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1634 s, inc stats = 0.1740, 
minCostFunction = 0.0942 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.1364, add (DA)= 0.0001decode = 0.1378 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2321 s, inc stats = 0.2452, 
minCostFunction = 0.0477 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1714 s, inc stats = 0.1846, 
minCostFunction = 0.0521 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1344, add (DA)= 0.0001decode = 0.1350 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1872 s, inc stats = 0.1923, 
minCostFunction = 0.0675 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1246, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1928 s, inc stats = 0.1977, 
minCostFunction = 0.0454 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1430, add (DA)= 0.0001decode = 0.1437 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1893 s, inc stats = 0.2028, 
minCostFunction = 0.0306 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1356, add (DA)= 0.0002decode = 0.1363 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1672 s, inc stats = 0.1960, 
minCostFunction = 0.0438 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1392, add (DA)= 0.0001decode = 0.1398 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1838 s, inc stats = 0.1971, 
DA - - L2: 40927.74, L1: 7370.37, % Improve: 16.47%, DA_MAE: 0.01, mse_ref: 0.94, mse_DA: 0.800, time(s): 1.2313s,
\% improve_point: 15.00, mse_ref_points: 3.6146594121086654e-05, mse_da_points: 3.0726493205082125e-05, % improve_overlap: 15.00, mse_ref_overlap: 0.94157, mse_da_overlap: 0.80040
minCostFunction = 0.0570 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1226, add (DA)= 0.0001decode = 0.1232 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1804 s, inc stats = 0.1939, 
minCostFunction = 0.0708 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1246, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1961 s, inc stats = 0.2099, 
minCostFunction = 0.0588 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1247, add (DA)= 0.0001decode = 0.1253 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1843 s, inc stats = 0.1970, 
minCostFunction = 0.0248 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1415, add (DA)= 0.0001decode = 0.1421 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1670 s, inc stats = 0.1800, 
minCostFunction = 0.0404 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1250, add (DA)= 0.0001decode = 0.1256 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1661 s, inc stats = 0.1797, 
minCostFunction = 0.0271 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1260, add (DA)= 0.0001decode = 0.1267 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1539 s, inc stats = 0.1658, 
DA - - L2: 38970.26, L1: 7309.05, % Improve: 16.45%, DA_MAE: 0.01, mse_ref: 0.95, mse_DA: 0.805, time(s): 1.1729s,
\% improve_point: 14.97, mse_ref_points: 3.635055790904895e-05, mse_da_points: 3.0912202920380645e-05, % improve_overlap: 14.97, mse_ref_overlap: 0.94689, mse_da_overlap: 0.80524
Results of DA at 2020-08-27 18:17:33.039867. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              16.901722      0.007516  ...  48.359649     0.182380
1              16.414706      0.007520  ...   0.191083     0.182502
2              16.301457      0.007523  ...   0.194863     0.178828
3              16.173097      0.007526  ...   0.200660     0.185251
4              15.968362      0.007529  ...   0.188060     0.172366
..                   ...           ...  ...        ...          ...
102            16.017444      0.008006  ...   0.212725     0.196127
103            16.049453      0.007999  ...   0.199060     0.184264
104            15.970700      0.007992  ...   0.182831     0.167043
105            16.111815      0.007984  ...   0.181760     0.166097
106            16.094483      0.007976  ...   0.167755     0.153876

[107 rows x 20 columns]
------------------------- Ended at 2020-08-27 18:17:34.163264 -------------------- 

