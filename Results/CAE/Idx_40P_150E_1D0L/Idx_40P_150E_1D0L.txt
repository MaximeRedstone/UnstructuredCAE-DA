Path ['/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/mredstone/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/', '/Users/maxime/IndividualProject/code/Data_Assimilation/src/']

------------------------- Simulation Started at 2020-08-28 12:22:29.444251 ------------------- 

data fp  /home/mredstone/unstructuredCAE/data/subdomain_8/
domain, other, pickle, dim 8 ['6'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_40P_150E_1D0L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_8/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 40                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
91, 85, 32, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
89, 83, 30, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
87, 81, 28, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
85, 79, 26, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
83, 77, 24, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
81, 75, 22, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
79, 73, 20, stride=(2, 2, 2, )  kernel_size=(3, 3, 2, )  padding=(0, 1, 1, )  
39, 37, 11, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 1, 0, )  
19, 19, 5, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 1, )  
9, 9, 3, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
5, 5, 2, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
OUT: 3, 3, 1, Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 8957, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  8957
DIM USED  1
When creating TucodecEncode1D, inputSize =  8957 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 8957, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  8957
DIM USED  1
Number of parameters: 567553
------------------------------ Training subdomain 8 at 2020-08-28 12:22:32.734982. ------------------------------
Loading data started 2020-08-28 12:22:32.735066
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (8957,) and std (8957,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fab8a0f8278>
Loading data finished 2020-08-28 12:22:37.818569
Loop AE Train begins at  12:22:37.822292
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [1/150], TRAIN: -loss:8293.58, av_diff: 0.87, time taken (m): 0.05m
epoch [1/150], TEST: -loss:8211.7183, time taken(m): 0.01m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [6/150], TRAIN: -loss:2774.30, av_diff: 0.02, time taken (m): 0.04m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [11/150], TRAIN: -loss:2029.45, av_diff: 0.02, time taken (m): 0.19m
epoch [11/150], TEST: -loss:4665.0134, time taken(m): 0.09m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [16/150], TRAIN: -loss:1759.58, av_diff: 0.01, time taken (m): 0.29m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [21/150], TRAIN: -loss:1598.34, av_diff: 0.01, time taken (m): 0.25m
epoch [21/150], TEST: -loss:2662.6470, time taken(m): 0.07m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [26/150], TRAIN: -loss:1466.22, av_diff: 0.01, time taken (m): 0.27m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [31/150], TRAIN: -loss:1374.90, av_diff: 0.01, time taken (m): 0.20m
epoch [31/150], TEST: -loss:1750.7183, time taken(m): 0.08m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [36/150], TRAIN: -loss:1286.55, av_diff: 0.01, time taken (m): 0.20m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [41/150], TRAIN: -loss:1196.49, av_diff: 0.01, time taken (m): 0.04m
epoch [41/150], TEST: -loss:1476.6689, time taken(m): 0.01m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [46/150], TRAIN: -loss:1132.06, av_diff: 0.01, time taken (m): 0.55m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [51/150], TRAIN: -loss:1069.83, av_diff: 0.01, time taken (m): 0.04m
epoch [51/150], TEST: -loss:1382.5598, time taken(m): 0.01m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [56/150], TRAIN: -loss:1003.82, av_diff: 0.01, time taken (m): 0.20m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [61/150], TRAIN: -loss:956.61, av_diff: 0.01, time taken (m): 0.16m
epoch [61/150], TEST: -loss:1265.0458, time taken(m): 0.08m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [66/150], TRAIN: -loss:902.02, av_diff: 0.01, time taken (m): 0.21m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [71/150], TRAIN: -loss:860.01, av_diff: 0.01, time taken (m): 0.24m
epoch [71/150], TEST: -loss:1164.6613, time taken(m): 0.10m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [76/150], TRAIN: -loss:810.88, av_diff: 0.01, time taken (m): 0.21m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [81/150], TRAIN: -loss:789.95, av_diff: 0.01, time taken (m): 0.04m
epoch [81/150], TEST: -loss:1121.6717, time taken(m): 0.02m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [86/150], TRAIN: -loss:748.69, av_diff: 0.00, time taken (m): 0.32m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [91/150], TRAIN: -loss:706.81, av_diff: 0.00, time taken (m): 0.04m
epoch [91/150], TEST: -loss:1032.7749, time taken(m): 0.02m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [96/150], TRAIN: -loss:698.69, av_diff: 0.00, time taken (m): 0.57m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [101/150], TRAIN: -loss:648.45, av_diff: 0.00, time taken (m): 0.69m
epoch [101/150], TEST: -loss:978.5615, time taken(m): 0.19m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [106/150], TRAIN: -loss:635.03, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [111/150], TRAIN: -loss:596.36, av_diff: 0.00, time taken (m): 0.55m
epoch [111/150], TEST: -loss:925.5496, time taken(m): 0.17m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [116/150], TRAIN: -loss:586.61, av_diff: 0.00, time taken (m): 0.50m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [121/150], TRAIN: -loss:561.42, av_diff: 0.00, time taken (m): 0.04m
epoch [121/150], TEST: -loss:904.0556, time taken(m): 0.02m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [126/150], TRAIN: -loss:539.38, av_diff: 0.00, time taken (m): 0.04m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [131/150], TRAIN: -loss:512.94, av_diff: 0.00, time taken (m): 0.02m
epoch [131/150], TEST: -loss:861.9046, time taken(m): 0.01m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [136/150], TRAIN: -loss:493.95, av_diff: 0.00, time taken (m): 0.07m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [141/150], TRAIN: -loss:502.72, av_diff: 0.00, time taken (m): 0.54m
epoch [141/150], TEST: -loss:849.2206, time taken(m): 0.07m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [146/150], TRAIN: -loss:456.64, av_diff: 0.00, time taken (m): 0.50m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([3, 8957])
Shape of y output of model torch.Size([3, 8957]) and x = torch.Size([3, 8957])
data shape in one loop:  torch.Size([2, 8957])
Shape of y output of model torch.Size([2, 8957]) and x = torch.Size([2, 8957])
epoch [150/150], TRAIN: -loss:469.18, av_diff: 0.00, time taken (m): 0.04m
epoch [150/150], TEST: -loss:812.4604, time taken(m): 0.02m
Loop AE Train Ends at  12:56:55.449693
------------------------------ DA subdomain 8 at 2020-08-28 12:56:55.516413. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (8957,) and std (8957,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 8957) , test_X = (107, 8957), X = (537, 8957)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_40_1D_clustered.pickle
Shape read X:  (537, 8957)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (8957,) and std (8957,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
u_c before reduction of space:  [-0.36615902 -0.44626321 -0.31202389 -0.3450264  -0.23221133 -1.80652529
 -0.62422098 -0.29008174 -0.34879337 -0.30617787]
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
u_c taken from control states: [-0.36594261 -0.44610658 -0.31152441 -0.34466144 -0.23034855 -1.52250289
 -0.62380749 -0.28301718 -0.28194079 -0.30577369]
u_c before reduction of space:  [-0.36594261 -0.44610658 -0.31152441 -0.34466144 -0.23034855 -1.52250289
 -0.62380749 -0.28301718 -0.28194079 -0.30577369]
data[u_c] post encoding of state:  [-0.36594261 -0.44610658 -0.31152441 -0.34466144 -0.23034855 -1.52250289
 -0.62380749 -0.28301718 -0.28194079 -0.30577369]
Shape of w_0 =  (429,)
J_b = 0.0, J_o = 147304.9799945534
J_b = 0.5, J_o = 4736246.262974307
J_b = 0.008988187549715237, J_o = 34586.83839835742
J_b = 0.00995635291721676, J_o = 27273.852217496576
J_b = 0.02487991885186783, J_o = 9190.327512568725
J_b = 0.03094405514383008, J_o = 6968.9694596912295
J_b = 0.04286800448021938, J_o = 4569.266388863474
J_b = 0.05885201717079321, J_o = 3202.8424011133284
J_b = 0.07879219768022605, J_o = 2249.7929763464
J_b = 0.08221016449671943, J_o = 1801.0385975567956
J_b = 0.08609628383995376, J_o = 1504.8438037387234
J_b = 0.0932914573476393, J_o = 1276.7549362438488
J_b = 0.10846974210174884, J_o = 967.4742393343993
J_b = 0.13513219279292799, J_o = 764.6729338433486
J_b = 0.13966884841832058, J_o = 643.2786764383576
J_b = 0.1418980045682328, J_o = 709.8116941513205
J_b = 0.14029116189154597, J_o = 624.8673751549155
J_b = 0.14255742223234338, J_o = 590.2488300046618
J_b = 0.14330533191401082, J_o = 578.3104554903401
J_b = 0.146178760740984, J_o = 553.2245387564952
J_b = 0.15015264581026558, J_o = 518.4652142119944
J_b = 0.16220304021877374, J_o = 488.06451961448477
J_b = 0.16180697723828705, J_o = 461.48318484201457
J_b = 0.16210717658902662, J_o = 448.9173013530314
J_b = 0.16501867547943497, J_o = 426.2413151192161
J_b = 0.1763155706564439, J_o = 396.1687148375977
J_b = 0.18544314047858992, J_o = 362.94344392799354
J_b = 0.1933453046141732, J_o = 339.4297484512957
J_b = 0.20149430366194204, J_o = 332.0761140717159
J_b = 0.20616019713746792, J_o = 321.98162969647296
J_b = 0.2033659525214607, J_o = 316.01632344914856
J_b = 0.20135993842747113, J_o = 303.42073830123604
J_b = 0.20381616603765848, J_o = 290.69089601580225
J_b = 0.20991562562018956, J_o = 280.039774665453
J_b = 0.22204956954003302, J_o = 277.9389392184867
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36594261 -0.44610658 -0.31152441 -0.34466144 -0.23034855 -1.52250289
 -0.62380749 -0.28301718 -0.28194079 -0.30577369]
W_opt:  [ 0.0182617  -0.00604123 -0.01685237 -0.0192087  -0.01062087  0.03191016
  0.04691004  0.0155979  -0.09555404 -0.27592711]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1037 s, v_trunc (Latent to Reduced) = 0.0504, dec (Reduced to Full) = 0.2333, add (DA)= 0.0001decode = 0.2863 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3901 s, inc stats = 12.9533, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.41028691e-07 6.27274955e-07 1.42239682e-06 1.09907960e-06
 1.31553480e-06]
u_DA:    [ 2.60942597e-03  6.75390400e-03  3.75985374e-03  2.10051620e-03
 -8.54482056e-05]
ref_MAE: [0.00805522 0.00987216 0.0044623  0.00560667 0.00061658]
da_MAE:  [2.60878494e-03 6.75327673e-03 3.75843134e-03 2.09941712e-03
 8.67637404e-05]
% 34.841806822514776 da_MAE 0.09269007648132208 ref_MAE 0.14225390846680233
u_c taken from control states: [-0.36594398 -0.4461074  -0.31149271 -0.34464925 -0.23039612 -1.52704131
 -0.62380591 -0.28304399 -0.27958517 -0.30577512]
u_c before reduction of space:  [-0.36594398 -0.4461074  -0.31149271 -0.34464925 -0.23039612 -1.52704131
 -0.62380591 -0.28304399 -0.27958517 -0.30577512]
data[u_c] post encoding of state:  [-0.36594398 -0.4461074  -0.31149271 -0.34464925 -0.23039612 -1.52704131
 -0.62380591 -0.28304399 -0.27958517 -0.30577512]
J_b = 0.0, J_o = 147303.05783755193
J_b = 0.5000000000000001, J_o = 4736128.101418094
J_b = 0.00898441548192045, J_o = 34643.73723050104
J_b = 0.009954143770337487, J_o = 27320.354425686062
J_b = 0.024872465715217586, J_o = 9233.903681614422
J_b = 0.030940756703261664, J_o = 7007.036970754567
J_b = 0.04292783163931174, J_o = 4594.28466089071
J_b = 0.058921097742679014, J_o = 3231.0797826454373
J_b = 0.07865246131357331, J_o = 2279.5260768133976
J_b = 0.08210048194248304, J_o = 1832.281544107693
J_b = 0.08614441142510654, J_o = 1531.6320135273597
J_b = 0.09346951256613137, J_o = 1301.6900098290182
J_b = 0.10871343497602108, J_o = 992.8176276093684
J_b = 0.13531221122818718, J_o = 793.529389107558
J_b = 0.13946742986479355, J_o = 674.0057694624625
J_b = 0.1413807587867699, J_o = 731.5712170588645
J_b = 0.140017735839524, J_o = 655.5999489777328
J_b = 0.14215804345079325, J_o = 621.9063998914285
J_b = 0.14293049684197628, J_o = 610.1208034392208
J_b = 0.14586418244229576, J_o = 584.9831350893404
J_b = 0.14991274359053744, J_o = 549.8701770490521
J_b = 0.16255929125175606, J_o = 522.3967048394628
J_b = 0.1615298623411538, J_o = 493.3813839432845
J_b = 0.16152517520217846, J_o = 482.1456817823329
J_b = 0.16413579231436584, J_o = 459.9706993303123
J_b = 0.17462801345710544, J_o = 427.6956784406712
J_b = 0.18528089115249674, J_o = 394.9040797962124
J_b = 0.19337378229970792, J_o = 370.6784596758912
J_b = 0.20292207191752837, J_o = 361.6499366084125
J_b = 0.2081826477814459, J_o = 351.2188306407007
J_b = 0.20437544743354033, J_o = 343.537128655277
J_b = 0.20295184811575626, J_o = 334.93094302588395
J_b = 0.20471311837236741, J_o = 322.3789918406391
J_b = 0.20942607487605988, J_o = 313.5289801931491
J_b = 0.2182948921140567, J_o = 308.5726240595806
J_b = 0.2193042539346586, J_o = 301.1109145655581
J_b = 0.2198833096282428, J_o = 295.5884710710944
J_b = 0.22132279777785652, J_o = 288.5669890898095
J_b = 0.22750147506344925, J_o = 274.90583907891454
J_b = 0.23127659083931798, J_o = 288.24210925172287
J_b = 0.22868202307312402, J_o = 268.72453106781217
J_b = 0.24195561084452796, J_o = 261.28389817816065
J_b = 0.24065304327438944, J_o = 255.27731627532748
J_b = 0.23944918663154685, J_o = 253.1493002168938
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36594398 -0.4461074  -0.31149271 -0.34464925 -0.23039612 -1.52704131
 -0.62380591 -0.28304399 -0.27958517 -0.30577512]
W_opt:  [ 0.02035329  0.0030125  -0.01121655 -0.02077429 -0.01983472  0.02284608
  0.04599312  0.02782637 -0.07850966 -0.27859703]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.9306 s, v_trunc (Latent to Reduced) = 0.0507, dec (Reduced to Full) = 0.2165, add (DA)= 0.0001decode = 0.2696 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.2003 s, inc stats = 6.2029, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.38750006e-07 6.25190542e-07 1.44904077e-06 1.11241503e-06
 1.30516677e-06]
u_DA:    [ 2.58423769e-03  6.67345489e-03  3.75204514e-03  2.06342151e-03
 -9.43893396e-05]
ref_MAE: [0.00805522 0.00987216 0.00446227 0.00560666 0.00061659]
da_MAE:  [2.58359894e-03 6.67282970e-03 3.75059609e-03 2.06230910e-03
 9.56945064e-05]
% 34.35452441908821 da_MAE 0.09337929172130983 ref_MAE 0.1422478714564487
u_c taken from control states: [-0.3659466  -0.44610846 -0.31146701 -0.34464016 -0.23045653 -1.53155522
 -0.62380571 -0.28320209 -0.27928577 -0.30578002]
u_c before reduction of space:  [-0.3659466  -0.44610846 -0.31146701 -0.34464016 -0.23045653 -1.53155522
 -0.62380571 -0.28320209 -0.27928577 -0.30578002]
data[u_c] post encoding of state:  [-0.3659466  -0.44610846 -0.31146701 -0.34464016 -0.23045653 -1.53155522
 -0.62380571 -0.28320209 -0.27928577 -0.30578002]
J_b = 0.0, J_o = 147297.28476452848
J_b = 0.5000000000000002, J_o = 4736064.343489923
J_b = 0.008980000093479363, J_o = 34704.88896853819
J_b = 0.009951212299897894, J_o = 27371.771074125296
J_b = 0.024860503660798804, J_o = 9285.93018401479
J_b = 0.03093273565677247, J_o = 7052.985437521628
J_b = 0.0429981476300515, J_o = 4623.803372697747
J_b = 0.059032583443678316, J_o = 3261.7983787299654
J_b = 0.07858397153526256, J_o = 2310.3851269119796
J_b = 0.08206302045877019, J_o = 1864.1401616199537
J_b = 0.0862770847204196, J_o = 1558.4650515260455
J_b = 0.09374686910520708, J_o = 1326.2968110466636
J_b = 0.1090760833631402, J_o = 1017.4512619222135
J_b = 0.13561775408176469, J_o = 821.74631425148
J_b = 0.13940115546677842, J_o = 704.0451439648937
J_b = 0.14098000387511836, J_o = 753.512954538676
J_b = 0.13986563844522765, J_o = 685.7975408434623
J_b = 0.14185254842931583, J_o = 653.2059300391286
J_b = 0.14264070028731476, J_o = 641.5793654802585
J_b = 0.14560788256091228, J_o = 616.543504942164
J_b = 0.1497090021484948, J_o = 581.3072001687003
J_b = 0.1628167753354184, J_o = 557.626537627155
J_b = 0.16118993436600976, J_o = 525.6051319821386
J_b = 0.16100512897527874, J_o = 515.4067028636424
J_b = 0.16337969294592924, J_o = 493.96868996669366
J_b = 0.17302471445751305, J_o = 460.801383919247
J_b = 0.18454828581335553, J_o = 428.6800753166654
J_b = 0.19279926651383011, J_o = 403.67504551397496
J_b = 0.20291493113288422, J_o = 384.5431887694701
J_b = 0.22130703851868525, J_o = 494.5858059661266
J_b = 0.206273760757109, J_o = 377.59410928886507
J_b = 0.20598249978379024, J_o = 371.88933437102656
J_b = 0.20713234572039535, J_o = 348.19196178172257
J_b = 0.21109382419925943, J_o = 338.296200647605
J_b = 0.21933326974076295, J_o = 331.763909491582
J_b = 0.22308584040855584, J_o = 321.6086267201399
J_b = 0.2227919557119667, J_o = 316.6972436959263
J_b = 0.22857533925197407, J_o = 298.3270228811298
J_b = 0.22896097798881443, J_o = 291.01951699669723
J_b = 0.23484464952881146, J_o = 275.90807913973885
J_b = 0.2374656938484737, J_o = 269.5569941833147
J_b = 0.2451641696009922, J_o = 289.23732340365126
J_b = 0.2394291012769284, J_o = 266.59122159290433
J_b = 0.24434940604807054, J_o = 258.9010340731796
J_b = 0.24664133731243493, J_o = 254.92222925035972
J_b = 0.2505516067429471, J_o = 249.35861170387915
J_b = 0.25509947363211233, J_o = 244.66514199000193
J_b = 0.27341376244540083, J_o = 230.61440983303999
J_b = 0.2949741617027274, J_o = 223.82508128622803
J_b = 0.30902674744728836, J_o = 214.01149393867638
J_b = 0.3048595764647237, J_o = 210.2510995279327
J_b = 0.3085922170616705, J_o = 204.27724487956777
J_b = 0.3146478653111872, J_o = 200.945520463678
J_b = 0.319805814988437, J_o = 198.12906978051177
J_b = 0.32887927223374847, J_o = 195.46262612609559
J_b = 0.33409006362632243, J_o = 193.13264005657032
J_b = 0.33446640279710216, J_o = 191.68189036884272
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3659466  -0.44610846 -0.31146701 -0.34464016 -0.23045653 -1.53155522
 -0.62380571 -0.28320209 -0.27928577 -0.30578002]
W_opt:  [-1.55944861e-02  1.32426301e-02  2.04625612e-02  1.78686662e-04
 -3.23581325e-02 -1.19933776e-02  2.53566994e-02  6.19863103e-02
 -6.37396706e-03 -2.79143735e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.7675 s, v_trunc (Latent to Reduced) = 0.0585, dec (Reduced to Full) = 0.1877, add (DA)= 0.0001decode = 0.2500 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 8.0175 s, inc stats = 8.0200, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.34407010e-07 6.22519674e-07 1.47063425e-06 1.12235981e-06
 1.29200059e-06]
u_DA:    [ 0.00258396  0.00659022  0.00374877  0.0020679  -0.00010361]
ref_MAE: [0.00805523 0.00987216 0.00446225 0.00560665 0.0006166 ]
da_MAE:  [0.00258333 0.00658959 0.0037473  0.00206678 0.0001049 ]
% 33.928431806318976 da_MAE 0.09410286533025901 ref_MAE 0.14242565736355392
u_c taken from control states: [-0.36595023 -0.44610978 -0.31144782 -0.34463432 -0.2305233  -1.53597331
 -0.62380757 -0.28344857 -0.28098734 -0.3057876 ]
u_c before reduction of space:  [-0.36595023 -0.44610978 -0.31144782 -0.34463432 -0.2305233  -1.53597331
 -0.62380757 -0.28344857 -0.28098734 -0.3057876 ]
data[u_c] post encoding of state:  [-0.36595023 -0.44610978 -0.31144782 -0.34463432 -0.2305233  -1.53597331
 -0.62380757 -0.28344857 -0.28098734 -0.3057876 ]
J_b = 0.0, J_o = 147273.74918492587
J_b = 0.5000000000000001, J_o = 4736002.704250451
J_b = 0.008974963635878817, J_o = 34756.99099500855
J_b = 0.009947753269501364, J_o = 27413.54434967226
J_b = 0.024846778531851854, J_o = 9329.520131655485
J_b = 0.030919950243155518, J_o = 7091.766512953954
J_b = 0.0430482582787036, J_o = 4649.274184958579
J_b = 0.05909144953170857, J_o = 3290.495119497841
J_b = 0.07843800266553395, J_o = 2340.2875176851658
J_b = 0.08195470616150341, J_o = 1895.3251073179617
J_b = 0.0863307033306827, J_o = 1585.1838104004773
J_b = 0.09393375174211972, J_o = 1351.0208268215638
J_b = 0.10932740441124701, J_o = 1042.380872173224
J_b = 0.13583223457530819, J_o = 849.9342885510044
J_b = 0.13930969862627648, J_o = 733.7496261484141
J_b = 0.14058779179569636, J_o = 776.8954712953152
J_b = 0.13968957610017893, J_o = 715.7953728666048
J_b = 0.14152251669612625, J_o = 684.330616376169
J_b = 0.14231702417898767, J_o = 672.8326613285835
J_b = 0.14528999608258564, J_o = 648.0239689415056
J_b = 0.1494272792447818, J_o = 612.8816684588106
J_b = 0.16283702476057885, J_o = 593.358142237738
J_b = 0.1607461256255038, J_o = 557.9871956595933
J_b = 0.16049008797743788, J_o = 548.4722804855777
J_b = 0.16271358656912857, J_o = 527.8635002883976
J_b = 0.17155592331288622, J_o = 494.8837449444864
J_b = 0.18333155291149536, J_o = 463.32676038823564
J_b = 0.1919188238506777, J_o = 437.4851053976417
J_b = 0.20199588553953662, J_o = 414.5027018691224
J_b = 0.20953029488403657, J_o = 419.69936101247805
J_b = 0.20506065905063348, J_o = 409.0454274127585
J_b = 0.20554333232079794, J_o = 402.25207329813054
J_b = 0.20656140847795182, J_o = 389.4466866291767
J_b = 0.20991732640984825, J_o = 377.85335306512764
J_b = 0.21350826411523988, J_o = 371.63159867435076
J_b = 0.2160045244234193, J_o = 364.9241213581747
J_b = 0.21922363198541125, J_o = 357.44457420199376
J_b = 0.22219972951206757, J_o = 348.9478145821625
J_b = 0.22914692281047397, J_o = 339.71162396825423
J_b = 0.234044356530448, J_o = 328.6487110353995
J_b = 0.23449919155706855, J_o = 322.21327756156876
J_b = 0.2374152625734331, J_o = 312.8319317242978
J_b = 0.24275763359532648, J_o = 305.48027238951977
J_b = 0.24465240193425264, J_o = 300.23562991039574
J_b = 0.25323292490724264, J_o = 290.1395766561535
J_b = 0.2580781727386032, J_o = 283.9301969953994
J_b = 0.2695409996110314, J_o = 273.54628561204277
J_b = 0.27837390376541876, J_o = 307.8488832263104
J_b = 0.2714935178944298, J_o = 269.81208961552915
J_b = 0.27813079320087225, J_o = 263.4259657939415
J_b = 0.2841804166069063, J_o = 255.86647189808713
J_b = 0.2903085663494971, J_o = 248.26526016817073
J_b = 0.29657180175800785, J_o = 243.9496311753766
J_b = 0.30219592958005376, J_o = 242.30345389067108
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36595023 -0.44610978 -0.31144782 -0.34463432 -0.2305233  -1.53597331
 -0.62380757 -0.28344857 -0.28098734 -0.3057876 ]
W_opt:  [-0.01476385  0.01356681  0.01772498 -0.00195799 -0.03003907 -0.00794519
  0.02614875  0.05202509 -0.02112685 -0.27656621]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.4500 s, v_trunc (Latent to Reduced) = 0.0575, dec (Reduced to Full) = 0.1663, add (DA)= 0.0001decode = 0.2263 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.6763 s, inc stats = 7.6789, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.28376344e-07 6.19158642e-07 1.48676441e-06 1.12875754e-06
 1.27744645e-06]
u_DA:    [ 0.00258221  0.00660316  0.00375517  0.00206987 -0.00010076]
ref_MAE: [0.00805523 0.00987217 0.00446224 0.00560664 0.00061662]
da_MAE:  [0.00258158 0.00660254 0.00375369 0.00206874 0.00010203]
% 33.40955818440974 da_MAE 0.09506568081483756 ref_MAE 0.14276175112053488
u_c taken from control states: [-0.36595455 -0.44611141 -0.31143539 -0.34463174 -0.23059009 -1.54015794
 -0.62381264 -0.28372193 -0.28436198 -0.30579692]
u_c before reduction of space:  [-0.36595455 -0.44611141 -0.31143539 -0.34463174 -0.23059009 -1.54015794
 -0.62381264 -0.28372193 -0.28436198 -0.30579692]
data[u_c] post encoding of state:  [-0.36595455 -0.44611141 -0.31143539 -0.34463174 -0.23059009 -1.54015794
 -0.62381264 -0.28372193 -0.28436198 -0.30579692]
J_b = 0.0, J_o = 147265.98616887338
J_b = 0.4999999999999997, J_o = 4735968.71442309
J_b = 0.008971551766422635, J_o = 34800.470061174536
J_b = 0.009945500567980659, J_o = 27449.010852394098
J_b = 0.02485531573161779, J_o = 9350.072617191176
J_b = 0.0309369266040339, J_o = 7108.273089064682
J_b = 0.04309033303995513, J_o = 4661.244317006796
J_b = 0.059113256311430565, J_o = 3306.0076168497108
J_b = 0.07831618568951801, J_o = 2358.786642078054
J_b = 0.08182243814745496, J_o = 1915.568467958265
J_b = 0.08625535402855718, J_o = 1603.9377714824836
J_b = 0.09389817012238921, J_o = 1369.4303957561774
J_b = 0.10926328541191627, J_o = 1061.9945743798194
J_b = 0.1355698915954355, J_o = 871.844720475226
J_b = 0.13890392076364358, J_o = 757.1976195529521
J_b = 0.14005140280358094, J_o = 797.4927729426231
J_b = 0.1392456373312671, J_o = 739.4771680051051
J_b = 0.14099789068554217, J_o = 708.7085171382176
J_b = 0.14178311438052688, J_o = 697.341313675792
J_b = 0.14472657826672444, J_o = 672.7968130683516
J_b = 0.14884045356745831, J_o = 637.9579030361133
J_b = 0.16224586245008832, J_o = 620.5783853415164
J_b = 0.16000820570790783, J_o = 583.6935687028712
J_b = 0.15974852211903626, J_o = 574.4562315536656
J_b = 0.16192298006651965, J_o = 554.3226909684231
J_b = 0.17035565843698, J_o = 521.9171790991892
J_b = 0.1820559517312319, J_o = 490.9537065568933
J_b = 0.19062058462204445, J_o = 465.15542946638436
J_b = 0.20027968630367615, J_o = 446.5252062863263
J_b = 0.20531931414067206, J_o = 437.289423906897
J_b = 0.20298909977307028, J_o = 430.9074771140427
J_b = 0.20134926690557106, J_o = 417.4781934067804
J_b = 0.20467723297388382, J_o = 407.0733935817499
J_b = 0.21241087368785747, J_o = 400.30023703074556
J_b = 0.21647750949720507, J_o = 394.1692480735917
J_b = 0.22044079520652016, J_o = 387.15901518938404
J_b = 0.22185163510841016, J_o = 378.8524159477033
J_b = 0.22853433060166867, J_o = 370.3111349636851
J_b = 0.2290735354567004, J_o = 359.1877582309305
J_b = 0.2300183812526077, J_o = 352.70550780624495
J_b = 0.22328828248205007, J_o = 361.66756319035574
J_b = 0.22766117880305414, J_o = 349.4857548781455
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36595455 -0.44611141 -0.31143539 -0.34463174 -0.23059009 -1.54015794
 -0.62381264 -0.28372193 -0.28436198 -0.30579692]
W_opt:  [ 0.01458383  0.00384131 -0.01070003 -0.01945402 -0.0183421   0.0223678
  0.04366555  0.02431319 -0.07807155 -0.27380074]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.6108 s, v_trunc (Latent to Reduced) = 0.0506, dec (Reduced to Full) = 0.1635, add (DA)= 0.0001decode = 0.2162 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.8270 s, inc stats = 5.8294, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.21196114e-07 6.15041934e-07 1.49721183e-06 1.13158204e-06
 1.26289111e-06]
u_DA:    [ 2.60896766e-03  6.68864178e-03  3.77279774e-03  2.05592817e-03
 -9.61207600e-05]
ref_MAE: [0.00805524 0.00987217 0.00446223 0.00560664 0.00061663]
da_MAE:  [2.60834646e-03 6.68802674e-03 3.77130053e-03 2.05479659e-03
 9.73836511e-05]
% 33.36802214748723 da_MAE 0.09538652012748532 ref_MAE 0.14315426796818126
u_c taken from control states: [-0.36595932 -0.44611332 -0.31142901 -0.3446322  -0.23065159 -1.5440342
 -0.62382061 -0.28397195 -0.28889616 -0.3058072 ]
u_c before reduction of space:  [-0.36595932 -0.44611332 -0.31142901 -0.3446322  -0.23065159 -1.5440342
 -0.62382061 -0.28397195 -0.28889616 -0.3058072 ]
data[u_c] post encoding of state:  [-0.36595932 -0.44611332 -0.31142901 -0.3446322  -0.23065159 -1.5440342
 -0.62382061 -0.28397195 -0.28889616 -0.3058072 ]
J_b = 0.0, J_o = 147278.84218270073
J_b = 0.5000000000000001, J_o = 4736022.454402442
J_b = 0.00896972926964534, J_o = 34839.35015211906
J_b = 0.009944198939669736, J_o = 27483.69739016634
J_b = 0.02488585322075897, J_o = 9353.967544933908
J_b = 0.03098397636486662, J_o = 7108.813280124105
J_b = 0.04313106773666524, J_o = 4664.495667235689
J_b = 0.0591398588884359, J_o = 3310.238110556119
J_b = 0.07832088737097434, J_o = 2366.4059368690932
J_b = 0.08175068914876775, J_o = 1925.0796799318077
J_b = 0.0861120626465861, J_o = 1615.223735159833
J_b = 0.09369007753740233, J_o = 1382.1341300094898
J_b = 0.10892556558212829, J_o = 1077.006366159235
J_b = 0.13482018033079232, J_o = 887.9603320116776
J_b = 0.13818737597537262, J_o = 775.0696413385681
J_b = 0.13940418871665944, J_o = 816.0612529632614
J_b = 0.13855059204855014, J_o = 757.426669341524
J_b = 0.14031671821293976, J_o = 726.7634215967429
J_b = 0.14107926132714405, J_o = 715.5334708884424
J_b = 0.1439650212896914, J_o = 691.2283361520014
J_b = 0.147985354998879, J_o = 656.8481779441711
J_b = 0.16110862560317507, J_o = 638.8346983280686
J_b = 0.15899649805254715, J_o = 603.1742712261007
J_b = 0.15875045812337915, J_o = 593.9768065887447
J_b = 0.1609455675228627, J_o = 573.8290754014934
J_b = 0.169458692277697, J_o = 541.7753944800709
J_b = 0.1810176263314945, J_o = 511.6768637185251
J_b = 0.18891908457836784, J_o = 487.0288695365416
J_b = 0.19806066138359799, J_o = 465.2818713788646
J_b = 0.2051678100428987, J_o = 469.94911839621466
J_b = 0.20097806642359548, J_o = 460.06160388232763
J_b = 0.20161191428405792, J_o = 453.45422905978467
J_b = 0.20284297453976058, J_o = 441.32353475438015
J_b = 0.20579616332138287, J_o = 430.3925326861122
J_b = 0.2093279256622194, J_o = 424.0935192372166
J_b = 0.2117470233610728, J_o = 417.24866640777515
J_b = 0.21430790277314776, J_o = 410.7640095393626
J_b = 0.2173077424256616, J_o = 402.2252113144768
J_b = 0.22374374592096202, J_o = 393.2958236479801
J_b = 0.22905452664088913, J_o = 383.1561812842181
J_b = 0.229571593976985, J_o = 376.97153985734656
J_b = 0.23218299430553463, J_o = 373.45953076304284
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36595932 -0.44611332 -0.31142901 -0.3446322  -0.23065159 -1.5440342
 -0.62382061 -0.28397195 -0.28889616 -0.3058072 ]
W_opt:  [ 0.01462764  0.00544353 -0.01086666 -0.02084552 -0.0204524   0.02179574
  0.04578274  0.02825984 -0.07371271 -0.27526447]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.7699 s, v_trunc (Latent to Reduced) = 0.0615, dec (Reduced to Full) = 0.2111, add (DA)= 0.0001decode = 0.2748 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.0448 s, inc stats = 6.0471, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.13272389e-07 6.10184836e-07 1.50256851e-06 1.13107010e-06
 1.24948514e-06]
u_DA:    [ 2.58368907e-03  6.70148056e-03  3.77826586e-03  2.05436021e-03
 -9.94213192e-05]
ref_MAE: [0.00805525 0.00987217 0.00446222 0.00560664 0.00061665]
da_MAE:  [0.00258308 0.00670087 0.00377676 0.00205323 0.00010067]
% 33.18412521698466 da_MAE 0.09585115067166006 ref_MAE 0.143455654787035
u_c taken from control states: [-0.36596428 -0.44611549 -0.31142782 -0.34463526 -0.23070395 -1.54760494
 -0.62383088 -0.28416455 -0.29409297 -0.30581767]
u_c before reduction of space:  [-0.36596428 -0.44611549 -0.31142782 -0.34463526 -0.23070395 -1.54760494
 -0.62383088 -0.28416455 -0.29409297 -0.30581767]
data[u_c] post encoding of state:  [-0.36596428 -0.44611549 -0.31142782 -0.34463526 -0.23070395 -1.54760494
 -0.62383088 -0.28416455 -0.29409297 -0.30581767]
J_b = 0.0, J_o = 147327.93200917507
J_b = 0.5, J_o = 4736039.514787721
J_b = 0.008969204202662898, J_o = 34897.01076451618
J_b = 0.00994418655531635, J_o = 27536.875876912873
J_b = 0.024931123683383665, J_o = 9364.17583911094
J_b = 0.03105274845765346, J_o = 7114.552566028629
J_b = 0.04319124131285649, J_o = 4673.694391429791
J_b = 0.059209281160395144, J_o = 3317.737032457825
J_b = 0.07844628150252715, J_o = 2376.662620652352
J_b = 0.08176821463744888, J_o = 1936.7966461120002
J_b = 0.08600939825975366, J_o = 1629.5555424373315
J_b = 0.0934948729971788, J_o = 1398.063781010011
J_b = 0.10861805760196389, J_o = 1094.3978056277426
J_b = 0.13418471586786468, J_o = 904.5789748614723
J_b = 0.13772846950654302, J_o = 792.6555474573491
J_b = 0.13914307827473202, J_o = 836.8246061631394
J_b = 0.1381502315680182, J_o = 774.9180999635786
J_b = 0.13999392467491367, J_o = 743.8670674115408
J_b = 0.14072906069436233, J_o = 732.6922077441106
J_b = 0.14355311527459394, J_o = 708.5011398268919
J_b = 0.14747608247773442, J_o = 674.4746195631049
J_b = 0.16025511668367665, J_o = 654.5298547497821
J_b = 0.15842496123785219, J_o = 620.9463961762071
J_b = 0.15821445494304723, J_o = 611.5765739786438
J_b = 0.1604885646677423, J_o = 591.1208620214834
J_b = 0.16931382701470865, J_o = 559.312775419322
J_b = 0.1807341369900117, J_o = 529.8761510462353
J_b = 0.18790164333215348, J_o = 506.55852288873297
J_b = 0.1967434522203089, J_o = 485.0791834054105
J_b = 0.21203163395980307, J_o = 1290.839992169632
J_b = 0.19736478440374003, J_o = 483.2606750062684
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36596428 -0.44611549 -0.31142782 -0.34463526 -0.23070395 -1.54760494
 -0.62383088 -0.28416455 -0.29409297 -0.30581767]
W_opt:  [ 0.00573535 -0.00405939 -0.00909825 -0.00545281  0.003785    0.03663263
  0.03966187 -0.00280554 -0.10994036 -0.26707507]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9755 s, v_trunc (Latent to Reduced) = 0.0532, dec (Reduced to Full) = 0.1768, add (DA)= 0.0001decode = 0.2329 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2084 s, inc stats = 4.2110, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [6.05027303e-07 6.04688465e-07 1.50357326e-06 1.12772606e-06
 1.23807468e-06]
u_DA:    [ 2.70921532e-03  6.67842574e-03  3.82285742e-03  2.08934219e-03
 -8.54509077e-05]
ref_MAE: [0.00805526 0.00987218 0.00446222 0.00560665 0.00061666]
da_MAE:  [2.70861029e-03 6.67782105e-03 3.82135385e-03 2.08821446e-03
 8.66889824e-05]
% 33.54391637254577 da_MAE 0.09545587019835766 ref_MAE 0.14363751967912097
u_c taken from control states: [-0.36596904 -0.44611782 -0.31143013 -0.34464008 -0.23073663 -1.5508376
 -0.62384316 -0.28423798 -0.2991807  -0.30582701]
u_c before reduction of space:  [-0.36596904 -0.44611782 -0.31143013 -0.34464008 -0.23073663 -1.5508376
 -0.62384316 -0.28423798 -0.2991807  -0.30582701]
data[u_c] post encoding of state:  [-0.36596904 -0.44611782 -0.31143013 -0.34464008 -0.23073663 -1.5508376
 -0.62384316 -0.28423798 -0.2991807  -0.30582701]
J_b = 0.0, J_o = 147386.45991090403
J_b = 0.5000000000000003, J_o = 4736074.802615083
J_b = 0.008968080394428255, J_o = 34972.77195504443
J_b = 0.009943767689480102, J_o = 27606.627689887686
J_b = 0.024986453485675002, J_o = 9381.213998205278
J_b = 0.031134634043998966, J_o = 7127.309040308828
J_b = 0.04324868942224594, J_o = 4693.148389708071
J_b = 0.05927336099395253, J_o = 3333.948978374975
J_b = 0.07864637503260088, J_o = 2394.5054754976213
J_b = 0.08186936091887714, J_o = 1954.5794124049996
J_b = 0.08596791066279776, J_o = 1650.1039269412743
J_b = 0.09336048513885697, J_o = 1419.6722971956192
J_b = 0.10845259841479808, J_o = 1115.4521959135236
J_b = 0.1338999476933143, J_o = 923.1375735197107
J_b = 0.13770165107438032, J_o = 810.9809033722506
J_b = 0.1393644440910469, J_o = 860.5354951559805
J_b = 0.13819061699276206, J_o = 793.1410941289768
J_b = 0.14013133525098528, J_o = 761.4343108537562
J_b = 0.14083845341679607, J_o = 750.2159810771584
J_b = 0.14359904757095482, J_o = 726.1027308159437
J_b = 0.14742870872414493, J_o = 692.3954523497707
J_b = 0.15982040820029936, J_o = 669.947104632161
J_b = 0.15838806192500524, J_o = 638.5969462318395
J_b = 0.15825502922474782, J_o = 628.8018156008566
J_b = 0.16065792615426125, J_o = 607.8892575353907
J_b = 0.16992334287666677, J_o = 576.7244386475206
J_b = 0.180843099442407, J_o = 547.373830349194
J_b = 0.18754074300560666, J_o = 525.2629235609668
J_b = 0.1965045238219154, J_o = 512.735773907455
J_b = 0.20372084558645545, J_o = 513.3735693363227
J_b = 0.19997962479898862, J_o = 502.5975551065071
J_b = 0.1981978026174496, J_o = 497.3771937048289
J_b = 0.1970533389781172, J_o = 476.90361758029076
J_b = 0.20281722662214952, J_o = 462.16376748241174
J_b = 0.214526054518132, J_o = 462.09158694193536
J_b = 0.20847738718617306, J_o = 455.99390635986924
J_b = 0.21401998004994763, J_o = 449.84079566473804
J_b = 0.21657819607571965, J_o = 445.3838399828355
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36596904 -0.44611782 -0.31143013 -0.34464008 -0.23073663 -1.5508376
 -0.62384316 -0.28423798 -0.2991807  -0.30582701]
W_opt:  [ 0.0172242   0.00052757 -0.01528435 -0.01923928 -0.01294569  0.02967609
  0.04814759  0.01661081 -0.0919658  -0.27455326]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3850 s, v_trunc (Latent to Reduced) = 0.0533, dec (Reduced to Full) = 0.2372, add (DA)= 0.0001decode = 0.2926 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6778 s, inc stats = 5.6801, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.97117794e-07 5.98788164e-07 1.50162923e-06 1.12244906e-06
 1.23095238e-06]
u_DA:    [ 2.66146581e-03  6.69692603e-03  3.80050960e-03  2.05771737e-03
 -9.19988155e-05]
ref_MAE: [0.00805527 0.00987219 0.00446222 0.00560665 0.00061667]
da_MAE:  [2.66086870e-03 6.69632725e-03 3.79900797e-03 2.05659492e-03
 9.32297678e-05]
% 33.518012862931094 da_MAE 0.09548911464961977 ref_MAE 0.14363155910599598
u_c taken from control states: [-0.36597327 -0.44612025 -0.31143456 -0.34464596 -0.23074511 -1.55368213
 -0.62385735 -0.28415469 -0.30355158 -0.30583439]
u_c before reduction of space:  [-0.36597327 -0.44612025 -0.31143456 -0.34464596 -0.23074511 -1.55368213
 -0.62385735 -0.28415469 -0.30355158 -0.30583439]
data[u_c] post encoding of state:  [-0.36597327 -0.44612025 -0.31143456 -0.34464596 -0.23074511 -1.55368213
 -0.62385735 -0.28415469 -0.30355158 -0.30583439]
J_b = 0.0, J_o = 147421.28247036884
J_b = 0.5, J_o = 4736407.753949662
J_b = 0.00896564552566115, J_o = 35036.395558059456
J_b = 0.00994106159810767, J_o = 27671.012351442823
J_b = 0.025038040899377712, J_o = 9398.408590137373
J_b = 0.031213069671370396, J_o = 7141.369906624487
J_b = 0.04329606508963898, J_o = 4715.16352403783
J_b = 0.05936696601590599, J_o = 3348.7099361643477
J_b = 0.07899494858708674, J_o = 2409.5171399380256
J_b = 0.08208145232022888, J_o = 1968.7607649351885
J_b = 0.08596758463315939, J_o = 1668.771233151339
J_b = 0.0932093347757229, J_o = 1440.3418558717478
J_b = 0.10820823410712176, J_o = 1136.0083792059238
J_b = 0.13343982158580225, J_o = 939.8620226667516
J_b = 0.13772435315237344, J_o = 827.0715646801425
J_b = 0.13983423614904142, J_o = 887.0888731187297
J_b = 0.1383244452327858, J_o = 809.1648311690662
J_b = 0.14042260434112766, J_o = 776.3918448915792
J_b = 0.14108112451202673, J_o = 765.024249248849
J_b = 0.1437230786538263, J_o = 741.054064559853
J_b = 0.14742368128686686, J_o = 707.8586083470587
J_b = 0.15917017682707785, J_o = 682.2227785431447
J_b = 0.15838611011947704, J_o = 653.7001859599173
J_b = 0.15844809759711806, J_o = 643.0956286160905
J_b = 0.16109657358754176, J_o = 621.6712163058229
J_b = 0.17097178714755085, J_o = 592.2203959774658
J_b = 0.18073728465446742, J_o = 562.7595511520883
J_b = 0.18709994081572617, J_o = 542.0141521915516
J_b = 0.19564729407973594, J_o = 536.7850683508519
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597327 -0.44612025 -0.31143456 -0.34464596 -0.23074511 -1.55368213
 -0.62385735 -0.28415469 -0.30355158 -0.30583439]
W_opt:  [ 0.00345238 -0.00422619 -0.00707331 -0.00370936  0.00477147  0.03684696
  0.03984859 -0.00355509 -0.11048422 -0.26534642]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8410 s, v_trunc (Latent to Reduced) = 0.0538, dec (Reduced to Full) = 0.1557, add (DA)= 0.0001decode = 0.2114 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0525 s, inc stats = 4.0549, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.90091011e-07 5.92629608e-07 1.49790675e-06 1.11602229e-06
 1.22910350e-06]
u_DA:    [ 2.70974730e-03  6.72551427e-03  3.82733262e-03  2.09745307e-03
 -8.40836468e-05]
ref_MAE: [0.00805527 0.00987219 0.00446222 0.00560666 0.00061667]
da_MAE:  [2.70915721e-03 6.72492164e-03 3.82583471e-03 2.09633704e-03
 8.53127503e-05]
% 33.88218044420417 da_MAE 0.09479210371380103 ref_MAE 0.1433684660968098
u_c taken from control states: [-0.36597677 -0.44612271 -0.31144011 -0.34465201 -0.23072996 -1.55614666
 -0.62387275 -0.28391859 -0.30687804 -0.30583919]
u_c before reduction of space:  [-0.36597677 -0.44612271 -0.31144011 -0.34465201 -0.23072996 -1.55614666
 -0.62387275 -0.28391859 -0.30687804 -0.30583919]
data[u_c] post encoding of state:  [-0.36597677 -0.44612271 -0.31144011 -0.34465201 -0.23072996 -1.55614666
 -0.62387275 -0.28391859 -0.30687804 -0.30583919]
J_b = 0.0, J_o = 147465.37693602598
J_b = 0.49999999999999994, J_o = 4736893.678418459
J_b = 0.008961245762675601, J_o = 35134.90900655994
J_b = 0.009936376962744617, J_o = 27770.393863275538
J_b = 0.025091204338068943, J_o = 9447.62005239342
J_b = 0.031295560669695216, J_o = 7186.919194317572
J_b = 0.04335292729993503, J_o = 4767.193376625495
J_b = 0.05950947651620353, J_o = 3389.700524651709
J_b = 0.07948680977254845, J_o = 2449.3439286896155
J_b = 0.08241624477989509, J_o = 2006.3071866659504
J_b = 0.08607647886540779, J_o = 1710.1067029783649
J_b = 0.09319377783204119, J_o = 1482.3598809173773
J_b = 0.10819694432338268, J_o = 1175.4427686865954
J_b = 0.13340764907392477, J_o = 973.0666657564535
J_b = 0.13840605142193918, J_o = 858.1444121784102
J_b = 0.14112212394979512, J_o = 935.0984133447092
J_b = 0.1391343629307932, J_o = 840.3353163402264
J_b = 0.1414128290350441, J_o = 806.1437943261683
J_b = 0.1420171111846456, J_o = 794.3372142210495
J_b = 0.1445137983742222, J_o = 770.4428131303464
J_b = 0.1481240048281629, J_o = 737.5804232780091
J_b = 0.15917663145733205, J_o = 708.6736981912084
J_b = 0.15922107553355938, J_o = 682.2986006507924
J_b = 0.15967078345287805, J_o = 670.1829464325285
J_b = 0.16274116477691475, J_o = 648.0424498690486
J_b = 0.17348296181228676, J_o = 621.5881901445858
J_b = 0.1813098309577306, J_o = 591.5088495847414
J_b = 0.1874684939857479, J_o = 571.6118712801689
J_b = 0.19443813063293963, J_o = 564.8915866303499
J_b = 0.1983431640880827, J_o = 555.6854588134913
J_b = 0.19610529900119322, J_o = 550.2627525063683
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597677 -0.44612271 -0.31144011 -0.34465201 -0.23072996 -1.55614666
 -0.62387275 -0.28391859 -0.30687804 -0.30583919]
W_opt:  [ 0.00349959 -0.00428223 -0.00650357 -0.00381451  0.00446773  0.0368185
  0.03942054 -0.0041837  -0.11066846 -0.26479448]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4983 s, v_trunc (Latent to Reduced) = 0.0545, dec (Reduced to Full) = 0.1670, add (DA)= 0.0001decode = 0.2235 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7219 s, inc stats = 4.7242, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.84278281e-07 5.86389318e-07 1.49324266e-06 1.10939804e-06
 1.23240600e-06]
u_DA:    [ 2.72518992e-03  6.69649460e-03  3.83287808e-03  2.07274710e-03
 -8.50741730e-05]
ref_MAE: [0.00805528 0.0098722  0.00446223 0.00560666 0.00061666]
da_MAE:  [2.72460564e-03 6.69590821e-03 3.83138483e-03 2.07163770e-03
 8.63065790e-05]
% 34.32500836475968 da_MAE 0.09387362927128935 ref_MAE 0.14293664442724957
u_c taken from control states: [-0.36597945 -0.44612511 -0.31144596 -0.34465736 -0.2306955  -1.55829814
 -0.62388879 -0.28356023 -0.30899714 -0.30584119]
u_c before reduction of space:  [-0.36597945 -0.44612511 -0.31144596 -0.34465736 -0.2306955  -1.55829814
 -0.62388879 -0.28356023 -0.30899714 -0.30584119]
data[u_c] post encoding of state:  [-0.36597945 -0.44612511 -0.31144596 -0.34465736 -0.2306955  -1.55829814
 -0.62388879 -0.28356023 -0.30899714 -0.30584119]
J_b = 0.0, J_o = 147498.0927536192
J_b = 0.4999999999999999, J_o = 4737378.197736329
J_b = 0.008953704949123377, J_o = 35268.37083614999
J_b = 0.009929479229909865, J_o = 27898.277658483927
J_b = 0.025153043296907915, J_o = 9511.702760103964
J_b = 0.03139356906592628, J_o = 7244.41638217433
J_b = 0.043445907582774605, J_o = 4826.922066106752
J_b = 0.05970989515626906, J_o = 3437.2774461807107
J_b = 0.08002425590806789, J_o = 2496.5515106882376
J_b = 0.08276134476077414, J_o = 2051.7913409248576
J_b = 0.08618663185039117, J_o = 1759.4872484511175
J_b = 0.09317653615974526, J_o = 1532.4166759476811
J_b = 0.108128687735601, J_o = 1223.7327015810138
J_b = 0.13319420138673205, J_o = 1014.7266863895385
J_b = 0.13913694672878105, J_o = 897.5373934224676
J_b = 0.14264251085734145, J_o = 999.3317450432052
J_b = 0.14000139198724185, J_o = 880.1865827567631
J_b = 0.14245289190571192, J_o = 844.630605430064
J_b = 0.1429876419365976, J_o = 832.1803556489224
J_b = 0.145278458042086, J_o = 808.4353463753939
J_b = 0.14882704382000606, J_o = 775.8260752099438
J_b = 0.1590025439550272, J_o = 743.8200575646721
J_b = 0.16007410586923507, J_o = 719.1356891650765
J_b = 0.1612687762474796, J_o = 704.4873065347324
J_b = 0.16500632924158626, J_o = 681.6068474649203
J_b = 0.17691076047993118, J_o = 658.8946009890076
J_b = 0.182738258336152, J_o = 627.5367242329901
J_b = 0.18806005929509023, J_o = 608.5824556627365
J_b = 0.19355136557009253, J_o = 601.5619071123917
J_b = 0.19826436016136811, J_o = 593.8907484928009
J_b = 0.1967392464386127, J_o = 588.2730108837301
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597945 -0.44612511 -0.31144596 -0.34465736 -0.2306955  -1.55829814
 -0.62388879 -0.28356023 -0.30899714 -0.30584119]
W_opt:  [ 0.00402811 -0.00369286 -0.00639354 -0.00391177  0.00488586  0.03721887
  0.03913796 -0.00529745 -0.11121594 -0.26441418]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5677 s, v_trunc (Latent to Reduced) = 0.0506, dec (Reduced to Full) = 0.1807, add (DA)= 0.0001decode = 0.2339 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8017 s, inc stats = 4.8043, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.79814709e-07 5.80298924e-07 1.48832936e-06 1.10354052e-06
 1.23991615e-06]
u_DA:    [ 2.71993741e-03  6.69057930e-03  3.83229230e-03  2.06635785e-03
 -8.61090761e-05]
ref_MAE: [0.00805528 0.0098722  0.00446223 0.00560667 0.00061666]
da_MAE:  [2.71935759e-03 6.68999901e-03 3.83080397e-03 2.06525431e-03
 8.73489922e-05]
% 34.80827460507969 da_MAE 0.0929713401050519 ref_MAE 0.1426121789872065
\% improve_point: 13.52, mse_ref_points: 1.921800582454184e-05, mse_da_points: 1.6620342294101934e-05, % improve_overlap: -22.97, mse_ref_overlap: 0.16460, mse_da_overlap: 0.20242
DA - - L2: 271.78, L1: 862.29, % Improve: 33.92%, DA_MAE: 0.09, mse_ref: 0.17, mse_DA: 0.149, time(s): 6.7648s,
u_c taken from control states: [-0.36598118 -0.44612734 -0.31145069 -0.34466139 -0.23064124 -1.5601606
 -0.62390531 -0.28307978 -0.30967482 -0.30584015]
u_c before reduction of space:  [-0.36598118 -0.44612734 -0.31145069 -0.34466139 -0.23064124 -1.5601606
 -0.62390531 -0.28307978 -0.30967482 -0.30584015]
data[u_c] post encoding of state:  [-0.36598118 -0.44612734 -0.31145069 -0.34466139 -0.23064124 -1.5601606
 -0.62390531 -0.28307978 -0.30967482 -0.30584015]
J_b = 0.0, J_o = 147521.32153011163
J_b = 0.5000000000000001, J_o = 4738010.473750882
J_b = 0.008945472182752375, J_o = 35398.75626558586
J_b = 0.009921430760660634, J_o = 28026.257604545797
J_b = 0.025213586734195912, J_o = 9578.322755428533
J_b = 0.03148941091240293, J_o = 7305.712410490196
J_b = 0.04351774121572758, J_o = 4895.027977855189
J_b = 0.059843453819586216, J_o = 3496.768963813743
J_b = 0.08044125102018745, J_o = 2557.260276388103
J_b = 0.08301875059423747, J_o = 2110.3058311000486
J_b = 0.08624632556565376, J_o = 1821.101619474657
J_b = 0.09313311713406622, J_o = 1594.2585880047131
J_b = 0.1080650814850572, J_o = 1283.2804961026102
J_b = 0.13304182505839995, J_o = 1067.2504852809132
J_b = 0.1400552886689097, J_o = 947.2841481127616
J_b = 0.14437217260739513, J_o = 1079.6349580353456
J_b = 0.14102222394559646, J_o = 930.7508456889664
J_b = 0.14357172324315284, J_o = 894.2539521379003
J_b = 0.14403776222576653, J_o = 880.9534816509201
J_b = 0.14611473762967075, J_o = 857.2861255881221
J_b = 0.1496680824477571, J_o = 824.7623166649312
J_b = 0.15886236720352376, J_o = 790.2877014745507
J_b = 0.16100795091909978, J_o = 766.6256204855966
J_b = 0.16350667913384748, J_o = 747.7323328355704
J_b = 0.16827112337179337, J_o = 723.5401542145347
J_b = 0.18211369645928036, J_o = 706.1445425546681
J_b = 0.18583195784392195, J_o = 670.917866036127
J_b = 0.18934829905521045, J_o = 653.7547031079772
J_b = 0.19384833760132886, J_o = 647.3470320705794
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36598118 -0.44612734 -0.31145069 -0.34466139 -0.23064124 -1.5601606
 -0.62390531 -0.28307978 -0.30967482 -0.30584015]
W_opt:  [ 0.00197213 -0.0035859  -0.00509955 -0.00231794  0.0075354   0.03740142
  0.03597964 -0.00920754 -0.11294954 -0.26204923]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8932 s, v_trunc (Latent to Reduced) = 0.0524, dec (Reduced to Full) = 0.2516, add (DA)= 0.0001decode = 0.3061 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 4.1993 s, inc stats = 4.2016, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.76950879e-07 5.74664637e-07 1.48435084e-06 1.09913779e-06
 1.25174145e-06]
u_DA:    [ 2.71842939e-03  6.70875481e-03  3.83195268e-03  2.07630906e-03
 -8.47643153e-05]
ref_MAE: [0.00805529 0.00987221 0.00446224 0.00560667 0.00061664]
da_MAE:  [2.71785244e-03 6.70818015e-03 3.83046833e-03 2.07520993e-03
 8.60160567e-05]
% 35.517850229256396 da_MAE 0.09201511180099799 ref_MAE 0.1426985795730192
u_c taken from control states: [-0.36598195 -0.44612932 -0.31145335 -0.3446635  -0.23057206 -1.56179715
 -0.62392139 -0.28250167 -0.30873242 -0.30583639]
u_c before reduction of space:  [-0.36598195 -0.44612932 -0.31145335 -0.3446635  -0.23057206 -1.56179715
 -0.62392139 -0.28250167 -0.30873242 -0.30583639]
data[u_c] post encoding of state:  [-0.36598195 -0.44612932 -0.31145335 -0.3446635  -0.23057206 -1.56179715
 -0.62392139 -0.28250167 -0.30873242 -0.30583639]
J_b = 0.0, J_o = 147509.79869662304
J_b = 0.5000000000000001, J_o = 4738798.0969312005
J_b = 0.008933362271983856, J_o = 35547.213325802506
J_b = 0.009909818294506649, J_o = 28170.41853496217
J_b = 0.02526719514637346, J_o = 9662.802472517884
J_b = 0.031578728444533105, J_o = 7383.810814492431
J_b = 0.04359542144372801, J_o = 4977.065436480817
J_b = 0.059992176051386625, J_o = 3569.7523231391665
J_b = 0.08086524256185301, J_o = 2631.266044453541
J_b = 0.08329069404615501, J_o = 2181.5771990683525
J_b = 0.08635118909302186, J_o = 1894.2619409709687
J_b = 0.0931719918979446, J_o = 1666.7691583454762
J_b = 0.10812327995122663, J_o = 1352.7583510912245
J_b = 0.13304271178437915, J_o = 1128.7219078357457
J_b = 0.14136653037652103, J_o = 1005.5980578120669
J_b = 0.14649315455118633, J_o = 1176.8591968720093
J_b = 0.14238988075870612, J_o = 990.379901197135
J_b = 0.14490269897610494, J_o = 953.6520170730507
J_b = 0.14529521798850406, J_o = 939.1282517857691
J_b = 0.14714077139219872, J_o = 915.4112456991903
J_b = 0.15079716884517327, J_o = 883.0055576110987
J_b = 0.15872236501261533, J_o = 846.8310577305274
J_b = 0.16208867841736185, J_o = 823.3592697559534
J_b = 0.16683706139949955, J_o = 797.2988052967844
J_b = 0.17379285644359166, J_o = 768.8840140347054
J_b = 0.1870090356440649, J_o = 725.7913358763814
J_b = 0.22104764699827933, J_o = 920.5228601523916
J_b = 0.19286339055717633, J_o = 713.3222853093042
J_b = 0.20493862673767332, J_o = 685.6229914661496
J_b = 0.22012120717748446, J_o = 889.966621199914
J_b = 0.206512881683645, J_o = 682.4349692328517
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36598195 -0.44612932 -0.31145335 -0.3446635  -0.23057206 -1.56179715
 -0.62392139 -0.28250167 -0.30873242 -0.30583639]
W_opt:  [ 0.00566126 -0.00366641 -0.00874194 -0.00831825  0.00303388  0.03660129
  0.04006944 -0.00277034 -0.11029993 -0.26959095]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2728 s, v_trunc (Latent to Reduced) = 0.0511, dec (Reduced to Full) = 0.2059, add (DA)= 0.0001decode = 0.2595 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.5324 s, inc stats = 4.5347, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.75665032e-07 5.69630165e-07 1.48211623e-06 1.09682421e-06
 1.26682030e-06]
u_DA:    [ 2.70471385e-03  6.66399990e-03  3.83020428e-03  2.05255170e-03
 -8.71645047e-05]
ref_MAE: [0.00805529 0.00987222 0.00446224 0.00560668 0.00061663]
da_MAE:  [2.70413818e-03 6.66343027e-03 3.82872216e-03 2.05145488e-03
 8.84313250e-05]
% 36.43004441123463 da_MAE 0.0909729244021727 ref_MAE 0.14310679244559707
u_c taken from control states: [-0.36598186 -0.44613103 -0.31145292 -0.34466311 -0.23049426 -1.56332896
 -0.62393615 -0.28186362 -0.30621506 -0.30583026]
u_c before reduction of space:  [-0.36598186 -0.44613103 -0.31145292 -0.34466311 -0.23049426 -1.56332896
 -0.62393615 -0.28186362 -0.30621506 -0.30583026]
data[u_c] post encoding of state:  [-0.36598186 -0.44613103 -0.31145292 -0.34466311 -0.23049426 -1.56332896
 -0.62393615 -0.28186362 -0.30621506 -0.30583026]
J_b = 0.0, J_o = 147483.23105647878
J_b = 0.4999999999999999, J_o = 4739477.483209471
J_b = 0.008919787753974742, J_o = 35704.58623153588
J_b = 0.009897533520983694, J_o = 28318.233435274647
J_b = 0.025316517492615, J_o = 9750.335812151172
J_b = 0.031664900912129396, J_o = 7462.496302672895
J_b = 0.04370056817999459, J_o = 5053.106763893366
J_b = 0.06018344972012977, J_o = 3637.0596420941765
J_b = 0.08126426255690695, J_o = 2699.351998393775
J_b = 0.0835526667408781, J_o = 2247.4670410290105
J_b = 0.08650138475776158, J_o = 1960.549437694766
J_b = 0.09329804197634699, J_o = 1731.9773853583947
J_b = 0.1082672848676472, J_o = 1415.7071261349388
J_b = 0.13304171621775207, J_o = 1185.2664377654396
J_b = 0.14259574303506128, J_o = 1059.9732593242522
J_b = 0.14831276215275904, J_o = 1267.7388486821035
J_b = 0.14362481613149908, J_o = 1046.1223375319394
J_b = 0.14596479312923405, J_o = 1009.9035818837051
J_b = 0.14630393520153914, J_o = 993.9759568996725
J_b = 0.14797647069945347, J_o = 969.9502751973513
J_b = 0.1518462266492999, J_o = 938.1208364222575
J_b = 0.15845888315398055, J_o = 901.8746392238065
J_b = 0.1627759955281809, J_o = 877.8571839082977
J_b = 0.16782949452910584, J_o = 853.6846034031025
J_b = 0.17597993212448754, J_o = 826.1949515010803
J_b = 0.19078965982315818, J_o = 800.2513662324834
J_b = 0.19673165954874625, J_o = 771.0690143532555
J_b = 0.19996857050663225, J_o = 751.537384417906
J_b = 0.20470975318219028, J_o = 763.3002702908368
J_b = 0.2015361710659692, J_o = 747.2279029303336
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36598186 -0.44613103 -0.31145292 -0.34466311 -0.23049426 -1.56332896
 -0.62393615 -0.28186362 -0.30621506 -0.30583026]
W_opt:  [ 0.00154339 -0.00480475 -0.00585436 -0.00372996  0.00732033  0.03746893
  0.03817596 -0.00602686 -0.1123893  -0.26548003]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.1643 s, v_trunc (Latent to Reduced) = 0.0507, dec (Reduced to Full) = 0.2107, add (DA)= 0.0001decode = 0.2637 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4280 s, inc stats = 4.4306, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.75821324e-07 5.65303051e-07 1.48247768e-06 1.09725119e-06
 1.28377554e-06]
u_DA:    [ 2.70622464e-03  6.70641063e-03  3.82250217e-03  2.06174815e-03
 -8.68546469e-05]
ref_MAE: [0.00805529 0.00987222 0.00446224 0.00560668 0.00061661]
da_MAE:  [2.70564881e-03 6.70584533e-03 3.82101970e-03 2.06065090e-03
 8.81384225e-05]
% 37.407177177836054 da_MAE 0.09002256031533276 ref_MAE 0.14382249634451064
u_c taken from control states: [-0.36598104 -0.44613245 -0.31144875 -0.34466001 -0.23041541 -1.56487108
 -0.62394912 -0.28121293 -0.30222576 -0.30582237]
u_c before reduction of space:  [-0.36598104 -0.44613245 -0.31144875 -0.34466001 -0.23041541 -1.56487108
 -0.62394912 -0.28121293 -0.30222576 -0.30582237]
data[u_c] post encoding of state:  [-0.36598104 -0.44613245 -0.31144875 -0.34466001 -0.23041541 -1.56487108
 -0.62394912 -0.28121293 -0.30222576 -0.30582237]
J_b = 0.0, J_o = 147447.940357022
J_b = 0.5000000000000001, J_o = 4740180.00187629
J_b = 0.008907090667810744, J_o = 35839.439827484486
J_b = 0.009885619934361153, J_o = 28447.462497119745
J_b = 0.025343498708037582, J_o = 9841.14735271368
J_b = 0.031720273190194374, J_o = 7545.2599005460215
J_b = 0.04379686831178902, J_o = 5128.035861241796
J_b = 0.060397353734960024, J_o = 3701.9312321344614
J_b = 0.08168690163279897, J_o = 2762.255625939284
J_b = 0.08388291205802142, J_o = 2307.5355530104293
J_b = 0.08677396567970792, J_o = 2019.8782540018733
J_b = 0.09357339406642552, J_o = 1790.2451179273626
J_b = 0.10857919564913705, J_o = 1471.9812741961593
J_b = 0.13328349975970266, J_o = 1236.261542233145
J_b = 0.1438502691227315, J_o = 1109.1123385824042
J_b = 0.14997197177648236, J_o = 1344.98939440523
J_b = 0.14487434275961777, J_o = 1096.1983441241125
J_b = 0.1470228395353642, J_o = 1060.4812557960104
J_b = 0.14734057468784492, J_o = 1043.1600664159541
J_b = 0.14893245963893825, J_o = 1018.5424683033275
J_b = 0.1530983162697392, J_o = 987.4998204421415
J_b = 0.15874819516763927, J_o = 951.6816671100277
J_b = 0.16356545327628963, J_o = 927.0260891021519
J_b = 0.16772873951513084, J_o = 908.6714107480124
J_b = 0.17475494630560973, J_o = 882.8767629569974
J_b = 0.18993688170172124, J_o = 856.1764197660964
J_b = 0.1978573319204646, J_o = 822.5958287993615
J_b = 0.1996412855606663, J_o = 804.3581912494096
J_b = 0.2039120107663245, J_o = 812.5794568214851
J_b = 0.20128031986357364, J_o = 798.0584452500939
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36598104 -0.44613245 -0.31144875 -0.34466001 -0.23041541 -1.56487108
 -0.62394912 -0.28121293 -0.30222576 -0.30582237]
W_opt:  [ 0.00108521 -0.00537947 -0.00512338 -0.0028189   0.00759053  0.03686423
  0.0373334  -0.00704653 -0.11315818 -0.26478109]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.0451 s, v_trunc (Latent to Reduced) = 0.0545, dec (Reduced to Full) = 0.2943, add (DA)= 0.0001decode = 0.3509 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.3961 s, inc stats = 4.3997, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.77185433e-07 5.61712233e-07 1.48597968e-06 1.10064748e-06
 1.30096138e-06]
u_DA:    [ 2.70315037e-03  6.70673843e-03  3.81664374e-03  2.06031011e-03
 -8.61857741e-05]
ref_MAE: [0.00805529 0.00987222 0.00446224 0.00560667 0.0006166 ]
da_MAE:  [2.70257319e-03 6.70617672e-03 3.81515776e-03 2.05920947e-03
 8.74867354e-05]
% 38.43153907557623 da_MAE 0.08916602362967078 ref_MAE 0.1448241880516121
u_c taken from control states: [-0.36597964 -0.44613356 -0.31144036 -0.34465417 -0.23033985 -1.5665334
 -0.62395976 -0.28058056 -0.2969139  -0.30581321]
u_c before reduction of space:  [-0.36597964 -0.44613356 -0.31144036 -0.34465417 -0.23033985 -1.5665334
 -0.62395976 -0.28058056 -0.2969139  -0.30581321]
data[u_c] post encoding of state:  [-0.36597964 -0.44613356 -0.31144036 -0.34465417 -0.23033985 -1.5665334
 -0.62395976 -0.28058056 -0.2969139  -0.30581321]
J_b = 0.0, J_o = 147450.04328239214
J_b = 0.5000000000000001, J_o = 4740517.299685316
J_b = 0.008898839622910017, J_o = 35955.60192958533
J_b = 0.009878531677687435, J_o = 28555.261674393296
J_b = 0.02537327649153997, J_o = 9910.565606866568
J_b = 0.03177575210810727, J_o = 7606.882210900472
J_b = 0.04389155053275125, J_o = 5182.304210876437
J_b = 0.06057473113612303, J_o = 3749.4122764148983
J_b = 0.08199058318732416, J_o = 2808.1826842068795
J_b = 0.08413581829423358, J_o = 2351.266829038553
J_b = 0.08701138895355166, J_o = 2062.2869825378502
J_b = 0.09383336332125886, J_o = 1831.554217346784
J_b = 0.10890486976477536, J_o = 1511.3035949811738
J_b = 0.13368367983844504, J_o = 1271.641428018035
J_b = 0.14487225843722867, J_o = 1142.7783983831957
J_b = 0.15129520240018696, J_o = 1395.558461558664
J_b = 0.14590921290305944, J_o = 1130.1815350939746
J_b = 0.1479810659671308, J_o = 1094.4134167638222
J_b = 0.14830240538610664, J_o = 1076.1740831326579
J_b = 0.1498774317808338, J_o = 1051.0470060591763
J_b = 0.15426800242036925, J_o = 1020.3945313896993
J_b = 0.15948257216819503, J_o = 984.572975731122
J_b = 0.1644921738751609, J_o = 959.4896948857285
J_b = 0.1682996409029929, J_o = 943.2970000369926
J_b = 0.17508787169106999, J_o = 917.3932269877434
J_b = 0.18992839868776085, J_o = 887.4503615359039
J_b = 0.2008012120623543, J_o = 852.5276136984312
J_b = 0.20151201240360642, J_o = 834.2892893091197
J_b = 0.20439820934923097, J_o = 838.6722376890947
J_b = 0.2027499987952091, J_o = 825.7840141073773
J_b = 0.20421820636605686, J_o = 817.0308639146842
J_b = 0.20554591802797756, J_o = 812.1295564850938
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597964 -0.44613356 -0.31144036 -0.34465417 -0.23033985 -1.5665334
 -0.62395976 -0.28058056 -0.2969139  -0.30581321]
W_opt:  [ 0.0051244  -0.00444875 -0.00626141 -0.00538887  0.00485447  0.03639243
  0.03955666 -0.00290229 -0.11007686 -0.2662725 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9487 s, v_trunc (Latent to Reduced) = 0.0485, dec (Reduced to Full) = 0.1707, add (DA)= 0.0001decode = 0.2213 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1701 s, inc stats = 5.1724, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.79501189e-07 5.58885033e-07 1.49303174e-06 1.10703750e-06
 1.31743023e-06]
u_DA:    [ 2.70002858e-03  6.69732574e-03  3.79959001e-03  2.03158302e-03
 -8.89067854e-05]
ref_MAE: [0.00805528 0.00987223 0.00446223 0.00560667 0.00061658]
da_MAE:  [2.69944908e-03 6.69676686e-03 3.79809698e-03 2.03047598e-03
 9.02242157e-05]
% 39.315483141614244 da_MAE 0.08845618304605213 ref_MAE 0.14576400641447756
u_c taken from control states: [-0.36597795 -0.44613443 -0.31142819 -0.34464619 -0.23027679 -1.56842261
 -0.62396781 -0.28001977 -0.29062891 -0.30580376]
u_c before reduction of space:  [-0.36597795 -0.44613443 -0.31142819 -0.34464619 -0.23027679 -1.56842261
 -0.62396781 -0.28001977 -0.29062891 -0.30580376]
data[u_c] post encoding of state:  [-0.36597795 -0.44613443 -0.31142819 -0.34464619 -0.23027679 -1.56842261
 -0.62396781 -0.28001977 -0.29062891 -0.30580376]
J_b = 0.0, J_o = 147487.54645152326
J_b = 0.5000000000000001, J_o = 4740630.022262781
J_b = 0.008895429509699005, J_o = 36041.77710850746
J_b = 0.009875905523966411, J_o = 28635.717658003014
J_b = 0.025396323134354346, J_o = 9963.488495718755
J_b = 0.03182081355531372, J_o = 7652.174043383094
J_b = 0.04399176806439467, J_o = 5216.791115746896
J_b = 0.060779459765541964, J_o = 3776.6224959724896
J_b = 0.08230006843394232, J_o = 2833.389411762955
J_b = 0.084387593616756, J_o = 2375.1977380342446
J_b = 0.08725205890815951, J_o = 2085.247661047937
J_b = 0.09408632910336379, J_o = 1853.7930070052785
J_b = 0.10922922992836258, J_o = 1531.7711003502168
J_b = 0.13415732728669738, J_o = 1289.7765126132779
J_b = 0.14556230239331344, J_o = 1159.1679526551384
J_b = 0.15230419189793723, J_o = 1420.6113358747284
J_b = 0.14664563917301732, J_o = 1146.2874877293532
J_b = 0.14882852167828417, J_o = 1109.6583366302277
J_b = 0.14916321680511935, J_o = 1091.2370355847913
J_b = 0.15072992280381156, J_o = 1066.0022341933607
J_b = 0.15514454002701222, J_o = 1035.0983202803443
J_b = 0.16037503442522405, J_o = 999.0824580274648
J_b = 0.16537925861993932, J_o = 974.076561569474
J_b = 0.1691940946268875, J_o = 957.8954840805443
J_b = 0.17601198741618995, J_o = 931.9521571513158
J_b = 0.19088270165278992, J_o = 902.3167433397492
J_b = 0.20149359408402903, J_o = 867.3922566959154
J_b = 0.20223084187350102, J_o = 849.2782854248157
J_b = 0.2051644892254965, J_o = 854.1455135373604
J_b = 0.20347342747830446, J_o = 840.9882991390539
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597795 -0.44613443 -0.31142819 -0.34464619 -0.23027679 -1.56842261
 -0.62396781 -0.28001977 -0.29062891 -0.30580376]
W_opt:  [ 0.00240071 -0.00580674 -0.00508078 -0.00282134  0.0071982   0.03642138
  0.03709677 -0.00657213 -0.11327458 -0.26488726]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5235 s, v_trunc (Latent to Reduced) = 0.0504, dec (Reduced to Full) = 0.2477, add (DA)= 0.0001decode = 0.3002 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8237 s, inc stats = 4.8260, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.82310384e-07 5.56699976e-07 1.50325595e-06 1.11576269e-06
 1.33117317e-06]
u_DA:    [ 2.68919676e-03  6.71405226e-03  3.79683747e-03  2.05829759e-03
 -8.57955289e-05]
ref_MAE: [0.00805528 0.00987223 0.00446222 0.00560666 0.00061656]
da_MAE:  [2.68861445e-03 6.71349556e-03 3.79533421e-03 2.05718183e-03
 8.71267021e-05]
% 39.80378786133453 da_MAE 0.08819494458551472 ref_MAE 0.14651244895999857
u_c taken from control states: [-0.36597627 -0.44613507 -0.31141271 -0.34463678 -0.23023271 -1.57061601
 -0.62397352 -0.27957118 -0.28381196 -0.30579492]
u_c before reduction of space:  [-0.36597627 -0.44613507 -0.31141271 -0.34463678 -0.23023271 -1.57061601
 -0.62397352 -0.27957118 -0.28381196 -0.30579492]
data[u_c] post encoding of state:  [-0.36597627 -0.44613507 -0.31141271 -0.34463678 -0.23023271 -1.57061601
 -0.62397352 -0.27957118 -0.28381196 -0.30579492]
J_b = 0.0, J_o = 147631.93842903778
J_b = 0.5, J_o = 4740097.835917449
J_b = 0.008900098800041778, J_o = 36133.44985542496
J_b = 0.009882219276843187, J_o = 28715.166652881595
J_b = 0.025440154826923966, J_o = 10001.287139141778
J_b = 0.03188768059828088, J_o = 7682.016870785968
J_b = 0.044111327636714076, J_o = 5236.746235129913
J_b = 0.060976064735702815, J_o = 3791.919913486622
J_b = 0.08253014845555931, J_o = 2847.3881257698345
J_b = 0.0845759033443481, J_o = 2389.2645628174637
J_b = 0.08743279287638897, J_o = 2099.170189030935
J_b = 0.09426014530632039, J_o = 1867.6198170420935
J_b = 0.10945572035421079, J_o = 1544.5499263894812
J_b = 0.13457337802872973, J_o = 1302.4567673408383
J_b = 0.1457139252596686, J_o = 1170.5035666983226
J_b = 0.15272186929262002, J_o = 1429.5602454684235
J_b = 0.14687178025348152, J_o = 1156.74613283963
J_b = 0.14934498336003585, J_o = 1118.5344653259951
J_b = 0.14970322906605696, J_o = 1100.6789814424162
J_b = 0.15129222608737697, J_o = 1075.5854763203072
J_b = 0.1555536467725885, J_o = 1043.632307768531
J_b = 0.16131312921463611, J_o = 1006.9897317018745
J_b = 0.16616621260343467, J_o = 982.2817890033873
J_b = 0.1704032265421172, J_o = 963.6974645486748
J_b = 0.17761533853217887, J_o = 937.5427984756744
J_b = 0.19305307940981756, J_o = 911.0929642622908
J_b = 0.2004870003832909, J_o = 877.5624702187511
J_b = 0.2023035126282193, J_o = 859.3236618254365
J_b = 0.2065750119654147, J_o = 867.8178731537669
J_b = 0.20392146136731576, J_o = 853.3114187073827
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597627 -0.44613507 -0.31141271 -0.34463678 -0.23023271 -1.57061601
 -0.62397352 -0.27957118 -0.28381196 -0.30579492]
W_opt:  [ 0.00056054 -0.0060666  -0.00395022 -0.0015183   0.00777149  0.03651856
  0.03696267 -0.00756692 -0.11443219 -0.26481257]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7409 s, v_trunc (Latent to Reduced) = 0.0527, dec (Reduced to Full) = 0.2961, add (DA)= 0.0001decode = 0.3515 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0924 s, inc stats = 5.0950, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.85107745e-07 5.55066567e-07 1.51626543e-06 1.12605883e-06
 1.34078216e-06]
u_DA:    [ 2.68361904e-03  6.72674391e-03  3.79002399e-03  2.06706539e-03
 -8.46927617e-05]
ref_MAE: [0.00805528 0.00987223 0.00446221 0.00560665 0.00061656]
da_MAE:  [2.68303393e-03 6.72618885e-03 3.78850773e-03 2.06593933e-03
 8.60335439e-05]
% 40.10101511904378 da_MAE 0.08806571632902918 ref_MAE 0.14702372085946327
u_c taken from control states: [-0.36597476 -0.44613555 -0.31139491 -0.34462683 -0.23020895 -1.57307699
 -0.62397787 -0.279235   -0.27681639 -0.3057873 ]
u_c before reduction of space:  [-0.36597476 -0.44613555 -0.31139491 -0.34462683 -0.23020895 -1.57307699
 -0.62397787 -0.279235   -0.27681639 -0.3057873 ]
data[u_c] post encoding of state:  [-0.36597476 -0.44613555 -0.31139491 -0.34462683 -0.23020895 -1.57307699
 -0.62397787 -0.279235   -0.27681639 -0.3057873 ]
J_b = 0.0, J_o = 147690.78636188008
J_b = 0.5000000000000002, J_o = 4739891.652548592
J_b = 0.008900442412160566, J_o = 36193.64459009513
J_b = 0.009883638558701701, J_o = 28767.674941442623
J_b = 0.025457931232774043, J_o = 10033.252531983502
J_b = 0.03192092150140157, J_o = 7707.149331276101
J_b = 0.04420461493057, J_o = 5250.111567820036
J_b = 0.061138131209337816, J_o = 3802.474555977351
J_b = 0.08265454187689747, J_o = 2857.3603814016287
J_b = 0.08466371636251481, J_o = 2400.594645534892
J_b = 0.08753919259834587, J_o = 2110.0026977185257
J_b = 0.09436895396958382, J_o = 1878.736799619554
J_b = 0.10957296506505501, J_o = 1556.1540872216074
J_b = 0.13473696541981903, J_o = 1316.2361936720772
J_b = 0.14532233625775903, J_o = 1184.5983958549764
J_b = 0.15245290607199208, J_o = 1431.051851526895
J_b = 0.14655798209986257, J_o = 1169.7211666548537
J_b = 0.14932541212651476, J_o = 1130.0635916251226
J_b = 0.1497056559009966, J_o = 1113.094717629298
J_b = 0.15132998112512602, J_o = 1088.3053153584733
J_b = 0.15538371141205495, J_o = 1055.3078521025157
J_b = 0.16194022563591118, J_o = 1017.9930541279894
J_b = 0.1664261258662247, J_o = 993.8199769131869
J_b = 0.17140852882372576, J_o = 970.4946800075691
J_b = 0.17978435399358098, J_o = 943.3405903320918
J_b = 0.19411055110660153, J_o = 914.8082855626074
J_b = 0.2008087763787387, J_o = 886.4689779878252
J_b = 0.20515268775800466, J_o = 864.4903599063433
J_b = 0.21037868998075016, J_o = 879.2204507937711
J_b = 0.20681165762434292, J_o = 859.8616476181053
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597476 -0.44613555 -0.31139491 -0.34462683 -0.23020895 -1.57307699
 -0.62397787 -0.279235   -0.27681639 -0.3057873 ]
W_opt:  [ 0.00126113 -0.00559842 -0.00389186 -0.00145357  0.00672028  0.03650945
  0.03862807 -0.00596275 -0.11369316 -0.26603633]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.0296 s, v_trunc (Latent to Reduced) = 0.0573, dec (Reduced to Full) = 0.1834, add (DA)= 0.0001decode = 0.2427 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2724 s, inc stats = 4.2748, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.87610244e-07 5.53848194e-07 1.53123034e-06 1.13694736e-06
 1.34595993e-06]
u_DA:    [ 2.68036534e-03  6.73346618e-03  3.77899499e-03  2.06137038e-03
 -8.52999020e-05]
ref_MAE: [0.00805527 0.00987223 0.00446219 0.00560664 0.00061655]
da_MAE:  [2.67977773e-03 6.73291233e-03 3.77746376e-03 2.06023343e-03
 8.66458620e-05]
% 40.277047775473726 da_MAE 0.08802403971571056 ref_MAE 0.1473872881983251
u_c taken from control states: [-0.3659737  -0.44613598 -0.31137608 -0.34461715 -0.23020707 -1.57579262
 -0.6239806  -0.27902152 -0.27003703 -0.30578161]
u_c before reduction of space:  [-0.3659737  -0.44613598 -0.31137608 -0.34461715 -0.23020707 -1.57579262
 -0.6239806  -0.27902152 -0.27003703 -0.30578161]
data[u_c] post encoding of state:  [-0.3659737  -0.44613598 -0.31137608 -0.34461715 -0.23020707 -1.57579262
 -0.6239806  -0.27902152 -0.27003703 -0.30578161]
J_b = 0.0, J_o = 147672.9583780285
J_b = 0.4999999999999997, J_o = 4740143.952080953
J_b = 0.008896754574362392, J_o = 36223.863141218026
J_b = 0.009879801929516697, J_o = 28799.447053553235
J_b = 0.02543879856583727, J_o = 10077.55664931641
J_b = 0.0319056263706197, J_o = 7746.848688530798
J_b = 0.04426362956330017, J_o = 5273.965927665717
J_b = 0.061315805482896134, J_o = 3819.934866624581
J_b = 0.0828715085603701, J_o = 2870.858812472657
J_b = 0.08486776055064522, J_o = 2413.9097240599863
J_b = 0.08779138511271696, J_o = 2121.508075987245
J_b = 0.0946606194015959, J_o = 1889.6545111487303
J_b = 0.10994741807697062, J_o = 1566.3219832026764
J_b = 0.13524932872864118, J_o = 1328.2105900737477
J_b = 0.14526827774791906, J_o = 1197.0530996515677
J_b = 0.15234868964817874, J_o = 1426.6997822664653
J_b = 0.1465622248139061, J_o = 1181.0456567088718
J_b = 0.14954091447358273, J_o = 1140.276465193825
J_b = 0.14993770743230023, J_o = 1124.1112804036738
J_b = 0.15161838180367146, J_o = 1099.5227420701312
J_b = 0.15551287680536235, J_o = 1065.866270056969
J_b = 0.16287398336403208, J_o = 1028.2270393950866
J_b = 0.16685864962821742, J_o = 1004.4880138389175
J_b = 0.17218072287024616, J_o = 977.6076320506332
J_b = 0.18097725725108976, J_o = 948.8179468798853
J_b = 0.19586616313495492, J_o = 923.3607875200207
J_b = 0.2009656933793928, J_o = 895.8738907606427
J_b = 0.20460658530816123, J_o = 876.1038109308464
J_b = 0.2095986286316971, J_o = 890.2974961356276
J_b = 0.20612564739969155, J_o = 872.3408529396255
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3659737  -0.44613598 -0.31137608 -0.34461715 -0.23020707 -1.57579262
 -0.6239806  -0.27902152 -0.27003703 -0.30578161]
W_opt:  [ 0.00061126 -0.00579054 -0.00369192 -0.00038459  0.00720681  0.03608433
  0.03836095 -0.00687173 -0.11423615 -0.26512802]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.0589 s, v_trunc (Latent to Reduced) = 0.0583, dec (Reduced to Full) = 0.1761, add (DA)= 0.0001decode = 0.2365 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2955 s, inc stats = 4.2978, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.89376621e-07 5.52769791e-07 1.54705006e-06 1.14753994e-06
 1.34636907e-06]
u_DA:    [ 2.68036455e-03  6.73900654e-03  3.77621630e-03  2.06476198e-03
 -8.44219804e-05]
ref_MAE: [0.00805527 0.00987223 0.00446218 0.00560663 0.00061655]
da_MAE:  [2.67977517e-03 6.73845377e-03 3.77466925e-03 2.06361444e-03
 8.57683495e-05]
% 40.27804636651098 da_MAE 0.088084237588613 ref_MAE 0.14749054950409368
u_c taken from control states: [-0.36597333 -0.44613645 -0.31135757 -0.34460843 -0.23022858 -1.57880968
 -0.62398146 -0.27895711 -0.26406501 -0.30577835]
u_c before reduction of space:  [-0.36597333 -0.44613645 -0.31135757 -0.34460843 -0.23022858 -1.57880968
 -0.62398146 -0.27895711 -0.26406501 -0.30577835]
data[u_c] post encoding of state:  [-0.36597333 -0.44613645 -0.31135757 -0.34460843 -0.23022858 -1.57880968
 -0.62398146 -0.27895711 -0.26406501 -0.30577835]
J_b = 0.0, J_o = 147711.60684063446
J_b = 0.5, J_o = 4740071.632591451
J_b = 0.00889489990479082, J_o = 36292.66318636042
J_b = 0.009878838514726785, J_o = 28862.692614398045
J_b = 0.025419485826331786, J_o = 10150.671415071249
J_b = 0.03189226107447616, J_o = 7811.612538906539
J_b = 0.044381038996818035, J_o = 5310.529332195372
J_b = 0.061630239293529794, J_o = 3846.0825818903727
J_b = 0.08322562454260249, J_o = 2890.0260257540817
J_b = 0.08520843004250178, J_o = 2433.301273873284
J_b = 0.08821908575884913, J_o = 2137.8777020686166
J_b = 0.09515684458515863, J_o = 1905.2758478210853
J_b = 0.11051687909890584, J_o = 1582.055931306738
J_b = 0.13588967337564767, J_o = 1347.2114427886718
J_b = 0.1451563581150164, J_o = 1217.5756398989406
J_b = 0.1520307342531101, J_o = 1422.2352800484944
J_b = 0.1465075391352893, J_o = 1200.1310481179412
J_b = 0.1496746360987689, J_o = 1158.3804873647236
J_b = 0.1500969248993085, J_o = 1143.1128302534983
J_b = 0.15187694346932248, J_o = 1118.605524112653
J_b = 0.1556336233137481, J_o = 1084.502481997127
J_b = 0.16398808907227924, J_o = 1047.3081489947274
J_b = 0.1672147413725115, J_o = 1023.6032619183363
J_b = 0.1712600868462976, J_o = 999.9469259503314
J_b = 0.1779943265703723, J_o = 971.768615744322
J_b = 0.19116124259211337, J_o = 928.8796087990397
J_b = 0.2235678240246372, J_o = 1148.7317463808206
J_b = 0.19619363204552762, J_o = 918.4297783785547
J_b = 0.20756238856766088, J_o = 889.8384412377033
J_b = 0.21730108430212897, J_o = 905.3096938361228
J_b = 0.2108875238662046, J_o = 883.1571298387769
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597333 -0.44613645 -0.31135757 -0.34460843 -0.23022858 -1.57880968
 -0.62398146 -0.27895711 -0.26406501 -0.30577835]
W_opt:  [ 0.00697231 -0.00482894 -0.00518768 -0.00361219  0.00339894  0.03324605
  0.03916569 -0.00461041 -0.11310288 -0.26775424]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2823 s, v_trunc (Latent to Reduced) = 0.0650, dec (Reduced to Full) = 0.1958, add (DA)= 0.0001decode = 0.2629 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.5452 s, inc stats = 4.5476, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.89994304e-07 5.51573429e-07 1.56260859e-06 1.15708416e-06
 1.34168192e-06]
u_DA:    [ 2.66938181e-03  6.70440543e-03  3.76709340e-03  2.04777164e-03
 -8.72866706e-05]
ref_MAE: [0.00805527 0.00987223 0.00446216 0.00560662 0.00061655]
da_MAE:  [2.66879182e-03 6.70385386e-03 3.76553079e-03 2.04661455e-03
 8.86283525e-05]
% 40.01144607259137 da_MAE 0.08829222486809081 ref_MAE 0.14718178567019982
\% improve_point: 16.46, mse_ref_points: 1.91021360157635e-05, mse_da_points: 1.5960793580418318e-05, % improve_overlap: -17.79, mse_ref_overlap: 0.16240, mse_da_overlap: 0.19140
DA - - L2: 365.54, L1: 1049.00, % Improve: 36.23%, DA_MAE: 0.09, mse_ref: 0.17, mse_DA: 0.143, time(s): 5.7252s,
u_c taken from control states: [-0.36597382 -0.44613704 -0.31134065 -0.34460137 -0.23027213 -1.58207088
 -0.62398174 -0.27905375 -0.25945673 -0.30577785]
u_c before reduction of space:  [-0.36597382 -0.44613704 -0.31134065 -0.34460137 -0.23027213 -1.58207088
 -0.62398174 -0.27905375 -0.25945673 -0.30577785]
data[u_c] post encoding of state:  [-0.36597382 -0.44613704 -0.31134065 -0.34460137 -0.23027213 -1.58207088
 -0.62398174 -0.27905375 -0.25945673 -0.30577785]
J_b = 0.0, J_o = 147686.16329141485
J_b = 0.4999999999999998, J_o = 4740096.535913129
J_b = 0.00888906050767842, J_o = 36352.44142687912
J_b = 0.009874254231478702, J_o = 28915.115996614193
J_b = 0.02537170981352848, J_o = 10234.304902454225
J_b = 0.031835041943799755, J_o = 7889.688195912971
J_b = 0.044452030628412194, J_o = 5359.558113751837
J_b = 0.06186964001772517, J_o = 3886.8065982521566
J_b = 0.08346099422389869, J_o = 2921.4120144648446
J_b = 0.08552312982693845, J_o = 2464.0082799979778
J_b = 0.08870704288486282, J_o = 2163.2058260679355
J_b = 0.09579277901608876, J_o = 1928.3636973755429
J_b = 0.11133687291438168, J_o = 1603.7476621933458
J_b = 0.13700879247090045, J_o = 1372.0668461895366
J_b = 0.14539776767530613, J_o = 1244.2262714906124
J_b = 0.15167192065175814, J_o = 1415.4669983977228
J_b = 0.14674681757356936, J_o = 1225.3884531491487
J_b = 0.14995776875882325, J_o = 1183.47026537467
J_b = 0.15041663228687632, J_o = 1169.0100311622084
J_b = 0.15237228757764112, J_o = 1144.2856904734524
J_b = 0.15608158071697895, J_o = 1109.78912964495
J_b = 0.16555395066606854, J_o = 1074.296536077731
J_b = 0.1678504219658343, J_o = 1049.4311330543267
J_b = 0.1700383979502127, J_o = 1031.9773905447678
J_b = 0.17500711723213058, J_o = 1006.610478128822
J_b = 0.18832845298013104, J_o = 981.5384764518992
J_b = 0.19608817268407872, J_o = 947.7516858892652
J_b = 0.20013198277658917, J_o = 929.7850454768834
J_b = 0.20527483095788512, J_o = 921.9678012731505
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597382 -0.44613704 -0.31134065 -0.34460137 -0.23027213 -1.58207088
 -0.62398174 -0.27905375 -0.25945673 -0.30577785]
W_opt:  [ 4.84517104e-03 -6.90459578e-03 -3.55656309e-03 -9.68153164e-05
  7.30677315e-03  3.44462785e-02  3.90765844e-02 -6.39203217e-03
 -1.13829610e-01 -2.63697036e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8865 s, v_trunc (Latent to Reduced) = 0.0513, dec (Reduced to Full) = 0.2139, add (DA)= 0.0001decode = 0.2674 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1540 s, inc stats = 4.1565, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.89171130e-07 5.50077646e-07 1.57682535e-06 1.16480540e-06
 1.33218904e-06]
u_DA:    [ 2.69052375e-03  6.73842677e-03  3.77218612e-03  2.04865110e-03
 -8.45691927e-05]
ref_MAE: [0.00805527 0.00987223 0.00446215 0.00560661 0.00061656]
da_MAE:  [2.68993458e-03 6.73787669e-03 3.77060930e-03 2.04748630e-03
 8.59013818e-05]
% 39.61129810846118 da_MAE 0.08859458924316059 ref_MAE 0.1467072258024042
u_c taken from control states: [-0.36597528 -0.4461378  -0.31132625 -0.34459658 -0.23033262 -1.58547391
 -0.62398244 -0.27929639 -0.2565242  -0.30578032]
u_c before reduction of space:  [-0.36597528 -0.4461378  -0.31132625 -0.34459658 -0.23033262 -1.58547391
 -0.62398244 -0.27929639 -0.2565242  -0.30578032]
data[u_c] post encoding of state:  [-0.36597528 -0.4461378  -0.31132625 -0.34459658 -0.23033262 -1.58547391
 -0.62398244 -0.27929639 -0.2565242  -0.30578032]
J_b = 0.0, J_o = 147625.8738793724
J_b = 0.5000000000000002, J_o = 4740195.707390838
J_b = 0.008880172901033144, J_o = 36419.82688034
J_b = 0.009866995136639169, J_o = 28972.951518860224
J_b = 0.02531045064459197, J_o = 10332.243064934832
J_b = 0.03175589238854731, J_o = 7983.821439493184
J_b = 0.04449688110757354, J_o = 5424.516831758948
J_b = 0.062074876745238323, J_o = 3943.294190573452
J_b = 0.08368677481947094, J_o = 2966.0003622891513
J_b = 0.08589846418451995, J_o = 2505.883898000248
J_b = 0.08931985139628593, J_o = 2197.478095621487
J_b = 0.09662434637143225, J_o = 1958.8265380009059
J_b = 0.11245029257313133, J_o = 1631.3008271653493
J_b = 0.1385268748573226, J_o = 1402.3425007635594
J_b = 0.14609036558132416, J_o = 1276.3249012786466
J_b = 0.15157085849493956, J_o = 1416.2809627026027
J_b = 0.1473720859782394, J_o = 1256.5271070855708
J_b = 0.15048447896889597, J_o = 1215.2638379118703
J_b = 0.15098573796618997, J_o = 1201.3566931253654
J_b = 0.1531384045979197, J_o = 1176.2317148855086
J_b = 0.1568833748320303, J_o = 1141.2826955119162
J_b = 0.1673839624632857, J_o = 1108.6499460131818
J_b = 0.16875404725769483, J_o = 1081.3583255080587
J_b = 0.16982857065918655, J_o = 1067.5084530031095
J_b = 0.17382191002805458, J_o = 1043.330725831064
J_b = 0.18555161060762468, J_o = 1016.6794127158239
J_b = 0.19358378952560418, J_o = 984.9053184730769
J_b = 0.1993773921934675, J_o = 964.8022086568783
J_b = 0.20573465604597158, J_o = 955.003524097189
J_b = 0.21214154315654876, J_o = 950.0338979465237
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597528 -0.4461378  -0.31132625 -0.34459658 -0.23033262 -1.58547391
 -0.62398244 -0.27929639 -0.2565242  -0.30578032]
W_opt:  [ 0.00841915 -0.00802981 -0.00415678 -0.00221275  0.00504329  0.0350502
  0.04428424 -0.00091929 -0.11106391 -0.2675339 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.1292 s, v_trunc (Latent to Reduced) = 0.0887, dec (Reduced to Full) = 0.2607, add (DA)= 0.0002decode = 0.3516 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4809 s, inc stats = 4.4835, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.86748477e-07 5.48140757e-07 1.58893178e-06 1.17004800e-06
 1.31900528e-06]
u_DA:    [ 2.71513132e-03  6.68706106e-03  3.76969466e-03  2.00910064e-03
 -8.62657977e-05]
ref_MAE: [0.00805528 0.00987224 0.00446213 0.0056066  0.00061658]
da_MAE:  [2.71454457e-03 6.68651292e-03 3.76810573e-03 2.00793059e-03
 8.75848030e-05]
% 39.19433463429345 da_MAE 0.08900059016983193 ref_MAE 0.14636891091405912
u_c taken from control states: [-0.36597766 -0.44613879 -0.31131529 -0.34459441 -0.23040386 -1.58895139
 -0.62398364 -0.27965435 -0.25541773 -0.30578557]
u_c before reduction of space:  [-0.36597766 -0.44613879 -0.31131529 -0.34459441 -0.23040386 -1.58895139
 -0.62398364 -0.27965435 -0.25541773 -0.30578557]
data[u_c] post encoding of state:  [-0.36597766 -0.44613879 -0.31131529 -0.34459441 -0.23040386 -1.58895139
 -0.62398364 -0.27965435 -0.25541773 -0.30578557]
J_b = 0.0, J_o = 147627.3871750184
J_b = 0.49999999999999994, J_o = 4739963.845862348
J_b = 0.008873498533037214, J_o = 36525.745098485306
J_b = 0.00986308755531502, J_o = 29060.80584390441
J_b = 0.025283434009603863, J_o = 10427.788762270771
J_b = 0.031725611421922935, J_o = 8072.147299462851
J_b = 0.04458393381555976, J_o = 5486.072562028743
J_b = 0.06228800504043224, J_o = 3998.1893996024783
J_b = 0.0838993474926565, J_o = 3010.6554773757625
J_b = 0.08626256506204982, J_o = 2547.4981196156186
J_b = 0.08991623845252744, J_o = 2231.76586458616
J_b = 0.09742631738639916, J_o = 1989.5881238700806
J_b = 0.11350248936495379, J_o = 1659.678645391234
J_b = 0.1398792993067, J_o = 1433.594474236834
J_b = 0.14672590539830785, J_o = 1309.3622724247657
J_b = 0.15149885695112764, J_o = 1424.5521653493927
J_b = 0.1479256280610255, J_o = 1288.8398150008852
J_b = 0.15091603726241973, J_o = 1248.381606611397
J_b = 0.15146195043762722, J_o = 1234.8593404418698
J_b = 0.15380641727698474, J_o = 1209.155916357416
J_b = 0.1576433688793115, J_o = 1173.533043879053
J_b = 0.16906953928389754, J_o = 1144.0335056316528
J_b = 0.16965928092706142, J_o = 1113.3678243923564
J_b = 0.17016250733079144, J_o = 1101.2998911918946
J_b = 0.1735857564379269, J_o = 1077.7201442841688
J_b = 0.18424808690996863, J_o = 1049.1104415524483
J_b = 0.1932147647036392, J_o = 1018.0909094322691
J_b = 0.19999110254792726, J_o = 996.3015627597629
J_b = 0.20751952119250366, J_o = 984.7544035312419
J_b = 0.21493888934306682, J_o = 982.0702187250929
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36597766 -0.44613879 -0.31131529 -0.34459441 -0.23040386 -1.58895139
 -0.62398364 -0.27965435 -0.25541773 -0.30578557]
W_opt:  [ 0.00986032 -0.00928476 -0.0047151  -0.00247667  0.00349939  0.03573527
  0.04641774  0.00066833 -0.11050994 -0.26973831]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7962 s, v_trunc (Latent to Reduced) = 0.0481, dec (Reduced to Full) = 0.2935, add (DA)= 0.0001decode = 0.3435 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1398 s, inc stats = 4.1421, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.82795546e-07 5.45639097e-07 1.59814443e-06 1.17242873e-06
 1.30347874e-06]
u_DA:    [ 2.72414100e-03  6.67149561e-03  3.77090518e-03  1.99849042e-03
 -8.62172639e-05]
ref_MAE: [0.00805528 0.00987224 0.00446212 0.0056066  0.00061659]
da_MAE:  [2.72355820e-03 6.67094997e-03 3.76930703e-03 1.99731799e-03
 8.75207426e-05]
% 38.631274347781726 da_MAE 0.08973842771961624 ref_MAE 0.1462282730591009
u_c taken from control states: [-0.36598087 -0.44614005 -0.31130871 -0.34459513 -0.2304798  -1.59241098
 -0.62398595 -0.28009853 -0.25621825 -0.3057932 ]
u_c before reduction of space:  [-0.36598087 -0.44614005 -0.31130871 -0.34459513 -0.2304798  -1.59241098
 -0.62398595 -0.28009853 -0.25621825 -0.3057932 ]
data[u_c] post encoding of state:  [-0.36598087 -0.44614005 -0.31130871 -0.34459513 -0.2304798  -1.59241098
 -0.62398595 -0.28009853 -0.25621825 -0.3057932 ]
J_b = 0.0, J_o = 147649.63824652147
J_b = 0.5, J_o = 4739645.244978118
J_b = 0.008867649189190502, J_o = 36642.76528823498
J_b = 0.009860340254208708, J_o = 29156.86876543865
J_b = 0.02528433694221215, J_o = 10506.464725245121
J_b = 0.031735366596543316, J_o = 8141.957296806919
J_b = 0.044691002180951477, J_o = 5534.507682550893
J_b = 0.062481850136280166, J_o = 4042.3803033947893
J_b = 0.08405955324969712, J_o = 3048.5420330064335
J_b = 0.08652060173987727, J_o = 2583.539618569467
J_b = 0.09034767175559533, J_o = 2262.2663186154605
J_b = 0.09800843849390653, J_o = 2017.5982102244093
J_b = 0.1142340737682078, J_o = 1686.6881806042636
J_b = 0.14070921112942056, J_o = 1463.0671035031023
J_b = 0.1470898076760427, J_o = 1340.4911442858986
J_b = 0.15141274919727765, J_o = 1440.6756491974616
J_b = 0.14822835897157782, J_o = 1319.5647082305577
J_b = 0.15112046634662693, J_o = 1279.7864407974391
J_b = 0.15169592274431143, J_o = 1266.4801088592756
J_b = 0.15416563866003782, J_o = 1240.3013408441825
J_b = 0.15809401384511165, J_o = 1204.051861182091
J_b = 0.17015585638290617, J_o = 1177.037713873865
J_b = 0.17027183201989637, J_o = 1143.2743279072615
J_b = 0.1705264719277563, J_o = 1131.9535871988805
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36598087 -0.44614005 -0.31130871 -0.34459513 -0.2304798  -1.59241098
 -0.62398595 -0.28009853 -0.25621825 -0.3057932 ]
W_opt:  [-0.01785459 -0.01340214  0.00643839  0.01684578  0.01970871  0.03042246
  0.01738552 -0.03426181 -0.12688325 -0.23897611]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.1736 s, v_trunc (Latent to Reduced) = 0.0501, dec (Reduced to Full) = 0.1560, add (DA)= 0.0001decode = 0.2082 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.3819 s, inc stats = 3.3860, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.77459845e-07 5.42447587e-07 1.60366978e-06 1.17163553e-06
 1.28692812e-06]
u_DA:    [ 2.74863528e-03  6.77080515e-03  3.83241944e-03  2.12414077e-03
 -7.49998732e-05]
ref_MAE: [0.00805529 0.00987224 0.00446212 0.0056066  0.00061661]
da_MAE:  [2.74805782e-03 6.77026270e-03 3.83081577e-03 2.12296913e-03
 7.62868013e-05]
% 37.890287265563266 da_MAE 0.09083270216417484 ref_MAE 0.1462455679879721
u_c taken from control states: [-0.36598474 -0.44614159 -0.31130689 -0.34459877 -0.23055322 -1.59572691
 -0.62399013 -0.28058998 -0.25878378 -0.30580257]
u_c before reduction of space:  [-0.36598474 -0.44614159 -0.31130689 -0.34459877 -0.23055322 -1.59572691
 -0.62399013 -0.28058998 -0.25878378 -0.30580257]
data[u_c] post encoding of state:  [-0.36598474 -0.44614159 -0.31130689 -0.34459877 -0.23055322 -1.59572691
 -0.62399013 -0.28058998 -0.25878378 -0.30580257]
J_b = 0.0, J_o = 147659.88560034792
J_b = 0.49999999999999983, J_o = 4739582.939809752
J_b = 0.008861741395569606, J_o = 36742.1360935627
J_b = 0.009856529707296698, J_o = 29241.71321744996
J_b = 0.025304743164079095, J_o = 10559.569549181417
J_b = 0.031776967765715314, J_o = 8185.602203882592
J_b = 0.04480266870222524, J_o = 5564.101406695609
J_b = 0.06265502722331116, J_o = 4069.2590620758597
J_b = 0.08419550673203763, J_o = 3074.122007875492
J_b = 0.08665495178752035, J_o = 2608.9456780387363
J_b = 0.09055493880284168, J_o = 2284.7378136818843
J_b = 0.0982830271094857, J_o = 2039.0232340179764
J_b = 0.11454925404255216, J_o = 1708.2662660298747
J_b = 0.1409018613057588, J_o = 1486.2062655614934
J_b = 0.14709877960262097, J_o = 1365.1469749720677
J_b = 0.15126187609115507, J_o = 1459.2962887616088
J_b = 0.14821671424248264, J_o = 1344.095126782361
J_b = 0.15104998183309215, J_o = 1304.7654161273085
J_b = 0.15162520004841892, J_o = 1291.577036153018
J_b = 0.15411399534961584, J_o = 1265.2592737546902
J_b = 0.1580699268327722, J_o = 1228.777934964479
J_b = 0.17037897790550371, J_o = 1203.517081179684
J_b = 0.17035399587864647, J_o = 1167.4256310123824
J_b = 0.17052759536402506, J_o = 1156.3616077763368
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36598474 -0.44614159 -0.31130689 -0.34459877 -0.23055322 -1.59572691
 -0.62399013 -0.28058998 -0.25878378 -0.30580257]
W_opt:  [-0.01729154 -0.01334196  0.00642422  0.01685052  0.01907582  0.03008865
  0.01760516 -0.03395625 -0.12660576 -0.2388183 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.9956 s, v_trunc (Latent to Reduced) = 0.0491, dec (Reduced to Full) = 0.3143, add (DA)= 0.0001decode = 0.3653 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.3609 s, inc stats = 3.3633, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.71032106e-07 5.38548246e-07 1.60520369e-06 1.16765733e-06
 1.27092569e-06]
u_DA:    [ 2.75448592e-03  6.77257922e-03  3.83688702e-03  2.11808520e-03
 -7.53973932e-05]
ref_MAE: [0.00805529 0.00987225 0.00446212 0.00560661 0.00061663]
da_MAE:  [2.75391489e-03 6.77204068e-03 3.83528181e-03 2.11691754e-03
 7.66683189e-05]
% 37.517646090280806 da_MAE 0.09150911484741796 ref_MAE 0.1464559337499345
u_c taken from control states: [-0.3659891  -0.4461434  -0.31130965 -0.34460505 -0.23061892 -1.59885917
 -0.62399568 -0.28110613 -0.26286837 -0.30581313]
u_c before reduction of space:  [-0.3659891  -0.4461434  -0.31130965 -0.34460505 -0.23061892 -1.59885917
 -0.62399568 -0.28110613 -0.26286837 -0.30581313]
data[u_c] post encoding of state:  [-0.3659891  -0.4461434  -0.31130965 -0.34460505 -0.23061892 -1.59885917
 -0.62399568 -0.28110613 -0.26286837 -0.30581313]
J_b = 0.0, J_o = 147655.82346410307
J_b = 0.4999999999999996, J_o = 4739752.4920029715
J_b = 0.008855434573175582, J_o = 36827.13619787397
J_b = 0.009851462208112149, J_o = 29317.827063954726
J_b = 0.025334587538226643, J_o = 10598.161522163588
J_b = 0.03183314500479937, J_o = 8215.785324694421
J_b = 0.044896080799447256, J_o = 5587.925542675568
J_b = 0.06277972963033494, J_o = 4091.39334803377
J_b = 0.08431323819506517, J_o = 3097.600479993435
J_b = 0.08672549207132847, J_o = 2632.461517123822
J_b = 0.09062971607131422, J_o = 2307.073616135203
J_b = 0.09837174667570907, J_o = 2061.0604749002146
J_b = 0.11464879774169376, J_o = 1730.227605911383
J_b = 0.14086094771452548, J_o = 1508.3123540068113
J_b = 0.147074094384339, J_o = 1388.0934099548954
J_b = 0.15126673314495861, J_o = 1481.8901512641382
J_b = 0.1482016709043753, J_o = 1367.0377250138122
J_b = 0.15101317712143406, J_o = 1327.8699195669242
J_b = 0.15157267476683092, J_o = 1314.6930890244632
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3659891  -0.4461434  -0.31130965 -0.34460505 -0.23061892 -1.59885917
 -0.62399568 -0.28110613 -0.26286837 -0.30581313]
W_opt:  [-0.01623451 -0.00495925  0.01511344  0.02242701  0.01859118  0.01641473
 -0.00575072 -0.05537452 -0.13351219 -0.22042482]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.6022 s, v_trunc (Latent to Reduced) = 0.0588, dec (Reduced to Full) = 0.1582, add (DA)= 0.0001decode = 0.2190 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.8212 s, inc stats = 2.8236, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.63792703e-07 5.33949337e-07 1.60287886e-06 1.16078172e-06
 1.25660622e-06]
u_DA:    [ 2.79639033e-03  6.80698577e-03  3.83092139e-03  2.10264039e-03
 -7.87667519e-05]
ref_MAE: [0.0080553  0.00987225 0.00446212 0.00560661 0.00061664]
da_MAE:  [2.79582654e-03 6.80645182e-03 3.82931851e-03 2.10147960e-03
 8.00233581e-05]
% 37.371968691881065 da_MAE 0.09196586123661571 ref_MAE 0.1468445667470526
u_c taken from control states: [-0.36599368 -0.44614544 -0.31131642 -0.34461346 -0.23067405 -1.60182081
 -0.62400214 -0.28162527 -0.26815525 -0.30582382]
u_c before reduction of space:  [-0.36599368 -0.44614544 -0.31131642 -0.34461346 -0.23067405 -1.60182081
 -0.62400214 -0.28162527 -0.26815525 -0.30582382]
data[u_c] post encoding of state:  [-0.36599368 -0.44614544 -0.31131642 -0.34461346 -0.23067405 -1.60182081
 -0.62400214 -0.28162527 -0.26815525 -0.30582382]
J_b = 0.0, J_o = 147695.13466118491
J_b = 0.49999999999999994, J_o = 4739834.410870434
J_b = 0.008850783070352638, J_o = 36934.18703389566
J_b = 0.009848187056885527, J_o = 29414.68284621621
J_b = 0.025380100233474732, J_o = 10644.52367605269
J_b = 0.03191125624657909, J_o = 8252.841007496705
J_b = 0.04500630155285649, J_o = 5620.040509463721
J_b = 0.06293283459621728, J_o = 4120.052572302367
J_b = 0.08452041807475807, J_o = 3127.0904969590315
J_b = 0.08687613782534524, J_o = 2660.9223310656644
J_b = 0.0907678809591033, J_o = 2334.1875533454004
J_b = 0.09852940059847369, J_o = 2087.221017814872
J_b = 0.11490222885970934, J_o = 1754.1412267132982
J_b = 0.14120049754851807, J_o = 1530.1290263143474
J_b = 0.14756646599489043, J_o = 1409.3840327042176
J_b = 0.15189169967423521, J_o = 1506.0090189235993
J_b = 0.1487217083739354, J_o = 1388.2698599524092
J_b = 0.15154467573657807, J_o = 1348.90680795122
J_b = 0.15208731423351615, J_o = 1335.6081728015433
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36599368 -0.44614544 -0.31131642 -0.34461346 -0.23067405 -1.60182081
 -0.62400214 -0.28162527 -0.26815525 -0.30582382]
W_opt:  [-0.01647129 -0.00488501  0.01529189  0.02265852  0.01878819  0.01640025
 -0.00584702 -0.05532075 -0.13346813 -0.22037613]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.7078 s, v_trunc (Latent to Reduced) = 0.0500, dec (Reduced to Full) = 0.2745, add (DA)= 0.0002decode = 0.3271 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.0349 s, inc stats = 3.0375, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.56184043e-07 5.28772977e-07 1.59719087e-06 1.15158304e-06
 1.24459097e-06]
u_DA:    [ 2.80302251e-03  6.80528179e-03  3.83434687e-03  2.10043689e-03
 -7.91262866e-05]
ref_MAE: [0.00805531 0.00987226 0.00446213 0.00560662 0.00061665]
da_MAE:  [2.80246633e-03 6.80475301e-03 3.83274968e-03 2.09928531e-03
 8.03708776e-05]
% 37.33683930819812 da_MAE 0.09238024883708695 ref_MAE 0.14742353851482776
u_c taken from control states: [-0.36599811 -0.44614763 -0.31132632 -0.34462338 -0.2307114  -1.60456683
 -0.62400972 -0.28209358 -0.27398988 -0.30583349]
u_c before reduction of space:  [-0.36599811 -0.44614763 -0.31132632 -0.34462338 -0.2307114  -1.60456683
 -0.62400972 -0.28209358 -0.27398988 -0.30583349]
data[u_c] post encoding of state:  [-0.36599811 -0.44614763 -0.31132632 -0.34462338 -0.2307114  -1.60456683
 -0.62400972 -0.28209358 -0.27398988 -0.30583349]
J_b = 0.0, J_o = 147722.38072473402
J_b = 0.5000000000000001, J_o = 4740036.818927722
J_b = 0.008845337566102892, J_o = 37037.70469332015
J_b = 0.009843827829114643, J_o = 29509.87064839041
J_b = 0.025431150213828968, J_o = 10684.899581549153
J_b = 0.031996926710633644, J_o = 8284.781582139347
J_b = 0.04509999517501991, J_o = 5652.709425895818
J_b = 0.06302337857221467, J_o = 4152.513698911258
J_b = 0.0846125271112785, J_o = 3163.6504746029455
J_b = 0.0868870489383441, J_o = 2697.4910851509862
J_b = 0.09074383831641512, J_o = 2369.937551969237
J_b = 0.09851510220496361, J_o = 2121.96063471332
J_b = 0.11500905358856772, J_o = 1785.631731195898
J_b = 0.14154171125382037, J_o = 1557.738219812309
J_b = 0.14820740339662158, J_o = 1435.4533957097156
J_b = 0.15278603266613502, J_o = 1538.033318280278
J_b = 0.1494121948038169, J_o = 1414.2662949496557
J_b = 0.15227657404291264, J_o = 1374.4189584196395
J_b = 0.1528037923027142, J_o = 1360.822344791197
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36599811 -0.44614763 -0.31132632 -0.34462338 -0.2307114  -1.60456683
 -0.62400972 -0.28209358 -0.27398988 -0.30583349]
W_opt:  [-0.01723002 -0.0048003   0.01539351  0.02291599  0.01918543  0.01671567
 -0.00571175 -0.05519445 -0.13341555 -0.22068533]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4873 s, v_trunc (Latent to Reduced) = 0.0482, dec (Reduced to Full) = 0.2965, add (DA)= 0.0001decode = 0.3466 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.8340 s, inc stats = 2.8364, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.48822315e-07 5.23224544e-07 1.58887490e-06 1.14072803e-06
 1.23645138e-06]
u_DA:    [ 2.81160518e-03  6.80508933e-03  3.83829830e-03  2.09638524e-03
 -7.97036000e-05]
ref_MAE: [0.00805531 0.00987226 0.00446213 0.00560663 0.00061666]
da_MAE:  [2.81105635e-03 6.80456611e-03 3.83670943e-03 2.09524451e-03
 8.09400514e-05]
% 37.45060227616629 da_MAE 0.0927432982229107 ref_MAE 0.1482720882979373
u_c taken from control states: [-0.36600202 -0.44614989 -0.31133841 -0.34463383 -0.23072594 -1.60706958
 -0.6240179  -0.28245574 -0.27970583 -0.30584116]
u_c before reduction of space:  [-0.36600202 -0.44614989 -0.31133841 -0.34463383 -0.23072594 -1.60706958
 -0.6240179  -0.28245574 -0.27970583 -0.30584116]
data[u_c] post encoding of state:  [-0.36600202 -0.44614989 -0.31133841 -0.34463383 -0.23072594 -1.60706958
 -0.6240179  -0.28245574 -0.27970583 -0.30584116]
J_b = 0.0, J_o = 147772.13120555066
J_b = 0.5000000000000003, J_o = 4740268.285764149
J_b = 0.008839479668525753, J_o = 37169.6555593744
J_b = 0.009839167768523671, J_o = 29632.648926422957
J_b = 0.025487020959217017, J_o = 10747.655468473675
J_b = 0.032091550886358594, J_o = 8337.688027949209
J_b = 0.045216667205461976, J_o = 5703.506092088994
J_b = 0.06317021144930611, J_o = 4201.0162335292525
J_b = 0.08478471228625216, J_o = 3216.146127170674
J_b = 0.08694839663022544, J_o = 2749.9582498366954
J_b = 0.09076319367866936, J_o = 2421.0727367765376
J_b = 0.09855807502625631, J_o = 2171.5273600994274
J_b = 0.1152062947978768, J_o = 1831.0179662195162
J_b = 0.14205041736132223, J_o = 1597.5904871372086
J_b = 0.14919078247903672, J_o = 1473.0362982539414
J_b = 0.15418847891953694, J_o = 1585.5564004742698
J_b = 0.150474009269334, J_o = 1451.7659017793817
J_b = 0.15340905038035846, J_o = 1411.1293491112394
J_b = 0.15392043894948013, J_o = 1397.026052715225
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600202 -0.44614989 -0.31133841 -0.34463383 -0.23072594 -1.60706958
 -0.6240179  -0.28245574 -0.27970583 -0.30584116]
W_opt:  [-0.01758947 -0.00458839  0.01538327  0.02305364  0.0196273   0.01722586
 -0.00550983 -0.05506516 -0.13346585 -0.22124312]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.5196 s, v_trunc (Latent to Reduced) = 0.0703, dec (Reduced to Full) = 0.3492, add (DA)= 0.0001decode = 0.4215 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 2.9412 s, inc stats = 2.9436, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.42325579e-07 5.17495156e-07 1.57871138e-06 1.12929524e-06
 1.23328092e-06]
u_DA:    [ 2.81839462e-03  6.80263971e-03  3.84119701e-03  2.09125923e-03
 -8.04997832e-05]
ref_MAE: [0.00805532 0.00987227 0.00446214 0.00560664 0.00061666]
da_MAE:  [2.81785229e-03 6.80212221e-03 3.83961830e-03 2.09012993e-03
 8.17330641e-05]
% 37.676971085559174 da_MAE 0.09304816062758985 ref_MAE 0.14929980498112427
u_c taken from control states: [-0.36600514 -0.44615216 -0.31135149 -0.34464373 -0.23071974 -1.60940802
 -0.62402531 -0.28270358 -0.28487663 -0.30584606]
u_c before reduction of space:  [-0.36600514 -0.44615216 -0.31135149 -0.34464373 -0.23071974 -1.60940802
 -0.62402531 -0.28270358 -0.28487663 -0.30584606]
data[u_c] post encoding of state:  [-0.36600514 -0.44615216 -0.31135149 -0.34464373 -0.23071974 -1.60940802
 -0.62402531 -0.28270358 -0.28487663 -0.30584606]
J_b = 0.0, J_o = 147816.45855044894
J_b = 0.49999999999999983, J_o = 4740507.11734305
J_b = 0.008833531486970615, J_o = 37297.20010249453
J_b = 0.00983435212690776, J_o = 29751.6292411621
J_b = 0.02553631227574657, J_o = 10812.292083621971
J_b = 0.032178389382079224, J_o = 8392.127568557993
J_b = 0.045335578158243954, J_o = 5753.530344849363
J_b = 0.06332881424695233, J_o = 4248.589484382344
J_b = 0.08495178465905454, J_o = 3268.068343876055
J_b = 0.08699017401986459, J_o = 2802.4872733892153
J_b = 0.09075759186876348, J_o = 2472.4773220623315
J_b = 0.09857205506249264, J_o = 2221.4306094610793
J_b = 0.11536593590616749, J_o = 1876.8006022912527
J_b = 0.1425603359151051, J_o = 1637.3721597416363
J_b = 0.15023634443519335, J_o = 1510.116189813602
J_b = 0.15573323747191897, J_o = 1634.0775048282576
J_b = 0.15161207429211873, J_o = 1488.6878819081514
J_b = 0.15464147871890666, J_o = 1447.0686281558524
J_b = 0.15514369571268777, J_o = 1432.3757874240441
J_b = 0.15738781940760427, J_o = 1405.4294461172392
J_b = 0.16151773902095776, J_o = 1367.3589135363618
J_b = 0.17389033398009326, J_o = 1344.9804832533441
J_b = 0.17509615486078195, J_o = 1299.3266063195474
J_b = 0.17557034786505693, J_o = 1286.7145963926553
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600514 -0.44615216 -0.31135149 -0.34464373 -0.23071974 -1.60940802
 -0.62402531 -0.28270358 -0.28487663 -0.30584606]
W_opt:  [-0.01922413 -0.01210187  0.0064487   0.01683234  0.02008875  0.03162033
  0.018376   -0.03279474 -0.1257156  -0.2398927 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.0216 s, v_trunc (Latent to Reduced) = 0.0497, dec (Reduced to Full) = 0.1549, add (DA)= 0.0001decode = 0.2066 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.2283 s, inc stats = 3.2307, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.37138363e-07 5.11765687e-07 1.56771678e-06 1.11845496e-06
 1.23463287e-06]
u_DA:    [ 2.78918180e-03  6.79670568e-03  3.85828180e-03  2.08985980e-03
 -7.88764986e-05]
ref_MAE: [0.00805533 0.00987227 0.00446215 0.00560665 0.00061666]
da_MAE:  [2.78864466e-03 6.79619391e-03 3.85671409e-03 2.08874135e-03
 8.01111314e-05]
% 38.010044091774006 da_MAE 0.09322357965696049 ref_MAE 0.15038497493848005
\% improve_point: 17.34, mse_ref_points: 1.923560617214775e-05, mse_da_points: 1.590010667688724e-05, % improve_overlap: -16.12, mse_ref_overlap: 0.16286, mse_da_overlap: 0.18919
DA - - L2: 482.44, L1: 1211.25, % Improve: 36.82%, DA_MAE: 0.09, mse_ref: 0.17, mse_DA: 0.142, time(s): 4.9894s,
u_c taken from control states: [-0.36600714 -0.4461543  -0.31136384 -0.34465201 -0.23069421 -1.61166976
 -0.62403138 -0.28283471 -0.28912201 -0.30584734]
u_c before reduction of space:  [-0.36600714 -0.4461543  -0.31136384 -0.34465201 -0.23069421 -1.61166976
 -0.62403138 -0.28283471 -0.28912201 -0.30584734]
data[u_c] post encoding of state:  [-0.36600714 -0.4461543  -0.31136384 -0.34465201 -0.23069421 -1.61166976
 -0.62403138 -0.28283471 -0.28912201 -0.30584734]
J_b = 0.0, J_o = 147909.39068928466
J_b = 0.4999999999999999, J_o = 4740406.540802442
J_b = 0.008830996377571227, J_o = 37432.245689835916
J_b = 0.009833601170830725, J_o = 29873.44209270424
J_b = 0.025592737793661103, J_o = 10874.373661012576
J_b = 0.032271391180911324, J_o = 8443.741237035345
J_b = 0.045464448034320405, J_o = 5799.821641352718
J_b = 0.06349046587224838, J_o = 4293.008045842695
J_b = 0.08510352020143533, J_o = 3315.830622512325
J_b = 0.0870468806549902, J_o = 2850.967319341339
J_b = 0.09077697441238061, J_o = 2520.3784119561037
J_b = 0.09859558257562358, J_o = 2268.494655137726
J_b = 0.11548445916632476, J_o = 1920.982643892099
J_b = 0.1429669602939198, J_o = 1677.0018177568793
J_b = 0.15104120267815016, J_o = 1547.4511086649131
J_b = 0.15693867270941136, J_o = 1679.8371598675635
J_b = 0.1524940090351878, J_o = 1525.7786880041303
J_b = 0.15561464502088904, J_o = 1483.2798154851616
J_b = 0.1561165255571912, J_o = 1468.1348981276656
J_b = 0.1583384480148281, J_o = 1440.8516137058255
J_b = 0.1625505889417955, J_o = 1402.098225672414
J_b = 0.17500831030074787, J_o = 1379.40838351934
J_b = 0.17651493303339863, J_o = 1332.3246041420045
J_b = 0.17706153616224513, J_o = 1319.2497655351563
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600714 -0.4461543  -0.31136384 -0.34465201 -0.23069421 -1.61166976
 -0.62403138 -0.28283471 -0.28912201 -0.30584734]
W_opt:  [-0.01947015 -0.01174094  0.00599728  0.01659015  0.02032885  0.03228153
  0.01854589 -0.03261523 -0.12556546 -0.2401921 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6604 s, v_trunc (Latent to Reduced) = 0.0546, dec (Reduced to Full) = 0.1633, add (DA)= 0.0001decode = 0.2202 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8807 s, inc stats = 3.8831, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.33813894e-07 5.06327060e-07 1.55733731e-06 1.10940081e-06
 1.24019742e-06]
u_DA:    [ 2.78935094e-03  6.80207262e-03  3.86157904e-03  2.08362030e-03
 -7.99975569e-05]
ref_MAE: [0.00805533 0.00987228 0.00446217 0.00560666 0.00061666]
da_MAE:  [2.78881712e-03 6.80156629e-03 3.86002170e-03 2.08251090e-03
 8.12377543e-05]
% 38.25093702856388 da_MAE 0.09353460221744703 ref_MAE 0.15147533859860232
u_c taken from control states: [-0.3660079  -0.44615624 -0.3113742  -0.34465788 -0.23065478 -1.6138861
 -0.62403632 -0.28286201 -0.29221376 -0.30584489]
u_c before reduction of space:  [-0.3660079  -0.44615624 -0.3113742  -0.34465788 -0.23065478 -1.6138861
 -0.62403632 -0.28286201 -0.29221376 -0.30584489]
data[u_c] post encoding of state:  [-0.3660079  -0.44615624 -0.3113742  -0.34465788 -0.23065478 -1.6138861
 -0.62403632 -0.28286201 -0.29221376 -0.30584489]
J_b = 0.0, J_o = 147992.09090760135
J_b = 0.49999999999999994, J_o = 4740284.267483393
J_b = 0.008828240759025068, J_o = 37560.58635286271
J_b = 0.009832710757701759, J_o = 29988.139766623877
J_b = 0.02564245054129697, J_o = 10935.254654273265
J_b = 0.03235219929282038, J_o = 8495.59082729658
J_b = 0.045571371104147405, J_o = 5848.170419593003
J_b = 0.06359889024098528, J_o = 4341.6697268262815
J_b = 0.0851671782001836, J_o = 3367.430964902801
J_b = 0.08705904584046917, J_o = 2903.279446481937
J_b = 0.09077654590507274, J_o = 2572.137169740226
J_b = 0.09860220063713179, J_o = 2319.616314217149
J_b = 0.11558695080438819, J_o = 1969.5348899173641
J_b = 0.14339495311006548, J_o = 1722.0592513700312
J_b = 0.15169992476775482, J_o = 1590.451136061924
J_b = 0.15784112990649693, J_o = 1726.5217290056103
J_b = 0.15320935991892365, J_o = 1568.395229576805
J_b = 0.156413638765605, J_o = 1525.1237670254905
J_b = 0.15692667552534334, J_o = 1509.657273511667
J_b = 0.15917741617556777, J_o = 1481.9002753602522
J_b = 0.16348757741573647, J_o = 1442.4155126334635
J_b = 0.17615393188169443, J_o = 1419.5351550605246
J_b = 0.17783884795143734, J_o = 1370.939348598351
J_b = 0.1784154726494097, J_o = 1357.5067849811212
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3660079  -0.44615624 -0.3113742  -0.34465788 -0.23065478 -1.6138861
 -0.62403632 -0.28286201 -0.29221376 -0.30584489]
W_opt:  [-0.01951106 -0.01203742  0.00547434  0.01665189  0.02074267  0.03262305
  0.01864207 -0.03232587 -0.12551093 -0.24058792]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.4065 s, v_trunc (Latent to Reduced) = 0.0566, dec (Reduced to Full) = 0.1726, add (DA)= 0.0001decode = 0.2313 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6379 s, inc stats = 3.6411, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.32555533e-07 5.01413680e-07 1.54862918e-06 1.10297244e-06
 1.24879107e-06]
u_DA:    [ 2.78693779e-03  6.80946077e-03  3.86274558e-03  2.08161065e-03
 -8.05082532e-05]
ref_MAE: [0.00805533 0.00987228 0.00446217 0.00560667 0.00061665]
da_MAE:  [2.78640524e-03 6.80895936e-03 3.86119695e-03 2.08050768e-03
 8.17570443e-05]
% 38.457977490229645 da_MAE 0.09392848995926938 ref_MAE 0.15262496442062393
u_c taken from control states: [-0.36600748 -0.44615789 -0.31138115 -0.34466062 -0.23060896 -1.61616047
 -0.62403921 -0.28282664 -0.29405138 -0.30583912]
u_c before reduction of space:  [-0.36600748 -0.44615789 -0.31138115 -0.34466062 -0.23060896 -1.61616047
 -0.62403921 -0.28282664 -0.29405138 -0.30583912]
data[u_c] post encoding of state:  [-0.36600748 -0.44615789 -0.31138115 -0.34466062 -0.23060896 -1.61616047
 -0.62403921 -0.28282664 -0.29405138 -0.30583912]
J_b = 0.0, J_o = 148091.66776913297
J_b = 0.4999999999999998, J_o = 4740017.8576392
J_b = 0.008826318043089058, J_o = 37697.364610474935
J_b = 0.009833062968205445, J_o = 30108.533955317598
J_b = 0.025689392257182617, J_o = 11003.569306842011
J_b = 0.032428127479848794, J_o = 8554.3874461264
J_b = 0.045684931854998424, J_o = 5900.890663294266
J_b = 0.06371312520349663, J_o = 4395.178340071232
J_b = 0.08521503355103331, J_o = 3422.0050360333103
J_b = 0.08710643336746296, J_o = 2958.2003667354284
J_b = 0.09085866782171272, J_o = 2625.6931660465484
J_b = 0.09871479243127014, J_o = 2372.349402855323
J_b = 0.11582774465863241, J_o = 2019.7734503794818
J_b = 0.14398741431716552, J_o = 1770.7632123382566
J_b = 0.15221671613458504, J_o = 1637.8286119709933
J_b = 0.15831171584059278, J_o = 1768.7715135410886
J_b = 0.15374720756919502, J_o = 1615.1393193471765
J_b = 0.15701092528374228, J_o = 1571.3330538071923
J_b = 0.15754896693194467, J_o = 1555.7974580545351
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600748 -0.44615789 -0.31138115 -0.34466062 -0.23060896 -1.61616047
 -0.62403921 -0.28282664 -0.29405138 -0.30583912]
W_opt:  [-0.01823549 -0.00475787  0.01445221  0.02317674  0.02095233  0.01868956
 -0.00509135 -0.05472216 -0.13367087 -0.22241354]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.0829 s, v_trunc (Latent to Reduced) = 0.0511, dec (Reduced to Full) = 0.1891, add (DA)= 0.0001decode = 0.2421 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.3251 s, inc stats = 3.3274, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.33252822e-07 4.97243702e-07 1.54279404e-06 1.09997076e-06
 1.25877670e-06]
u_DA:    [ 2.81964001e-03  6.80808580e-03  3.83786341e-03  2.08283450e-03
 -8.20259482e-05]
ref_MAE: [0.00805533 0.00987229 0.00446218 0.00560667 0.00061664]
da_MAE:  [2.81910676e-03 6.80758856e-03 3.83632061e-03 2.08173453e-03
 8.32847249e-05]
% 38.48395077712243 da_MAE 0.09458280198054289 ref_MAE 0.15375305009894544
u_c taken from control states: [-0.36600601 -0.44615917 -0.31138376 -0.34465982 -0.23056397 -1.61861243
 -0.62403948 -0.28276575 -0.29467086 -0.30583061]
u_c before reduction of space:  [-0.36600601 -0.44615917 -0.31138376 -0.34465982 -0.23056397 -1.61861243
 -0.62403948 -0.28276575 -0.29467086 -0.30583061]
data[u_c] post encoding of state:  [-0.36600601 -0.44615917 -0.31138376 -0.34465982 -0.23056397 -1.61861243
 -0.62403948 -0.28276575 -0.29467086 -0.30583061]
J_b = 0.0, J_o = 148213.319241255
J_b = 0.4999999999999998, J_o = 4739560.487544875
J_b = 0.008825150664099037, J_o = 37850.17664860818
J_b = 0.009834762574651781, J_o = 30241.22726107636
J_b = 0.025722792155976573, J_o = 11094.495741196044
J_b = 0.03248452119627154, J_o = 8634.829855067375
J_b = 0.045815265195785396, J_o = 5966.596988799211
J_b = 0.06389582660782042, J_o = 4458.418697545354
J_b = 0.0853686459370535, J_o = 3481.51164079308
J_b = 0.08731852232746608, J_o = 3016.779882895172
J_b = 0.09116894907353643, J_o = 2681.3170634847884
J_b = 0.09910227704025829, J_o = 2426.3636514475425
J_b = 0.11641805732813311, J_o = 2070.6892826008975
J_b = 0.14500031574094505, J_o = 1822.1329287001681
J_b = 0.15281812212474039, J_o = 1688.6841325653731
J_b = 0.15848944822814015, J_o = 1805.497761460458
J_b = 0.15430711564434257, J_o = 1665.2510432712365
J_b = 0.1575605159797245, J_o = 1621.4518486704865
J_b = 0.15813007116156672, J_o = 1606.1628539439573
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600601 -0.44615917 -0.31138376 -0.34465982 -0.23056397 -1.61861243
 -0.62403948 -0.28276575 -0.29467086 -0.30583061]
W_opt:  [-0.01839301 -0.00519711  0.01445831  0.02350213  0.02134188  0.0186663
 -0.00544756 -0.05513196 -0.13413275 -0.22240989]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4703 s, v_trunc (Latent to Reduced) = 0.0504, dec (Reduced to Full) = 0.1866, add (DA)= 0.0001decode = 0.2390 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.7093 s, inc stats = 2.7116, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.35688748e-07 4.93981236e-07 1.54060008e-06 1.10085204e-06
 1.26858398e-06]
u_DA:    [ 2.81726648e-03  6.81288264e-03  3.83478437e-03  2.08294877e-03
 -8.18349307e-05]
ref_MAE: [0.00805533 0.00987229 0.00446218 0.00560667 0.00061663]
da_MAE:  [2.81673079e-03 6.81238865e-03 3.83324377e-03 2.08184792e-03
 8.31035147e-05]
% 38.378515881044834 da_MAE 0.09538374334053953 ref_MAE 0.15478975345093787
u_c taken from control states: [-0.36600385 -0.44616011 -0.31138199 -0.34465584 -0.23053184 -1.62126588
 -0.62403788 -0.2827304  -0.29435413 -0.30582068]
u_c before reduction of space:  [-0.36600385 -0.44616011 -0.31138199 -0.34465584 -0.23053184 -1.62126588
 -0.62403788 -0.2827304  -0.29435413 -0.30582068]
data[u_c] post encoding of state:  [-0.36600385 -0.44616011 -0.31138199 -0.34465584 -0.23053184 -1.62126588
 -0.62403788 -0.2827304  -0.29435413 -0.30582068]
J_b = 0.0, J_o = 148267.55525690352
J_b = 0.5000000000000001, J_o = 4739102.056692139
J_b = 0.008819900114183338, J_o = 37994.26133161602
J_b = 0.009833100909949126, J_o = 30361.176841458313
J_b = 0.025719801503844276, J_o = 11199.539384332904
J_b = 0.03248631973787454, J_o = 8731.367434465345
J_b = 0.04590994399592389, J_o = 6042.42652766219
J_b = 0.06403934462645385, J_o = 4532.641257487403
J_b = 0.08543347763828692, J_o = 3549.1078111060797
J_b = 0.08752018201196393, J_o = 3083.157444154498
J_b = 0.09156029899384538, J_o = 2742.407908283726
J_b = 0.09965671555642402, J_o = 2484.1254471409293
J_b = 0.11730249132729914, J_o = 2123.9809237434993
J_b = 0.14648007362972051, J_o = 1877.9388616898887
J_b = 0.15352981502584573, J_o = 1744.7146856810057
J_b = 0.15832711431742197, J_o = 1839.6128795376226
J_b = 0.15487450924906723, J_o = 1720.709643185942
J_b = 0.15799198195310976, J_o = 1677.7995044996735
J_b = 0.15861550781088865, J_o = 1662.9386090735666
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600385 -0.44616011 -0.31138199 -0.34465584 -0.23053184 -1.62126588
 -0.62403788 -0.2827304  -0.29435413 -0.30582068]
W_opt:  [-0.01836217 -0.00565468  0.01471519  0.02362201  0.02129604  0.01845984
 -0.00579124 -0.05535343 -0.13419839 -0.22208833]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4208 s, v_trunc (Latent to Reduced) = 0.0521, dec (Reduced to Full) = 0.1611, add (DA)= 0.0001decode = 0.2152 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6361 s, inc stats = 2.6385, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.39287234e-07 4.91605162e-07 1.54208273e-06 1.10520738e-06
 1.27558630e-06]
u_DA:    [ 2.81370460e-03  6.81521987e-03  3.83032079e-03  2.08255012e-03
 -8.18880373e-05]
ref_MAE: [0.00805532 0.00987229 0.00446218 0.00560667 0.00061662]
da_MAE:  [2.81316531e-03 6.81472827e-03 3.82877871e-03 2.08144492e-03
 8.31636236e-05]
% 38.11498991876773 da_MAE 0.09651949744586305 ref_MAE 0.1559658749657929
u_c taken from control states: [-0.3660015  -0.44616073 -0.31137573 -0.34464918 -0.23052294 -1.6242008
 -0.624034   -0.28278422 -0.29339593 -0.30581106]
u_c before reduction of space:  [-0.3660015  -0.44616073 -0.31137573 -0.34464918 -0.23052294 -1.6242008
 -0.624034   -0.28278422 -0.29339593 -0.30581106]
data[u_c] post encoding of state:  [-0.3660015  -0.44616073 -0.31137573 -0.34464918 -0.23052294 -1.6242008
 -0.624034   -0.28278422 -0.29339593 -0.30581106]
J_b = 0.0, J_o = 148225.89234084467
J_b = 0.4999999999999999, J_o = 4738770.9366155565
J_b = 0.008808688918075515, J_o = 38125.03270968287
J_b = 0.009826005369695249, J_o = 30465.52011405363
J_b = 0.025666393451058377, J_o = 11326.797615377543
J_b = 0.03241862044160084, J_o = 8850.594415321782
J_b = 0.045984126417837404, J_o = 6129.064341795455
J_b = 0.06416177897266023, J_o = 4621.003671366164
J_b = 0.08531103508899905, J_o = 3629.022512575694
J_b = 0.08762555589030742, J_o = 3162.8946295647984
J_b = 0.09201447657602359, J_o = 2813.1936449166187
J_b = 0.1003916237512491, J_o = 2550.0633902053955
J_b = 0.11842991190660936, J_o = 2186.1506977594736
J_b = 0.1481897817416875, J_o = 1946.4059898656694
J_b = 0.15411037739028305, J_o = 1815.0358996573507
J_b = 0.15763791069092756, J_o = 1882.2866355951014
J_b = 0.15518783527949317, J_o = 1790.898264954627
J_b = 0.15798958341010552, J_o = 1750.198997276623
J_b = 0.15869200041648424, J_o = 1735.9043896560545
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3660015  -0.44616073 -0.31137573 -0.34464918 -0.23052294 -1.6242008
 -0.624034   -0.28278422 -0.29339593 -0.30581106]
W_opt:  [-0.01798877 -0.00527018  0.0148038   0.02317702  0.02077919  0.01797271
 -0.00618923 -0.05558456 -0.1341289  -0.22190015]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3935 s, v_trunc (Latent to Reduced) = 0.0488, dec (Reduced to Full) = 0.1913, add (DA)= 0.0001decode = 0.2425 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6361 s, inc stats = 2.6386, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.43182085e-07 4.90045641e-07 1.54734783e-06 1.11249003e-06
 1.27752647e-06]
u_DA:    [ 2.80976878e-03  6.81486185e-03  3.82630293e-03  2.08030958e-03
 -8.23226072e-05]
ref_MAE: [0.00805532 0.00987229 0.00446218 0.00560666 0.00061662]
da_MAE:  [2.80922560e-03 6.81437181e-03 3.82475559e-03 2.07919709e-03
 8.36001337e-05]
% 37.679742697443025 da_MAE 0.09817167658005926 ref_MAE 0.15752771382738068
u_c taken from control states: [-0.36599951 -0.44616108 -0.31136567 -0.34464067 -0.2305478  -1.62751931
 -0.62402722 -0.28297228 -0.29226468 -0.30580343]
u_c before reduction of space:  [-0.36599951 -0.44616108 -0.31136567 -0.34464067 -0.2305478  -1.62751931
 -0.62402722 -0.28297228 -0.29226468 -0.30580343]
data[u_c] post encoding of state:  [-0.36599951 -0.44616108 -0.31136567 -0.34464067 -0.2305478  -1.62751931
 -0.62402722 -0.28297228 -0.29226468 -0.30580343]
J_b = 0.0, J_o = 148028.36865541694
J_b = 0.5000000000000001, J_o = 4738887.709905021
J_b = 0.008784075881955875, J_o = 38283.08289577931
J_b = 0.009806432682484987, J_o = 30592.96526479141
J_b = 0.02553738216545533, J_o = 11530.177169573371
J_b = 0.03224984020616203, J_o = 9045.95992298932
J_b = 0.04603528156799824, J_o = 6272.416584713939
J_b = 0.06429862244862611, J_o = 4766.626175873281
J_b = 0.08508612790567327, J_o = 3761.878515566072
J_b = 0.08775301573620467, J_o = 3294.053686004427
J_b = 0.09273061078923092, J_o = 2928.380448020961
J_b = 0.10163018306789211, J_o = 2655.3067119812317
J_b = 0.12037556095040446, J_o = 2283.472912254769
J_b = 0.1512350530574916, J_o = 2052.5368629220166
J_b = 0.15571388404582626, J_o = 1921.765360728058
J_b = 0.1576559611982863, J_o = 1961.9284240867808
J_b = 0.15635765660764592, J_o = 1898.257407598552
J_b = 0.15864187682646813, J_o = 1860.8500821214125
J_b = 0.15948118749758775, J_o = 1846.8648057014912
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36599951 -0.44616108 -0.31136567 -0.34464067 -0.2305478  -1.62751931
 -0.62402722 -0.28297228 -0.29226468 -0.30580343]
W_opt:  [-0.01656283 -0.00496033  0.01425604  0.02184183  0.01993055  0.01816052
 -0.00606024 -0.05588535 -0.13413881 -0.22139222]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.8202 s, v_trunc (Latent to Reduced) = 0.0528, dec (Reduced to Full) = 0.1912, add (DA)= 0.0001decode = 0.2460 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.0663 s, inc stats = 3.0686, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.46492332e-07 4.89135649e-07 1.55580454e-06 1.12180686e-06
 1.27210683e-06]
u_DA:    [ 2.80370819e-03  6.80918463e-03  3.82282476e-03  2.07000382e-03
 -8.33197848e-05]
ref_MAE: [0.00805532 0.0098723  0.00446217 0.00560665 0.00061662]
da_MAE:  [2.80316170e-03 6.80869550e-03 3.82126896e-03 2.06888202e-03
 8.45918916e-05]
% 36.82796952369847 da_MAE 0.10075811781658418 ref_MAE 0.15949798836113518
u_c taken from control states: [-0.36599845 -0.4461613  -0.31135328 -0.34463165 -0.23061551 -1.63124692
 -0.6240179  -0.2833262  -0.29150756 -0.30579957]
u_c before reduction of space:  [-0.36599845 -0.4461613  -0.31135328 -0.34463165 -0.23061551 -1.63124692
 -0.6240179  -0.2833262  -0.29150756 -0.30579957]
data[u_c] post encoding of state:  [-0.36599845 -0.4461613  -0.31135328 -0.34463165 -0.23061551 -1.63124692
 -0.6240179  -0.2833262  -0.29150756 -0.30579957]
J_b = 0.0, J_o = 147572.78446944244
J_b = 0.5000000000000001, J_o = 4739658.454039454
J_b = 0.008741531371198596, J_o = 38425.32085089985
J_b = 0.009769562105161254, J_o = 30703.714204183736
J_b = 0.025284524574374273, J_o = 11812.490647343413
J_b = 0.031905485774780765, J_o = 9326.256987664023
J_b = 0.0459840941317404, J_o = 6479.891095786221
J_b = 0.06432720105026281, J_o = 4980.7840155668555
J_b = 0.084563280106679, J_o = 3961.0597182021384
J_b = 0.08772646027817568, J_o = 3489.638553174397
J_b = 0.09359522020320775, J_o = 3099.7290625233536
J_b = 0.10334865632683178, J_o = 2809.448036479062
J_b = 0.12319485452537388, J_o = 2423.5558933449497
J_b = 0.15595882661200045, J_o = 2204.984846517425
J_b = 0.15892612539206113, J_o = 2069.617273235992
J_b = 0.1592381548453727, J_o = 2091.372827302215
J_b = 0.1589954447953673, J_o = 2048.102130693768
J_b = 0.16055345481524175, J_o = 2014.646170007597
J_b = 0.16158240611492428, J_o = 1999.934099634147
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36599845 -0.4461613  -0.31135328 -0.34463165 -0.23061551 -1.63124692
 -0.6240179  -0.2833262  -0.29150756 -0.30579957]
W_opt:  [-0.01483051 -0.00502257  0.012202    0.0194157   0.0188895   0.0186693
 -0.00548043 -0.05519355 -0.13313228 -0.22023218]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.7242 s, v_trunc (Latent to Reduced) = 0.0573, dec (Reduced to Full) = 0.3316, add (DA)= 0.0001decode = 0.3909 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.1152 s, inc stats = 3.1193, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.48250546e-07 4.88577543e-07 1.56621351e-06 1.13168001e-06
 1.25735005e-06]
u_DA:    [ 2.79697777e-03  6.80362977e-03  3.82152068e-03  2.05570276e-03
 -8.52152017e-05]
ref_MAE: [0.00805531 0.0098723  0.00446216 0.00560664 0.00061664]
da_MAE:  [2.79642952e-03 6.80314119e-03 3.81995446e-03 2.05457108e-03
 8.64725518e-05]
% 35.49501878418085 da_MAE 0.10476350405520479 ref_MAE 0.16241149455526493
u_c taken from control states: [-0.36599881 -0.44616151 -0.31134049 -0.34462362 -0.23072472 -1.63532041
 -0.62400773 -0.28383947 -0.2916251  -0.30580076]
u_c before reduction of space:  [-0.36599881 -0.44616151 -0.31134049 -0.34462362 -0.23072472 -1.63532041
 -0.62400773 -0.28383947 -0.2916251  -0.30580076]
data[u_c] post encoding of state:  [-0.36599881 -0.44616151 -0.31134049 -0.34462362 -0.23072472 -1.63532041
 -0.62400773 -0.28383947 -0.2916251  -0.30580076]
J_b = 0.0, J_o = 146904.10478737895
J_b = 0.4999999999999999, J_o = 4742012.0368266115
J_b = 0.008668930972975825, J_o = 38753.69741327833
J_b = 0.009703080487449826, J_o = 31000.85466461549
J_b = 0.024944703959170814, J_o = 12330.876974722294
J_b = 0.03148050265161741, J_o = 9826.872019108381
J_b = 0.04618151920032563, J_o = 6835.186029272344
J_b = 0.06511496210202684, J_o = 5316.683025103779
J_b = 0.08501993613460058, J_o = 4267.830218233645
J_b = 0.08857969061678284, J_o = 3787.9173600354106
J_b = 0.09560575744153745, J_o = 3360.7282602740534
J_b = 0.10664148542663043, J_o = 3042.712373559176
J_b = 0.12801257012564832, J_o = 2636.312727326342
J_b = 0.16204166568195097, J_o = 2427.4315151768874
J_b = 0.1649596836316288, J_o = 2285.473193808067
J_b = 0.1644311319078796, J_o = 2307.02211501058
J_b = 0.1647008144203801, J_o = 2266.581143639789
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36599881 -0.44616151 -0.31134049 -0.34462362 -0.23072472 -1.63532041
 -0.62400773 -0.28383947 -0.2916251  -0.30580076]
W_opt:  [-0.00828255 -0.0022423   0.01276246  0.01752577  0.01618971  0.01405553
 -0.01194249 -0.06066906 -0.13571782 -0.21857885]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.6109 s, v_trunc (Latent to Reduced) = 0.0531, dec (Reduced to Full) = 0.1624, add (DA)= 0.0001decode = 0.2177 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.8286 s, inc stats = 2.8310, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.47662413e-07 4.88055412e-07 1.57696583e-06 1.14046847e-06
 1.23354694e-06]
u_DA:    [ 2.78283204e-03  6.76268978e-03  3.81589437e-03  2.06126080e-03
 -8.87509472e-05]
ref_MAE: [0.00805531 0.0098723  0.00446215 0.00560663 0.00061666]
da_MAE:  [2.78228438e-03 6.76220173e-03 3.81431741e-03 2.06012034e-03
 8.99844941e-05]
% 33.287247217662035 da_MAE 0.11095403692374403 ref_MAE 0.16631608245240756
u_c taken from control states: [-0.36600102 -0.44616187 -0.31132966 -0.34461826 -0.23087066 -1.63964782
 -0.62399784 -0.28450883 -0.29302668 -0.30580863]
u_c before reduction of space:  [-0.36600102 -0.44616187 -0.31132966 -0.34461826 -0.23087066 -1.63964782
 -0.62399784 -0.28450883 -0.29302668 -0.30580863]
data[u_c] post encoding of state:  [-0.36600102 -0.44616187 -0.31132966 -0.34461826 -0.23087066 -1.63964782
 -0.62399784 -0.28450883 -0.29302668 -0.30580863]
J_b = 0.0, J_o = 146439.1818603826
J_b = 0.49999999999999994, J_o = 4745119.088079399
J_b = 0.00859140534120105, J_o = 39344.214204786156
J_b = 0.009630663193646905, J_o = 31567.088491854356
J_b = 0.024626215920190816, J_o = 13096.852276582511
J_b = 0.031115366518749812, J_o = 10559.626602355702
J_b = 0.0466934238952724, J_o = 7369.177561932202
J_b = 0.06679294037965543, J_o = 5795.67086755208
J_b = 0.08698333341450763, J_o = 4695.6577087358155
J_b = 0.09084063500413349, J_o = 4197.811670479283
J_b = 0.09910650791977485, J_o = 3723.935046931605
J_b = 0.11172917821394142, J_o = 3369.199872254573
J_b = 0.13519503564238675, J_o = 2934.004659869138
J_b = 0.16949536937663917, J_o = 2718.731526229172
J_b = 0.17548340752316377, J_o = 2567.086740722096
J_b = 0.1752536209266109, J_o = 2631.573871307738
J_b = 0.1753694033484729, J_o = 2552.0512675569066
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600102 -0.44616187 -0.31132966 -0.34461826 -0.23087066 -1.63964782
 -0.62399784 -0.28450883 -0.29302668 -0.30580863]
W_opt:  [-0.00931153 -0.00354566  0.01219533  0.01746722  0.01678255  0.01561864
 -0.01049327 -0.05891067 -0.13453135 -0.21975908]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1153 s, v_trunc (Latent to Reduced) = 0.0494, dec (Reduced to Full) = 0.1647, add (DA)= 0.0001decode = 0.2161 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3315 s, inc stats = 2.3354, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.43977597e-07 4.87152794e-07 1.58606540e-06 1.14633342e-06
 1.20173896e-06]
u_DA:    [ 2.79720276e-03  6.74516626e-03  3.82207850e-03  2.04020994e-03
 -8.77218121e-05]
ref_MAE: [0.00805532 0.0098723  0.00446214 0.00560663 0.00061669]
da_MAE:  [2.79665879e-03 6.74467910e-03 3.82049243e-03 2.03906361e-03
 8.89235511e-05]
% 31.433594692796653 da_MAE 0.11734943303928719 ref_MAE 0.17114712739207705
\% improve_point: 17.53, mse_ref_points: 1.9784141079882655e-05, mse_da_points: 1.6316912649031988e-05, % improve_overlap: -15.13, mse_ref_overlap: 0.16810, mse_da_overlap: 0.19339
DA - - L2: 658.73, L1: 1392.22, % Improve: 36.78%, DA_MAE: 0.09, mse_ref: 0.18, mse_DA: 0.146, time(s): 4.5097s,
u_c taken from control states: [-0.36600528 -0.44616253 -0.31132334 -0.34461714 -0.23104726 -1.64411694
 -0.62398966 -0.28532252 -0.29599964 -0.3058238 ]
u_c before reduction of space:  [-0.36600528 -0.44616253 -0.31132334 -0.34461714 -0.23104726 -1.64411694
 -0.62398966 -0.28532252 -0.29599964 -0.3058238 ]
data[u_c] post encoding of state:  [-0.36600528 -0.44616253 -0.31132334 -0.34461714 -0.23104726 -1.64411694
 -0.62398966 -0.28532252 -0.29599964 -0.3058238 ]
J_b = 0.0, J_o = 146170.81764437293
J_b = 0.5000000000000002, J_o = 4748960.475567743
J_b = 0.008515418900808792, J_o = 40095.23348779167
J_b = 0.009557279896616906, J_o = 32309.806671344704
J_b = 0.024356815752394095, J_o = 14001.28021376931
J_b = 0.030844769230020858, J_o = 11419.578959718629
J_b = 0.047424919395739416, J_o = 8007.471281511321
J_b = 0.06904330350117013, J_o = 6357.468504083708
J_b = 0.08997535256212981, J_o = 5193.396204812147
J_b = 0.09400160444615133, J_o = 4673.526199702653
J_b = 0.10340451517871203, J_o = 4152.007123053294
J_b = 0.1176014100984739, J_o = 3759.683047921422
J_b = 0.14337916038310733, J_o = 3293.1150486247216
J_b = 0.17847692166731866, J_o = 3084.5595906445187
J_b = 0.18874737363591668, J_o = 2902.5827903242184
J_b = 0.18752051811721132, J_o = 3020.053260178542
J_b = 0.18845315806582685, J_o = 2893.1139360626175
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36600528 -0.44616253 -0.31132334 -0.34461714 -0.23104726 -1.64411694
 -0.62398966 -0.28532252 -0.29599964 -0.3058238 ]
W_opt:  [-0.01131207 -0.00473228  0.01066127  0.0179779   0.01800432  0.01752702
 -0.00907762 -0.0576968  -0.13492248 -0.22258193]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4770 s, v_trunc (Latent to Reduced) = 0.0544, dec (Reduced to Full) = 0.1655, add (DA)= 0.0001decode = 0.2220 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6990 s, inc stats = 2.7032, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.36906404e-07 4.85478930e-07 1.59137464e-06 1.14755729e-06
 1.16324882e-06]
u_DA:    [ 2.82519515e-03  6.73871318e-03  3.83230933e-03  2.02454545e-03
 -8.35697287e-05]
ref_MAE: [0.00805533 0.0098723  0.00446213 0.00560663 0.00061673]
da_MAE:  [2.82465825e-03 6.73822770e-03 3.83071796e-03 2.02339790e-03
 8.47329776e-05]
% 30.392545169576803 da_MAE 0.12317950226850971 ref_MAE 0.17696308903780214
u_c taken from control states: [-0.3660117  -0.44616365 -0.3113238  -0.34462161 -0.23124608 -1.64852636
 -0.6239856  -0.28624746 -0.30060685 -0.3058466 ]
u_c before reduction of space:  [-0.3660117  -0.44616365 -0.3113238  -0.34462161 -0.23124608 -1.64852636
 -0.6239856  -0.28624746 -0.30060685 -0.3058466 ]
data[u_c] post encoding of state:  [-0.3660117  -0.44616365 -0.3113238  -0.34462161 -0.23124608 -1.64852636
 -0.6239856  -0.28624746 -0.30060685 -0.3058466 ]
J_b = 0.0, J_o = 146028.26166577512
J_b = 0.5, J_o = 4752515.402756139
J_b = 0.008450186241072098, J_o = 40823.30942459262
J_b = 0.009493679979387907, J_o = 33034.17886717198
J_b = 0.024154436555744604, J_o = 14841.967877192792
J_b = 0.030648029752037332, J_o = 12224.71757843631
J_b = 0.04805881959858524, J_o = 8628.416888839522
J_b = 0.07109756326562222, J_o = 6900.780175436243
J_b = 0.09305054500532121, J_o = 5674.551511146012
J_b = 0.09713899663609227, J_o = 5134.125732683324
J_b = 0.10729463997364665, J_o = 4577.483442824883
J_b = 0.12261077426741789, J_o = 4157.653437230161
J_b = 0.15024605050692938, J_o = 3665.6415843853556
J_b = 0.18632827148283712, J_o = 3477.4820020900816
J_b = 0.19650007693267846, J_o = 3272.4559302721227
J_b = 0.19449981088577784, J_o = 3299.87180284774
J_b = 0.19573179333985324, J_o = 3258.6894858001115
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3660117  -0.44616365 -0.3113238  -0.34462161 -0.23124608 -1.64852636
 -0.6239856  -0.28624746 -0.30060685 -0.3058466 ]
W_opt:  [-0.01052898 -0.00449394  0.00980376  0.01756423  0.01741776  0.0171429
 -0.01036025 -0.05868003 -0.1348282  -0.2217155 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1140 s, v_trunc (Latent to Reduced) = 0.0489, dec (Reduced to Full) = 0.2924, add (DA)= 0.0001decode = 0.3437 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4578 s, inc stats = 2.4604, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.26242117e-07 4.82623445e-07 1.59099177e-06 1.14265885e-06
 1.11991605e-06]
u_DA:    [ 2.83924304e-03  6.72875364e-03  3.84448033e-03  2.01981522e-03
 -8.17229496e-05]
ref_MAE: [0.00805534 0.0098723  0.00446213 0.00560663 0.00061678]
da_MAE:  [2.83871680e-03 6.72827102e-03 3.84288933e-03 2.01867256e-03
 8.28428656e-05]
% 29.505349950318752 da_MAE 0.1289216820271455 ref_MAE 0.18288151219459586
u_c taken from control states: [-0.36602025 -0.44616535 -0.31133228 -0.34463233 -0.23145818 -1.65278213
 -0.62398505 -0.28726622 -0.30676144 -0.30587601]
u_c before reduction of space:  [-0.36602025 -0.44616535 -0.31133228 -0.34463233 -0.23145818 -1.65278213
 -0.62398505 -0.28726622 -0.30676144 -0.30587601]
data[u_c] post encoding of state:  [-0.36602025 -0.44616535 -0.31133228 -0.34463233 -0.23145818 -1.65278213
 -0.62398505 -0.28726622 -0.30676144 -0.30587601]
J_b = 0.0, J_o = 146014.709218134
J_b = 0.5, J_o = 4754698.195578039
J_b = 0.008407032403594436, J_o = 41391.10256532536
J_b = 0.009452627675345531, J_o = 33592.31323271363
J_b = 0.02403442502726903, J_o = 15465.77098566171
J_b = 0.030515956038778828, J_o = 12834.271717616022
J_b = 0.048360103519905585, J_o = 9137.905834441584
J_b = 0.07226174959144557, J_o = 7355.474791492138
J_b = 0.09515140823516322, J_o = 6085.655733654816
J_b = 0.09930556879558944, J_o = 5529.154349031201
J_b = 0.10982277615558873, J_o = 4954.191025070328
J_b = 0.12570562833826063, J_o = 4519.734259479648
J_b = 0.15461957116219588, J_o = 4008.419521895951
J_b = 0.1917067667274336, J_o = 3827.9919884128585
J_b = 0.20059828823149128, J_o = 3613.1338762279124
J_b = 0.19872140935769908, J_o = 3638.1215589494977
J_b = 0.19985517319137963, J_o = 3598.7401001208227
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36602025 -0.44616535 -0.31133228 -0.34463233 -0.23145818 -1.65278213
 -0.62398505 -0.28726622 -0.30676144 -0.30587601]
W_opt:  [-0.00834042 -0.00418757  0.00907132  0.01747338  0.01755216  0.01710571
 -0.01192468 -0.06036947 -0.13577026 -0.22126518]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0854 s, v_trunc (Latent to Reduced) = 0.0483, dec (Reduced to Full) = 0.2427, add (DA)= 0.0001decode = 0.2931 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3785 s, inc stats = 2.3817, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [5.12039987e-07 4.78328823e-07 1.58385996e-06 1.13093358e-06
 1.07368974e-06]
u_DA:    [ 2.85561930e-03  6.71194162e-03  3.85181235e-03  2.02106359e-03
 -8.09207386e-05]
ref_MAE: [0.00805535 0.00987231 0.00446214 0.00560664 0.00061682]
da_MAE:  [2.85510726e-03 6.71146329e-03 3.85022849e-03 2.01993265e-03
 8.19944284e-05]
% 28.993769330131304 da_MAE 0.13387651542025186 ref_MAE 0.18854192675384754
u_c taken from control states: [-0.36603055 -0.44616762 -0.31134909 -0.34464907 -0.2316667  -1.6568685
 -0.62398656 -0.28831713 -0.31404098 -0.30590974]
u_c before reduction of space:  [-0.36603055 -0.44616762 -0.31134909 -0.34464907 -0.2316667  -1.6568685
 -0.62398656 -0.28831713 -0.31404098 -0.30590974]
data[u_c] post encoding of state:  [-0.36603055 -0.44616762 -0.31134909 -0.34464907 -0.2316667  -1.6568685
 -0.62398656 -0.28831713 -0.31404098 -0.30590974]
J_b = 0.0, J_o = 146070.40805774744
J_b = 0.5000000000000002, J_o = 4756050.813891835
J_b = 0.008380639200458376, J_o = 41803.262131197785
J_b = 0.00942777757535065, J_o = 33996.432304758135
J_b = 0.02397512114485015, J_o = 15899.034144571959
J_b = 0.03044144917423878, J_o = 13265.67880391277
J_b = 0.04843241817900631, J_o = 9532.464550565146
J_b = 0.07271658527594119, J_o = 7720.6315351789435
J_b = 0.09621971337672348, J_o = 6427.478075024603
J_b = 0.10043217765659392, J_o = 5861.557507122008
J_b = 0.11103394018654057, J_o = 5281.426682094997
J_b = 0.12707348555819925, J_o = 4841.985368922379
J_b = 0.15670625020850204, J_o = 4317.964121306248
J_b = 0.19492947304667432, J_o = 4137.230191075522
J_b = 0.20286771028114342, J_o = 3916.7372310771525
J_b = 0.20114183519429438, J_o = 3966.437166928583
J_b = 0.20229588722930358, J_o = 3903.9721469816773
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36603055 -0.44616762 -0.31134909 -0.34464907 -0.2316667  -1.6568685
 -0.62398656 -0.28831713 -0.31404098 -0.30590974]
W_opt:  [-0.00617783 -0.00383707  0.00965369  0.01741675  0.01702323  0.01658028
 -0.01314081 -0.06184041 -0.13688004 -0.22176913]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1346 s, v_trunc (Latent to Reduced) = 0.0489, dec (Reduced to Full) = 0.1870, add (DA)= 0.0001decode = 0.2379 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3725 s, inc stats = 2.3750, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [4.94925608e-07 4.72571763e-07 1.56973468e-06 1.11261670e-06
 1.02824263e-06]
u_DA:    [ 2.87631997e-03  6.70344044e-03  3.86018399e-03  2.01956920e-03
 -8.09034868e-05]
ref_MAE: [0.00805537 0.00987231 0.00446215 0.00560666 0.00061687]
da_MAE:  [2.87582504e-03 6.70296787e-03 3.85861425e-03 2.01845658e-03
 8.19317294e-05]
% 28.699934000581553 da_MAE 0.1380834593647668 ref_MAE 0.19366526163649422
u_c taken from control states: [-0.36604205 -0.44617049 -0.31137525 -0.34467175 -0.23186154 -1.66069811
 -0.62399061 -0.28935115 -0.32208533 -0.30594559]
u_c before reduction of space:  [-0.36604205 -0.44617049 -0.31137525 -0.34467175 -0.23186154 -1.66069811
 -0.62399061 -0.28935115 -0.32208533 -0.30594559]
data[u_c] post encoding of state:  [-0.36604205 -0.44617049 -0.31137525 -0.34467175 -0.23186154 -1.66069811
 -0.62399061 -0.28935115 -0.32208533 -0.30594559]
J_b = 0.0, J_o = 146137.6484646474
J_b = 0.5, J_o = 4756652.261204107
J_b = 0.008372082278362076, J_o = 41983.47599911645
J_b = 0.009419464221031062, J_o = 34174.96949533963
J_b = 0.023981524878333358, J_o = 16067.20763270285
J_b = 0.030436916221879592, J_o = 13442.925858273511
J_b = 0.04826807866055638, J_o = 9742.72710319138
J_b = 0.07234770694454953, J_o = 7936.608516421956
J_b = 0.09590142492501141, J_o = 6646.199737660413
J_b = 0.1002074027930063, J_o = 6079.040930619678
J_b = 0.1106855032487106, J_o = 5505.843666376863
J_b = 0.12654615391915988, J_o = 5069.326950439918
J_b = 0.15645625607631605, J_o = 4538.002346846561
J_b = 0.19626032983398375, J_o = 4356.603882166844
J_b = 0.20374213540852137, J_o = 4125.970886675079
J_b = 0.20193699827221645, J_o = 4188.202903304362
J_b = 0.2031844313795787, J_o = 4113.49330290437
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36604205 -0.44617049 -0.31137525 -0.34467175 -0.23186154 -1.66069811
 -0.62399061 -0.28935115 -0.32208533 -0.30594559]
W_opt:  [-0.00711028 -0.00393962  0.011143    0.01818169  0.01725406  0.01652115
 -0.01308184 -0.06138934 -0.13662172 -0.22254879]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0427 s, v_trunc (Latent to Reduced) = 0.0467, dec (Reduced to Full) = 0.2095, add (DA)= 0.0001decode = 0.2583 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3010 s, inc stats = 2.3034, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [4.75810156e-07 4.65300474e-07 1.54774945e-06 1.08779742e-06
 9.85777587e-07]
u_DA:    [ 2.89800617e-03  6.70263981e-03  3.87468645e-03  2.02174452e-03
 -8.05077336e-05]
ref_MAE: [0.00805539 0.00987232 0.00446217 0.00560669 0.00061691]
da_MAE:  [2.89753036e-03 6.70217451e-03 3.87313870e-03 2.02065672e-03
 8.14935111e-05]
% 28.675533364319516 da_MAE 0.14119386574610576 ref_MAE 0.1979599321328436
u_c taken from control states: [-0.36605417 -0.44617391 -0.31141077 -0.34469958 -0.23203308 -1.66416757
 -0.62399769 -0.29031995 -0.33043222 -0.30598194]
u_c before reduction of space:  [-0.36605417 -0.44617391 -0.31141077 -0.34469958 -0.23203308 -1.66416757
 -0.62399769 -0.29031995 -0.33043222 -0.30598194]
data[u_c] post encoding of state:  [-0.36605417 -0.44617391 -0.31141077 -0.34469958 -0.23203308 -1.66416757
 -0.62399769 -0.29031995 -0.33043222 -0.30598194]
J_b = 0.0, J_o = 146283.2769995156
J_b = 0.49999999999999994, J_o = 4756100.159829809
J_b = 0.008379118480205072, J_o = 42042.05350636156
J_b = 0.009427949220162317, J_o = 34221.09014735138
J_b = 0.024073782895849476, J_o = 16036.58548287709
J_b = 0.030530789338395817, J_o = 13426.684584902461
J_b = 0.04799133143207235, J_o = 9807.39223576375
J_b = 0.07150114559650465, J_o = 8028.191338030327
J_b = 0.09474040473299315, J_o = 6759.869699002212
J_b = 0.09905227834230734, J_o = 6199.934884831463
J_b = 0.10912320872762345, J_o = 5644.983868255131
J_b = 0.12442642334087876, J_o = 5220.713293204501
J_b = 0.1538092532950574, J_o = 4693.375280725873
J_b = 0.1946127788927098, J_o = 4499.898145399717
J_b = 0.2015192375100297, J_o = 4273.532185835146
J_b = 0.19978348138454716, J_o = 4368.807436070794
J_b = 0.20105194653236144, J_o = 4261.62268966301
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36605417 -0.44617391 -0.31141077 -0.34469958 -0.23203308 -1.66416757
 -0.62399769 -0.29031995 -0.33043222 -0.30598194]
W_opt:  [-0.00714729 -0.00240443  0.01339857  0.01890792  0.0164573   0.01558862
 -0.01343838 -0.061185   -0.13660701 -0.22335173]
----------------------------- DA Assimilate ----------------------
minCostFunction = 1.9818 s, v_trunc (Latent to Reduced) = 0.0462, dec (Reduced to Full) = 0.2984, add (DA)= 0.0001decode = 0.3466 s, unnorm = 0.0000 s, TOTAL = unnormalising + decoding + minimising = 2.3285 s, inc stats = 2.3314, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [4.55674332e-07 4.56639093e-07 1.51790106e-06 1.05734722e-06
 9.48390021e-07]
u_DA:    [ 2.91874289e-03  6.68222496e-03  3.88789243e-03  2.01202915e-03
 -8.27802488e-05]
ref_MAE: [0.00805541 0.00987233 0.0044622  0.00560672 0.00061695]
da_MAE:  [2.91828722e-03 6.68176832e-03 3.88637453e-03 2.01097181e-03
 8.37286389e-05]
% 28.830660459163116 da_MAE 0.1432055909639756 ref_MAE 0.20121809741090035
u_c taken from control states: [-0.36606637 -0.44617779 -0.31145484 -0.3447312  -0.23217654 -1.6672314
 -0.62400723 -0.29119276 -0.3387088  -0.30601744]
u_c before reduction of space:  [-0.36606637 -0.44617779 -0.31145484 -0.3447312  -0.23217654 -1.6672314
 -0.62400723 -0.29119276 -0.3387088  -0.30601744]
data[u_c] post encoding of state:  [-0.36606637 -0.44617779 -0.31145484 -0.3447312  -0.23217654 -1.6672314
 -0.62400723 -0.29119276 -0.3387088  -0.30601744]
J_b = 0.0, J_o = 146376.00008885787
J_b = 0.5, J_o = 4755571.259108278
J_b = 0.008390575142454774, J_o = 41981.400055039856
J_b = 0.00943976548505751, J_o = 34153.55904776446
J_b = 0.024225368710740946, J_o = 15845.531579455735
J_b = 0.03070336124549676, J_o = 13253.198103183528
J_b = 0.04763537626378544, J_o = 9751.623040901595
J_b = 0.0703788333041698, J_o = 8009.334959067391
J_b = 0.0931958678904397, J_o = 6777.329641692623
J_b = 0.09733047774836871, J_o = 6230.946219393212
J_b = 0.10675067995489561, J_o = 5699.816577389084
J_b = 0.12125502170520895, J_o = 5293.624765794083
J_b = 0.14971249189749836, J_o = 4775.297466898356
J_b = 0.19118782245889512, J_o = 4552.2550691714605
J_b = 0.19662743933906582, J_o = 4352.077761575156
J_b = 0.19535137604019556, J_o = 4433.078368228543
J_b = 0.19621911620830063, J_o = 4336.285648909228
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36606637 -0.44617779 -0.31145484 -0.3447312  -0.23217654 -1.6672314
 -0.62400723 -0.29119276 -0.3387088  -0.30601744]
W_opt:  [-0.00568201 -0.00077301  0.01516972  0.0204045   0.01659453  0.01439021
 -0.01480498 -0.06282713 -0.13886899 -0.22476244]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0417 s, v_trunc (Latent to Reduced) = 0.0465, dec (Reduced to Full) = 0.2427, add (DA)= 0.0001decode = 0.2912 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3330 s, inc stats = 2.3353, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [4.35409552e-07 4.46786035e-07 1.48086061e-06 1.02273818e-06
 9.17122444e-07]
u_DA:    [ 2.92815898e-03  6.65304124e-03  3.89834918e-03  2.01063416e-03
 -8.64903835e-05]
ref_MAE: [0.00805543 0.00987234 0.00446224 0.00560675 0.00061698]
da_MAE:  [2.92772357e-03 6.65259445e-03 3.89686832e-03 2.00961142e-03
 8.74075059e-05]
% 29.553178388677114 da_MAE 0.14335071935741794 ref_MAE 0.2034878452690579
u_c taken from control states: [-0.36607805 -0.44618202 -0.3115054  -0.34476465 -0.23229234 -1.66992823
 -0.62401782 -0.29193921 -0.34652013 -0.30605064]
u_c before reduction of space:  [-0.36607805 -0.44618202 -0.3115054  -0.34476465 -0.23229234 -1.66992823
 -0.62401782 -0.29193921 -0.34652013 -0.30605064]
data[u_c] post encoding of state:  [-0.36607805 -0.44618202 -0.3115054  -0.34476465 -0.23229234 -1.66992823
 -0.62401782 -0.29193921 -0.34652013 -0.30605064]
J_b = 0.0, J_o = 146585.00123672668
J_b = 0.4999999999999999, J_o = 4754835.274935615
J_b = 0.008405854485520827, J_o = 41988.45245522907
J_b = 0.009455760711124974, J_o = 34150.743647325115
J_b = 0.024400295550027633, J_o = 15699.70991236757
J_b = 0.03091147380884194, J_o = 13121.690215621265
J_b = 0.04731629622461891, J_o = 9740.053347967627
J_b = 0.06918331573355078, J_o = 8045.3531652444035
J_b = 0.09135471605465938, J_o = 6855.406091242356
J_b = 0.09536051874915326, J_o = 6322.721614332291
J_b = 0.1042979115141177, J_o = 5810.187453019511
J_b = 0.11818588005142346, J_o = 5418.499631128907
J_b = 0.14595081082879302, J_o = 4907.773911282013
J_b = 0.18796340240644216, J_o = 4662.723972417489
J_b = 0.1931786225809656, J_o = 4477.755557415841
J_b = 0.19232752782971133, J_o = 4531.497070431595
J_b = 0.19284200618936093, J_o = 4458.47968683435
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36607805 -0.44618202 -0.3115054  -0.34476465 -0.23229234 -1.66992823
 -0.62401782 -0.29193921 -0.34652013 -0.30605064]
W_opt:  [-0.00752676 -0.00050604  0.01655304  0.02108347  0.01698198  0.0138239
 -0.01460953 -0.06291515 -0.13981924 -0.22497587]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0803 s, v_trunc (Latent to Reduced) = 0.0493, dec (Reduced to Full) = 0.1391, add (DA)= 0.0001decode = 0.1905 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2708 s, inc stats = 2.2732, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [4.15999978e-07 4.36084714e-07 1.43837177e-06 9.86142479e-07
 8.91883535e-07]
u_DA:    [ 2.94393037e-03  6.63687455e-03  3.91623995e-03  2.00512360e-03
 -8.74844953e-05]
ref_MAE: [0.00805545 0.00987235 0.00446228 0.00560679 0.000617  ]
da_MAE:  [2.94351437e-03 6.63643847e-03 3.91480158e-03 2.00413746e-03
 8.83763788e-05]
% 30.418044368445212 da_MAE 0.14255845447240195 ref_MAE 0.20487848204104367
u_c taken from control states: [-0.36608868 -0.44618641 -0.31155946 -0.34479827 -0.23237626 -1.67230291
 -0.6240285  -0.29252224 -0.35350926 -0.30607961]
u_c before reduction of space:  [-0.36608868 -0.44618641 -0.31155946 -0.34479827 -0.23237626 -1.67230291
 -0.6240285  -0.29252224 -0.35350926 -0.30607961]
data[u_c] post encoding of state:  [-0.36608868 -0.44618641 -0.31155946 -0.34479827 -0.23237626 -1.67230291
 -0.6240285  -0.29252224 -0.35350926 -0.30607961]
J_b = 0.0, J_o = 146823.5572334074
J_b = 0.5000000000000002, J_o = 4754169.6336780405
J_b = 0.008425275631344431, J_o = 41963.52943968048
J_b = 0.009474761396563692, J_o = 34122.878645527315
J_b = 0.024606138795989777, J_o = 15502.705999795273
J_b = 0.03119211670574871, J_o = 12923.823017857778
J_b = 0.04722866980334722, J_o = 9632.87131670868
J_b = 0.06844394769045199, J_o = 7979.955286450232
J_b = 0.08988858207720246, J_o = 6834.042066742821
J_b = 0.09353660866396864, J_o = 6320.537754755042
J_b = 0.10194380739947294, J_o = 5824.682670740052
J_b = 0.11520485163104963, J_o = 5448.132685873345
J_b = 0.14195027861523676, J_o = 4951.085863586373
J_b = 0.1833552973944258, J_o = 4687.26618877767
J_b = 0.18897389303346862, J_o = 4519.017394622089
J_b = 0.1887068755306716, J_o = 4555.138807539788
J_b = 0.18881920835776317, J_o = 4497.503962134174
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36608868 -0.44618641 -0.31155946 -0.34479827 -0.23237626 -1.67230291
 -0.6240285  -0.29252224 -0.35350926 -0.30607961]
W_opt:  [-1.11254680e-02 -1.45042686e-04  1.80149692e-02  2.24758868e-02
  1.90303667e-02  1.45043283e-02 -1.35524301e-02 -6.29409283e-02
 -1.40448541e-01 -2.25041415e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2292 s, v_trunc (Latent to Reduced) = 0.0599, dec (Reduced to Full) = 0.1606, add (DA)= 0.0001decode = 0.2225 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4518 s, inc stats = 2.4542, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.98341162e-07 4.24943951e-07 1.39294287e-06 9.49352704e-07
 8.73594488e-07]
u_DA:    [ 2.96129970e-03  6.63989580e-03  3.93833441e-03  2.00270982e-03
 -8.86760160e-05]
ref_MAE: [0.00805546 0.00987236 0.00446233 0.00560682 0.00061702]
da_MAE:  [2.96090136e-03 6.63947086e-03 3.93694147e-03 2.00176047e-03
 8.95496105e-05]
% 31.44424131451195 da_MAE 0.1410270487129034 ref_MAE 0.20571145505061142
u_c taken from control states: [-0.36609791 -0.44619083 -0.31161403 -0.34483065 -0.23242513 -1.6744835
 -0.62403747 -0.29293514 -0.35947171 -0.30610329]
u_c before reduction of space:  [-0.36609791 -0.44619083 -0.31161403 -0.34483065 -0.23242513 -1.6744835
 -0.62403747 -0.29293514 -0.35947171 -0.30610329]
data[u_c] post encoding of state:  [-0.36609791 -0.44619083 -0.31161403 -0.34483065 -0.23242513 -1.6744835
 -0.62403747 -0.29293514 -0.35947171 -0.30610329]
J_b = 0.0, J_o = 147178.92340337552
J_b = 0.49999999999999994, J_o = 4752749.587171715
J_b = 0.008448510449848503, J_o = 42019.42542548739
J_b = 0.009500379108243077, J_o = 34155.00335161839
J_b = 0.02490168818139904, J_o = 15276.348338761563
J_b = 0.03162390351261432, J_o = 12673.958354680432
J_b = 0.04751667359466593, J_o = 9430.144175449757
J_b = 0.0684775087741365, J_o = 7799.309946302173
J_b = 0.08933848096578971, J_o = 6688.678551300278
J_b = 0.09245964072491669, J_o = 6195.781089528668
J_b = 0.1002680312544691, J_o = 5716.54329605166
J_b = 0.11278923350208285, J_o = 5358.760172887201
J_b = 0.13786612342398685, J_o = 4886.368910447555
J_b = 0.17707520034776503, J_o = 4606.529491744936
J_b = 0.18403221567196423, J_o = 4456.391491299374
J_b = 0.1848613789882442, J_o = 4488.138216496751
J_b = 0.18429346580864703, J_o = 4433.938941704973
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36609791 -0.44619083 -0.31161403 -0.34483065 -0.23242513 -1.6744835
 -0.62403747 -0.29293514 -0.35947171 -0.30610329]
W_opt:  [-0.01065185  0.00094862  0.01894188  0.02318285  0.01940216  0.01401195
 -0.01486371 -0.0645619  -0.14176967 -0.22524883]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0658 s, v_trunc (Latent to Reduced) = 0.0470, dec (Reduced to Full) = 0.3393, add (DA)= 0.0001decode = 0.3883 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4541 s, inc stats = 2.4565, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.83007183e-07 4.13745758e-07 1.34707845e-06 9.13919815e-07
 8.62943164e-07]
u_DA:    [ 2.98137094e-03  6.61330642e-03  3.95941953e-03  1.99812647e-03
 -9.10658646e-05]
ref_MAE: [0.00805548 0.00987237 0.00446238 0.00560686 0.00061703]
da_MAE:  [2.98098793e-03 6.61289268e-03 3.95807245e-03 1.99721255e-03
 9.19288078e-05]
% 32.70015039375084 da_MAE 0.13894340320385226 ref_MAE 0.20645425512355173
\% improve_point: 16.99, mse_ref_points: 2.148904935637146e-05, mse_da_points: 1.787351079451496e-05, % improve_overlap: -13.54, mse_ref_overlap: 0.18616, mse_da_overlap: 0.21007
DA - - L2: 1199.54, L1: 1725.32, % Improve: 35.43%, DA_MAE: 0.10, mse_ref: 0.19, mse_DA: 0.160, time(s): 4.0982s,
u_c taken from control states: [-0.36610546 -0.44619511 -0.31166648 -0.34486036 -0.2324384  -1.67665295
 -0.62404347 -0.29317232 -0.36429747 -0.30612073]
u_c before reduction of space:  [-0.36610546 -0.44619511 -0.31166648 -0.34486036 -0.2324384  -1.67665295
 -0.62404347 -0.29317232 -0.36429747 -0.30612073]
data[u_c] post encoding of state:  [-0.36610546 -0.44619511 -0.31166648 -0.34486036 -0.2324384  -1.67665295
 -0.62404347 -0.29317232 -0.36429747 -0.30612073]
J_b = 0.0, J_o = 147438.29682943368
J_b = 0.49999999999999967, J_o = 4751519.412724997
J_b = 0.008463953244754938, J_o = 42086.84372286663
J_b = 0.009518917317514603, J_o = 34195.1307673213
J_b = 0.025159708619365374, J_o = 15083.945277958674
J_b = 0.03200985331334333, J_o = 12454.671630150277
J_b = 0.04788580914100246, J_o = 9229.442339430429
J_b = 0.06876423305702153, J_o = 7614.114352679727
J_b = 0.08904554306230456, J_o = 6533.213508386514
J_b = 0.09163398198947138, J_o = 6060.93291694244
J_b = 0.09891222972795072, J_o = 5596.132360033465
J_b = 0.11079701076645977, J_o = 5255.338034580832
J_b = 0.1340947930004624, J_o = 4811.163093292051
J_b = 0.17060456080058362, J_o = 4523.533386004628
J_b = 0.17917710828878775, J_o = 4386.09291688399
J_b = 0.18136109454608593, J_o = 4426.341641457878
J_b = 0.17991388378349296, J_o = 4364.112555986635
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36610546 -0.44619511 -0.31166648 -0.34486036 -0.2324384  -1.67665295
 -0.62404347 -0.29317232 -0.36429747 -0.30612073]
W_opt:  [-0.00971875  0.0029029   0.01952262  0.02303297  0.01920343  0.01286218
 -0.0168353  -0.0661476  -0.14252754 -0.22481818]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1974 s, v_trunc (Latent to Reduced) = 0.0469, dec (Reduced to Full) = 0.1416, add (DA)= 0.0001decode = 0.1904 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3879 s, inc stats = 2.3903, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.70459665e-07 4.02912508e-07 1.30299738e-06 8.81409238e-07
 8.60050323e-07]
u_DA:    [ 3.02164334e-03  6.56029263e-03  3.98100877e-03  1.98498690e-03
 -9.41167396e-05]
ref_MAE: [0.00805549 0.00987238 0.00446242 0.00560689 0.00061704]
da_MAE:  [3.02127288e-03 6.55988972e-03 3.97970577e-03 1.98410549e-03
 9.49767900e-05]
% 34.219581295949915 da_MAE 0.13620341750549284 ref_MAE 0.20705769313856134
u_c taken from control states: [-0.36611119 -0.44619911 -0.31171503 -0.34488652 -0.23241816 -1.67884641
 -0.62404754 -0.29321472 -0.36785443 -0.30613153]
u_c before reduction of space:  [-0.36611119 -0.44619911 -0.31171503 -0.34488652 -0.23241816 -1.67884641
 -0.62404754 -0.29321472 -0.36785443 -0.30613153]
data[u_c] post encoding of state:  [-0.36611119 -0.44619911 -0.31171503 -0.34488652 -0.23241816 -1.67884641
 -0.62404754 -0.29321472 -0.36785443 -0.30613153]
J_b = 0.0, J_o = 147682.57968116264
J_b = 0.5000000000000001, J_o = 4750285.077285863
J_b = 0.008477638511839542, J_o = 42164.68030585443
J_b = 0.009535957163098248, J_o = 34244.74210341475
J_b = 0.025389205805562868, J_o = 14925.447362961615
J_b = 0.03235410998745277, J_o = 12270.654678637944
J_b = 0.04824359475008543, J_o = 9055.481000276908
J_b = 0.06907828063396973, J_o = 7451.89289619068
J_b = 0.08889396047299128, J_o = 6394.191854170524
J_b = 0.09107074955291224, J_o = 5937.498236006931
J_b = 0.0979765511086054, J_o = 5481.794711172288
J_b = 0.10945054364066528, J_o = 5152.236117872388
J_b = 0.13151053146400085, J_o = 4728.193749582317
J_b = 0.16615714934472536, J_o = 4436.466334570354
J_b = 0.17599654673058113, J_o = 4305.322232514738
J_b = 0.17934046466094208, J_o = 4358.376865742504
J_b = 0.17707043598970057, J_o = 4284.149241295603
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611119 -0.44619911 -0.31171503 -0.34488652 -0.23241816 -1.67884641
 -0.62404754 -0.29321472 -0.36785443 -0.30613153]
W_opt:  [-0.00849522  0.00367181  0.01920574  0.02271753  0.01923062  0.01259951
 -0.01703995 -0.0665464  -0.14299427 -0.22531006]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3652 s, v_trunc (Latent to Reduced) = 0.0517, dec (Reduced to Full) = 0.2459, add (DA)= 0.0001decode = 0.3002 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6655 s, inc stats = 2.6697, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.60943933e-07 3.92760079e-07 1.26219627e-06 8.52779714e-07
 8.64460952e-07]
u_DA:    [ 3.05458996e-03  6.51191071e-03  3.99975160e-03  1.97770514e-03
 -9.62436015e-05]
ref_MAE: [0.0080555  0.00987239 0.00446246 0.00560692 0.00061703]
da_MAE:  [3.05422902e-03 6.51151795e-03 3.99848940e-03 1.97685236e-03
 9.71080625e-05]
% 35.52423352092714 da_MAE 0.13379198252845867 ref_MAE 0.20750739360637774
u_c taken from control states: [-0.36611518 -0.44620279 -0.31175837 -0.34490868 -0.23237525 -1.68103237
 -0.62405097 -0.29308186 -0.37020363 -0.30613647]
u_c before reduction of space:  [-0.36611518 -0.44620279 -0.31175837 -0.34490868 -0.23237525 -1.68103237
 -0.62405097 -0.29308186 -0.37020363 -0.30613647]
data[u_c] post encoding of state:  [-0.36611518 -0.44620279 -0.31175837 -0.34490868 -0.23237525 -1.68103237
 -0.62405097 -0.29308186 -0.37020363 -0.30613647]
J_b = 0.0, J_o = 147966.24185199884
J_b = 0.4999999999999998, J_o = 4749145.4745605625
J_b = 0.008493099930356464, J_o = 42254.66015292459
J_b = 0.009553978297734718, J_o = 34312.26996706912
J_b = 0.025600145513332465, J_o = 14805.323006630453
J_b = 0.03267457643579109, J_o = 12125.171976706124
J_b = 0.04861335661686481, J_o = 8911.951768879344
J_b = 0.06947314510924212, J_o = 7316.091033558054
J_b = 0.0889050922087168, J_o = 6276.643271894692
J_b = 0.09073256795959599, J_o = 5832.293502995385
J_b = 0.09738093481759744, J_o = 5381.119406039554
J_b = 0.10860885750477837, J_o = 5058.6612894295295
J_b = 0.12980592936621815, J_o = 4649.194749264777
J_b = 0.16303175362032907, J_o = 4354.990485849893
J_b = 0.1739008289264015, J_o = 4227.634234794666
J_b = 0.17823229558475046, J_o = 4294.868504022725
J_b = 0.1752069969097914, J_o = 4207.369828896066
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611518 -0.44620279 -0.31175837 -0.34490868 -0.23237525 -1.68103237
 -0.62405097 -0.29308186 -0.37020363 -0.30613647]
W_opt:  [-0.00746638  0.00347038  0.01918997  0.02352072  0.01948338  0.01250585
 -0.01730591 -0.06691062 -0.14360999 -0.22612907]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0813 s, v_trunc (Latent to Reduced) = 0.0482, dec (Reduced to Full) = 0.1525, add (DA)= 0.0001decode = 0.2028 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2841 s, inc stats = 2.2865, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.54310358e-07 3.83432349e-07 1.22577381e-06 8.28537694e-07
 8.73814210e-07]
u_DA:    [ 3.08581110e-03  6.48283516e-03  4.01103646e-03  1.97366001e-03
 -9.71036997e-05]
ref_MAE: [0.00805551 0.0098724  0.0044625  0.00560694 0.00061702]
da_MAE:  [3.08545679e-03 6.48245172e-03 4.00981069e-03 1.97283147e-03
 9.79775139e-05]
% 36.568608291026536 da_MAE 0.1317212428244212 ref_MAE 0.2076593927321745
u_c taken from control states: [-0.36611763 -0.44620608 -0.31179487 -0.34492625 -0.23231826 -1.68325742
 -0.62405367 -0.29281203 -0.37137268 -0.30613731]
u_c before reduction of space:  [-0.36611763 -0.44620608 -0.31179487 -0.34492625 -0.23231826 -1.68325742
 -0.62405367 -0.29281203 -0.37137268 -0.30613731]
data[u_c] post encoding of state:  [-0.36611763 -0.44620608 -0.31179487 -0.34492625 -0.23231826 -1.68325742
 -0.62405367 -0.29281203 -0.37137268 -0.30613731]
J_b = 0.0, J_o = 148204.42631843395
J_b = 0.49999999999999983, J_o = 4748104.2565444065
J_b = 0.008508120480827577, J_o = 42302.3317456337
J_b = 0.009570904017130021, J_o = 34342.83812763986
J_b = 0.025770371987182614, J_o = 14688.058242215347
J_b = 0.032928098736557686, J_o = 11990.019931171793
J_b = 0.04887916210573977, J_o = 8783.663197868906
J_b = 0.0697232815853445, J_o = 7194.85574986871
J_b = 0.08887825872951252, J_o = 6170.406749883841
J_b = 0.09043984955104564, J_o = 5735.340315134509
J_b = 0.09686016015380697, J_o = 5288.82635020718
J_b = 0.10786472918562932, J_o = 4972.790305215803
J_b = 0.12830262456216823, J_o = 4576.671365977482
J_b = 0.16014477012396372, J_o = 4284.663897193918
J_b = 0.1715152619985595, J_o = 4160.807930309642
J_b = 0.17650646849845555, J_o = 4239.734649194591
J_b = 0.17294204065748717, J_o = 4141.417124386042
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611763 -0.44620608 -0.31179487 -0.34492625 -0.23231826 -1.68325742
 -0.62405367 -0.29281203 -0.37137268 -0.30613731]
W_opt:  [-0.00748649  0.00354468  0.01939439  0.0238172   0.01960744  0.0124406
 -0.01766559 -0.06728829 -0.14388855 -0.22613334]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0752 s, v_trunc (Latent to Reduced) = 0.0480, dec (Reduced to Full) = 0.3379, add (DA)= 0.0001decode = 0.3879 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4631 s, inc stats = 2.4656, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.50236141e-07 3.75101094e-07 1.19510481e-06 8.09307316e-07
 8.86235961e-07]
u_DA:    [ 3.10818179e-03  6.46232543e-03  4.01556105e-03  1.96971897e-03
 -9.70099577e-05]
ref_MAE: [0.00805551 0.00987241 0.00446253 0.00560696 0.00061701]
da_MAE:  [3.10783156e-03 6.46195033e-03 4.01436595e-03 1.96890966e-03
 9.78961937e-05]
% 37.39507560364026 da_MAE 0.13002149311758365 ref_MAE 0.20768572819352202
u_c taken from control states: [-0.36611883 -0.44620893 -0.31182377 -0.34493897 -0.23225543 -1.68561611
 -0.624055   -0.2924432  -0.37143972 -0.30613542]
u_c before reduction of space:  [-0.36611883 -0.44620893 -0.31182377 -0.34493897 -0.23225543 -1.68561611
 -0.624055   -0.2924432  -0.37143972 -0.30613542]
data[u_c] post encoding of state:  [-0.36611883 -0.44620893 -0.31182377 -0.34493897 -0.23225543 -1.68561611
 -0.624055   -0.2924432  -0.37143972 -0.30613542]
J_b = 0.0, J_o = 148471.56348182008
J_b = 0.4999999999999998, J_o = 4746773.227081308
J_b = 0.00852515605796581, J_o = 42356.81125424861
J_b = 0.009590500560087962, J_o = 34376.06737348657
J_b = 0.025927064908902394, J_o = 14586.38831762257
J_b = 0.033153926054640445, J_o = 11873.535415206643
J_b = 0.04911031173330953, J_o = 8673.04926590569
J_b = 0.06995711008693771, J_o = 7086.338378708431
J_b = 0.08899814768682053, J_o = 6070.788394170227
J_b = 0.09037603521947812, J_o = 5641.196186328621
J_b = 0.09659363048750992, J_o = 5199.629534660095
J_b = 0.10739411157815873, J_o = 4888.879557808097
J_b = 0.12727260564073792, J_o = 4502.2874354565965
J_b = 0.15817703237079703, J_o = 4213.372038730347
J_b = 0.16969241982265793, J_o = 4091.384430247588
J_b = 0.1750652201107311, J_o = 4178.32263513959
J_b = 0.1711767042842495, J_o = 4072.428947341998
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611883 -0.44620893 -0.31182377 -0.34493897 -0.23225543 -1.68561611
 -0.624055   -0.2924432  -0.37143972 -0.30613542]
W_opt:  [-0.00858452  0.00357967  0.02028575  0.02441795  0.01983716  0.01227041
 -0.0181215  -0.06752204 -0.1439494  -0.22620649]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2668 s, v_trunc (Latent to Reduced) = 0.0507, dec (Reduced to Full) = 0.1743, add (DA)= 0.0001decode = 0.2270 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4939 s, inc stats = 2.4963, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.48253250e-07 3.67874135e-07 1.17081501e-06 7.95391687e-07
 8.99928632e-07]
u_DA:    [ 3.12653943e-03  6.44994105e-03  4.01772221e-03  1.96551548e-03
 -9.73317670e-05]
ref_MAE: [0.00805551 0.00987242 0.00446255 0.00560698 0.000617  ]
da_MAE:  [3.12619118e-03 6.44957317e-03 4.01655139e-03 1.96472008e-03
 9.82316957e-05]
% 38.05001540103308 da_MAE 0.12863050687336017 ref_MAE 0.20763605948580852
u_c taken from control states: [-0.3661191  -0.44621136 -0.31184556 -0.34494725 -0.23219493 -1.6881498
 -0.62405541 -0.29201097 -0.37050572 -0.30613203]
u_c before reduction of space:  [-0.3661191  -0.44621136 -0.31184556 -0.34494725 -0.23219493 -1.6881498
 -0.62405541 -0.29201097 -0.37050572 -0.30613203]
data[u_c] post encoding of state:  [-0.3661191  -0.44621136 -0.31184556 -0.34494725 -0.23219493 -1.6881498
 -0.62405541 -0.29201097 -0.37050572 -0.30613203]
J_b = 0.0, J_o = 148665.1677418646
J_b = 0.4999999999999999, J_o = 4745766.042789397
J_b = 0.008537901240134683, J_o = 42391.45648385576
J_b = 0.009605112282021284, J_o = 34395.47831465293
J_b = 0.026029666311167418, J_o = 14518.709380630287
J_b = 0.03329791844408921, J_o = 11797.57413713007
J_b = 0.04924353096560094, J_o = 8602.992734884418
J_b = 0.07009407679621858, J_o = 7014.84515038327
J_b = 0.08916605896128611, J_o = 6002.412354272552
J_b = 0.09045443863961124, J_o = 5574.444407108766
J_b = 0.09652361543806331, J_o = 5137.425054171479
J_b = 0.10715224897698675, J_o = 4830.847191248345
J_b = 0.12666074041516928, J_o = 4450.380168756294
J_b = 0.15695980084918962, J_o = 4165.151101825584
J_b = 0.16833421091153083, J_o = 4044.3496564510233
J_b = 0.17380579452168554, J_o = 4134.5308466066
J_b = 0.16982452950543808, J_o = 4025.5573601858946
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3661191  -0.44621136 -0.31184556 -0.34494725 -0.23219493 -1.6881498
 -0.62405541 -0.29201097 -0.37050572 -0.30613203]
W_opt:  [-0.00965857  0.0031999   0.02089005  0.02502264  0.02043377  0.01210165
 -0.01856454 -0.06774333 -0.14386877 -0.2261103 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3629 s, v_trunc (Latent to Reduced) = 0.0532, dec (Reduced to Full) = 0.1564, add (DA)= 0.0001decode = 0.2117 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5747 s, inc stats = 2.5779, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.47794605e-07 3.61722995e-07 1.15250062e-06 7.86324206e-07
 9.13115215e-07]
u_DA:    [ 3.13786837e-03  6.44418950e-03  4.01753907e-03  1.96100204e-03
 -9.72020144e-05]
ref_MAE: [0.00805551 0.00987242 0.00446257 0.00560699 0.00061698]
da_MAE:  [3.13752058e-03 6.44382778e-03 4.01638657e-03 1.96021572e-03
 9.81151296e-05]
% 38.567073242321534 da_MAE 0.1275538939818751 ref_MAE 0.20763115272858496
u_c taken from control states: [-0.3661189  -0.44621341 -0.31186113 -0.34495199 -0.23214546 -1.69085018
 -0.62405568 -0.29155503 -0.36872102 -0.3061281 ]
u_c before reduction of space:  [-0.3661189  -0.44621341 -0.31186113 -0.34495199 -0.23214546 -1.69085018
 -0.62405568 -0.29155503 -0.36872102 -0.3061281 ]
data[u_c] post encoding of state:  [-0.3661189  -0.44621341 -0.31186113 -0.34495199 -0.23214546 -1.69085018
 -0.62405568 -0.29155503 -0.36872102 -0.3061281 ]
J_b = 0.0, J_o = 148858.79089298917
J_b = 0.49999999999999983, J_o = 4744735.201992423
J_b = 0.008549459545829353, J_o = 42444.077964196986
J_b = 0.009618878498946206, J_o = 34430.938450259986
J_b = 0.02611815986892646, J_o = 14477.850815037062
J_b = 0.03341994545157553, J_o = 11749.603688723055
J_b = 0.04935516872165577, J_o = 8559.469105794127
J_b = 0.07021049228395466, J_o = 6968.246515923647
J_b = 0.08937130601165967, J_o = 5956.465712035498
J_b = 0.09060909059882234, J_o = 5528.546684348575
J_b = 0.09655076641848752, J_o = 5095.979935203866
J_b = 0.10702110364623907, J_o = 4792.999249179586
J_b = 0.12624911179732676, J_o = 4417.01916146983
J_b = 0.15610072003459255, J_o = 4135.794464915763
J_b = 0.16719413459711857, J_o = 4015.8221131953187
J_b = 0.1726398486339351, J_o = 4106.641115885539
J_b = 0.16867303168958217, J_o = 3997.0049710411645
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3661189  -0.44621341 -0.31186113 -0.34495199 -0.23214546 -1.69085018
 -0.62405568 -0.29155503 -0.36872102 -0.3061281 ]
W_opt:  [-0.01034565  0.00285046  0.02112356  0.0250086   0.02047479  0.01207406
 -0.01848729 -0.06745229 -0.14365534 -0.22612686]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.5189 s, v_trunc (Latent to Reduced) = 0.0491, dec (Reduced to Full) = 0.2196, add (DA)= 0.0001decode = 0.2711 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.7901 s, inc stats = 2.7943, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.48129461e-07 3.56533358e-07 1.13942084e-06 7.81145131e-07
 9.23897524e-07]
u_DA:    [ 3.13872715e-03  6.44602491e-03  4.01712752e-03  1.95600074e-03
 -9.72300747e-05]
ref_MAE: [0.00805551 0.00987243 0.00446258 0.00560699 0.00061697]
da_MAE:  [3.13837902e-03 6.44566838e-03 4.01598810e-03 1.95521959e-03
 9.81539722e-05]
% 38.87675942007889 da_MAE 0.12689581762643057 ref_MAE 0.20760649537308015
u_c taken from control states: [-0.36611862 -0.44621513 -0.31187151 -0.34495412 -0.2321119  -1.69372866
 -0.6240559  -0.29111881 -0.36626159 -0.30612485]
u_c before reduction of space:  [-0.36611862 -0.44621513 -0.31187151 -0.34495412 -0.2321119  -1.69372866
 -0.6240559  -0.29111881 -0.36626159 -0.30612485]
data[u_c] post encoding of state:  [-0.36611862 -0.44621513 -0.31187151 -0.34495412 -0.2321119  -1.69372866
 -0.6240559  -0.29111881 -0.36626159 -0.30612485]
J_b = 0.0, J_o = 149036.17237976225
J_b = 0.49999999999999994, J_o = 4743887.686033336
J_b = 0.008558065634106, J_o = 42519.11334180267
J_b = 0.009629626676119704, J_o = 34489.64608688868
J_b = 0.026193734928019966, J_o = 14469.305181658492
J_b = 0.03352641373171715, J_o = 11733.539696080647
J_b = 0.049470222219643374, J_o = 8543.587686218621
J_b = 0.07035260343539206, J_o = 6948.558244214147
J_b = 0.08959898882941211, J_o = 5935.990700021413
J_b = 0.09080421620703956, J_o = 5507.751903673707
J_b = 0.09665168590015893, J_o = 5078.779301187714
J_b = 0.10699324988884452, J_o = 4778.781775749312
J_b = 0.12596677474466547, J_o = 4407.230205613266
J_b = 0.15531556679922967, J_o = 4131.27513819682
J_b = 0.1660173388623639, J_o = 4012.643781723546
J_b = 0.17133732354057296, J_o = 4101.965635750925
J_b = 0.16746762917709845, J_o = 3993.8033889387134
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611862 -0.44621513 -0.31187151 -0.34495412 -0.2321119  -1.69372866
 -0.6240559  -0.29111881 -0.36626159 -0.30612485]
W_opt:  [-0.01024403  0.00237689  0.02113991  0.02456312  0.0200671   0.01183286
 -0.01843114 -0.06716102 -0.14334656 -0.2258024 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4332 s, v_trunc (Latent to Reduced) = 0.0607, dec (Reduced to Full) = 0.1863, add (DA)= 0.0001decode = 0.2490 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6823 s, inc stats = 2.6847, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.48591319e-07 3.52150278e-07 1.13069368e-06 7.78810720e-07
 9.31211695e-07]
u_DA:    [ 3.13481035e-03  6.44984165e-03  4.01710508e-03  1.95025850e-03
 -9.75457523e-05]
ref_MAE: [0.00805551 0.00987243 0.00446259 0.00560699 0.00061696]
da_MAE:  [3.13446176e-03 6.44948950e-03 4.01597438e-03 1.94947969e-03
 9.84769640e-05]
% 39.02167186745775 da_MAE 0.1265642654369732 ref_MAE 0.2075561421786993
u_c taken from control states: [-0.36611855 -0.44621662 -0.31187838 -0.34495466 -0.23209596 -1.69675854
 -0.62405647 -0.29072053 -0.36328047 -0.30612306]
u_c before reduction of space:  [-0.36611855 -0.44621662 -0.31187838 -0.34495466 -0.23209596 -1.69675854
 -0.62405647 -0.29072053 -0.36328047 -0.30612306]
data[u_c] post encoding of state:  [-0.36611855 -0.44621662 -0.31187838 -0.34495466 -0.23209596 -1.69675854
 -0.62405647 -0.29072053 -0.36328047 -0.30612306]
J_b = 0.0, J_o = 149180.34112897972
J_b = 0.5, J_o = 4743209.756654115
J_b = 0.008562549407549818, J_o = 42616.65142875249
J_b = 0.009636434807845989, J_o = 34570.289386453005
J_b = 0.026246244069378616, J_o = 14499.148597898968
J_b = 0.03360185885018023, J_o = 11756.101949572278
J_b = 0.049578084415690137, J_o = 8560.070728172837
J_b = 0.07052366541549202, J_o = 6958.7353294104705
J_b = 0.08989564009760549, J_o = 5941.924465860556
J_b = 0.09111114766233065, J_o = 5511.72789793522
J_b = 0.09692872907865993, J_o = 5084.226943901066
J_b = 0.10721290809872902, J_o = 4785.449961099258
J_b = 0.12606919341356412, J_o = 4416.216942071858
J_b = 0.15504552649296058, J_o = 4145.821497712804
J_b = 0.16522038633889505, J_o = 4028.821206857726
J_b = 0.17021803407425978, J_o = 4113.139610346887
J_b = 0.16660400007221146, J_o = 4009.961264025032
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611855 -0.44621662 -0.31187838 -0.34495466 -0.23209596 -1.69675854
 -0.62405647 -0.29072053 -0.36328047 -0.30612306]
W_opt:  [-0.01005628  0.00200428  0.02111197  0.02395469  0.01969284  0.01151218
 -0.01854188 -0.06701694 -0.14297596 -0.22500705]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1712 s, v_trunc (Latent to Reduced) = 0.0488, dec (Reduced to Full) = 0.2161, add (DA)= 0.0001decode = 0.2671 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4384 s, inc stats = 2.4408, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.48708190e-07 3.48388267e-07 1.12491709e-06 7.78216703e-07
 9.34686354e-07]
u_DA:    [ 3.13189018e-03  6.45243871e-03  4.01672488e-03  1.94360288e-03
 -9.78985838e-05]
ref_MAE: [0.00805551 0.00987244 0.0044626  0.00560699 0.00061696]
da_MAE:  [3.13154147e-03 6.45209032e-03 4.01559996e-03 1.94282467e-03
 9.88332701e-05]
% 39.08477863441338 da_MAE 0.12643432040855676 ref_MAE 0.2075578444503272
u_c taken from control states: [-0.36611903 -0.44621798 -0.3118837  -0.3449548  -0.23210226 -1.69989737
 -0.62405769 -0.29039508 -0.35996337 -0.30612357]
u_c before reduction of space:  [-0.36611903 -0.44621798 -0.3118837  -0.3449548  -0.23210226 -1.69989737
 -0.62405769 -0.29039508 -0.35996337 -0.30612357]
data[u_c] post encoding of state:  [-0.36611903 -0.44621798 -0.3118837  -0.3449548  -0.23210226 -1.69989737
 -0.62405769 -0.29039508 -0.35996337 -0.30612357]
J_b = 0.0, J_o = 149252.38196491287
J_b = 0.5, J_o = 4743021.010205914
J_b = 0.00856060911317357, J_o = 42723.166879045995
J_b = 0.00963613340959358, J_o = 34665.48470862806
J_b = 0.026264908675126982, J_o = 14570.1145915511
J_b = 0.03363469990832361, J_o = 11820.463575248497
J_b = 0.04967353775042877, J_o = 8611.04827898208
J_b = 0.0707379584569585, J_o = 7000.958107540748
J_b = 0.09025040057386027, J_o = 5977.905243822857
J_b = 0.09147507571606563, J_o = 5545.438414521148
J_b = 0.09729813823434014, J_o = 5117.570843733293
J_b = 0.1075867305490553, J_o = 4818.461740716879
J_b = 0.1264293558035722, J_o = 4449.892385848457
J_b = 0.1551343650351527, J_o = 4184.315066144401
J_b = 0.16480424295717636, J_o = 4069.0040509186933
J_b = 0.16943266536019855, J_o = 4147.405308203872
J_b = 0.1661099548666327, J_o = 4050.168382050181
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36611903 -0.44621798 -0.3118837  -0.3449548  -0.23210226 -1.69989737
 -0.62405769 -0.29039508 -0.35996337 -0.30612357]
W_opt:  [-0.01004209  0.00186648  0.02138661  0.02357859  0.01920603  0.01103722
 -0.01896219 -0.06717204 -0.14255394 -0.22396863]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.8457 s, v_trunc (Latent to Reduced) = 0.0489, dec (Reduced to Full) = 0.1503, add (DA)= 0.0001decode = 0.2012 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.0470 s, inc stats = 10.6972, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.47919103e-07 3.44936189e-07 1.12045321e-06 7.78062166e-07
 9.33312953e-07]
u_DA:    [ 3.13043960e-03  6.45305504e-03  4.01674301e-03  1.93516537e-03
 -9.83947823e-05]
ref_MAE: [0.00805551 0.00987244 0.0044626  0.00560699 0.00061696]
da_MAE:  [3.13009168e-03 6.45271011e-03 4.01562256e-03 1.93438731e-03
 9.93280952e-05]
% 39.12129306447092 da_MAE 0.1264131299321082 ref_MAE 0.20764752783921722
\% improve_point: 18.23, mse_ref_points: 2.3112836228646893e-05, mse_da_points: 1.882392553580838e-05, % improve_overlap: -10.92, mse_ref_overlap: 0.19989, mse_da_overlap: 0.21879
DA - - L2: 1417.70, L1: 1924.16, % Improve: 35.79%, DA_MAE: 0.11, mse_ref: 0.21, mse_DA: 0.169, time(s): 3.9763s,
u_c taken from control states: [-0.36612028 -0.44621931 -0.31188809 -0.34495527 -0.23213109 -1.70319146
 -0.62405866 -0.29017141 -0.35654493 -0.30612684]
u_c before reduction of space:  [-0.36612028 -0.44621931 -0.31188809 -0.34495527 -0.23213109 -1.70319146
 -0.62405866 -0.29017141 -0.35654493 -0.30612684]
data[u_c] post encoding of state:  [-0.36612028 -0.44621931 -0.31188809 -0.34495527 -0.23213109 -1.70319146
 -0.62405866 -0.29017141 -0.35654493 -0.30612684]
J_b = 0.0, J_o = 149277.3324612698
J_b = 0.4999999999999998, J_o = 4743055.219027776
J_b = 0.008554532536617114, J_o = 42836.91321444515
J_b = 0.009631546554774438, J_o = 34769.84965090401
J_b = 0.02624773445777376, J_o = 14679.337638577254
J_b = 0.03361632434756548, J_o = 11925.27233597246
J_b = 0.049737797342586, J_o = 8696.26610359058
J_b = 0.07096556987504532, J_o = 7073.827521677003
J_b = 0.09069217527725326, J_o = 6039.760597970548
J_b = 0.09198184125124788, J_o = 5602.799624904446
J_b = 0.09787519830055548, J_o = 5172.706846940444
J_b = 0.10823409997498722, J_o = 4871.597053039381
J_b = 0.12720711693684528, J_o = 4501.318132983481
J_b = 0.15582171414268686, J_o = 4240.718470868859
J_b = 0.1648537570666981, J_o = 4127.005829234435
J_b = 0.16893007917347658, J_o = 4196.528373419559
J_b = 0.16603986542354282, J_o = 4108.1603748703565
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36612028 -0.44621931 -0.31188809 -0.34495527 -0.23213109 -1.70319146
 -0.62405866 -0.29017141 -0.35654493 -0.30612684]
W_opt:  [-0.01054388  0.00206703  0.02195204  0.02328058  0.01874818  0.01050754
 -0.0194743  -0.06724608 -0.14201276 -0.22303349]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1789 s, v_trunc (Latent to Reduced) = 0.0481, dec (Reduced to Full) = 0.1787, add (DA)= 0.0001decode = 0.2289 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4078 s, inc stats = 2.4103, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.45845281e-07 3.41570052e-07 1.11676155e-06 7.77554629e-07
 9.27028422e-07]
u_DA:    [ 3.12744337e-03  6.45600952e-03  4.01604203e-03  1.92686952e-03
 -9.86302804e-05]
ref_MAE: [0.00805552 0.00987244 0.00446261 0.005607   0.00061697]
da_MAE:  [3.12709752e-03 6.45566795e-03 4.01492527e-03 1.92609197e-03
 9.95573088e-05]
% 38.98543176886985 da_MAE 0.12682024250478455 ref_MAE 0.207852396864262
u_c taken from control states: [-0.36612228 -0.44622066 -0.31189228 -0.34495656 -0.2321762  -1.70665274
 -0.62405921 -0.290037   -0.35314569 -0.30613268]
u_c before reduction of space:  [-0.36612228 -0.44622066 -0.31189228 -0.34495656 -0.2321762  -1.70665274
 -0.62405921 -0.290037   -0.35314569 -0.30613268]
data[u_c] post encoding of state:  [-0.36612228 -0.44622066 -0.31189228 -0.34495656 -0.2321762  -1.70665274
 -0.62405921 -0.290037   -0.35314569 -0.30613268]
J_b = 0.0, J_o = 149285.42141697626
J_b = 0.5, J_o = 4743138.231699309
J_b = 0.00854523095272375, J_o = 42979.485092658426
J_b = 0.009624256874277178, J_o = 34899.97254829416
J_b = 0.02621627634202724, J_o = 14822.91218516271
J_b = 0.03357782514726768, J_o = 12064.266514046052
J_b = 0.049808872714013616, J_o = 8808.370423109407
J_b = 0.07127438563467085, J_o = 7167.085577830327
J_b = 0.09134982994353799, J_o = 6116.23238678248
J_b = 0.09274232879848553, J_o = 5671.97860989091
J_b = 0.09874226326080204, J_o = 5238.1724770440815
J_b = 0.1092240767114467, J_o = 4933.413382600385
J_b = 0.12848483171400044, J_o = 4558.513518162479
J_b = 0.15725020834344766, J_o = 4302.6230389933025
J_b = 0.16551998271747279, J_o = 4189.81681658549
J_b = 0.16891596451695798, J_o = 4249.106969335402
J_b = 0.16654736034729242, J_o = 4170.852876902016
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36612228 -0.44622066 -0.31189228 -0.34495656 -0.2321762  -1.70665274
 -0.62405921 -0.290037   -0.35314569 -0.30613268]
W_opt:  [-0.01098725  0.00217945  0.0226993   0.02314857  0.01826171  0.0099892
 -0.01997085 -0.06734069 -0.14153325 -0.22210436]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3352 s, v_trunc (Latent to Reduced) = 0.0530, dec (Reduced to Full) = 0.2050, add (DA)= 0.0001decode = 0.2601 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5954 s, inc stats = 2.5979, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.42526695e-07 3.38136982e-07 1.11324124e-06 7.76138802e-07
 9.17197779e-07]
u_DA:    [ 3.12299102e-03  6.46013594e-03  4.01450812e-03  1.91905763e-03
 -9.90601216e-05]
ref_MAE: [0.00805552 0.00987245 0.00446261 0.005607   0.00061698]
da_MAE:  [3.12264849e-03 6.45979780e-03 4.01339488e-03 1.91828149e-03
 9.99773194e-05]
% 38.675123761685725 da_MAE 0.12764737615716484 ref_MAE 0.20814942318206245
u_c taken from control states: [-0.36612496 -0.44622212 -0.31189746 -0.3449595  -0.23223358 -1.71019567
 -0.62406027 -0.28998086 -0.349911   -0.3061409 ]
u_c before reduction of space:  [-0.36612496 -0.44622212 -0.31189746 -0.3449595  -0.23223358 -1.71019567
 -0.62406027 -0.28998086 -0.349911   -0.3061409 ]
data[u_c] post encoding of state:  [-0.36612496 -0.44622212 -0.31189746 -0.3449595  -0.23223358 -1.71019567
 -0.62406027 -0.28998086 -0.349911   -0.3061409 ]
J_b = 0.0, J_o = 149313.54558216973
J_b = 0.5000000000000001, J_o = 4743199.255275369
J_b = 0.00853423367740207, J_o = 43167.84760720904
J_b = 0.009615879352825204, J_o = 35071.88198854804
J_b = 0.026185498669821363, J_o = 15003.949851883212
J_b = 0.033544260850478604, J_o = 12237.493980280979
J_b = 0.04993510621731091, J_o = 8944.032558643237
J_b = 0.07172247681407218, J_o = 7279.993457485565
J_b = 0.0921646700988661, J_o = 6209.861246507418
J_b = 0.09364646663408667, J_o = 5758.147291217646
J_b = 0.0997802000252526, J_o = 5318.944296654727
J_b = 0.11043126694030948, J_o = 5009.609509287219
J_b = 0.129983426055961, J_o = 4630.361117726796
J_b = 0.15880663733770248, J_o = 4378.97734064231
J_b = 0.16643313271360965, J_o = 4267.220273990833
J_b = 0.1692686025760488, J_o = 4318.442551047412
J_b = 0.16731752743224895, J_o = 4248.25035849772
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36612496 -0.44622212 -0.31189746 -0.3449595  -0.23223358 -1.71019567
 -0.62406027 -0.28998086 -0.349911   -0.3061409 ]
W_opt:  [-0.01061185  0.00270286  0.02337636  0.02323779  0.0176342   0.00889437
 -0.02087503 -0.06784635 -0.14135815 -0.22132688]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3798 s, v_trunc (Latent to Reduced) = 0.0548, dec (Reduced to Full) = 0.1752, add (DA)= 0.0001decode = 0.2320 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6119 s, inc stats = 2.6143, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.38057996e-07 3.34443490e-07 1.10888832e-06 7.72921662e-07
 9.04691103e-07]
u_DA:    [ 3.12224790e-03  6.45838029e-03  4.01393357e-03  1.91184474e-03
 -9.98048610e-05]
ref_MAE: [0.00805552 0.00987245 0.00446261 0.005607   0.00061699]
da_MAE:  [0.00312191 0.00645805 0.00401282 0.00191107 0.00010071]
% 38.31587942220352 da_MAE 0.12866221552607598 ref_MAE 0.20858239417356406
u_c taken from control states: [-0.36612827 -0.44622373 -0.31190432 -0.34496455 -0.23230037 -1.71374952
 -0.62406218 -0.2900001  -0.34698094 -0.3061511 ]
u_c before reduction of space:  [-0.36612827 -0.44622373 -0.31190432 -0.34496455 -0.23230037 -1.71374952
 -0.62406218 -0.2900001  -0.34698094 -0.3061511 ]
data[u_c] post encoding of state:  [-0.36612827 -0.44622373 -0.31190432 -0.34496455 -0.23230037 -1.71374952
 -0.62406218 -0.2900001  -0.34698094 -0.3061511 ]
J_b = 0.0, J_o = 149376.85600129588
J_b = 0.5, J_o = 4743164.908931894
J_b = 0.008524654277190161, J_o = 43373.60643651078
J_b = 0.00960910837757262, J_o = 35259.643561145516
J_b = 0.026165245548776236, J_o = 15192.470241501498
J_b = 0.03352338375879309, J_o = 12418.261858848964
J_b = 0.050066196989188586, J_o = 9089.474851673298
J_b = 0.07215133532317317, J_o = 7405.300323044452
J_b = 0.09289506486846778, J_o = 6317.973372962444
J_b = 0.09445930676780803, J_o = 5859.578169883171
J_b = 0.10074997853611149, J_o = 5413.557009554839
J_b = 0.11161739382654605, J_o = 5098.610866719495
J_b = 0.1315114137577482, J_o = 4714.262206830788
J_b = 0.16044661291119347, J_o = 4465.70388759761
J_b = 0.16761596357337058, J_o = 4354.754110073419
J_b = 0.1700321194811318, J_o = 4400.193582362815
J_b = 0.16838562777946364, J_o = 4335.849597669226
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36612827 -0.44622373 -0.31190432 -0.34496455 -0.23230037 -1.71374952
 -0.62406218 -0.2900001  -0.34698094 -0.3061511 ]
W_opt:  [-0.01057103  0.00302058  0.02394995  0.02361187  0.0175481   0.0082254
 -0.02167161 -0.06839571 -0.14145786 -0.22100595]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3114 s, v_trunc (Latent to Reduced) = 0.0517, dec (Reduced to Full) = 0.1885, add (DA)= 0.0001decode = 0.2422 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5537 s, inc stats = 2.5560, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.32559145e-07 3.30365004e-07 1.10311621e-06 7.67398650e-07
 8.90133584e-07]
u_DA:    [ 0.00312439  0.00645741  0.0040141   0.00190744 -0.00010028]
ref_MAE: [0.00805553 0.00987245 0.00446262 0.00560701 0.00061701]
da_MAE:  [0.00312406 0.00645708 0.004013   0.00190668 0.00010117]
% 38.01307666414756 da_MAE 0.1296335929200188 ref_MAE 0.20913054874114134
u_c taken from control states: [-0.36613207 -0.4462255  -0.31191332 -0.34497172 -0.23237091 -1.7172819
 -0.6240646  -0.29007673 -0.34439539 -0.30616265]
u_c before reduction of space:  [-0.36613207 -0.4462255  -0.31191332 -0.34497172 -0.23237091 -1.7172819
 -0.6240646  -0.29007673 -0.34439539 -0.30616265]
data[u_c] post encoding of state:  [-0.36613207 -0.4462255  -0.31191332 -0.34497172 -0.23237091 -1.7172819
 -0.6240646  -0.29007673 -0.34439539 -0.30616265]
J_b = 0.0, J_o = 149442.75283288248
J_b = 0.4999999999999999, J_o = 4743193.446796995
J_b = 0.008515249154905221, J_o = 43577.96302029536
J_b = 0.009602249810374778, J_o = 35447.624159462604
J_b = 0.026151420691557285, J_o = 15376.386231375689
J_b = 0.033512798432538314, J_o = 12594.286686441685
J_b = 0.05019450876189065, J_o = 9233.653346599995
J_b = 0.0725448701566823, J_o = 7532.015438413433
J_b = 0.09353928086881048, J_o = 6430.269888267516
J_b = 0.09516394511541464, J_o = 5966.187101475276
J_b = 0.10160280199958588, J_o = 5513.203329564822
J_b = 0.11268775143041218, J_o = 5192.671897972613
J_b = 0.13292856932717467, J_o = 4803.0400135544405
J_b = 0.16202840915246874, J_o = 4555.468319244388
J_b = 0.1689388028380488, J_o = 4444.855145311434
J_b = 0.17110277769787502, J_o = 4486.737723794766
J_b = 0.16963730350035158, J_o = 4425.959643056925
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36613207 -0.4462255  -0.31191332 -0.34497172 -0.23237091 -1.7172819
 -0.6240646  -0.29007673 -0.34439539 -0.30616265]
W_opt:  [-0.01036433  0.00337334  0.02421957  0.02381607  0.01753013  0.00788926
 -0.0221179  -0.0688552  -0.14164796 -0.22087926]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1610 s, v_trunc (Latent to Reduced) = 0.0469, dec (Reduced to Full) = 0.3073, add (DA)= 0.0001decode = 0.3563 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5174 s, inc stats = 2.5198, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.26259315e-07 3.25870825e-07 1.09555712e-06 7.59555715e-07
 8.74759351e-07]
u_DA:    [ 0.00312896  0.0064517   0.00401446  0.00190373 -0.00010091]
ref_MAE: [0.00805554 0.00987246 0.00446263 0.00560701 0.00061702]
da_MAE:  [0.00312863 0.00645137 0.00401336 0.00190297 0.00010179]
% 37.79139947060982 da_MAE 0.13045353207798702 ref_MAE 0.2097033705433621
u_c taken from control states: [-0.36613615 -0.44622744 -0.31192495 -0.34498091 -0.23244003 -1.7207317
 -0.62406787 -0.29018744 -0.34216644 -0.30617479]
u_c before reduction of space:  [-0.36613615 -0.44622744 -0.31192495 -0.34498091 -0.23244003 -1.7207317
 -0.62406787 -0.29018744 -0.34216644 -0.30617479]
data[u_c] post encoding of state:  [-0.36613615 -0.44622744 -0.31192495 -0.34498091 -0.23244003 -1.7207317
 -0.62406787 -0.29018744 -0.34216644 -0.30617479]
J_b = 0.0, J_o = 149486.47610547926
J_b = 0.4999999999999999, J_o = 4743307.829613264
J_b = 0.008507705274569653, J_o = 43730.39663211567
J_b = 0.009596383996958485, J_o = 35589.19809748787
J_b = 0.02614795161624303, J_o = 15508.9091836818
J_b = 0.03351678597988272, J_o = 12720.28494528965
J_b = 0.05029414971965028, J_o = 9338.403466111648
J_b = 0.0728187398472802, J_o = 7625.952050885385
J_b = 0.09395265123935932, J_o = 6515.7954655028525
J_b = 0.0956038371106941, J_o = 6048.249907164836
J_b = 0.1021560974431261, J_o = 5589.401837013313
J_b = 0.11341942021030714, J_o = 5264.401814932261
J_b = 0.13393389714285797, J_o = 4870.670107183152
J_b = 0.1631443353115124, J_o = 4622.848017465259
J_b = 0.16997444682659563, J_o = 4512.574011676021
J_b = 0.17203861862981842, J_o = 4552.820142151421
J_b = 0.1706450335851259, J_o = 4493.699315590454
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36613615 -0.44622744 -0.31192495 -0.34498091 -0.23244003 -1.7207317
 -0.62406787 -0.29018744 -0.34216644 -0.30617479]
W_opt:  [-0.01034645  0.00380137  0.02445481  0.02387524  0.01738591  0.00762217
 -0.02228722 -0.06903768 -0.14169984 -0.22079398]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3350 s, v_trunc (Latent to Reduced) = 0.0532, dec (Reduced to Full) = 0.1925, add (DA)= 0.0001decode = 0.2478 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5828 s, inc stats = 2.5851, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.19480749e-07 3.20957041e-07 1.08577921e-06 7.49493680e-07
 8.59695687e-07]
u_DA:    [ 0.00313423  0.0064441   0.00401522  0.00190121 -0.00010143]
ref_MAE: [0.00805554 0.00987246 0.00446264 0.00560702 0.00061704]
da_MAE:  [0.00313391 0.00644378 0.00401413 0.00190046 0.00010229]
% 37.685891163643525 da_MAE 0.13097398740214086 ref_MAE 0.21018351998917706
u_c taken from control states: [-0.36614035 -0.44622954 -0.31193937 -0.3449919  -0.23250528 -1.72403246
 -0.62407234 -0.29032373 -0.34032024 -0.3061869 ]
u_c before reduction of space:  [-0.36614035 -0.44622954 -0.31193937 -0.3449919  -0.23250528 -1.72403246
 -0.62407234 -0.29032373 -0.34032024 -0.3061869 ]
data[u_c] post encoding of state:  [-0.36614035 -0.44622954 -0.31193937 -0.3449919  -0.23250528 -1.72403246
 -0.62407234 -0.29032373 -0.34032024 -0.3061869 ]
J_b = 0.0, J_o = 149559.90017974123
J_b = 0.4999999999999999, J_o = 4743304.019803058
J_b = 0.008504630198183946, J_o = 43850.56702956619
J_b = 0.009594561619740361, J_o = 35700.448402743925
J_b = 0.026178058238834994, J_o = 15585.624452019925
J_b = 0.033570520093989496, J_o = 12788.671358883355
J_b = 0.05041166611351063, J_o = 9394.857862423412
J_b = 0.07303273495301402, J_o = 7678.164649686269
J_b = 0.09417014962407042, J_o = 6567.048478833111
J_b = 0.09577462295847365, J_o = 6099.375619957628
J_b = 0.10237404611356578, J_o = 5636.2701719903625
J_b = 0.11375347845116263, J_o = 5308.420779427332
J_b = 0.13442013814502923, J_o = 4912.4789014177
J_b = 0.16362483454284993, J_o = 4662.887630781771
J_b = 0.170598023809519, J_o = 4553.207447843348
J_b = 0.17274786315692048, J_o = 4594.183627056796
J_b = 0.17129499455316183, J_o = 4534.416692769697
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36614035 -0.44622954 -0.31193937 -0.3449919  -0.23250528 -1.72403246
 -0.62407234 -0.29032373 -0.34032024 -0.3061869 ]
W_opt:  [-0.01074417  0.00424783  0.02486123  0.02412674  0.01739501  0.00759478
 -0.02236334 -0.06915933 -0.14177753 -0.22072044]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0961 s, v_trunc (Latent to Reduced) = 0.0484, dec (Reduced to Full) = 0.2813, add (DA)= 0.0001decode = 0.3316 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4279 s, inc stats = 2.4303, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.12488699e-07 3.15653595e-07 1.07366138e-06 7.37474317e-07
 8.45472874e-07]
u_DA:    [ 0.00314131  0.00643709  0.00401693  0.00190086 -0.00010147]
ref_MAE: [0.00805555 0.00987247 0.00446265 0.00560704 0.00061705]
da_MAE:  [0.003141   0.00643678 0.00401586 0.00190012 0.00010231]
% 37.760044104835174 da_MAE 0.13104000924946815 ref_MAE 0.2105400098132912
u_c taken from control states: [-0.3661445  -0.44623174 -0.3119562  -0.34500416 -0.23256191 -1.72714325
 -0.62407802 -0.29047191 -0.3388232  -0.30619843]
u_c before reduction of space:  [-0.3661445  -0.44623174 -0.3119562  -0.34500416 -0.23256191 -1.72714325
 -0.62407802 -0.29047191 -0.3388232  -0.30619843]
data[u_c] post encoding of state:  [-0.3661445  -0.44623174 -0.3119562  -0.34500416 -0.23256191 -1.72714325
 -0.62407802 -0.29047191 -0.3388232  -0.30619843]
J_b = 0.0, J_o = 149662.6979829917
J_b = 0.4999999999999997, J_o = 4743180.0250874655
J_b = 0.008505572210138585, J_o = 43944.80936183408
J_b = 0.009596419690449854, J_o = 35787.308582390135
J_b = 0.02623358150471609, J_o = 15619.42523370232
J_b = 0.033660439784330205, J_o = 12813.396686978424
J_b = 0.050537852653277475, J_o = 9415.107042945765
J_b = 0.07320659179561245, J_o = 7697.815534981315
J_b = 0.09428181990508497, J_o = 6590.536170023496
J_b = 0.09578684392733748, J_o = 6124.579357172257
J_b = 0.10238546378423453, J_o = 5657.943007099138
J_b = 0.11384939240057876, J_o = 5327.98426128515
J_b = 0.1346224381474839, J_o = 4930.417377850065
J_b = 0.1637765454677096, J_o = 4677.637945877583
J_b = 0.17104791869293437, J_o = 4568.681794773594
J_b = 0.1734079989045486, J_o = 4612.220638100446
J_b = 0.1718052580422373, J_o = 4550.053840748914
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3661445  -0.44623174 -0.3119562  -0.34500416 -0.23256191 -1.72714325
 -0.62407802 -0.29047191 -0.3388232  -0.30619843]
W_opt:  [-0.01170889  0.00455747  0.02530759  0.02463951  0.01761433  0.00782585
 -0.02197082 -0.069003   -0.14187467 -0.22077671]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1923 s, v_trunc (Latent to Reduced) = 0.0485, dec (Reduced to Full) = 0.2853, add (DA)= 0.0001decode = 0.3359 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5283 s, inc stats = 2.5307, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [3.05606418e-07 3.10067028e-07 1.05952208e-06 7.24050738e-07
 8.33131112e-07]
u_DA:    [ 0.00314994  0.00642758  0.0040183   0.00190106 -0.00010158]
ref_MAE: [0.00805556 0.00987247 0.00446266 0.00560705 0.00061706]
da_MAE:  [0.00314963 0.00642727 0.00401724 0.00190034 0.00010241]
% 38.06357706483227 da_MAE 0.13054397642303828 ref_MAE 0.21077093289627957
u_c taken from control states: [-0.36614836 -0.44623401 -0.31197491 -0.34501718 -0.2326038  -1.73001749
 -0.6240849  -0.29060804 -0.33760797 -0.30620876]
u_c before reduction of space:  [-0.36614836 -0.44623401 -0.31197491 -0.34501718 -0.2326038  -1.73001749
 -0.6240849  -0.29060804 -0.33760797 -0.30620876]
data[u_c] post encoding of state:  [-0.36614836 -0.44623401 -0.31197491 -0.34501718 -0.2326038  -1.73001749
 -0.6240849  -0.29060804 -0.33760797 -0.30620876]
J_b = 0.0, J_o = 149725.64563890823
J_b = 0.5, J_o = 4743116.79892535
J_b = 0.008508405557049487, J_o = 43969.22955791174
J_b = 0.00959937552728838, J_o = 35809.14395373914
J_b = 0.026308261412518585, J_o = 15575.469025843648
J_b = 0.03377647478774202, J_o = 12761.941498784325
J_b = 0.050633235052456795, J_o = 9372.6052284356
J_b = 0.07326072353419337, J_o = 7659.74973426749
J_b = 0.09421886682146186, J_o = 6562.378367533601
J_b = 0.09557033039874081, J_o = 6100.034692965738
J_b = 0.10208431250117114, J_o = 5632.3214246192365
J_b = 0.11353838619416734, J_o = 5302.723611276675
J_b = 0.134243243264478, J_o = 4906.280682168545
J_b = 0.16314623285618218, J_o = 4649.433170289305
J_b = 0.17093326569928802, J_o = 4541.29122079266
J_b = 0.17374632054343894, J_o = 4590.921262441615
J_b = 0.17181300048428724, J_o = 4522.874982114565
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36614836 -0.44623401 -0.31197491 -0.34501718 -0.2326038  -1.73001749
 -0.6240849  -0.29060804 -0.33760797 -0.30620876]
W_opt:  [-0.01194497  0.00499948  0.02527501  0.02461854  0.0172642   0.0076627
 -0.02153075 -0.06880321 -0.1416987  -0.22069162]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2613 s, v_trunc (Latent to Reduced) = 0.0489, dec (Reduced to Full) = 0.2112, add (DA)= 0.0001decode = 0.2621 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5235 s, inc stats = 2.5258, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.99193879e-07 3.04315410e-07 1.04379924e-06 7.09808401e-07
 8.24002090e-07]
u_DA:    [ 0.00315832  0.00641358  0.0040184   0.00189904 -0.00010187]
ref_MAE: [0.00805556 0.00987248 0.00446268 0.00560706 0.00061707]
da_MAE:  [0.00315802 0.00641327 0.00401735 0.00189833 0.00010269]
% 38.56535793880239 da_MAE 0.12955277351875677 ref_MAE 0.2108790239059322
u_c taken from control states: [-0.36615181 -0.44623632 -0.31199507 -0.34503053 -0.23262783 -1.73259733
 -0.62409328 -0.29072781 -0.33668807 -0.30621772]
u_c before reduction of space:  [-0.36615181 -0.44623632 -0.31199507 -0.34503053 -0.23262783 -1.73259733
 -0.62409328 -0.29072781 -0.33668807 -0.30621772]
data[u_c] post encoding of state:  [-0.36615181 -0.44623632 -0.31199507 -0.34503053 -0.23262783 -1.73259733
 -0.62409328 -0.29072781 -0.33668807 -0.30621772]
J_b = 0.0, J_o = 149793.17713527312
J_b = 0.5000000000000001, J_o = 4743094.2676772885
J_b = 0.008510414793161523, J_o = 44009.45233592095
J_b = 0.009601708655413987, J_o = 35844.88427524413
J_b = 0.02640931194790289, J_o = 15520.591637600528
J_b = 0.03393344043136185, J_o = 12697.242952012695
J_b = 0.05075110670132753, J_o = 9322.373986350445
J_b = 0.07328836855509899, J_o = 7617.634703380276
J_b = 0.09405518725491849, J_o = 6535.3033329951
J_b = 0.09519852596989686, J_o = 6078.332489484015
J_b = 0.10158229379662641, J_o = 5609.982160201233
J_b = 0.1129952519462912, J_o = 5281.701851832877
J_b = 0.13353489420227943, J_o = 4887.910285654423
J_b = 0.1621075521650099, J_o = 4625.009886124666
J_b = 0.1707476120967061, J_o = 4517.035959056595
J_b = 0.17435298485759934, J_o = 4578.499538213472
J_b = 0.17181988857715974, J_o = 4498.905437832835
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615181 -0.44623632 -0.31199507 -0.34503053 -0.23262783 -1.73259733
 -0.62409328 -0.29072781 -0.33668807 -0.30621772]
W_opt:  [-0.01151895  0.00510021  0.02492962  0.02436243  0.01681088  0.00769293
 -0.02104729 -0.06863482 -0.14180976 -0.22064234]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0745 s, v_trunc (Latent to Reduced) = 0.0489, dec (Reduced to Full) = 0.1897, add (DA)= 0.0001decode = 0.2412 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3157 s, inc stats = 2.3189, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.93460700e-07 2.98470538e-07 1.02685561e-06 6.95202707e-07
 8.18764553e-07]
u_DA:    [ 0.00316842  0.00640402  0.00401553  0.00189858 -0.00010189]
ref_MAE: [0.00805557 0.00987249 0.0044627  0.00560708 0.00061708]
da_MAE:  [0.00316813 0.00640372 0.0040145  0.00189789 0.00010271]
% 39.247640011808244 da_MAE 0.12818993600113532 ref_MAE 0.21100404334259804
\% improve_point: 19.63, mse_ref_points: 2.445691533744615e-05, mse_da_points: 1.9478294462070083e-05, % improve_overlap: -7.87, mse_ref_overlap: 0.21106, mse_da_overlap: 0.22309
DA - - L2: 1613.36, L1: 2090.44, % Improve: 36.15%, DA_MAE: 0.11, mse_ref: 0.22, mse_DA: 0.174, time(s): 3.7701s,
u_c taken from control states: [-0.36615472 -0.4462386  -0.31201561 -0.34504351 -0.23263502 -1.7349029
 -0.62410216 -0.29083318 -0.33604093 -0.30622491]
u_c before reduction of space:  [-0.36615472 -0.4462386  -0.31201561 -0.34504351 -0.23263502 -1.7349029
 -0.62410216 -0.29083318 -0.33604093 -0.30622491]
data[u_c] post encoding of state:  [-0.36615472 -0.4462386  -0.31201561 -0.34504351 -0.23263502 -1.7349029
 -0.62410216 -0.29083318 -0.33604093 -0.30622491]
J_b = 0.0, J_o = 149876.69568424337
J_b = 0.5000000000000001, J_o = 4743351.06892353
J_b = 0.00850775345834992, J_o = 44127.89956316345
J_b = 0.009599604320568748, J_o = 35957.22571621247
J_b = 0.026523259557141302, J_o = 15524.76567684517
J_b = 0.034123785206277665, J_o = 12683.882255903753
J_b = 0.05098407472379912, J_o = 9307.477333884312
J_b = 0.07359032616106723, J_o = 7602.364712495904
J_b = 0.0942567543186499, J_o = 6531.141518394417
J_b = 0.0951436241711698, J_o = 6078.363226236466
J_b = 0.10141361478171826, J_o = 5606.292011356835
J_b = 0.11286735466566103, J_o = 5277.017149512899
J_b = 0.13337843443971326, J_o = 4883.511060166195
J_b = 0.16177224336566307, J_o = 4613.22793236253
J_b = 0.1713746197698766, J_o = 4504.405694693715
J_b = 0.17588451624894463, J_o = 4581.110325493493
J_b = 0.17263705734792725, J_o = 4486.5680829715875
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615472 -0.4462386  -0.31201561 -0.34504351 -0.23263502 -1.7349029
 -0.62410216 -0.29083318 -0.33604093 -0.30622491]
W_opt:  [-0.01043049  0.0050056   0.02377804  0.0241438   0.01681705  0.00822361
 -0.02051436 -0.06809247 -0.14151262 -0.22090317]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0324 s, v_trunc (Latent to Reduced) = 0.0466, dec (Reduced to Full) = 0.2024, add (DA)= 0.0001decode = 0.2510 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2835 s, inc stats = 2.2875, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.88614983e-07 2.92668842e-07 1.00958933e-06 6.80998908e-07
 8.17196587e-07]
u_DA:    [ 0.00318219  0.00639439  0.0040123   0.0018988  -0.00010228]
ref_MAE: [0.00805557 0.00987249 0.00446271 0.00560709 0.00061708]
da_MAE:  [0.0031819  0.0063941  0.00401129 0.00189812 0.00010309]
% 40.172997415990736 da_MAE 0.12650427864698652 ref_MAE 0.21145013653216008
u_c taken from control states: [-0.36615694 -0.44624081 -0.31203562 -0.34505537 -0.2326242  -1.73701368
 -0.62411045 -0.2909173  -0.33563978 -0.30622979]
u_c before reduction of space:  [-0.36615694 -0.44624081 -0.31203562 -0.34505537 -0.2326242  -1.73701368
 -0.62411045 -0.2909173  -0.33563978 -0.30622979]
data[u_c] post encoding of state:  [-0.36615694 -0.44624081 -0.31203562 -0.34505537 -0.2326242  -1.73701368
 -0.62411045 -0.2909173  -0.33563978 -0.30622979]
J_b = 0.0, J_o = 150030.82299802115
J_b = 0.4999999999999999, J_o = 4743410.2816678295
J_b = 0.008504632665427584, J_o = 44329.84519778201
J_b = 0.009598220071433463, J_o = 36145.190776346324
J_b = 0.02663756033291953, J_o = 15600.705670544416
J_b = 0.03431223284682836, J_o = 12741.093892992269
J_b = 0.05124508460543003, J_o = 9355.628484385323
J_b = 0.07398599112272575, J_o = 7644.717872078637
J_b = 0.09465495993375142, J_o = 6578.859672027734
J_b = 0.09534840015939987, J_o = 6126.802002755022
J_b = 0.10160208736797012, J_o = 5646.733153272118
J_b = 0.11323311083821073, J_o = 5312.970500947496
J_b = 0.1339844646407977, J_o = 4915.193755118844
J_b = 0.16253838452614247, J_o = 4636.081107614132
J_b = 0.1730710402899055, J_o = 4525.710582470916
J_b = 0.17836350197148765, J_o = 4617.228270649185
J_b = 0.17447430287007581, J_o = 4508.185005103502
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615694 -0.44624081 -0.31203562 -0.34505537 -0.2326242  -1.73701368
 -0.62411045 -0.2909173  -0.33563978 -0.30622979]
W_opt:  [-0.01010492  0.00477281  0.02335212  0.02436443  0.01738909  0.00901925
 -0.02018453 -0.06783173 -0.14164542 -0.22143421]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4361 s, v_trunc (Latent to Reduced) = 0.0527, dec (Reduced to Full) = 0.1667, add (DA)= 0.0001decode = 0.2218 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6579 s, inc stats = 2.6603, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.84932794e-07 2.87080452e-07 9.92777193e-07 6.68016570e-07
 8.19554228e-07]
u_DA:    [ 0.00319306  0.00639017  0.00400816  0.00190236 -0.00010233]
ref_MAE: [0.00805558 0.0098725  0.00446273 0.0056071  0.00061708]
da_MAE:  [0.00319278 0.00638988 0.00400716 0.00190169 0.00010315]
% 41.2098411729385 da_MAE 0.12485036688650994 ref_MAE 0.21236609898226794
u_c taken from control states: [-0.36615835 -0.44624288 -0.31205439 -0.34506561 -0.23259773 -1.73897816
 -0.624118   -0.29098415 -0.33552923 -0.30623211]
u_c before reduction of space:  [-0.36615835 -0.44624288 -0.31205439 -0.34506561 -0.23259773 -1.73897816
 -0.624118   -0.29098415 -0.33552923 -0.30623211]
data[u_c] post encoding of state:  [-0.36615835 -0.44624288 -0.31205439 -0.34506561 -0.23259773 -1.73897816
 -0.624118   -0.29098415 -0.33552923 -0.30623211]
J_b = 0.0, J_o = 150078.9439672055
J_b = 0.49999999999999994, J_o = 4743665.221122414
J_b = 0.008495379985768398, J_o = 44508.4813588388
J_b = 0.009590939498521668, J_o = 36309.30984830434
J_b = 0.026713203001583582, J_o = 15683.442879876877
J_b = 0.03443499937724204, J_o = 12813.084218579745
J_b = 0.05137228672981796, J_o = 9429.5794923954
J_b = 0.07413828256480028, J_o = 7714.719366605203
J_b = 0.09489667154881841, J_o = 6651.936481574319
J_b = 0.09551356257025344, J_o = 6197.0240919201515
J_b = 0.10181256649866503, J_o = 5708.509450893054
J_b = 0.11364953308710524, J_o = 5369.336288582245
J_b = 0.13482476335849725, J_o = 4963.790966413681
J_b = 0.16383343926692712, J_o = 4675.90196870414
J_b = 0.17504797725957202, J_o = 4563.925756005146
J_b = 0.18079736694447007, J_o = 4665.2898878203105
J_b = 0.17652177596476679, J_o = 4546.638623850905
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615835 -0.44624288 -0.31205439 -0.34506561 -0.23259773 -1.73897816
 -0.624118   -0.29098415 -0.33552923 -0.30623211]
W_opt:  [-0.01113911  0.00394955  0.02313529  0.0249356   0.01832264  0.00974064
 -0.02028271 -0.06790407 -0.14173826 -0.22168621]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.1249 s, v_trunc (Latent to Reduced) = 0.0542, dec (Reduced to Full) = 0.1909, add (DA)= 0.0001decode = 0.2472 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.3722 s, inc stats = 3.3748, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.82583220e-07 2.81824679e-07 9.77002400e-07 6.56811630e-07
 8.25325312e-07]
u_DA:    [ 0.00319991  0.00639123  0.00400301  0.00190862 -0.00010116]
ref_MAE: [0.00805558 0.0098725  0.00446275 0.00560712 0.00061707]
da_MAE:  [0.00319963 0.00639094 0.00400203 0.00190797 0.00010199]
% 42.13989037888945 da_MAE 0.12354754532321656 ref_MAE 0.21352801806331112
u_c taken from control states: [-0.36615895 -0.44624477 -0.31207103 -0.34507374 -0.23255945 -1.74087196
 -0.62412431 -0.29104573 -0.3357875  -0.30623166]
u_c before reduction of space:  [-0.36615895 -0.44624477 -0.31207103 -0.34507374 -0.23255945 -1.74087196
 -0.62412431 -0.29104573 -0.3357875  -0.30623166]
data[u_c] post encoding of state:  [-0.36615895 -0.44624477 -0.31207103 -0.34507374 -0.23255945 -1.74087196
 -0.62412431 -0.29104573 -0.3357875  -0.30623166]
J_b = 0.0, J_o = 150128.85155371038
J_b = 0.5000000000000001, J_o = 4743839.594014477
J_b = 0.008485526448026953, J_o = 44699.54636620667
J_b = 0.009583477485144976, J_o = 36483.33914057609
J_b = 0.02677735293306561, J_o = 15784.477569901472
J_b = 0.03454069442922753, J_o = 12903.205666122642
J_b = 0.05150360690222961, J_o = 9516.486717285241
J_b = 0.0743152439779043, J_o = 7796.883781596613
J_b = 0.09515885800626568, J_o = 6734.884264217394
J_b = 0.09573009080724924, J_o = 6277.025810759788
J_b = 0.1020929799239381, J_o = 5780.820268312567
J_b = 0.11411909749559042, J_o = 5436.809127912921
J_b = 0.13568198490313627, J_o = 5024.126638224683
J_b = 0.1651748195779444, J_o = 4728.184493717295
J_b = 0.1769973166802318, J_o = 4614.546450896597
J_b = 0.1831091682690416, J_o = 4723.744073205944
J_b = 0.17852595812963387, J_o = 4597.405109746161
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615895 -0.44624477 -0.31207103 -0.34507374 -0.23255945 -1.74087196
 -0.62412431 -0.29104573 -0.3357875  -0.30623166]
W_opt:  [-0.0120274   0.00330434  0.02296511  0.02538927  0.01891212  0.01001341
 -0.02011853 -0.06751138 -0.14159892 -0.22196468]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2318 s, v_trunc (Latent to Reduced) = 0.0514, dec (Reduced to Full) = 0.1679, add (DA)= 0.0001decode = 0.2214 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4533 s, inc stats = 2.4557, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.81588894e-07 2.77051033e-07 9.63019607e-07 6.47919373e-07
 8.33667926e-07]
u_DA:    [ 3.20585390e-03  6.39499849e-03  3.99939725e-03  1.91571743e-03
 -9.95893168e-05]
ref_MAE: [0.00805558 0.00987251 0.00446276 0.00560713 0.00061706]
da_MAE:  [0.00320557 0.00639472 0.00399843 0.00191507 0.00010042]
% 43.003173586663635 da_MAE 0.12253415810345963 ref_MAE 0.2149841768642553
u_c taken from control states: [-0.36615875 -0.44624641 -0.31208486 -0.34507935 -0.2325142  -1.74278242
 -0.62412904 -0.29111105 -0.33647662 -0.3062285 ]
u_c before reduction of space:  [-0.36615875 -0.44624641 -0.31208486 -0.34507935 -0.2325142  -1.74278242
 -0.62412904 -0.29111105 -0.33647662 -0.3062285 ]
data[u_c] post encoding of state:  [-0.36615875 -0.44624641 -0.31208486 -0.34507935 -0.2325142  -1.74278242
 -0.62412904 -0.29111105 -0.33647662 -0.3062285 ]
J_b = 0.0, J_o = 150232.8041026271
J_b = 0.5, J_o = 4743619.970930229
J_b = 0.008482084835516721, J_o = 44861.21287364244
J_b = 0.009582549324715438, J_o = 36626.78179466975
J_b = 0.026847600439544712, J_o = 15854.9700625771
J_b = 0.03464699861510729, J_o = 12964.958648103922
J_b = 0.051614079738544726, J_o = 9579.372241218574
J_b = 0.07443169838934172, J_o = 7857.244769847676
J_b = 0.09533213317560713, J_o = 6796.993301456006
J_b = 0.09585888561560675, J_o = 6337.760950269044
J_b = 0.102203091736981, J_o = 5839.273369320344
J_b = 0.11427003382959358, J_o = 5493.835760467959
J_b = 0.1359854156218917, J_o = 5077.505813341046
J_b = 0.1658390899613271, J_o = 4775.476977023524
J_b = 0.178173327813229, J_o = 4659.907231656604
J_b = 0.18464031688213445, J_o = 4776.205076242546
J_b = 0.1797610158884282, J_o = 4642.72743863688
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615875 -0.44624641 -0.31208486 -0.34507935 -0.2325142  -1.74278242
 -0.62412904 -0.29111105 -0.33647662 -0.3062285 ]
W_opt:  [-0.01274009  0.00331344  0.02270833  0.02554402  0.01930582  0.0101862
 -0.01988136 -0.0672617  -0.14164511 -0.22228148]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4295 s, v_trunc (Latent to Reduced) = 0.0482, dec (Reduced to Full) = 0.2029, add (DA)= 0.0001decode = 0.2534 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6829 s, inc stats = 2.6853, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.81924875e-07 2.72899079e-07 9.51391127e-07 6.41775436e-07
 8.43529894e-07]
u_DA:    [ 3.20701769e-03  6.40193135e-03  3.99642991e-03  1.91918886e-03
 -9.81724828e-05]
ref_MAE: [0.00805558 0.00987251 0.00446277 0.00560713 0.00061705]
da_MAE:  [3.20673577e-03 6.40165845e-03 3.99547852e-03 1.91854708e-03
 9.90160127e-05]
% 43.67273135535048 da_MAE 0.12188614674104889 ref_MAE 0.2163892368188294
u_c taken from control states: [-0.36615783 -0.44624776 -0.31209553 -0.34508236 -0.23246858 -1.74474903
 -0.62413262 -0.29118576 -0.3376564  -0.3062231 ]
u_c before reduction of space:  [-0.36615783 -0.44624776 -0.31209553 -0.34508236 -0.23246858 -1.74474903
 -0.62413262 -0.29118576 -0.3376564  -0.3062231 ]
data[u_c] post encoding of state:  [-0.36615783 -0.44624776 -0.31209553 -0.34508236 -0.23246858 -1.74474903
 -0.62413262 -0.29118576 -0.3376564  -0.3062231 ]
J_b = 0.0, J_o = 150299.32655852335
J_b = 0.5000000000000001, J_o = 4743515.3896929715
J_b = 0.008479556854044251, J_o = 44968.59342423103
J_b = 0.009581561958107714, J_o = 36723.01612978084
J_b = 0.026890042766160988, J_o = 15907.125780132812
J_b = 0.03470901035015797, J_o = 13013.25779143411
J_b = 0.05165349423146204, J_o = 9633.475002429243
J_b = 0.07442573335279143, J_o = 7912.158606335025
J_b = 0.09533936847764651, J_o = 6855.042661694182
J_b = 0.09582781215659841, J_o = 6396.071750796309
J_b = 0.10209318774033117, J_o = 5899.72526986428
J_b = 0.11408661135892748, J_o = 5555.513389469352
J_b = 0.1357782922360452, J_o = 5138.263529832904
J_b = 0.16589088743161315, J_o = 4832.028018085874
J_b = 0.17863159534675463, J_o = 4714.352741066309
J_b = 0.18544400748786183, J_o = 4836.682301684731
J_b = 0.1802839513264775, J_o = 4696.964448284401
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615783 -0.44624776 -0.31209553 -0.34508236 -0.23246858 -1.74474903
 -0.62413262 -0.29118576 -0.3376564  -0.3062231 ]
W_opt:  [-0.0130775   0.00329317  0.02260891  0.02555749  0.01952134  0.01029823
 -0.01975562 -0.06702927 -0.1416313  -0.22274113]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.2232 s, v_trunc (Latent to Reduced) = 0.0486, dec (Reduced to Full) = 0.1410, add (DA)= 0.0001decode = 0.1917 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.4149 s, inc stats = 3.4188, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.83448918e-07 2.69469519e-07 9.42428597e-07 6.38478702e-07
 8.53473400e-07]
u_DA:    [ 3.20562574e-03  6.41279302e-03  3.99346368e-03  1.91966081e-03
 -9.64456352e-05]
ref_MAE: [0.00805558 0.00987252 0.00446278 0.00560713 0.00061704]
da_MAE:  [3.20534229e-03 6.41252355e-03 3.99252125e-03 1.91902233e-03
 9.72991086e-05]
% 44.233676929272995 da_MAE 0.12139402069562559 ref_MAE 0.21768338669498552
u_c taken from control states: [-0.36615639 -0.44624882 -0.31210293 -0.345083   -0.23243082 -1.74674771
 -0.62413613 -0.29127855 -0.33941807 -0.30621636]
u_c before reduction of space:  [-0.36615639 -0.44624882 -0.31210293 -0.345083   -0.23243082 -1.74674771
 -0.62413613 -0.29127855 -0.33941807 -0.30621636]
data[u_c] post encoding of state:  [-0.36615639 -0.44624882 -0.31210293 -0.345083   -0.23243082 -1.74674771
 -0.62413613 -0.29127855 -0.33941807 -0.30621636]
J_b = 0.0, J_o = 150334.9763777188
J_b = 0.4999999999999999, J_o = 4743551.156181277
J_b = 0.008475880064335839, J_o = 45057.95184455668
J_b = 0.009578950337047445, J_o = 36804.906104180554
J_b = 0.02691078049526564, J_o = 15965.309402148545
J_b = 0.03473625800441332, J_o = 13071.165458476707
J_b = 0.05164376456019902, J_o = 9699.269229646572
J_b = 0.07434975762108499, J_o = 7979.921572227815
J_b = 0.09526884394714223, J_o = 6925.332175305948
J_b = 0.09574569559073196, J_o = 6466.675260351304
J_b = 0.10193941736890981, J_o = 5973.3810155847805
J_b = 0.11384301221982357, J_o = 5630.833099278684
J_b = 0.13549740011415937, J_o = 5212.864343331158
J_b = 0.16589533826055627, J_o = 4902.893667632262
J_b = 0.17897494424610527, J_o = 4783.095608707025
J_b = 0.1860721303215486, J_o = 4909.94499425387
J_b = 0.18068493527006854, J_o = 4765.4425050480195
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615639 -0.44624882 -0.31210293 -0.345083   -0.23243082 -1.74674771
 -0.62413613 -0.29127855 -0.33941807 -0.30621636]
W_opt:  [-0.01297179  0.00292523  0.02254159  0.02551882  0.01967858  0.01051086
 -0.01968813 -0.06690874 -0.14155082 -0.22312741]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0481 s, v_trunc (Latent to Reduced) = 0.0478, dec (Reduced to Full) = 0.1547, add (DA)= 0.0001decode = 0.2046 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2528 s, inc stats = 2.2552, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.85848396e-07 2.66778790e-07 9.36205552e-07 6.37782027e-07
 8.61702865e-07]
u_DA:    [ 3.20604602e-03  6.42463691e-03  3.99132366e-03  1.91808685e-03
 -9.46941569e-05]
ref_MAE: [0.00805558 0.00987252 0.00446279 0.00560714 0.00061703]
da_MAE:  [3.20576017e-03 6.42437013e-03 3.99038746e-03 1.91744907e-03
 9.55558598e-05]
% 44.65834441878666 da_MAE 0.1212449628335704 ref_MAE 0.21908445195616638
u_c taken from control states: [-0.36615472 -0.44624961 -0.31210702 -0.34508152 -0.23240746 -1.74878872
 -0.62413945 -0.2914009  -0.34172931 -0.30620939]
u_c before reduction of space:  [-0.36615472 -0.44624961 -0.31210702 -0.34508152 -0.23240746 -1.74878872
 -0.62413945 -0.2914009  -0.34172931 -0.30620939]
data[u_c] post encoding of state:  [-0.36615472 -0.44624961 -0.31210702 -0.34508152 -0.23240746 -1.74878872
 -0.62413945 -0.2914009  -0.34172931 -0.30620939]
J_b = 0.0, J_o = 150362.70997378667
J_b = 0.49999999999999994, J_o = 4743721.5146774575
J_b = 0.008471165099493472, J_o = 45151.28629465298
J_b = 0.009574925281437555, J_o = 36893.69743541529
J_b = 0.026914086530454472, J_o = 16046.294128096473
J_b = 0.03473760034090893, J_o = 13153.771533846368
J_b = 0.051607715024744955, J_o = 9789.13289352203
J_b = 0.07425043050527468, J_o = 8071.607021991496
J_b = 0.09518011765399327, J_o = 7018.678465774593
J_b = 0.09565726914997295, J_o = 6560.3231785997095
J_b = 0.10178313767103135, J_o = 6070.479460541282
J_b = 0.11359458616336604, J_o = 5729.55139717435
J_b = 0.13523250985764382, J_o = 5310.4172957916235
J_b = 0.16597977342169787, J_o = 4996.7899111835795
J_b = 0.17934450305515676, J_o = 4874.783982996468
J_b = 0.18666617501304958, J_o = 5004.643456627552
J_b = 0.18110589936066165, J_o = 4856.806977183669
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615472 -0.44624961 -0.31210702 -0.34508152 -0.23240746 -1.74878872
 -0.62413945 -0.2914009  -0.34172931 -0.30620939]
W_opt:  [-0.0130436   0.0024102   0.0225654   0.02563775  0.0200521   0.01098278
 -0.01936752 -0.06660946 -0.14152782 -0.22370678]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0007 s, v_trunc (Latent to Reduced) = 0.0463, dec (Reduced to Full) = 0.2159, add (DA)= 0.0001decode = 0.2643 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2651 s, inc stats = 2.2692, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.88615782e-07 2.64769906e-07 9.32767398e-07 6.39404828e-07
 8.66793686e-07]
u_DA:    [ 3.20631419e-03  6.43978120e-03  3.98972884e-03  1.91630261e-03
 -9.28316328e-05]
ref_MAE: [0.00805557 0.00987252 0.00446279 0.00560713 0.00061703]
da_MAE:  [3.20602557e-03 6.43951643e-03 3.98879607e-03 1.91566320e-03
 9.36984265e-05]
% 44.925833973320906 da_MAE 0.12144777926738076 ref_MAE 0.220516783147563
u_c taken from control states: [-0.36615305 -0.44625017 -0.31210808 -0.34507828 -0.23239867 -1.75091313
 -0.6241421  -0.29154488 -0.34448131 -0.30620287]
u_c before reduction of space:  [-0.36615305 -0.44625017 -0.31210808 -0.34507828 -0.23239867 -1.75091313
 -0.6241421  -0.29154488 -0.34448131 -0.30620287]
data[u_c] post encoding of state:  [-0.36615305 -0.44625017 -0.31210808 -0.34507828 -0.23239867 -1.75091313
 -0.6241421  -0.29154488 -0.34448131 -0.30620287]
J_b = 0.0, J_o = 150386.74950778962
J_b = 0.49999999999999994, J_o = 4743893.724376588
J_b = 0.008467350536282395, J_o = 45227.64398050995
J_b = 0.009571449493235774, J_o = 36968.253695862986
J_b = 0.02689791105213672, J_o = 16132.230623995045
J_b = 0.034708305812432776, J_o = 13243.77729704116
J_b = 0.05153950733161549, J_o = 9885.503585071465
J_b = 0.07413034532377165, J_o = 8168.158982165589
J_b = 0.0951215464399422, J_o = 7114.595335838832
J_b = 0.09562190477796191, J_o = 6655.825964330384
J_b = 0.10167342672457977, J_o = 6170.839887284921
J_b = 0.11335679819178772, J_o = 5832.371382375487
J_b = 0.134936360094977, J_o = 5412.735453018569
J_b = 0.1660074948222822, J_o = 5096.66333152547
J_b = 0.17953149855384862, J_o = 4972.347438917099
J_b = 0.1870266814793921, J_o = 5103.83934848325
J_b = 0.18134169129156075, J_o = 4953.916154845105
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615305 -0.44625017 -0.31210808 -0.34507828 -0.23239867 -1.75091313
 -0.6241421  -0.29154488 -0.34448131 -0.30620287]
W_opt:  [-0.01290079  0.00198901  0.0226692   0.02582389  0.02034194  0.01118645
 -0.01910615 -0.06638083 -0.14170595 -0.22446802]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3059 s, v_trunc (Latent to Reduced) = 0.0573, dec (Reduced to Full) = 0.1988, add (DA)= 0.0001decode = 0.2582 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5642 s, inc stats = 2.5682, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.91397967e-07 2.63358344e-07 9.31876737e-07 6.42951224e-07
 8.68709136e-07]
u_DA:    [ 3.20623972e-03  6.45248675e-03  3.98576368e-03  1.91326061e-03
 -9.14650994e-05]
ref_MAE: [0.00805557 0.00987252 0.00446279 0.00560713 0.00061703]
da_MAE:  [3.20594832e-03 6.45222339e-03 3.98483180e-03 1.91261765e-03
 9.23338085e-05]
% 45.05191512056391 da_MAE 0.12187432936528073 ref_MAE 0.22179904837937542
u_c taken from control states: [-0.36615161 -0.44625058 -0.31210691 -0.34507407 -0.23240643 -1.75308891
 -0.62414495 -0.29170903 -0.34764835 -0.30619763]
u_c before reduction of space:  [-0.36615161 -0.44625058 -0.31210691 -0.34507407 -0.23240643 -1.75308891
 -0.62414495 -0.29170903 -0.34764835 -0.30619763]
data[u_c] post encoding of state:  [-0.36615161 -0.44625058 -0.31210691 -0.34507407 -0.23240643 -1.75308891
 -0.62414495 -0.29170903 -0.34764835 -0.30619763]
J_b = 0.0, J_o = 150402.99534246651
J_b = 0.5, J_o = 4744093.004815783
J_b = 0.008462815201149509, J_o = 45305.932137133466
J_b = 0.009567213233866213, J_o = 37045.437472532576
J_b = 0.02686302645205436, J_o = 16237.169797006534
J_b = 0.034649675542217505, J_o = 13354.819499600857
J_b = 0.05144322329659358, J_o = 10001.529728827174
J_b = 0.07398373824291773, J_o = 8283.960089439193
J_b = 0.09505139082409655, J_o = 7227.799550515763
J_b = 0.09561215058649589, J_o = 6767.804293286304
J_b = 0.10163176668174718, J_o = 6286.644748623376
J_b = 0.1132264837487271, J_o = 5949.735949640315
J_b = 0.1348309827879105, J_o = 5528.377440663859
J_b = 0.16631170205198545, J_o = 5210.264636545099
J_b = 0.179854624912146, J_o = 5083.928225951451
J_b = 0.18736307103209607, J_o = 5213.902373569113
J_b = 0.1816897558552679, J_o = 5065.022167670382
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615161 -0.44625058 -0.31210691 -0.34507407 -0.23240643 -1.75308891
 -0.62414495 -0.29170903 -0.34764835 -0.30619763]
W_opt:  [-0.01288936  0.00133001  0.02300223  0.02633538  0.02057228  0.01109567
 -0.01892293 -0.06604889 -0.14170608 -0.22483609]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0414 s, v_trunc (Latent to Reduced) = 0.0479, dec (Reduced to Full) = 0.2674, add (DA)= 0.0001decode = 0.3173 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3588 s, inc stats = 2.3612, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.93786837e-07 2.62330112e-07 9.32861536e-07 6.47553591e-07
 8.67018783e-07]
u_DA:    [ 3.20687271e-03  6.46274750e-03  3.98125512e-03  1.91045028e-03
 -9.04698444e-05]
ref_MAE: [0.00805557 0.00987252 0.00446279 0.00560713 0.00061703]
da_MAE:  [3.20657893e-03 6.46248517e-03 3.98032226e-03 1.90980272e-03
 9.13368632e-05]
% 45.0676294383232 da_MAE 0.12252588611530076 ref_MAE 0.22304860478892224
\% improve_point: 21.43, mse_ref_points: 2.558745586083833e-05, mse_da_points: 1.98004871781788e-05, % improve_overlap: -3.47, mse_ref_overlap: 0.22038, mse_da_overlap: 0.22105
DA - - L2: 1780.90, L1: 2220.94, % Improve: 37.05%, DA_MAE: 0.11, mse_ref: 0.23, mse_DA: 0.177, time(s): 3.6303s,
u_c taken from control states: [-0.36615067 -0.4462509  -0.31210409 -0.34506962 -0.23243174 -1.75527803
 -0.62414843 -0.29189104 -0.35109674 -0.30619434]
u_c before reduction of space:  [-0.36615067 -0.4462509  -0.31210409 -0.34506962 -0.23243174 -1.75527803
 -0.62414843 -0.29189104 -0.35109674 -0.30619434]
data[u_c] post encoding of state:  [-0.36615067 -0.4462509  -0.31210409 -0.34506962 -0.23243174 -1.75527803
 -0.62414843 -0.29189104 -0.35109674 -0.30619434]
J_b = 0.0, J_o = 150433.21086689702
J_b = 0.5000000000000001, J_o = 4744232.660786053
J_b = 0.008456980320840772, J_o = 45418.842050859545
J_b = 0.009562326499684179, J_o = 37152.84509697784
J_b = 0.026833452566145187, J_o = 16364.333396965081
J_b = 0.03460088627891864, J_o = 13485.604090413528
J_b = 0.051386986796839104, J_o = 10130.819396117247
J_b = 0.07393679583545262, J_o = 8409.177073933759
J_b = 0.095134793311914, J_o = 7347.430447170207
J_b = 0.09576611894219933, J_o = 6884.902619916682
J_b = 0.10179170670524665, J_o = 6405.4920805258
J_b = 0.11335819654383547, J_o = 6068.607752348981
J_b = 0.1350980697562013, J_o = 5643.762282613721
J_b = 0.16708516777874372, J_o = 5323.259424966186
J_b = 0.18059127436985858, J_o = 5194.975266124858
J_b = 0.1880283679744216, J_o = 5321.8390138898085
J_b = 0.18243853841468213, J_o = 5175.569980738884
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615067 -0.4462509  -0.31210409 -0.34506962 -0.23243174 -1.75527803
 -0.62414843 -0.29189104 -0.35109674 -0.30619434]
W_opt:  [-0.01286592  0.00067566  0.02315512  0.02678446  0.02093121  0.01118524
 -0.01859977 -0.06567072 -0.14164309 -0.22514202]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.4500 s, v_trunc (Latent to Reduced) = 0.0488, dec (Reduced to Full) = 0.2177, add (DA)= 0.0001decode = 0.2689 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.7190 s, inc stats = 2.7213, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.95356878e-07 2.61495990e-07 9.35230414e-07 6.52423661e-07
 8.61503063e-07]
u_DA:    [ 3.20597036e-03  6.47178707e-03  3.97768719e-03  1.90698589e-03
 -8.98354233e-05]
ref_MAE: [0.00805557 0.00987252 0.00446279 0.00560712 0.00061703]
da_MAE:  [3.20567500e-03 6.47152557e-03 3.97675196e-03 1.90633347e-03
 9.06969264e-05]
% 44.98142815069228 da_MAE 0.1234454979228956 ref_MAE 0.22437059664326578
u_c taken from control states: [-0.36615032 -0.44625122 -0.31210039 -0.34506559 -0.23247176 -1.7574205
 -0.62415295 -0.29206612 -0.35459547 -0.30619325]
u_c before reduction of space:  [-0.36615032 -0.44625122 -0.31210039 -0.34506559 -0.23247176 -1.7574205
 -0.62415295 -0.29206612 -0.35459547 -0.30619325]
data[u_c] post encoding of state:  [-0.36615032 -0.44625122 -0.31210039 -0.34506559 -0.23247176 -1.7574205
 -0.62415295 -0.29206612 -0.35459547 -0.30619325]
J_b = 0.0, J_o = 150445.88164005446
J_b = 0.5000000000000002, J_o = 4744561.529424527
J_b = 0.008447693329329226, J_o = 45559.86467548979
J_b = 0.009554030208013101, J_o = 37288.372000931915
J_b = 0.0267974436765877, J_o = 16521.943254275004
J_b = 0.03454793183306698, J_o = 13645.114009021949
J_b = 0.05135360419201325, J_o = 10282.882533146168
J_b = 0.07396943209683969, J_o = 8553.510226716313
J_b = 0.0953551921367103, J_o = 7483.68662398776
J_b = 0.09606234007793127, J_o = 7017.052715901087
J_b = 0.1021435793086311, J_o = 6536.373198400074
J_b = 0.11376170309247283, J_o = 6197.743648048197
J_b = 0.1357427423277536, J_o = 5768.046662934629
J_b = 0.16821419796908055, J_o = 5445.097198138021
J_b = 0.18166306613301228, J_o = 5315.4213167862235
J_b = 0.1889851659018558, J_o = 5438.676760558797
J_b = 0.18351047904408793, J_o = 5295.622453992938
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615032 -0.44625122 -0.31210039 -0.34506559 -0.23247176 -1.7574205
 -0.62415295 -0.29206612 -0.35459547 -0.30619325]
W_opt:  [-0.01297544  0.00049994  0.02351215  0.02709685  0.0212552   0.01117205
 -0.01875829 -0.06586581 -0.14187327 -0.22545671]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3236 s, v_trunc (Latent to Reduced) = 0.0524, dec (Reduced to Full) = 0.3970, add (DA)= 0.0001decode = 0.4517 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.7754 s, inc stats = 2.7778, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.95936352e-07 2.60685600e-07 9.38340988e-07 6.56829669e-07
 8.52780408e-07]
u_DA:    [ 3.20530964e-03  6.47689781e-03  3.97559505e-03  1.90515182e-03
 -8.95159004e-05]
ref_MAE: [0.00805557 0.00987252 0.00446278 0.00560712 0.00061704]
da_MAE:  [3.20501370e-03 6.47663712e-03 3.97465671e-03 1.90449499e-03
 9.03686808e-05]
% 44.888453205689046 da_MAE 0.12444401364596479 ref_MAE 0.22580388482003352
u_c taken from control states: [-0.36615065 -0.44625163 -0.31209711 -0.34506274 -0.23252409 -1.75943238
 -0.62415882 -0.29222439 -0.35796177 -0.30619452]
u_c before reduction of space:  [-0.36615065 -0.44625163 -0.31209711 -0.34506274 -0.23252409 -1.75943238
 -0.62415882 -0.29222439 -0.35796177 -0.30619452]
data[u_c] post encoding of state:  [-0.36615065 -0.44625163 -0.31209711 -0.34506274 -0.23252409 -1.75943238
 -0.62415882 -0.29222439 -0.35796177 -0.30619452]
J_b = 0.0, J_o = 150443.41642736061
J_b = 0.5000000000000001, J_o = 4745224.310143635
J_b = 0.008435131221002562, J_o = 45725.56586295569
J_b = 0.00954197368269687, J_o = 37451.74584868594
J_b = 0.026771755688211447, J_o = 16696.02269639851
J_b = 0.03452043030415696, J_o = 13817.06601592995
J_b = 0.05137153277246343, J_o = 10443.579924464748
J_b = 0.07409447781834214, J_o = 8705.575460340628
J_b = 0.09564669995447508, J_o = 7629.297018883567
J_b = 0.0963779366561578, J_o = 7159.11677374534
J_b = 0.10251857344201674, J_o = 6675.032306450656
J_b = 0.11423603328945772, J_o = 6333.560378596631
J_b = 0.1365001252750889, J_o = 5898.500957762626
J_b = 0.16941428483249021, J_o = 5571.987835610698
J_b = 0.18296746582869577, J_o = 5441.076401728524
J_b = 0.19028740991224902, J_o = 5563.274195811513
J_b = 0.18482711302019114, J_o = 5421.037638389306
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615065 -0.44625163 -0.31209711 -0.34506274 -0.23252409 -1.75943238
 -0.62415882 -0.29222439 -0.35796177 -0.30619452]
W_opt:  [-0.01301943  0.00053867  0.02389362  0.02717633  0.02136099  0.01125973
 -0.01889295 -0.06596773 -0.14191964 -0.22548611]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1588 s, v_trunc (Latent to Reduced) = 0.0529, dec (Reduced to Full) = 0.2107, add (DA)= 0.0001decode = 0.2656 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4245 s, inc stats = 2.4268, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.95375870e-07 2.59650999e-07 9.41095389e-07 6.59954766e-07
 8.41373209e-07]
u_DA:    [ 3.20595927e-03  6.48125353e-03  3.97500037e-03  1.90536053e-03
 -8.93051888e-05]
ref_MAE: [0.00805557 0.00987253 0.00446278 0.00560711 0.00061705]
da_MAE:  [3.20566389e-03 6.48099388e-03 3.97405927e-03 1.90470058e-03
 9.01465620e-05]
% 44.83587627399518 da_MAE 0.12546480334286436 ref_MAE 0.22743913048639477
u_c taken from control states: [-0.36615165 -0.44625218 -0.31209492 -0.34506133 -0.23258133 -1.76128903
 -0.62416526 -0.29235238 -0.36096683 -0.30619779]
u_c before reduction of space:  [-0.36615165 -0.44625218 -0.31209492 -0.34506133 -0.23258133 -1.76128903
 -0.62416526 -0.29235238 -0.36096683 -0.30619779]
data[u_c] post encoding of state:  [-0.36615165 -0.44625218 -0.31209492 -0.34506133 -0.23258133 -1.76128903
 -0.62416526 -0.29235238 -0.36096683 -0.30619779]
J_b = 0.0, J_o = 150448.8863331559
J_b = 0.5000000000000001, J_o = 4745922.5233497275
J_b = 0.008421279611016054, J_o = 45917.36639689142
J_b = 0.009528921777674126, J_o = 37638.97009872656
J_b = 0.02676196425709126, J_o = 16877.305948413217
J_b = 0.03452135353836359, J_o = 13992.464042659612
J_b = 0.051441850638787985, J_o = 10604.039992978996
J_b = 0.07429325655550789, J_o = 8857.977690098798
J_b = 0.09595419178011873, J_o = 7776.544500412781
J_b = 0.0966883601895257, J_o = 7303.405976974715
J_b = 0.10293044380517277, J_o = 6812.90740640102
J_b = 0.114827567336119, J_o = 6466.884244305246
J_b = 0.13746130443826496, J_o = 6025.379649842131
J_b = 0.17086327998655038, J_o = 5693.6729311174695
J_b = 0.18470550975161854, J_o = 5561.506593763306
J_b = 0.19213827328348856, J_o = 5684.7838882975575
J_b = 0.18659368166510584, J_o = 5541.3421325294075
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615165 -0.44625218 -0.31209492 -0.34506133 -0.23258133 -1.76128903
 -0.62416526 -0.29235238 -0.36096683 -0.30619779]
W_opt:  [-0.01305724  0.00055966  0.02408816  0.02709047  0.02126311  0.0114247
 -0.01875013 -0.06571239 -0.14180696 -0.22545942]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0415 s, v_trunc (Latent to Reduced) = 0.0466, dec (Reduced to Full) = 0.2559, add (DA)= 0.0001decode = 0.3050 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3466 s, inc stats = 2.3498, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.93726130e-07 2.58270652e-07 9.42937367e-07 6.61490944e-07
 8.28899319e-07]
u_DA:    [ 3.21061443e-03  6.48067436e-03  3.97626378e-03  1.90598432e-03
 -8.90195460e-05]
ref_MAE: [0.00805557 0.00987253 0.00446278 0.00560711 0.00061707]
da_MAE:  [3.21032071e-03 6.48041609e-03 3.97532084e-03 1.90532283e-03
 8.98484453e-05]
% 44.881353861539075 da_MAE 0.12631353893173883 ref_MAE 0.2291666210640091
u_c taken from control states: [-0.3661531  -0.44625288 -0.31209417 -0.34506146 -0.23263477 -1.76301633
 -0.62417116 -0.29243391 -0.36341994 -0.3062023 ]
u_c before reduction of space:  [-0.3661531  -0.44625288 -0.31209417 -0.34506146 -0.23263477 -1.76301633
 -0.62417116 -0.29243391 -0.36341994 -0.3062023 ]
data[u_c] post encoding of state:  [-0.3661531  -0.44625288 -0.31209417 -0.34506146 -0.23263477 -1.76301633
 -0.62417116 -0.29243391 -0.36341994 -0.3062023 ]
J_b = 0.0, J_o = 150444.31367371586
J_b = 0.5000000000000001, J_o = 4746604.362037815
J_b = 0.008407828666143466, J_o = 46093.39399219208
J_b = 0.009516232501197043, J_o = 37810.45810464399
J_b = 0.026762009251400067, J_o = 17034.108287856794
J_b = 0.03453979981542555, J_o = 14141.19189666339
J_b = 0.0515474787307873, J_o = 10734.853261137525
J_b = 0.07456250862902859, J_o = 8979.418469715158
J_b = 0.09633085625236987, J_o = 7893.057880924802
J_b = 0.09703906191028107, J_o = 7417.276220697176
J_b = 0.1033777397768967, J_o = 6919.61971450722
J_b = 0.11546844133621444, J_o = 6568.814444547963
J_b = 0.13844736399397428, J_o = 6121.464458377991
J_b = 0.17223694480223675, J_o = 5784.4783689701635
J_b = 0.18645084850343258, J_o = 5651.302363221472
J_b = 0.19407060376226104, J_o = 5777.436062868308
J_b = 0.18837437445174138, J_o = 5631.127664673764
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3661531  -0.44625288 -0.31209417 -0.34506146 -0.23263477 -1.76301633
 -0.62417116 -0.29243391 -0.36341994 -0.3062023 ]
W_opt:  [-0.0129349   0.00063835  0.02421733  0.02692659  0.02119339  0.01178907
 -0.01863074 -0.0656548  -0.1417298  -0.22539602]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0321 s, v_trunc (Latent to Reduced) = 0.0465, dec (Reduced to Full) = 0.1531, add (DA)= 0.0001decode = 0.2017 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2338 s, inc stats = 2.2363, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.91313258e-07 2.56491105e-07 9.43568776e-07 6.61357640e-07
 8.17251331e-07]
u_DA:    [ 3.21834109e-03  6.47440498e-03  3.97855387e-03  1.90666343e-03
 -8.90830453e-05]
ref_MAE: [0.00805557 0.00987253 0.00446278 0.00560711 0.00061708]
da_MAE:  [3.21804977e-03 6.47414849e-03 3.97761030e-03 1.90600207e-03
 8.99002966e-05]
% 45.00282541642638 da_MAE 0.1268847725997384 ref_MAE 0.23071143847021544
u_c taken from control states: [-0.36615473 -0.44625373 -0.31209488 -0.34506292 -0.23267612 -1.76467557
 -0.62417553 -0.29245586 -0.36520045 -0.30620704]
u_c before reduction of space:  [-0.36615473 -0.44625373 -0.31209488 -0.34506292 -0.23267612 -1.76467557
 -0.62417553 -0.29245586 -0.36520045 -0.30620704]
data[u_c] post encoding of state:  [-0.36615473 -0.44625373 -0.31209488 -0.34506292 -0.23267612 -1.76467557
 -0.62417553 -0.29245586 -0.36520045 -0.30620704]
J_b = 0.0, J_o = 150449.88339170956
J_b = 0.5, J_o = 4747040.96725147
J_b = 0.008398200903238603, J_o = 46229.58120930648
J_b = 0.009507451457501958, J_o = 37941.071740003455
J_b = 0.026776472696447586, J_o = 17140.323622145916
J_b = 0.03457550982798717, J_o = 14239.656253759933
J_b = 0.05165247458149272, J_o = 10819.587702343677
J_b = 0.0748059014458551, J_o = 9055.886355634919
J_b = 0.09667627994626421, J_o = 7966.000748150644
J_b = 0.0973448377144459, J_o = 7488.136680108977
J_b = 0.10373446879610752, J_o = 6985.3163790039425
J_b = 0.11595788794456759, J_o = 6631.188509807882
J_b = 0.1391435463487031, J_o = 6180.372002510139
J_b = 0.17309762988141583, J_o = 5840.023573040208
J_b = 0.18759476202437364, J_o = 5706.377189993806
J_b = 0.1953909814800625, J_o = 5835.822849635937
J_b = 0.1895455666599146, J_o = 5686.267631773964
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615473 -0.44625373 -0.31209488 -0.34506292 -0.23267612 -1.76467557
 -0.62417553 -0.29245586 -0.36520045 -0.30620704]
W_opt:  [-0.0130587   0.00097327  0.02442927  0.02679217  0.02112208  0.01190052
 -0.01865995 -0.0657537  -0.14175438 -0.22527699]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.7799 s, v_trunc (Latent to Reduced) = 0.0592, dec (Reduced to Full) = 0.3149, add (DA)= 0.0001decode = 0.3779 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.1578 s, inc stats = 3.1602, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.88598461e-07 2.54338294e-07 9.42976912e-07 6.59751860e-07
 8.08238612e-07]
u_DA:    [ 3.22927708e-03  6.46241093e-03  3.98167639e-03  1.90572265e-03
 -8.95290991e-05]
ref_MAE: [0.00805557 0.00987253 0.00446278 0.00560711 0.00061709]
da_MAE:  [3.22898848e-03 6.46215660e-03 3.98073342e-03 1.90506290e-03
 9.03373377e-05]
% 45.15892304738651 da_MAE 0.12710556682575552 ref_MAE 0.23177073443613003
u_c taken from control states: [-0.36615627 -0.44625469 -0.31209708 -0.34506544 -0.23270049 -1.76628847
 -0.62417863 -0.29241489 -0.36633145 -0.306211  ]
u_c before reduction of space:  [-0.36615627 -0.44625469 -0.31209708 -0.34506544 -0.23270049 -1.76628847
 -0.62417863 -0.29241489 -0.36633145 -0.306211  ]
data[u_c] post encoding of state:  [-0.36615627 -0.44625469 -0.31209708 -0.34506544 -0.23270049 -1.76628847
 -0.62417863 -0.29241489 -0.36633145 -0.306211  ]
J_b = 0.0, J_o = 150488.22492618786
J_b = 0.5000000000000002, J_o = 4747177.087185608
J_b = 0.008393563164150856, J_o = 46333.324523437244
J_b = 0.009503770727184759, J_o = 38037.91413611955
J_b = 0.026808620440852613, J_o = 17201.257860442896
J_b = 0.03463108998209721, J_o = 14293.851810356078
J_b = 0.05174749910870555, J_o = 10866.799766185752
J_b = 0.07499173499066408, J_o = 9097.197728479827
J_b = 0.09694232719005255, J_o = 8006.167215420897
J_b = 0.09755682403976176, J_o = 7527.0704469328475
J_b = 0.1039424570437273, J_o = 7021.531676050334
J_b = 0.11622492256572914, J_o = 6665.867128726455
J_b = 0.13945021623857198, J_o = 6214.398694442232
J_b = 0.17331146490012073, J_o = 5872.661916802118
J_b = 0.18802187029803002, J_o = 5739.208981148156
J_b = 0.1959911352067102, J_o = 5872.732332035084
J_b = 0.18999051662701996, J_o = 5719.294087474884
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615627 -0.44625469 -0.31209708 -0.34506544 -0.23270049 -1.76628847
 -0.62417863 -0.29241489 -0.36633145 -0.306211  ]
W_opt:  [-0.01325756  0.00147594  0.02469197  0.02683029  0.02103575  0.01165386
 -0.01893708 -0.06618527 -0.14195232 -0.22502957]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0781 s, v_trunc (Latent to Reduced) = 0.0470, dec (Reduced to Full) = 0.2255, add (DA)= 0.0001decode = 0.2746 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3528 s, inc stats = 2.3552, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.86038312e-07 2.51897259e-07 9.41122642e-07 6.56993263e-07
 8.02926815e-07]
u_DA:    [ 3.24413978e-03  6.44231482e-03  3.98479991e-03  1.90307955e-03
 -9.04322229e-05]
ref_MAE: [0.00805558 0.00987253 0.00446278 0.00560712 0.00061709]
da_MAE:  [3.24385374e-03 6.44206292e-03 3.98385879e-03 1.90242256e-03
 9.12351497e-05]
% 45.37478168940286 da_MAE 0.12690872398171732 ref_MAE 0.23232625499108966
u_c taken from control states: [-0.36615757 -0.44625572 -0.3121004  -0.34506848 -0.23270653 -1.76788981
 -0.62418043 -0.29232282 -0.36685933 -0.30621357]
u_c before reduction of space:  [-0.36615757 -0.44625572 -0.3121004  -0.34506848 -0.23270653 -1.76788981
 -0.62418043 -0.29232282 -0.36685933 -0.30621357]
data[u_c] post encoding of state:  [-0.36615757 -0.44625572 -0.3121004  -0.34506848 -0.23270653 -1.76788981
 -0.62418043 -0.29232282 -0.36685933 -0.30621357]
J_b = 0.0, J_o = 150548.4509790953
J_b = 0.4999999999999999, J_o = 4747141.91685503
J_b = 0.008393035132835024, J_o = 46403.41007479829
J_b = 0.009503973687906567, J_o = 38102.12098531045
J_b = 0.02685595864103087, J_o = 17220.001392484162
J_b = 0.03470733255589052, J_o = 14305.6515967905
J_b = 0.051845338354201416, J_o = 10876.27054505931
J_b = 0.07514696724134777, J_o = 9102.71190035716
J_b = 0.09715744125865601, J_o = 8012.467469422132
J_b = 0.09770691966573888, J_o = 7532.701308116066
J_b = 0.10405467063293192, J_o = 7026.019934786807
J_b = 0.11634502219213491, J_o = 6669.993299962345
J_b = 0.13953264007374006, J_o = 6219.036728970817
J_b = 0.17323263923660215, J_o = 5876.611525038801
J_b = 0.18812767014063025, J_o = 5743.31030626695
J_b = 0.1962746269721183, J_o = 5881.308610224307
J_b = 0.1901131072529003, J_o = 5723.574410163363
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615757 -0.44625572 -0.3121004  -0.34506848 -0.23270653 -1.76788981
 -0.62418043 -0.29232282 -0.36685933 -0.30621357]
W_opt:  [-0.01342257  0.0015766   0.02460929  0.02688834  0.0210919   0.01146459
 -0.01919189 -0.06656823 -0.14217714 -0.22481701]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.3799 s, v_trunc (Latent to Reduced) = 0.0522, dec (Reduced to Full) = 0.1668, add (DA)= 0.0001decode = 0.2211 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.6011 s, inc stats = 2.6036, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.83886756e-07 2.49303417e-07 9.38331866e-07 6.53673080e-07
 8.01612359e-07]
u_DA:    [ 3.25656200e-03  6.41888053e-03  3.98772156e-03  1.89954733e-03
 -9.16427103e-05]
ref_MAE: [0.00805558 0.00987254 0.00446278 0.00560712 0.00061709]
da_MAE:  [3.25627812e-03 6.41863123e-03 3.98678323e-03 1.89889366e-03
 9.24443226e-05]
% 45.62798047141878 da_MAE 0.1263590041957223 ref_MAE 0.232397113977531
u_c taken from control states: [-0.3661584  -0.44625671 -0.31210412 -0.34507126 -0.23269162 -1.76953752
 -0.62418079 -0.29217534 -0.36680811 -0.30621407]
u_c before reduction of space:  [-0.3661584  -0.44625671 -0.31210412 -0.34507126 -0.23269162 -1.76953752
 -0.62418079 -0.29217534 -0.36680811 -0.30621407]
data[u_c] post encoding of state:  [-0.3661584  -0.44625671 -0.31210412 -0.34507126 -0.23269162 -1.76953752
 -0.62418079 -0.29217534 -0.36680811 -0.30621407]
J_b = 0.0, J_o = 150605.0790124031
J_b = 0.5000000000000004, J_o = 4746910.933267047
J_b = 0.008397568186368606, J_o = 46400.46886977283
J_b = 0.00950869934668999, J_o = 38096.67480370232
J_b = 0.026903954232789427, J_o = 17174.82348128211
J_b = 0.03477785812439813, J_o = 14257.072490052054
J_b = 0.05189310215366115, J_o = 10834.560385312589
J_b = 0.0751788970031471, J_o = 9060.573751933687
J_b = 0.09722902079448104, J_o = 7973.579835017306
J_b = 0.09771407589075837, J_o = 7493.973245063835
J_b = 0.10396165846708386, J_o = 6989.737807882239
J_b = 0.1161610794974834, J_o = 6635.528165435989
J_b = 0.13917123435282536, J_o = 6187.118001129553
J_b = 0.17260270292483032, J_o = 5845.522913601029
J_b = 0.18758865898248162, J_o = 5712.330953432442
J_b = 0.1959000237547788, J_o = 5854.753975865878
J_b = 0.18958867939843194, J_o = 5692.716987300572
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3661584  -0.44625671 -0.31210412 -0.34507126 -0.23269162 -1.76953752
 -0.62418079 -0.29217534 -0.36680811 -0.30621407]
W_opt:  [-0.0134464   0.00119414  0.02426998  0.02700066  0.02132465  0.01151982
 -0.01933272 -0.06683873 -0.14234209 -0.22478187]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2984 s, v_trunc (Latent to Reduced) = 0.0490, dec (Reduced to Full) = 0.3766, add (DA)= 0.0001decode = 0.4279 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.7264 s, inc stats = 2.7288, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.82501114e-07 2.46790528e-07 9.35210569e-07 6.50624793e-07
 8.04861709e-07]
u_DA:    [ 3.26357208e-03  6.39863547e-03  3.98868793e-03  1.89437958e-03
 -9.30126213e-05]
ref_MAE: [0.00805558 0.00987254 0.00446279 0.00560712 0.00061709]
da_MAE:  [3.26328958e-03 6.39838868e-03 3.98775272e-03 1.89372896e-03
 9.38174831e-05]
% 45.89416754951736 da_MAE 0.12547788039116298 ref_MAE 0.23191193020826292
u_c taken from control states: [-0.36615867 -0.44625761 -0.31210764 -0.34507324 -0.23265817 -1.77126323
 -0.62417995 -0.29197945 -0.36624081 -0.30621227]
u_c before reduction of space:  [-0.36615867 -0.44625761 -0.31210764 -0.34507324 -0.23265817 -1.77126323
 -0.62417995 -0.29197945 -0.36624081 -0.30621227]
data[u_c] post encoding of state:  [-0.36615867 -0.44625761 -0.31210764 -0.34507324 -0.23265817 -1.77126323
 -0.62417995 -0.29197945 -0.36624081 -0.30621227]
J_b = 0.0, J_o = 150651.28832664635
J_b = 0.5, J_o = 4746677.732564324
J_b = 0.008404101416190747, J_o = 46357.75583809681
J_b = 0.009514845580294957, J_o = 38055.411093779636
J_b = 0.026944108514882603, J_o = 17104.609693539584
J_b = 0.034833330494455805, J_o = 14186.314194498755
J_b = 0.05190643981321444, J_o = 10774.045977221505
J_b = 0.07517596679491452, J_o = 8998.153396948122
J_b = 0.09733153889375319, J_o = 7913.77745682599
J_b = 0.09774309124114562, J_o = 7433.993159077559
J_b = 0.10382608290276596, J_o = 6935.371930324911
J_b = 0.11584756738571282, J_o = 6584.7234387026565
J_b = 0.13856276560150427, J_o = 6140.421576507049
J_b = 0.17160790123277786, J_o = 5801.035398928114
J_b = 0.1866098164268445, J_o = 5667.827317236283
J_b = 0.19510530961500266, J_o = 5815.105257630121
J_b = 0.1886288510605122, J_o = 5648.254095015062
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615867 -0.44625761 -0.31210764 -0.34507324 -0.23265817 -1.77126323
 -0.62417995 -0.29197945 -0.36624081 -0.30621227]
W_opt:  [-0.01299085  0.00099812  0.02379369  0.02690389  0.02139364  0.01129614
 -0.01956181 -0.06700645 -0.14240207 -0.22467297]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2861 s, v_trunc (Latent to Reduced) = 0.0529, dec (Reduced to Full) = 0.1759, add (DA)= 0.0001decode = 0.2308 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5170 s, inc stats = 2.5211, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.82060374e-07 2.44493307e-07 9.32246854e-07 6.48456536e-07
 8.12151217e-07]
u_DA:    [ 3.26405376e-03  6.38266456e-03  3.98868132e-03  1.88864987e-03
 -9.42806322e-05]
ref_MAE: [0.00805558 0.00987254 0.00446279 0.00560712 0.00061708]
da_MAE:  [3.26377170e-03 6.38242007e-03 3.98774907e-03 1.88800141e-03
 9.50927834e-05]
% 46.168751043916 da_MAE 0.1243057347949871 ref_MAE 0.23091742659806536
\% improve_point: 23.17, mse_ref_points: 2.675471884515577e-05, mse_da_points: 2.0121984879792063e-05, % improve_overlap: 1.23, mse_ref_overlap: 0.23053, mse_da_overlap: 0.21760
DA - - L2: 1958.04, L1: 2345.23, % Improve: 37.95%, DA_MAE: 0.11, mse_ref: 0.24, mse_DA: 0.180, time(s): 3.5162s,
u_c taken from control states: [-0.36615833 -0.44625838 -0.31211013 -0.34507384 -0.23260951 -1.77312242
 -0.62417786 -0.29175119 -0.3652208  -0.30620815]
u_c before reduction of space:  [-0.36615833 -0.44625838 -0.31211013 -0.34507384 -0.23260951 -1.77312242
 -0.62417786 -0.29175119 -0.3652208  -0.30620815]
data[u_c] post encoding of state:  [-0.36615833 -0.44625838 -0.31211013 -0.34507384 -0.23260951 -1.77312242
 -0.62417786 -0.29175119 -0.3652208  -0.30620815]
J_b = 0.0, J_o = 150718.88436261355
J_b = 0.5, J_o = 4746213.054249484
J_b = 0.008416194757341539, J_o = 46261.071394025756
J_b = 0.009526102633684724, J_o = 37963.010794413414
J_b = 0.026981417721878696, J_o = 16992.370010275376
J_b = 0.034876525476110774, J_o = 14077.43735243341
J_b = 0.05187226843840324, J_o = 10682.264502044614
J_b = 0.07507993521832283, J_o = 8906.169835282946
J_b = 0.09735101224434177, J_o = 7825.2068369726385
J_b = 0.09769500656399076, J_o = 7345.661450058602
J_b = 0.10355642973480102, J_o = 6856.30476129915
J_b = 0.11530371009669212, J_o = 6511.334627488432
J_b = 0.13758932837546559, J_o = 6073.151826780317
J_b = 0.17013222837597294, J_o = 5737.780235389177
J_b = 0.18503026821450347, J_o = 5604.46762122714
J_b = 0.19369536994357717, J_o = 5756.713989785114
J_b = 0.1870658069342212, J_o = 5584.857759141197
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615833 -0.44625838 -0.31211013 -0.34507384 -0.23260951 -1.77312242
 -0.62417786 -0.29175119 -0.3652208  -0.30620815]
W_opt:  [-0.01264816  0.00083338  0.0234649   0.02704555  0.02127019  0.01075797
 -0.01983391 -0.06690365 -0.14217991 -0.22450556]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2187 s, v_trunc (Latent to Reduced) = 0.0489, dec (Reduced to Full) = 0.1771, add (DA)= 0.0001decode = 0.2280 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4467 s, inc stats = 2.4492, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.82622081e-07 2.42556495e-07 9.30157928e-07 6.47803046e-07
 8.22756381e-07]
u_DA:    [ 3.25696802e-03  6.37517489e-03  3.98714901e-03  1.88417870e-03
 -9.53567942e-05]
ref_MAE: [0.00805558 0.00987254 0.00446279 0.00560713 0.00061707]
da_MAE:  [3.25668540e-03 6.37493234e-03 3.98621886e-03 1.88353090e-03
 9.61795505e-05]
% 46.42299262877885 da_MAE 0.12291189410520055 ref_MAE 0.22941164528577718
u_c taken from control states: [-0.36615737 -0.44625895 -0.31211085 -0.34507266 -0.23254892 -1.77513826
 -0.62417502 -0.29149926 -0.36383028 -0.30620187]
u_c before reduction of space:  [-0.36615737 -0.44625895 -0.31211085 -0.34507266 -0.23254892 -1.77513826
 -0.62417502 -0.29149926 -0.36383028 -0.30620187]
data[u_c] post encoding of state:  [-0.36615737 -0.44625895 -0.31211085 -0.34507266 -0.23254892 -1.77513826
 -0.62417502 -0.29149926 -0.36383028 -0.30620187]
J_b = 0.0, J_o = 150817.3955781073
J_b = 0.4999999999999998, J_o = 4745489.768066713
J_b = 0.008432843008383454, J_o = 46135.40771335551
J_b = 0.009541864750760912, J_o = 37841.82634006932
J_b = 0.027016881111925056, J_o = 16857.419331040044
J_b = 0.034909688093277394, J_o = 13948.841524811218
J_b = 0.05179780815676232, J_o = 10576.679349436024
J_b = 0.07488039028208521, J_o = 8803.99925289531
J_b = 0.09722259249047648, J_o = 7728.217215900886
J_b = 0.09750933468638835, J_o = 7250.084527916487
J_b = 0.10311134669976026, J_o = 6772.961394091831
J_b = 0.11451203255604424, J_o = 6435.30251771012
J_b = 0.13627393698567805, J_o = 6004.735237251605
J_b = 0.16826477107416946, J_o = 5674.901430990187
J_b = 0.18292778120172226, J_o = 5541.36431509044
J_b = 0.19171872961312966, J_o = 5698.156919355574
J_b = 0.18497360183198563, J_o = 5521.6269462327255
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615737 -0.44625895 -0.31211085 -0.34507266 -0.23254892 -1.77513826
 -0.62417502 -0.29149926 -0.36383028 -0.30620187]
W_opt:  [-0.01232585  0.0002912   0.02309094  0.02694014  0.02098357  0.010404
 -0.01964732 -0.06640862 -0.14161325 -0.22427189]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1259 s, v_trunc (Latent to Reduced) = 0.0486, dec (Reduced to Full) = 0.3120, add (DA)= 0.0001decode = 0.3629 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4888 s, inc stats = 2.4916, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.84222300e-07 2.41096926e-07 9.29548700e-07 6.49091888e-07
 8.35961946e-07]
u_DA:    [ 3.24483021e-03  6.37609909e-03  3.98547695e-03  1.88054891e-03
 -9.60824630e-05]
ref_MAE: [0.00805558 0.00987254 0.00446279 0.00560712 0.00061706]
da_MAE:  [3.24454599e-03 6.37585800e-03 3.98454740e-03 1.87989981e-03
 9.69184250e-05]
% 46.61889729968106 da_MAE 0.12143833872293437 ref_MAE 0.22749312505717273
u_c taken from control states: [-0.36615596 -0.44625934 -0.31210946 -0.34506965 -0.23248579 -1.7773154
 -0.62417211 -0.29126096 -0.36228676 -0.30619419]
u_c before reduction of space:  [-0.36615596 -0.44625934 -0.31210946 -0.34506965 -0.23248579 -1.7773154
 -0.62417211 -0.29126096 -0.36228676 -0.30619419]
data[u_c] post encoding of state:  [-0.36615596 -0.44625934 -0.31210946 -0.34506965 -0.23248579 -1.7773154
 -0.62417211 -0.29126096 -0.36228676 -0.30619419]
J_b = 0.0, J_o = 150881.46025634283
J_b = 0.5, J_o = 4744802.374725286
J_b = 0.008449177287125246, J_o = 45978.22864120135
J_b = 0.009557006026706252, J_o = 37691.67317413069
J_b = 0.02702963252544346, J_o = 16715.13807395582
J_b = 0.03490386027357329, J_o = 13817.741240943415
J_b = 0.051649503500673655, J_o = 10474.439480957824
J_b = 0.07454774994934732, J_o = 8707.374373979324
J_b = 0.09697240923262791, J_o = 7636.268356711571
J_b = 0.09724818047805829, J_o = 7159.023491624556
J_b = 0.10259622046593973, J_o = 6695.5123884132445
J_b = 0.11362328296254302, J_o = 6365.814999884229
J_b = 0.13486023386006563, J_o = 5942.998942054123
J_b = 0.16630672190001616, J_o = 5620.431718809812
J_b = 0.18048614457278944, J_o = 5486.872316136142
J_b = 0.18922929841965966, J_o = 5645.571513654068
J_b = 0.18251560181939658, J_o = 5466.916490879585
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615596 -0.44625934 -0.31210946 -0.34506965 -0.23248579 -1.7773154
 -0.62417211 -0.29126096 -0.36228676 -0.30619419]
W_opt:  [-0.01203743 -0.00054293  0.02258145  0.02671338  0.02098627  0.01041413
 -0.01925915 -0.06617285 -0.14132346 -0.22400158]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1401 s, v_trunc (Latent to Reduced) = 0.0486, dec (Reduced to Full) = 0.1407, add (DA)= 0.0001decode = 0.1913 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3314 s, inc stats = 2.3346, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.86565070e-07 2.40112262e-07 9.30722484e-07 6.52394481e-07
 8.49721406e-07]
u_DA:    [ 3.22614578e-03  6.38571783e-03  3.98218222e-03  1.87837828e-03
 -9.58198920e-05]
ref_MAE: [0.00805558 0.00987254 0.00446279 0.00560712 0.00061705]
da_MAE:  [3.22585921e-03 6.38547772e-03 3.98125150e-03 1.87772589e-03
 9.66696134e-05]
% 46.63759084573189 da_MAE 0.120261695381011 ref_MAE 0.2253678146976842
u_c taken from control states: [-0.36615431 -0.44625953 -0.31210526 -0.34506477 -0.23242618 -1.77965589
 -0.62416969 -0.29106157 -0.36075019 -0.3061859 ]
u_c before reduction of space:  [-0.36615431 -0.44625953 -0.31210526 -0.34506477 -0.23242618 -1.77965589
 -0.62416969 -0.29106157 -0.36075019 -0.3061859 ]
data[u_c] post encoding of state:  [-0.36615431 -0.44625953 -0.31210526 -0.34506477 -0.23242618 -1.77965589
 -0.62416969 -0.29106157 -0.36075019 -0.3061859 ]
J_b = 0.0, J_o = 150899.04594159604
J_b = 0.5, J_o = 4744286.872003424
J_b = 0.008461779892522128, J_o = 45824.0131910434
J_b = 0.009568419311958131, J_o = 37545.041323132726
J_b = 0.027022798465827707, J_o = 16590.634827987426
J_b = 0.03487122076744499, J_o = 13705.468963421226
J_b = 0.05147376522109384, J_o = 10390.206406654932
J_b = 0.07417461296996114, J_o = 8628.950382773859
J_b = 0.09669824537152202, J_o = 7560.876071352641
J_b = 0.09700518080934974, J_o = 7083.452243820444
J_b = 0.10214677026452548, J_o = 6632.181916601698
J_b = 0.1128456794705889, J_o = 6309.375306854118
J_b = 0.13368344398083387, J_o = 5892.342674750376
J_b = 0.16476588533274228, J_o = 5576.996572857315
J_b = 0.17830920658171884, J_o = 5443.190289461309
J_b = 0.18686500388258728, J_o = 5600.38104652789
J_b = 0.18031123658134976, J_o = 5422.794980756278
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615431 -0.44625953 -0.31210526 -0.34506477 -0.23242618 -1.77965589
 -0.62416969 -0.29106157 -0.36075019 -0.3061859 ]
W_opt:  [-0.01192013 -0.00103493  0.02232195  0.02625528  0.02062677  0.01027751
 -0.01886417 -0.06600684 -0.14107102 -0.22360123]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0595 s, v_trunc (Latent to Reduced) = 0.0477, dec (Reduced to Full) = 0.1637, add (DA)= 0.0001decode = 0.2134 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.2730 s, inc stats = 2.2769, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.89309493e-07 2.39642767e-07 9.34246292e-07 6.57733840e-07
 8.62713017e-07]
u_DA:    [ 3.19821598e-03  6.40343925e-03  3.97869784e-03  1.87750638e-03
 -9.52278210e-05]
ref_MAE: [0.00805557 0.00987255 0.00446279 0.00560712 0.00061703]
da_MAE:  [3.19792667e-03 6.40319961e-03 3.97776359e-03 1.87684865e-03
 9.60905340e-05]
% 46.50099993925007 da_MAE 0.11942526115153242 ref_MAE 0.22322895944956164
u_c taken from control states: [-0.36615265 -0.44625953 -0.31209834 -0.34505837 -0.23237552 -1.78211653
 -0.62416848 -0.29091159 -0.35932803 -0.30617796]
u_c before reduction of space:  [-0.36615265 -0.44625953 -0.31209834 -0.34505837 -0.23237552 -1.78211653
 -0.62416848 -0.29091159 -0.35932803 -0.30617796]
data[u_c] post encoding of state:  [-0.36615265 -0.44625953 -0.31209834 -0.34505837 -0.23237552 -1.78211653
 -0.62416848 -0.29091159 -0.35932803 -0.30617796]
J_b = 0.0, J_o = 150949.57403136176
J_b = 0.4999999999999999, J_o = 4743740.341695379
J_b = 0.008474531061203317, J_o = 45702.00305165064
J_b = 0.009580233094990134, J_o = 37428.72541237045
J_b = 0.027026343541393043, J_o = 16485.87596547527
J_b = 0.034858242497290796, J_o = 13609.666625119999
J_b = 0.05133993548943962, J_o = 10318.943445234094
J_b = 0.07384836348027429, J_o = 8564.788984230574
J_b = 0.09641556048064259, J_o = 7499.551726245532
J_b = 0.09677164447792479, J_o = 7022.423154979975
J_b = 0.10175045820598391, J_o = 6582.211270435981
J_b = 0.11214742508181884, J_o = 6266.127135277106
J_b = 0.13261248546010332, J_o = 5854.9944408127885
J_b = 0.16334777255674943, J_o = 5547.901490919705
J_b = 0.1760806691522392, J_o = 5414.266537318307
J_b = 0.18426219707560443, J_o = 5565.70601785881
J_b = 0.1780310233271379, J_o = 5393.320731700695
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615265 -0.44625953 -0.31209834 -0.34505837 -0.23237552 -1.78211653
 -0.62416848 -0.29091159 -0.35932803 -0.30617796]
W_opt:  [-0.01192476 -0.00118831  0.02194545  0.02580591  0.02004597  0.00986238
 -0.01888658 -0.06587494 -0.14046802 -0.22259249]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5539 s, v_trunc (Latent to Reduced) = 0.0482, dec (Reduced to Full) = 0.2630, add (DA)= 0.0001decode = 0.3133 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8672 s, inc stats = 3.8696, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.92067985e-07 2.39629146e-07 9.40065476e-07 6.64735385e-07
 8.73754993e-07]
u_DA:    [ 3.16599108e-03  6.42856966e-03  3.97432252e-03  1.88261909e-03
 -9.43414294e-05]
ref_MAE: [0.00805557 0.00987255 0.00446278 0.00560711 0.00061702]
da_MAE:  [3.16569901e-03 6.42833004e-03 3.97338246e-03 1.88195435e-03
 9.52151844e-05]
% 46.196930987720634 da_MAE 0.11905679249549816 ref_MAE 0.22128253031128403
u_c taken from control states: [-0.36615124 -0.44625942 -0.31208925 -0.34505109 -0.23233851 -1.78462255
 -0.62416914 -0.29081497 -0.35811212 -0.30617132]
u_c before reduction of space:  [-0.36615124 -0.44625942 -0.31208925 -0.34505109 -0.23233851 -1.78462255
 -0.62416914 -0.29081497 -0.35811212 -0.30617132]
data[u_c] post encoding of state:  [-0.36615124 -0.44625942 -0.31208925 -0.34505109 -0.23233851 -1.78462255
 -0.62416914 -0.29081497 -0.35811212 -0.30617132]
J_b = 0.0, J_o = 151026.6579896907
J_b = 0.4999999999999997, J_o = 4743351.558985572
J_b = 0.008481181153471906, J_o = 45692.63526556903
J_b = 0.009586991433733361, J_o = 37418.37634414115
J_b = 0.027027207150441657, J_o = 16480.04322678529
J_b = 0.03485190624959966, J_o = 13606.456336358486
J_b = 0.05129690933482137, J_o = 10322.533761031369
J_b = 0.07374605074241934, J_o = 8568.951500017261
J_b = 0.09639093367879253, J_o = 7501.991640803776
J_b = 0.09678975431068354, J_o = 7024.4278398140395
J_b = 0.1016772356002372, J_o = 6591.206581309623
J_b = 0.11188451909940413, J_o = 6279.313855616219
J_b = 0.13212775069754992, J_o = 5872.00996688647
J_b = 0.1625876309229624, J_o = 5572.718127638408
J_b = 0.17446889953202357, J_o = 5440.055494965689
J_b = 0.18210569099844415, J_o = 5581.079160383633
J_b = 0.17634263342432796, J_o = 5418.605663232197
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615124 -0.44625942 -0.31208925 -0.34505109 -0.23233851 -1.78462255
 -0.62416914 -0.29081497 -0.35811212 -0.30617132]
W_opt:  [-0.01166448 -0.00092731  0.02191303  0.02525175  0.01952023  0.00940876
 -0.01924593 -0.06607493 -0.14003917 -0.22152522]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1387 s, v_trunc (Latent to Reduced) = 0.0480, dec (Reduced to Full) = 0.1869, add (DA)= 0.0001decode = 0.2368 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3756 s, inc stats = 2.3780, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.94411548e-07 2.39924703e-07 9.47700993e-07 6.72696890e-07
 8.81822540e-07]
u_DA:    [ 3.14330310e-03  6.45714249e-03  3.96890140e-03  1.88352673e-03
 -9.37801207e-05]
ref_MAE: [0.00805557 0.00987254 0.00446277 0.0056071  0.00061701]
da_MAE:  [3.14300868e-03 6.45690256e-03 3.96795369e-03 1.88285403e-03
 9.46619433e-05]
% 45.84032321315583 da_MAE 0.11900473994670649 ref_MAE 0.21972941311129413
u_c taken from control states: [-0.36615031 -0.44625926 -0.31207897 -0.34504365 -0.23231819 -1.78710794
 -0.62417177 -0.29077259 -0.3571622  -0.30616672]
u_c before reduction of space:  [-0.36615031 -0.44625926 -0.31207897 -0.34504365 -0.23231819 -1.78710794
 -0.62417177 -0.29077259 -0.3571622  -0.30616672]
data[u_c] post encoding of state:  [-0.36615031 -0.44625926 -0.31207897 -0.34504365 -0.23231819 -1.78710794
 -0.62417177 -0.29077259 -0.3571622  -0.30616672]
J_b = 0.0, J_o = 151078.9181739001
J_b = 0.5, J_o = 4743187.682108847
J_b = 0.008480691692375864, J_o = 45757.00215199523
J_b = 0.009587356938358752, J_o = 37477.60350518148
J_b = 0.027002191441943463, J_o = 16558.299286191468
J_b = 0.03481245797673085, J_o = 13686.041002052869
J_b = 0.05126749397864957, J_o = 10397.551267620445
J_b = 0.07372734242733506, J_o = 8640.454854637685
J_b = 0.09649228583433254, J_o = 7566.546912527208
J_b = 0.09699411828499711, J_o = 7086.173340796326
J_b = 0.10192443934573069, J_o = 6653.892383057835
J_b = 0.11211493705023208, J_o = 6342.346068173647
J_b = 0.1324265236605255, J_o = 5934.241558774528
J_b = 0.16294951232935698, J_o = 5639.806277353429
J_b = 0.17407451380414593, J_o = 5508.159582012199
J_b = 0.18104419379680955, J_o = 5635.174493958411
J_b = 0.17585153095000525, J_o = 5486.266817528256
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615031 -0.44625926 -0.31207897 -0.34504365 -0.23231819 -1.78710794
 -0.62417177 -0.29077259 -0.3571622  -0.30616672]
W_opt:  [-0.01140038 -0.00049758  0.02202696  0.02469688  0.01921955  0.0088535
 -0.01951469 -0.06610038 -0.13981199 -0.22092043]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1498 s, v_trunc (Latent to Reduced) = 0.0487, dec (Reduced to Full) = 0.2650, add (DA)= 0.0001decode = 0.3159 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4657 s, inc stats = 2.4681, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.95942076e-07 2.40331299e-07 9.56346416e-07 6.80836635e-07
 8.86251024e-07]
u_DA:    [ 3.12830651e-03  6.47585306e-03  3.96477003e-03  1.88382962e-03
 -9.37262867e-05]
ref_MAE: [0.00805557 0.00987254 0.00446277 0.00560709 0.00061701]
da_MAE:  [3.12801057e-03 6.47561273e-03 3.96381368e-03 1.88314879e-03
 9.46125377e-05]
% 45.43783973854868 da_MAE 0.11930930697508299 ref_MAE 0.21866675806708508
u_c taken from control states: [-0.36615    -0.44625913 -0.31206841 -0.34503671 -0.23231264 -1.78952902
 -0.62417597 -0.29077183 -0.35646083 -0.30616444]
u_c before reduction of space:  [-0.36615    -0.44625913 -0.31206841 -0.34503671 -0.23231264 -1.78952902
 -0.62417597 -0.29077183 -0.35646083 -0.30616444]
data[u_c] post encoding of state:  [-0.36615    -0.44625913 -0.31206841 -0.34503671 -0.23231264 -1.78952902
 -0.62417597 -0.29077183 -0.35646083 -0.30616444]
J_b = 0.0, J_o = 151101.14034111105
J_b = 0.49999999999999983, J_o = 4743138.422649214
J_b = 0.008475392955308225, J_o = 45858.2497392099
J_b = 0.009583575072084342, J_o = 37569.546175995645
J_b = 0.026973515000466623, J_o = 16666.689170350663
J_b = 0.03476982074687978, J_o = 13794.619702041025
J_b = 0.05124735068383707, J_o = 10498.590361230621
J_b = 0.07372447048361949, J_o = 8737.705415191998
J_b = 0.09660107214125385, J_o = 7655.875650195477
J_b = 0.09723303690072296, J_o = 7171.711902778085
J_b = 0.10227434394819805, J_o = 6736.904291265663
J_b = 0.1125514306009182, J_o = 6423.112818407807
J_b = 0.13314112413610651, J_o = 6010.49303632658
J_b = 0.1640470262514568, J_o = 5718.062777639991
J_b = 0.17455994143859943, J_o = 5586.677452160357
J_b = 0.18088724296651243, J_o = 5699.959582125959
J_b = 0.17624017740734657, J_o = 5564.315926305375
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615    -0.44625913 -0.31206841 -0.34503671 -0.23231264 -1.78952902
 -0.62417597 -0.29077183 -0.35646083 -0.30616444]
W_opt:  [-1.16256197e-02  3.10500184e-05  2.23537631e-02  2.41075463e-02
  1.89471518e-02  8.67134045e-03 -1.94931123e-02 -6.60796364e-02
 -1.39797360e-01 -2.20664108e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1086 s, v_trunc (Latent to Reduced) = 0.0483, dec (Reduced to Full) = 0.1625, add (DA)= 0.0001decode = 0.2132 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3219 s, inc stats = 2.3246, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.96463505e-07 2.40658546e-07 9.65222175e-07 6.88431704e-07
 8.87459395e-07]
u_DA:    [ 3.11687933e-03  6.49287294e-03  3.96027730e-03  1.88440828e-03
 -9.36550968e-05]
ref_MAE: [0.00805557 0.00987254 0.00446276 0.00560708 0.00061701]
da_MAE:  [3.11658287e-03 6.49263228e-03 3.95931208e-03 1.88371985e-03
 9.45425562e-05]
% 44.99276714623099 da_MAE 0.1199469279337629 ref_MAE 0.2180566476641886
u_c taken from control states: [-0.36615033 -0.44625911 -0.31205854 -0.34503097 -0.23231865 -1.79184103
 -0.62418148 -0.29079946 -0.35600902 -0.30616444]
u_c before reduction of space:  [-0.36615033 -0.44625911 -0.31205854 -0.34503097 -0.23231865 -1.79184103
 -0.62418148 -0.29079946 -0.35600902 -0.30616444]
data[u_c] post encoding of state:  [-0.36615033 -0.44625911 -0.31205854 -0.34503097 -0.23231865 -1.79184103
 -0.62418148 -0.29079946 -0.35600902 -0.30616444]
J_b = 0.0, J_o = 151086.99628038474
J_b = 0.49999999999999994, J_o = 4743324.545528621
J_b = 0.008468028953565512, J_o = 45947.04660131988
J_b = 0.009577171826231249, J_o = 37652.919594008556
J_b = 0.02694120667937337, J_o = 16769.84917847872
J_b = 0.03472394894172683, J_o = 13898.861875499297
J_b = 0.05120664154669183, J_o = 10599.282439703788
J_b = 0.07366696290226407, J_o = 8837.029120685409
J_b = 0.09661769174071436, J_o = 7749.976490943419
J_b = 0.09736257601092695, J_o = 7262.415767727669
J_b = 0.10251409146735296, J_o = 6824.203739265913
J_b = 0.11290747194279341, J_o = 6507.161507588551
J_b = 0.13386552645562494, J_o = 6088.0984092308645
J_b = 0.16534652838277378, J_o = 5795.299401515105
J_b = 0.17544601322332504, J_o = 5663.223785080265
J_b = 0.181280669039542, J_o = 5766.110631349165
J_b = 0.17704881357022786, J_o = 5640.397288076014
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615033 -0.44625911 -0.31205854 -0.34503097 -0.23231865 -1.79184103
 -0.62418148 -0.29079946 -0.35600902 -0.30616444]
W_opt:  [-0.01191322  0.00041331  0.02248761  0.02367373  0.01888085  0.00884687
 -0.01934887 -0.06601673 -0.13977821 -0.22057456]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.2009 s, v_trunc (Latent to Reduced) = 0.0483, dec (Reduced to Full) = 0.3425, add (DA)= 0.0001decode = 0.3930 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.5939 s, inc stats = 2.5963, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.95920307e-07 2.40697442e-07 9.73512312e-07 6.94712074e-07
 8.86151060e-07]
u_DA:    [ 3.10573894e-03  6.50986080e-03  3.95604445e-03  1.88521835e-03
 -9.36835208e-05]
ref_MAE: [0.00805557 0.00987254 0.00446275 0.00560708 0.00061701]
da_MAE:  [3.10544302e-03 6.50962010e-03 3.95507094e-03 1.88452364e-03
 9.45696718e-05]
% 44.61460635978217 da_MAE 0.12067586920593644 ref_MAE 0.21788392439682555
u_c taken from control states: [-0.36615129 -0.44625926 -0.31204995 -0.34502682 -0.23233201 -1.79404815
 -0.62418747 -0.29085041 -0.35578554 -0.30616648]
u_c before reduction of space:  [-0.36615129 -0.44625926 -0.31204995 -0.34502682 -0.23233201 -1.79404815
 -0.62418747 -0.29085041 -0.35578554 -0.30616648]
data[u_c] post encoding of state:  [-0.36615129 -0.44625926 -0.31204995 -0.34502682 -0.23233201 -1.79404815
 -0.62418747 -0.29085041 -0.35578554 -0.30616648]
J_b = 0.0, J_o = 151043.55659972315
J_b = 0.49999999999999994, J_o = 4743761.045349705
J_b = 0.008457774359315915, J_o = 46042.33094148646
J_b = 0.00956748864928404, J_o = 37745.64742091955
J_b = 0.026902256444787356, J_o = 16886.84330822697
J_b = 0.034672793169424745, J_o = 14016.339630164686
J_b = 0.05117267868866209, J_o = 10710.844160481372
J_b = 0.07364127693105689, J_o = 8946.280592115156
J_b = 0.09666622704191705, J_o = 7854.354231478661
J_b = 0.09749938288594197, J_o = 7363.671388442501
J_b = 0.10275662956246938, J_o = 6921.604365074273
J_b = 0.11327701044118142, J_o = 6601.037940512495
J_b = 0.1346190016184373, J_o = 6175.106017854115
J_b = 0.16673316916938416, J_o = 5880.347210789782
J_b = 0.17660955644535728, J_o = 5746.9806573247315
J_b = 0.18212434272989422, J_o = 5842.724191084948
J_b = 0.1781642860743573, J_o = 5723.698663569001
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615129 -0.44625926 -0.31204995 -0.34502682 -0.23233201 -1.79404815
 -0.62418747 -0.29085041 -0.35578554 -0.30616648]
W_opt:  [-0.01173833  0.00079407  0.02243336  0.02325712  0.01877855  0.00912713
 -0.01908554 -0.06597429 -0.13988355 -0.22070431]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0752 s, v_trunc (Latent to Reduced) = 0.0487, dec (Reduced to Full) = 0.2221, add (DA)= 0.0001decode = 0.2728 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3481 s, inc stats = 2.3504, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.94326184e-07 2.40315038e-07 9.80728994e-07 6.99258607e-07
 8.83238153e-07]
u_DA:    [ 3.09844405e-03  6.52060828e-03  3.95171041e-03  1.88608843e-03
 -9.38445553e-05]
ref_MAE: [0.00805557 0.00987254 0.00446274 0.00560707 0.00061701]
da_MAE:  [3.09814973e-03 6.52036796e-03 3.95072968e-03 1.88538917e-03
 9.47277935e-05]
% 44.27998642176418 da_MAE 0.12148536770012013 ref_MAE 0.21802824496721263
\% improve_point: 24.57, mse_ref_points: 2.7585142189453965e-05, mse_da_points: 2.031140378516286e-05, % improve_overlap: 5.13, mse_ref_overlap: 0.23812, mse_da_overlap: 0.21409
DA - - L2: 2105.28, L1: 2443.97, % Improve: 38.72%, DA_MAE: 0.11, mse_ref: 0.25, mse_DA: 0.182, time(s): 3.4212s,
u_c taken from control states: [-0.36615269 -0.44625957 -0.3120429  -0.34502425 -0.23234474 -1.79616744
 -0.62419345 -0.29089725 -0.3556724  -0.30616975]
u_c before reduction of space:  [-0.36615269 -0.44625957 -0.3120429  -0.34502425 -0.23234474 -1.79616744
 -0.62419345 -0.29089725 -0.3556724  -0.30616975]
data[u_c] post encoding of state:  [-0.36615269 -0.44625957 -0.3120429  -0.34502425 -0.23234474 -1.79616744
 -0.62419345 -0.29089725 -0.3556724  -0.30616975]
J_b = 0.0, J_o = 151032.3162553471
J_b = 0.5000000000000001, J_o = 4744081.003038185
J_b = 0.008448622925819922, J_o = 46157.09244668869
J_b = 0.009559262706975876, J_o = 37855.18773687829
J_b = 0.026875205903466617, J_o = 17010.012052082187
J_b = 0.034637867514703984, J_o = 14139.091159174068
J_b = 0.05115438674566166, J_o = 10827.998951446743
J_b = 0.07363787064436378, J_o = 9060.148875146733
J_b = 0.09676349227417688, J_o = 7963.056970393346
J_b = 0.09768042484653736, J_o = 7468.833928723506
J_b = 0.10303188758470683, J_o = 7023.174608248346
J_b = 0.1136704888750989, J_o = 6699.179697269769
J_b = 0.13539427070214888, J_o = 6266.279968777066
J_b = 0.1681628455926697, J_o = 5969.22841281288
J_b = 0.17785850272262935, J_o = 5834.167092639595
J_b = 0.1831219925471652, J_o = 5924.296480145169
J_b = 0.17937601718845653, J_o = 5810.37251207814
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615269 -0.44625957 -0.3120429  -0.34502425 -0.23234474 -1.79616744
 -0.62419345 -0.29089725 -0.3556724  -0.30616975]
W_opt:  [-0.01125132  0.00088535  0.02224226  0.02294567  0.01861623  0.00932247
 -0.01883648 -0.06597779 -0.14004105 -0.22088267]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1041 s, v_trunc (Latent to Reduced) = 0.1004, dec (Reduced to Full) = 0.1653, add (DA)= 0.0001decode = 0.2676 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3718 s, inc stats = 2.3742, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.91996257e-07 2.39524572e-07 9.86657254e-07 7.02068218e-07
 8.80462595e-07]
u_DA:    [ 3.09098676e-03  6.52911127e-03  3.94794862e-03  1.88792876e-03
 -9.42826068e-05]
ref_MAE: [0.00805557 0.00987255 0.00446274 0.00560707 0.00061702]
da_MAE:  [3.09069476e-03 6.52887174e-03 3.94696196e-03 1.88722669e-03
 9.51630694e-05]
% 43.96405971005119 da_MAE 0.1223386883852945 ref_MAE 0.21832182658535393
u_c taken from control states: [-0.36615427 -0.44626003 -0.31203754 -0.34502319 -0.23234986 -1.79816787
 -0.6241994  -0.2909008  -0.35547168 -0.30617334]
u_c before reduction of space:  [-0.36615427 -0.44626003 -0.31203754 -0.34502319 -0.23234986 -1.79816787
 -0.6241994  -0.2909008  -0.35547168 -0.30617334]
data[u_c] post encoding of state:  [-0.36615427 -0.44626003 -0.31203754 -0.34502319 -0.23234986 -1.79816787
 -0.6241994  -0.2909008  -0.35547168 -0.30617334]
J_b = 0.0, J_o = 151016.83140924052
J_b = 0.5, J_o = 4744389.558441179
J_b = 0.00844000310823754, J_o = 46259.99535679176
J_b = 0.009551511197581162, J_o = 37952.99020345096
J_b = 0.026858663527471495, J_o = 17113.064630640198
J_b = 0.03461683004544354, J_o = 14241.971193574953
J_b = 0.05113366564537619, J_o = 10929.454515760144
J_b = 0.07359864154413971, J_o = 9161.040469876776
J_b = 0.09676769034508341, J_o = 8061.593906937801
J_b = 0.09774628704011694, J_o = 7565.05684370094
J_b = 0.10316946566791003, J_o = 7116.480402470051
J_b = 0.11390601727164447, J_o = 6789.609600037561
J_b = 0.13594967248461695, J_o = 6350.764567092264
J_b = 0.16929985102769637, J_o = 6050.962543776342
J_b = 0.17893924208176518, J_o = 5914.180184078697
J_b = 0.18408284334350508, J_o = 6001.166169156701
J_b = 0.18044381385872257, J_o = 5889.950638756662
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615427 -0.44626003 -0.31203754 -0.34502319 -0.23234986 -1.79816787
 -0.6241994  -0.2909008  -0.35547168 -0.30617334]
W_opt:  [-0.01077886  0.00085937  0.02200832  0.02282745  0.01853807  0.00938544
 -0.01873472 -0.06603807 -0.14025444 -0.2210586 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1345 s, v_trunc (Latent to Reduced) = 0.0465, dec (Reduced to Full) = 0.1739, add (DA)= 0.0001decode = 0.2223 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3569 s, inc stats = 2.3593, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.89377327e-07 2.38367943e-07 9.91161524e-07 7.03229705e-07
 8.79346891e-07]
u_DA:    [ 3.08054116e-03  6.53398726e-03  3.94394679e-03  1.88961752e-03
 -9.46377766e-05]
ref_MAE: [0.00805557 0.00987255 0.00446273 0.00560707 0.00061702]
da_MAE:  [3.08025178e-03 6.53374889e-03 3.94295563e-03 1.88891429e-03
 9.55171235e-05]
% 43.730337654079605 da_MAE 0.1230627413526434 ref_MAE 0.21870175903333028
u_c taken from control states: [-0.36615582 -0.44626062 -0.31203389 -0.34502342 -0.23234553 -1.80002681
 -0.62420524 -0.29084907 -0.35506809 -0.30617664]
u_c before reduction of space:  [-0.36615582 -0.44626062 -0.31203389 -0.34502342 -0.23234553 -1.80002681
 -0.62420524 -0.29084907 -0.35506809 -0.30617664]
data[u_c] post encoding of state:  [-0.36615582 -0.44626062 -0.31203389 -0.34502342 -0.23234553 -1.80002681
 -0.62420524 -0.29084907 -0.35506809 -0.30617664]
J_b = 0.0, J_o = 150998.1882226076
J_b = 0.5000000000000001, J_o = 4744771.061603048
J_b = 0.00843184805410007, J_o = 46351.20862812638
J_b = 0.009543873618118542, J_o = 38041.116129209964
J_b = 0.026856186352384813, J_o = 17195.287956713153
J_b = 0.034618235601398685, J_o = 14322.91659922326
J_b = 0.0511324097647581, J_o = 11010.78181091549
J_b = 0.07358169732015478, J_o = 9242.58108235036
J_b = 0.09675919027484521, J_o = 8143.601830983236
J_b = 0.09774534780724249, J_o = 7646.04748771449
J_b = 0.10320141147184607, J_o = 7195.045120314811
J_b = 0.11401478413051082, J_o = 6865.774795968319
J_b = 0.13629985334176709, J_o = 6422.177527795525
J_b = 0.17009598393389297, J_o = 6118.765819519314
J_b = 0.1798770475080215, J_o = 5980.432737790996
J_b = 0.18508876032538202, J_o = 6067.795179809853
J_b = 0.18140519564715182, J_o = 5955.935885115022
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615582 -0.44626062 -0.31203389 -0.34502342 -0.23234553 -1.80002681
 -0.62420524 -0.29084907 -0.35506809 -0.30617664]
W_opt:  [-0.01067137  0.00084875  0.02193474  0.02298405  0.01873382  0.00955133
 -0.01879909 -0.06625024 -0.14051391 -0.22120988]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1715 s, v_trunc (Latent to Reduced) = 0.0900, dec (Reduced to Full) = 0.1698, add (DA)= 0.0001decode = 0.2619 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4334 s, inc stats = 2.4358, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.86792072e-07 2.36882123e-07 9.94230235e-07 7.02973053e-07
 8.80291119e-07]
u_DA:    [ 3.07228925e-03  6.53754387e-03  3.94017068e-03  1.89118052e-03
 -9.46899479e-05]
ref_MAE: [0.00805558 0.00987255 0.00446273 0.00560707 0.00061702]
da_MAE:  [3.07200246e-03 6.53730698e-03 3.93917645e-03 1.89047755e-03
 9.55702390e-05]
% 43.59695797521858 da_MAE 0.12358246427410233 ref_MAE 0.21910602662140943
u_c taken from control states: [-0.3661572  -0.44626128 -0.31203141 -0.34502444 -0.23233047 -1.80176323
 -0.62421056 -0.29074212 -0.35433202 -0.30617909]
u_c before reduction of space:  [-0.3661572  -0.44626128 -0.31203141 -0.34502444 -0.23233047 -1.80176323
 -0.62421056 -0.29074212 -0.35433202 -0.30617909]
data[u_c] post encoding of state:  [-0.3661572  -0.44626128 -0.31203141 -0.34502444 -0.23233047 -1.80176323
 -0.62421056 -0.29074212 -0.35433202 -0.30617909]
J_b = 0.0, J_o = 150994.42862638202
J_b = 0.49999999999999967, J_o = 4745107.137718362
J_b = 0.008424915395601511, J_o = 46440.83747802152
J_b = 0.009537445165959172, J_o = 38127.40067615005
J_b = 0.02686743131584989, J_o = 17264.255664465116
J_b = 0.034641269021683345, J_o = 14388.78296615092
J_b = 0.05116212304575614, J_o = 11076.066504980581
J_b = 0.07361008114155439, J_o = 9308.34102806282
J_b = 0.09675952778481668, J_o = 8211.42529019956
J_b = 0.0977166531985501, J_o = 7713.998566516695
J_b = 0.10318687034892851, J_o = 7260.7313504204085
J_b = 0.1140662264472032, J_o = 6929.407397514231
J_b = 0.13652814052737197, J_o = 6482.18479539114
J_b = 0.17066469135753862, J_o = 6174.658498234236
J_b = 0.180728609254072, J_o = 6034.912821587939
J_b = 0.18614933411534199, J_o = 6124.9503773535125
J_b = 0.18231001520229, J_o = 6010.233621495189
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.3661572  -0.44626128 -0.31203141 -0.34502444 -0.23233047 -1.80176323
 -0.62421056 -0.29074212 -0.35433202 -0.30617909]
W_opt:  [-0.01053117  0.00081527  0.02173066  0.02318481  0.01901556  0.00978566
 -0.01882774 -0.06639714 -0.14066402 -0.22138914]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.0688 s, v_trunc (Latent to Reduced) = 0.0484, dec (Reduced to Full) = 0.3213, add (DA)= 0.0001decode = 0.3716 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4405 s, inc stats = 2.4445, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.84499229e-07 2.35190692e-07 9.96312411e-07 7.01861707e-07
 8.83574332e-07]
u_DA:    [ 3.06563845e-03  6.54060076e-03  3.93670723e-03  1.89280797e-03
 -9.46319048e-05]
ref_MAE: [0.00805558 0.00987255 0.00446273 0.00560707 0.00061701]
da_MAE:  [3.06535395e-03 6.54036557e-03 3.93571092e-03 1.89210611e-03
 9.55154791e-05]
% 43.54688437456716 da_MAE 0.12389016478553189 ref_MAE 0.2194567357584739
u_c taken from control states: [-0.36615823 -0.44626197 -0.31202929 -0.34502559 -0.23230199 -1.80340414
 -0.62421505 -0.29056985 -0.35308728 -0.30618017]
u_c before reduction of space:  [-0.36615823 -0.44626197 -0.31202929 -0.34502559 -0.23230199 -1.80340414
 -0.62421505 -0.29056985 -0.35308728 -0.30618017]
data[u_c] post encoding of state:  [-0.36615823 -0.44626197 -0.31202929 -0.34502559 -0.23230199 -1.80340414
 -0.62421505 -0.29056985 -0.35308728 -0.30618017]
J_b = 0.0, J_o = 150994.2646760994
J_b = 0.5000000000000002, J_o = 4745341.8636134425
J_b = 0.008420908018606881, J_o = 46493.77787873131
J_b = 0.009533643650055443, J_o = 38178.68455300796
J_b = 0.02688719195620457, J_o = 17294.116097577033
J_b = 0.03467428402357238, J_o = 14416.470912617566
J_b = 0.05117875376333627, J_o = 11108.642943055369
J_b = 0.0735806887085736, J_o = 9344.436877324668
J_b = 0.09665492957222867, J_o = 8252.248695714194
J_b = 0.09756901067956393, J_o = 7756.024792111271
J_b = 0.10302160798522479, J_o = 7301.939551700478
J_b = 0.11392386284674982, J_o = 6969.652942572244
J_b = 0.1364639789119226, J_o = 6520.507000427969
J_b = 0.17081389772642644, J_o = 6209.407802981876
J_b = 0.18120160349231335, J_o = 6068.317316007193
J_b = 0.18692422692023142, J_o = 6162.529799195543
J_b = 0.1828556576958959, J_o = 6043.452139683244
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615823 -0.44626197 -0.31202929 -0.34502559 -0.23230199 -1.80340414
 -0.62421505 -0.29056985 -0.35308728 -0.30618017]
W_opt:  [-0.01036265  0.00102123  0.02135797  0.02300557  0.01897612  0.01000066
 -0.01868739 -0.06643686 -0.1406463  -0.22148947]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1061 s, v_trunc (Latent to Reduced) = 0.0485, dec (Reduced to Full) = 0.2874, add (DA)= 0.0001decode = 0.3379 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.4441 s, inc stats = 2.4464, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.82792215e-07 2.33459989e-07 9.98098173e-07 7.00604529e-07
 8.89781760e-07]
u_DA:    [ 3.05797953e-03  6.54373742e-03  3.93270180e-03  1.89381292e-03
 -9.46582502e-05]
ref_MAE: [0.00805558 0.00987255 0.00446272 0.00560707 0.00061701]
da_MAE:  [3.05769674e-03 6.54350396e-03 3.93170370e-03 1.89311232e-03
 9.55480320e-05]
% 43.567566255915644 da_MAE 0.12396967753729707 ref_MAE 0.2196780633270002
u_c taken from control states: [-0.36615885 -0.44626263 -0.31202695 -0.3450264  -0.23226201 -1.80498136
 -0.62421852 -0.29034592 -0.35126259 -0.30617977]
u_c before reduction of space:  [-0.36615885 -0.44626263 -0.31202695 -0.3450264  -0.23226201 -1.80498136
 -0.62421852 -0.29034592 -0.35126259 -0.30617977]
data[u_c] post encoding of state:  [-0.36615885 -0.44626263 -0.31202695 -0.3450264  -0.23226201 -1.80498136
 -0.62421852 -0.29034592 -0.35126259 -0.30617977]
J_b = 0.0, J_o = 150985.14820819607
J_b = 0.49999999999999994, J_o = 4745603.8064604495
J_b = 0.008418470330446, J_o = 46514.04954311675
J_b = 0.009530858818890882, J_o = 38200.966605275564
J_b = 0.026905726387815614, J_o = 17298.75302319469
J_b = 0.03470656916479107, J_o = 14419.258781685174
J_b = 0.051190199277919554, J_o = 11117.671166494127
J_b = 0.07353513433246356, J_o = 9358.272712829077
J_b = 0.09650573019676056, J_o = 8272.322484837787
J_b = 0.09735756024313424, J_o = 7778.236121800787
J_b = 0.10276708754571001, J_o = 7324.439778709411
J_b = 0.11365727385941542, J_o = 6992.136812163767
J_b = 0.13617674205300595, J_o = 6542.970957339812
J_b = 0.17054336287111793, J_o = 6229.7478993137165
J_b = 0.18121518843709042, J_o = 6087.905185574264
J_b = 0.18724819655801067, J_o = 6186.630286686796
J_b = 0.18293966296888478, J_o = 6062.944174276949
Following minimisation and before DA stats:
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795 0.00204167
 0.00259055 0.00179313 0.00107136 0.00101358]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05 4.58366148e-03 1.61779461e-03 5.58213430e-04
 4.86296718e-04 3.10917059e-04]
u_0:     [4.48241126 3.44915109 4.99820949 4.77904686 2.59864722 1.2682963
 2.46646438 4.34600195 4.37873007 4.24520892]
u_c:     [-0.36615885 -0.44626263 -0.31202695 -0.3450264  -0.23226201 -1.80498136
 -0.62421852 -0.29034592 -0.35126259 -0.30617977]
W_opt:  [-0.01041143  0.00133458  0.02114215  0.02292545  0.01876751  0.00998034
 -0.01862277 -0.06638116 -0.14046263 -0.22133462]
----------------------------- DA Assimilate ----------------------
minCostFunction = 2.1221 s, v_trunc (Latent to Reduced) = 0.0491, dec (Reduced to Full) = 0.1795, add (DA)= 0.0001decode = 0.2312 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 2.3534 s, inc stats = 2.3559, 
std:     [0.00166143 0.0025344  0.0008404  0.00109426 0.00021795]
mean:    [6.08630643e-04 1.13124167e-03 2.63227494e-04 3.78248634e-04
 5.15200666e-05]
u_0:     [0.00805586 0.00987278 0.00446372 0.00560777 0.0006179 ]
u_c:     [2.81765876e-07 2.31784589e-07 1.00005896e-06 6.99717039e-07
 8.98495451e-07]
u_DA:    [ 3.05419820e-03  6.54548793e-03  3.92959230e-03  1.89445941e-03
 -9.46784640e-05]
ref_MAE: [0.00805558 0.00987255 0.00446272 0.00560707 0.000617  ]
da_MAE:  [3.05391644e-03 6.54525614e-03 3.92859224e-03 1.89375970e-03
 9.55769594e-05]
% 43.65404139312291 da_MAE 0.12381253511387483 ref_MAE 0.21973631858445897
\% improve_point: 25.17, mse_ref_points: 2.7965246871915533e-05, mse_da_points: 2.0419647404587797e-05, % improve_overlap: 6.75, mse_ref_overlap: 0.24141, mse_da_overlap: 0.21308
DA - - L2: 2191.97, L1: 2499.64, % Improve: 39.00%, DA_MAE: 0.11, mse_ref: 0.25, mse_DA: 0.183, time(s): 3.3643s,
Results of DA at 2020-08-28 13:04:17.289639. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              34.841807      0.142254  ...  17.125342     5.390084
1              34.354524      0.142248  ...   6.206439     6.200343
2              33.928432      0.142426  ...   8.023500     8.017549
3              33.409558      0.142762  ...   7.682323     7.676315
4              33.368022      0.143154  ...   5.832922     5.826973
..                   ...           ...  ...        ...          ...
102            43.730338      0.218702  ...   2.362686     2.356876
103            43.596958      0.219106  ...   2.439157     2.433416
104            43.546884      0.219457  ...   2.449467     2.440531
105            43.567566      0.219678  ...   2.449702     2.444072
106            43.654041      0.219736  ...   2.359335     2.353380

[107 rows x 20 columns]
data fp  /home/mredstone/unstructuredCAE/data/subdomain_6/
domain, other, pickle, dim 6 ['8'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_40P_150E_1D0L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_6/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 40                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
91, 85, 32, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
89, 83, 30, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
87, 81, 28, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
85, 79, 26, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
83, 77, 24, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
81, 75, 22, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
79, 73, 20, stride=(2, 2, 2, )  kernel_size=(3, 3, 2, )  padding=(0, 1, 1, )  
39, 37, 11, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 1, 0, )  
19, 19, 5, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 1, )  
9, 9, 3, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
5, 5, 2, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
OUT: 3, 3, 1, Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
When creating TucodecEncode1D, inputSize =  26032 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
Number of parameters: 567553
------------------------------ Training subdomain 6 at 2020-08-28 13:04:26.653917. ------------------------------
Loading data started 2020-08-28 13:04:26.654016
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fab8838a588>
Loading data finished 2020-08-28 13:04:41.443056
Loop AE Train begins at  13:04:41.449177
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [1/150], TRAIN: -loss:13273.76, av_diff: 0.30, time taken (m): 0.07m
epoch [1/150], TEST: -loss:14363.3149, time taken(m): 0.02m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [6/150], TRAIN: -loss:7101.86, av_diff: 0.04, time taken (m): 0.06m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [11/150], TRAIN: -loss:6458.32, av_diff: 0.01, time taken (m): 0.06m
epoch [11/150], TEST: -loss:11308.0537, time taken(m): 0.02m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [16/150], TRAIN: -loss:6161.76, av_diff: 0.01, time taken (m): 0.05m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [21/150], TRAIN: -loss:5967.57, av_diff: 0.01, time taken (m): 0.06m
epoch [21/150], TEST: -loss:10731.9553, time taken(m): 0.03m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [26/150], TRAIN: -loss:5790.73, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [31/150], TRAIN: -loss:5663.61, av_diff: 0.02, time taken (m): 0.06m
epoch [31/150], TEST: -loss:10777.1128, time taken(m): 0.02m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [36/150], TRAIN: -loss:5486.85, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [41/150], TRAIN: -loss:5278.09, av_diff: 0.02, time taken (m): 0.05m
epoch [41/150], TEST: -loss:10814.7847, time taken(m): 0.03m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [46/150], TRAIN: -loss:5070.75, av_diff: 0.01, time taken (m): 0.06m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [51/150], TRAIN: -loss:4925.05, av_diff: 0.01, time taken (m): 0.06m
epoch [51/150], TEST: -loss:10497.5957, time taken(m): 0.02m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [56/150], TRAIN: -loss:4735.95, av_diff: 0.02, time taken (m): 0.07m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [61/150], TRAIN: -loss:4602.11, av_diff: 0.02, time taken (m): 0.06m
epoch [61/150], TEST: -loss:10266.9285, time taken(m): 0.02m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [66/150], TRAIN: -loss:4440.75, av_diff: 0.02, time taken (m): 0.04m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [71/150], TRAIN: -loss:4245.59, av_diff: 0.01, time taken (m): 0.06m
epoch [71/150], TEST: -loss:9858.2173, time taken(m): 0.02m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [76/150], TRAIN: -loss:4137.45, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [81/150], TRAIN: -loss:4000.24, av_diff: 0.01, time taken (m): 0.03m
epoch [81/150], TEST: -loss:9518.6580, time taken(m): 0.01m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [86/150], TRAIN: -loss:3848.86, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [91/150], TRAIN: -loss:3691.17, av_diff: 0.01, time taken (m): 0.05m
epoch [91/150], TEST: -loss:9239.6433, time taken(m): 0.02m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [96/150], TRAIN: -loss:3584.42, av_diff: 0.01, time taken (m): 0.16m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [101/150], TRAIN: -loss:3477.88, av_diff: 0.01, time taken (m): 0.03m
epoch [101/150], TEST: -loss:8942.6113, time taken(m): 0.01m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [106/150], TRAIN: -loss:3416.93, av_diff: 0.01, time taken (m): 0.04m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [111/150], TRAIN: -loss:3280.42, av_diff: 0.01, time taken (m): 0.03m
epoch [111/150], TEST: -loss:8616.0271, time taken(m): 0.01m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [116/150], TRAIN: -loss:3210.01, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [121/150], TRAIN: -loss:3081.16, av_diff: 0.01, time taken (m): 0.04m
epoch [121/150], TEST: -loss:8374.9048, time taken(m): 0.14m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [126/150], TRAIN: -loss:2942.19, av_diff: 0.01, time taken (m): 0.18m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [131/150], TRAIN: -loss:2843.85, av_diff: 0.01, time taken (m): 0.11m
epoch [131/150], TEST: -loss:8096.5176, time taken(m): 0.11m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [136/150], TRAIN: -loss:2790.39, av_diff: 0.01, time taken (m): 0.22m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [141/150], TRAIN: -loss:2710.13, av_diff: 0.01, time taken (m): 0.19m
epoch [141/150], TEST: -loss:7921.4827, time taken(m): 0.10m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [146/150], TRAIN: -loss:2598.05, av_diff: 0.02, time taken (m): 0.28m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [150/150], TRAIN: -loss:2553.49, av_diff: 0.01, time taken (m): 0.21m
epoch [150/150], TEST: -loss:7707.3818, time taken(m): 0.09m
Loop AE Train Ends at  13:17:28.055635
------------------------------ DA subdomain 6 at 2020-08-28 13:17:28.165999. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 26032) , test_X = (107, 26032), X = (537, 26032)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_40_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
u_c before reduction of space:  [-0.8531082  -0.80088433  0.03712867 -0.14295814 -0.99493482 -0.66263901
 -0.84611558  0.09697116 -0.648397   -1.36865512]
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
u_c taken from control states: [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
u_c before reduction of space:  [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
data[u_c] post encoding of state:  [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
Shape of w_0 =  (429,)
J_b = 0.0, J_o = 406666.58442652266
J_b = 0.5, J_o = 11594255.680779794
J_b = 0.004647428652760699, J_o = 277839.04720669537
J_b = 0.01227399450944837, J_o = 192599.41823139897
J_b = 0.01795017911209346, J_o = 163360.21982001123
J_b = 0.0291840496256828, J_o = 130448.20389412744
J_b = 0.038490269583999204, J_o = 112837.41087878938
J_b = 0.06280993499854971, J_o = 88215.12614088759
J_b = 0.09396848800317434, J_o = 78474.93723490472
J_b = 0.09897609120303916, J_o = 69694.68742505062
J_b = 0.10728648544811745, J_o = 63872.48498223983
J_b = 0.1246923453076221, J_o = 58321.45144133174
J_b = 0.1694797330939186, J_o = 49191.31741859205
J_b = 0.2741291122449703, J_o = 54393.9673960527
J_b = 0.20515167509459892, J_o = 45477.732859659816
J_b = 0.24195740792166798, J_o = 40904.064867671514
J_b = 0.2675622784795292, J_o = 41506.97954391374
J_b = 0.2528157605176286, J_o = 39879.52244199013
J_b = 0.265531700637376, J_o = 38073.899562876846
J_b = 0.2723767592106524, J_o = 36822.16283939533
J_b = 0.29130127614776913, J_o = 34631.386709840524
J_b = 0.31756082956828724, J_o = 32579.50974369129
J_b = 0.3786502243525866, J_o = 33770.99565372146
J_b = 0.34094762586493493, J_o = 31443.21984206938
J_b = 0.36594749842983565, J_o = 29870.782946202922
J_b = 0.38195201975809834, J_o = 28787.141287791776
J_b = 0.4061759975922199, J_o = 27402.724519608288
J_b = 0.44580398140335337, J_o = 27031.393415788283
J_b = 0.44266823815082784, J_o = 25995.668950285562
J_b = 0.44493757621694185, J_o = 25559.692318512676
J_b = 0.456451957063925, J_o = 25158.099539274775
J_b = 0.4864157881709951, J_o = 24918.571762998345
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
W_opt:  [-0.00818243 -0.01388272 -0.00942734  0.00062346  0.01682923  0.02994261
  0.03429331 -0.01279141 -0.10409683 -0.23432079]
----------------------------- DA Assimilate ----------------------
minCostFunction = 8.9015 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1867, add (DA)= 0.0001decode = 0.2929 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 9.1945 s, inc stats = 81.6169, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95971306 2.8606017  3.44302222 3.07860686 2.45294002]
u_DA:    [3.8929712  1.92557666 3.0146016  1.64600809 2.66530052]
ref_MAE: [0.11925866 0.69882131 0.90408743 1.22605341 0.07630631]
da_MAE:  [0.06674186 0.93502504 0.42842061 1.43259877 0.2123605 ]
% 17.87667269634517 da_MAE 0.006172783017117173 ref_MAE 0.007516479445959393
u_c taken from control states: [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
u_c before reduction of space:  [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
data[u_c] post encoding of state:  [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
J_b = 0.0, J_o = 421088.4660746515
J_b = 0.5000000000000001, J_o = 10601428.54643021
J_b = 0.005401445942664739, J_o = 282250.5638647008
J_b = 0.01413443379713269, J_o = 203083.68903230267
J_b = 0.017399555458160083, J_o = 178903.85273537601
J_b = 0.03219064119784543, J_o = 134476.58403547952
J_b = 0.040909622197198015, J_o = 121075.66104042549
J_b = 0.06544293929741372, J_o = 102334.37874190102
J_b = 0.0991410760200887, J_o = 98152.55378395022
J_b = 0.09110263731381185, J_o = 88186.85223936844
J_b = 0.09280699217736356, J_o = 84775.61403521369
J_b = 0.10381053735961425, J_o = 80753.80559610341
J_b = 0.12747435129960252, J_o = 74941.56491416629
J_b = 0.1906843694328251, J_o = 67104.57611769246
J_b = 0.2682131229163085, J_o = 77593.15706922126
J_b = 0.20882057840759355, J_o = 65585.88135573374
J_b = 0.23030920152882256, J_o = 62911.940693887576
J_b = 0.2341164722143376, J_o = 61957.205577653986
J_b = 0.23906505673542255, J_o = 61041.53204948065
J_b = 0.25761797805232534, J_o = 59274.8637580918
J_b = 0.2891114034138656, J_o = 57264.829017870245
J_b = 0.34964600480992597, J_o = 56373.301356520824
J_b = 0.33874845993398844, J_o = 54894.966713909846
J_b = 0.3376195950791636, J_o = 54328.73582877669
J_b = 0.34683382541310154, J_o = 53548.33331408405
J_b = 0.37610908231202456, J_o = 52178.346554658936
J_b = 0.42584157932240707, J_o = 53928.15823394452
J_b = 0.39075964761254234, J_o = 51677.061725229105
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
W_opt:  [-0.01270935 -0.00754545 -0.00508844  0.004552    0.02157925  0.03167746
  0.02887422 -0.02483345 -0.11258216 -0.22883265]
----------------------------- DA Assimilate ----------------------
minCostFunction = 9.5134 s, v_trunc (Latent to Reduced) = 0.1021, dec (Reduced to Full) = 0.2998, add (DA)= 0.0001decode = 0.4041 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 9.9177 s, inc stats = 9.9341, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95948174 2.86219835 3.44235992 3.07760999 2.45160571]
u_DA:    [3.89395474 1.94974052 2.99983416 1.66915395 2.65028828]
ref_MAE: [0.11902734 0.70041795 0.90342514 1.22505654 0.074972  ]
da_MAE:  [0.065527   0.91245782 0.44252576 1.40845605 0.19868257]
% 17.94248462655435 da_MAE 0.006170374213824572 ref_MAE 0.007519572321612537
u_c taken from control states: [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
u_c before reduction of space:  [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
data[u_c] post encoding of state:  [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
J_b = 0.0, J_o = 453265.6860549223
J_b = 0.5, J_o = 9480042.086916223
J_b = 0.006591689169527755, J_o = 298788.4567951144
J_b = 0.016816522387305195, J_o = 232905.0443005605
J_b = 0.017202125186822036, J_o = 207916.2104398775
J_b = 0.025341801659374958, J_o = 174568.81709607656
J_b = 0.030955091641915698, J_o = 162405.4359269524
J_b = 0.05176300379424077, J_o = 136742.45357567904
J_b = 0.0776329959999405, J_o = 130745.72975906087
J_b = 0.07821902043659415, J_o = 120210.12011006288
J_b = 0.08347857702894682, J_o = 115209.35835723083
J_b = 0.09540776652178268, J_o = 111199.76853222177
J_b = 0.11512937266556927, J_o = 105584.88558270558
J_b = 0.16736854872909054, J_o = 101023.65375458205
J_b = 0.19031905392925763, J_o = 98807.13834269831
J_b = 0.17807566205451358, J_o = 96172.45054484808
J_b = 0.17876047537035228, J_o = 95502.41678488103
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
W_opt:  [ 0.0038046   0.01165601  0.01226778  0.01135773  0.00853764 -0.00399088
 -0.02820558 -0.07433314 -0.13180586 -0.19006777]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.5760 s, v_trunc (Latent to Reduced) = 0.1088, dec (Reduced to Full) = 0.2056, add (DA)= 0.0002decode = 0.3170 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.8933 s, inc stats = 6.9364, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95925042 2.86385592 3.44170924 3.07663321 2.45090041]
u_DA:    [3.89436083 1.96610939 3.00213311 1.67691152 2.64431465]
ref_MAE: [0.11879602 0.70207552 0.90277445 1.22407976 0.0742667 ]
da_MAE:  [0.06488959 0.89774653 0.43957613 1.39972169 0.19341424]
% 18.140515942526207 da_MAE 0.00615819255752516 ref_MAE 0.0075228822028752034
u_c taken from control states: [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
u_c before reduction of space:  [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
data[u_c] post encoding of state:  [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
J_b = 0.0, J_o = 497482.90205921256
J_b = 0.49999999999999983, J_o = 8586813.18718946
J_b = 0.008073793585594884, J_o = 322350.4566450198
J_b = 0.019381398229925167, J_o = 278808.4850060432
J_b = 0.017238818799312394, J_o = 243682.7627003895
J_b = 0.02012758771767432, J_o = 219966.06104110647
J_b = 0.02765446037792538, J_o = 203097.11777447446
J_b = 0.038008899253344317, J_o = 183863.51505501842
J_b = 0.06250070909033544, J_o = 165367.6380622089
J_b = 0.07504490813685358, J_o = 155335.94189605222
J_b = 0.08329623540330496, J_o = 149250.3011400996
J_b = 0.10376881092216668, J_o = 142451.3119134368
J_b = 0.12469727121863769, J_o = 139336.29359325246
J_b = 0.12470406045635243, J_o = 136362.75104915764
J_b = 0.13349678694726144, J_o = 133056.7783831982
J_b = 0.14881217112046655, J_o = 130538.99284784251
J_b = 0.18077884040159836, J_o = 136340.9966088342
J_b = 0.15633484611736456, J_o = 129574.20397835805
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
W_opt:  [-0.00214956  0.01022496  0.01415954  0.01565268  0.01218019 -0.00304427
 -0.03033857 -0.07601448 -0.13199242 -0.18505514]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.7483 s, v_trunc (Latent to Reduced) = 0.1410, dec (Reduced to Full) = 0.6751, add (DA)= 0.0001decode = 0.8183 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.5667 s, inc stats = 7.5837, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95902457 2.86543938 3.44108005 3.07580368 2.45092479]
u_DA:    [3.89575648 1.97650062 2.99928484 1.72566383 2.61576562]
ref_MAE: [0.11857017 0.70365898 0.90214526 1.22325023 0.07429108]
da_MAE:  [0.06326809 0.88893876 0.44179521 1.35013985 0.16484084]
% 18.194589718721854 da_MAE 0.0061566466033936606 ref_MAE 0.007525965070311078
u_c taken from control states: [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
u_c before reduction of space:  [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
data[u_c] post encoding of state:  [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
J_b = 0.0, J_o = 541282.5446393499
J_b = 0.5000000000000001, J_o = 7815942.932913454
J_b = 0.010060503926212985, J_o = 336936.7136631108
J_b = 0.02121609471753664, J_o = 315140.0727265153
J_b = 0.018331293951459757, J_o = 266744.5476917291
J_b = 0.02095051057292992, J_o = 245299.1047347713
J_b = 0.028900858435525183, J_o = 226980.98699355288
J_b = 0.037876659055608525, J_o = 209274.21504712067
J_b = 0.06202163391970684, J_o = 187142.60298164634
J_b = 0.08060628683542957, J_o = 176781.71551060665
J_b = 0.08636275021206138, J_o = 170122.96100649604
J_b = 0.09941301900019596, J_o = 163683.87736830785
J_b = 0.1113075963563845, J_o = 159853.01209612977
J_b = 0.14446584394535622, J_o = 154476.79461600777
J_b = 0.17132511089476946, J_o = 151860.41541162724
J_b = 0.16810511734718703, J_o = 150256.1760899166
J_b = 0.1672802116137655, J_o = 149108.6761202152
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
W_opt:  [-0.01276277  0.00633642  0.01360705  0.01889661  0.01875999  0.00455946
 -0.02629253 -0.07483709 -0.13619925 -0.1951487 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.6584 s, v_trunc (Latent to Reduced) = 0.1025, dec (Reduced to Full) = 0.2648, add (DA)= 0.0001decode = 0.3699 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 7.0286 s, inc stats = 7.0513, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95880786 2.86683621 3.4404808  3.07524578 2.4516614 ]
u_DA:    [3.89593373 1.9611863  2.99207366 1.69884047 2.64943307]
ref_MAE: [0.11835346 0.70505581 0.90154602 1.22269233 0.07502769]
da_MAE:  [0.06287413 0.90564991 0.44840714 1.3764053  0.19777167]
% 17.700433516021548 da_MAE 0.0061960681058020346 ref_MAE 0.007528676480948712
u_c taken from control states: [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
u_c before reduction of space:  [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
data[u_c] post encoding of state:  [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
J_b = 0.0, J_o = 591970.4967840061
J_b = 0.5, J_o = 7342234.3323470205
J_b = 0.011886673041493908, J_o = 359943.4334398848
J_b = 0.02049549197108099, J_o = 310083.64583058335
J_b = 0.026253293017914434, J_o = 269661.9976229799
J_b = 0.032474195168116136, J_o = 256178.669913336
J_b = 0.0381441694601356, J_o = 244813.95141864443
J_b = 0.05193058378736661, J_o = 224557.14215772078
J_b = 0.06961079298440266, J_o = 207655.9665863883
J_b = 0.10703813527523492, J_o = 194707.85993457408
J_b = 0.11403315799362905, J_o = 187232.87964681408
J_b = 0.11736839952226721, J_o = 184263.94519183523
J_b = 0.1283040931570904, J_o = 180487.74111869742
J_b = 0.1535669115162616, J_o = 176600.7316437497
J_b = 0.17886038964914863, J_o = 172854.29203631272
J_b = 0.18948641649341566, J_o = 170857.29249928048
J_b = 0.21136791056983187, J_o = 171144.24592348412
J_b = 0.19929560814468708, J_o = 169925.2498577949
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
W_opt:  [-0.0218935   0.00106489  0.01411984  0.02403446  0.0246685   0.01004859
 -0.02202336 -0.0737809  -0.13924622 -0.20227354]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.5783 s, v_trunc (Latent to Reduced) = 0.1016, dec (Reduced to Full) = 0.2495, add (DA)= 0.0001decode = 0.3533 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.9318 s, inc stats = 7.9423, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95860674 2.86790726 3.43992101 3.07506961 2.45312898]
u_DA:    [3.89962509 1.95397334 2.99715778 1.70752579 2.65639199]
ref_MAE: [0.11815234 0.70612686 0.90098623 1.22251616 0.07649527]
da_MAE:  [0.05898164 0.91393392 0.44276323 1.36754382 0.20326301]
% 17.3231561450609 da_MAE 0.006226248255097758 ref_MAE 0.00753082479300013
u_c taken from control states: [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
u_c before reduction of space:  [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
data[u_c] post encoding of state:  [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
J_b = 0.0, J_o = 665300.294152221
J_b = 0.4999999999999998, J_o = 7596839.621813044
J_b = 0.012336739336423956, J_o = 415935.7480553568
J_b = 0.020472099966610837, J_o = 354368.6707098385
J_b = 0.03211940464278528, J_o = 309863.2077051742
J_b = 0.0366734453602824, J_o = 297770.0067610939
J_b = 0.05529910589150538, J_o = 268009.41468809603
J_b = 0.07162240327614446, J_o = 251346.06795209783
J_b = 0.12260187277449044, J_o = 236127.19989822863
J_b = 0.13197288359527268, J_o = 225397.92293140088
J_b = 0.13138395500585098, J_o = 222355.22948150517
J_b = 0.14284967655266026, J_o = 217367.0677321775
J_b = 0.17803501859409981, J_o = 214062.29315709948
J_b = 0.18893975242199026, J_o = 210111.79757954174
J_b = 0.21090406187306193, J_o = 207316.98056727654
J_b = 0.22473752050805837, J_o = 205825.48931439186
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
W_opt:  [-0.03299858 -0.00733765  0.01500016  0.02904354  0.02982203  0.01511859
 -0.01674234 -0.06971141 -0.13643724 -0.20242054]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.1628 s, v_trunc (Latent to Reduced) = 0.1088, dec (Reduced to Full) = 0.6477, add (DA)= 0.0002decode = 0.7588 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.9218 s, inc stats = 6.9516, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95842699 2.86857279 3.43940488 3.07534712 2.45528936]
u_DA:    [3.90030779 1.95283202 3.00987482 1.74821458 2.67421727]
ref_MAE: [0.11797259 0.70679239 0.9004701  1.22279367 0.07865565]
da_MAE:  [0.0581192  0.91574077 0.42953006 1.32713254 0.21892791]
% 17.234981488550158 da_MAE 0.006234025510544336 ref_MAE 0.007532198533468474
u_c taken from control states: [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
u_c before reduction of space:  [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
data[u_c] post encoding of state:  [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
J_b = 0.0, J_o = 745478.4419546626
J_b = 0.49999999999999994, J_o = 8383437.076934032
J_b = 0.011556964292045797, J_o = 491800.54197718203
J_b = 0.02187843488841107, J_o = 456889.0619825548
J_b = 0.021162293666594056, J_o = 406182.0988591775
J_b = 0.02736871340059652, J_o = 370255.5200360039
J_b = 0.03694833506148671, J_o = 352728.0851374088
J_b = 0.05142395592780454, J_o = 326577.5589897514
J_b = 0.07879761498462307, J_o = 305824.190804889
J_b = 0.08918415574124387, J_o = 295902.99907946313
J_b = 0.11104505266143595, J_o = 283575.0580130328
J_b = 0.14452976672861956, J_o = 276932.8435010903
J_b = 0.15834637725126216, J_o = 270566.1381358818
J_b = 0.16227257288512562, J_o = 267666.031256429
J_b = 0.17923233858060902, J_o = 262949.25409088924
J_b = 0.21299594874023314, J_o = 258953.88144411257
J_b = 0.25772576763718114, J_o = 256350.56973739152
J_b = 0.2493824829863551, J_o = 254743.21721263794
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
W_opt:  [-0.04256187 -0.01657993  0.01643953  0.03563121  0.03657326  0.0222243
 -0.00937416 -0.06463593 -0.13515831 -0.20672625]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.9353 s, v_trunc (Latent to Reduced) = 0.1033, dec (Reduced to Full) = 0.3283, add (DA)= 0.0001decode = 0.4338 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.3692 s, inc stats = 7.4104, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95827183 2.86878598 3.43893538 3.07613228 2.45807752]
u_DA:    [3.90191764 1.95979201 3.03222223 1.7884272  2.64491875]
ref_MAE: [0.11781743 0.70700558 0.9000006  1.22357883 0.08144381]
da_MAE:  [0.05635419 0.90899397 0.40671315 1.28770508 0.18684124]
% 17.72157177807048 da_MAE 0.006197726540786389 ref_MAE 0.007532626321044038
u_c taken from control states: [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
u_c before reduction of space:  [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
data[u_c] post encoding of state:  [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
J_b = 0.0, J_o = 792427.7050013194
J_b = 0.4999999999999997, J_o = 8510776.960501209
J_b = 0.011487175163246231, J_o = 537964.0168625526
J_b = 0.022244404982226396, J_o = 500614.4971649416
J_b = 0.021444600911314712, J_o = 448275.67962541676
J_b = 0.028012889510113506, J_o = 408836.4172338466
J_b = 0.03862962139961305, J_o = 389418.0139931591
J_b = 0.05370657328412837, J_o = 362617.521727558
J_b = 0.08224011488524319, J_o = 341349.08088795556
J_b = 0.09246052834497705, J_o = 331624.84843232343
J_b = 0.11250520690755851, J_o = 320226.1585093977
J_b = 0.1443088081588861, J_o = 313239.0716324105
J_b = 0.1625654386575992, J_o = 307153.19348937937
J_b = 0.16604189672276679, J_o = 304296.8667394316
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
W_opt:  [-0.01528448 -0.00475864  0.01072643  0.01910886  0.0151762  -0.00118512
 -0.02889345 -0.07120252 -0.12164255 -0.16903427]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8211 s, v_trunc (Latent to Reduced) = 0.1030, dec (Reduced to Full) = 0.3766, add (DA)= 0.0001decode = 0.4817 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3030 s, inc stats = 5.3315, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95814197 2.86844629 3.43851228 3.07743919 2.46136035]
u_DA:    [3.90153659 1.96599806 3.09080364 1.81174125 2.64797424]
ref_MAE: [0.11768757 0.70666589 0.8995775  1.22488574 0.08472664]
da_MAE:  [0.05660538 0.90244822 0.34770865 1.26569794 0.18661389]
% 18.389154667685094 da_MAE 0.00614703797132961 ref_MAE 0.007532133684315126
u_c taken from control states: [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
u_c before reduction of space:  [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
data[u_c] post encoding of state:  [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
J_b = 0.0, J_o = 809554.5583730134
J_b = 0.4999999999999998, J_o = 8402709.487533748
J_b = 0.01158070356252363, J_o = 556733.2965660156
J_b = 0.022387752667546005, J_o = 516112.2532281798
J_b = 0.02223392284505267, J_o = 463223.81373534276
J_b = 0.030508714611352267, J_o = 420454.4564450801
J_b = 0.04099645865793999, J_o = 402936.8018252557
J_b = 0.058372545254009756, J_o = 373771.91868956777
J_b = 0.08517543667226674, J_o = 353777.28946699447
J_b = 0.09489364272075003, J_o = 345339.01313308574
J_b = 0.11751426302948902, J_o = 333096.5810212473
J_b = 0.14922636225902092, J_o = 325888.19525539596
J_b = 0.1610346572970281, J_o = 321088.77013367764
J_b = 0.1675849351634266, J_o = 317995.80585371057
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
W_opt:  [-0.01439123 -0.00264649  0.00701124  0.01539475  0.01460503 -0.00020096
 -0.02728939 -0.07010986 -0.12169418 -0.17025172]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1918 s, v_trunc (Latent to Reduced) = 0.1648, dec (Reduced to Full) = 1.0369, add (DA)= 0.0001decode = 1.2039 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.3959 s, inc stats = 6.4269, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95803318 2.86753935 3.43812562 3.07919254 2.46480604]
u_DA:    [3.90228344 1.96213056 3.09782493 1.77545953 2.65181283]
ref_MAE: [0.11757878 0.70575895 0.89919084 1.22663909 0.08817233]
da_MAE:  [0.05574974 0.90540879 0.34030069 1.30373301 0.18700678]
% 18.343367647131544 da_MAE 0.006149206861749145 ref_MAE 0.007530566329476033
u_c taken from control states: [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
u_c before reduction of space:  [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
data[u_c] post encoding of state:  [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
J_b = 0.0, J_o = 777051.2355946329
J_b = 0.4999999999999997, J_o = 7976681.039584277
J_b = 0.012015719722429943, J_o = 526286.1555155746
J_b = 0.022291171070656517, J_o = 476385.7091904664
J_b = 0.025090855767318634, J_o = 423805.1710556996
J_b = 0.038697234839255745, J_o = 384263.9611900738
J_b = 0.04473263109080614, J_o = 372445.9467968887
J_b = 0.0715890933674058, J_o = 334946.81147587125
J_b = 0.09485116825191263, J_o = 321840.49662310083
J_b = 0.10501294643258835, J_o = 315315.5664985987
J_b = 0.1265161629928047, J_o = 305674.33826793457
J_b = 0.15095303799434243, J_o = 301318.1571840477
J_b = 0.15563219460713246, J_o = 297024.00486219395
J_b = 0.16309004150066786, J_o = 293962.05924017006
J_b = 0.1798527649423074, J_o = 290426.9145235135
J_b = 0.22224946009507027, J_o = 287842.6686177223
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
W_opt:  [-0.02816858 -0.0078043   0.00206255  0.01533559  0.02469142  0.01672762
 -0.01028242 -0.06515882 -0.13549878 -0.20524259]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.6557 s, v_trunc (Latent to Reduced) = 0.1015, dec (Reduced to Full) = 0.3654, add (DA)= 0.0001decode = 0.4698 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.1257 s, inc stats = 7.1456, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95793666 2.86609556 3.43775667 3.08119687 2.46791533]
u_DA:    [3.90408074 1.95065621 3.08174136 1.73763252 2.65894835]
ref_MAE: [0.11748226 0.70431517 0.89882188 1.22864342 0.09128162]
da_MAE:  [0.05385593 0.91543935 0.3560153  1.34356436 0.19103302]
% 18.03979738489457 da_MAE 0.006169744605070035 ref_MAE 0.007527732250789896
\% improve_point: 13.02, mse_ref_points: 3.515884780171926e-05, mse_da_points: 3.058122277902106e-05, % improve_overlap: 13.02, mse_ref_overlap: 0.91577, mse_da_overlap: 0.79657
DA - - L2: 176227.91, L1: 9717.08, % Improve: 17.90%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.796, time(s): 15.0663s,
u_c taken from control states: [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
u_c before reduction of space:  [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
data[u_c] post encoding of state:  [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
J_b = 0.0, J_o = 710725.5139660775
J_b = 0.5, J_o = 7324273.266248098
J_b = 0.012697165046271611, J_o = 464212.102796776
J_b = 0.021605975926589978, J_o = 379801.0608683787
J_b = 0.05376562851363682, J_o = 395507.2469332606
J_b = 0.033382258172112184, J_o = 345897.54775335675
J_b = 0.044376992140290276, J_o = 326723.19216358446
J_b = 0.04925530362675614, J_o = 317128.37018062087
J_b = 0.0685284999834456, J_o = 291137.2148787594
J_b = 0.08367665487372275, J_o = 276298.7902771023
J_b = 0.12052882372035842, J_o = 261558.58032091477
J_b = 0.13474785791159252, J_o = 254656.7825927693
J_b = 0.1361999054271364, J_o = 251673.56475510407
J_b = 0.14958917943686947, J_o = 246845.4284624063
J_b = 0.17354340942788993, J_o = 243668.26153629398
J_b = 0.18791602405806207, J_o = 240666.52254231006
J_b = 0.21990961576004073, J_o = 236834.65163793787
J_b = 0.23510043012899084, J_o = 235191.44456066884
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
W_opt:  [-0.0188255  -0.0068351   0.00088504  0.01252223  0.02595511  0.02587942
  0.00132733 -0.05650348 -0.13363953 -0.21211536]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.8929 s, v_trunc (Latent to Reduced) = 0.1214, dec (Reduced to Full) = 0.2893, add (DA)= 0.0002decode = 0.4130 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.3062 s, inc stats = 7.3219, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95784129 2.86437295 3.43738685 3.08325985 2.47020013]
u_DA:    [3.89664976 1.96190317 3.04443579 1.74213674 2.67572166]
ref_MAE: [0.11738689 0.70259255 0.89845206 1.2307064  0.09356642]
da_MAE:  [0.06119153 0.90246978 0.39295106 1.3411231  0.20552154]
% 18.401185032641155 da_MAE 0.006139278726878209 ref_MAE 0.007523735153916198
u_c taken from control states: [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
u_c before reduction of space:  [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
data[u_c] post encoding of state:  [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
J_b = 0.0, J_o = 657805.9308549743
J_b = 0.5, J_o = 7161521.451141309
J_b = 0.01214870179300625, J_o = 428203.3260222033
J_b = 0.023179172388894314, J_o = 374400.73097060027
J_b = 0.027776323741491894, J_o = 323682.7466456387
J_b = 0.03876110807373157, J_o = 299325.59909868496
J_b = 0.04338427417561193, J_o = 288833.09087404446
J_b = 0.06707357209479255, J_o = 255775.97364890407
J_b = 0.08858751321954368, J_o = 239108.5748661179
J_b = 0.1272820655782702, J_o = 228958.82234353948
J_b = 0.13704171922971792, J_o = 221725.5585057232
J_b = 0.13312650036260182, J_o = 219428.3055094604
J_b = 0.13782775512654916, J_o = 215643.31654817142
J_b = 0.15451215338970084, J_o = 212408.26206870525
J_b = 0.18350266598866746, J_o = 209172.00990990383
J_b = 0.22203958609347976, J_o = 206199.41879996445
J_b = 0.2164590678899666, J_o = 205332.2861909085
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
W_opt:  [-0.00432599 -0.00644195 -0.00245062  0.00638429  0.017883    0.01924345
 -0.00462263 -0.05906789 -0.13194808 -0.20641005]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.4139 s, v_trunc (Latent to Reduced) = 0.0996, dec (Reduced to Full) = 1.4972, add (DA)= 0.0001decode = 1.5989 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.0131 s, inc stats = 7.0274, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95774023 2.86262327 3.43700345 3.08521932 2.47138718]
u_DA:    [3.89662496 1.9598132  3.02868327 1.71978703 2.67147803]
ref_MAE: [0.11728582 0.70084287 0.89806867 1.23266587 0.09475347]
da_MAE:  [0.06111527 0.90281007 0.40832018 1.36543229 0.20009085]
% 18.522774842420965 da_MAE 0.006126114146995447 ref_MAE 0.007518805574376626
u_c taken from control states: [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
u_c before reduction of space:  [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
data[u_c] post encoding of state:  [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
J_b = 0.0, J_o = 552077.7996061819
J_b = 0.4999999999999999, J_o = 8393100.306245647
J_b = 0.008861976940969202, J_o = 362672.2274157813
J_b = 0.021411949220919983, J_o = 309611.6848949227
J_b = 0.02004023590679909, J_o = 268967.35236274905
J_b = 0.02546892681229011, J_o = 235168.3158239693
J_b = 0.03454574026720154, J_o = 218548.15292166057
J_b = 0.04782133846905166, J_o = 195545.42422416035
J_b = 0.07602038397383203, J_o = 173336.27340311598
J_b = 0.09178667201840972, J_o = 163996.02576835154
J_b = 0.10397961478895382, J_o = 158011.35568406168
J_b = 0.12142181701076786, J_o = 152518.5276289964
J_b = 0.13235456276725424, J_o = 148932.88351530122
J_b = 0.14080007238839565, J_o = 146463.01322779636
J_b = 0.1566770214514958, J_o = 143407.1460927742
J_b = 0.19061804721442904, J_o = 145703.79246766822
J_b = 0.16760904295888576, J_o = 142508.32861034304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
W_opt:  [ 1.00352152e-02 -1.08736427e-04 -1.34970961e-04  2.00708907e-03
  4.54818828e-03 -7.40035121e-04 -2.32242513e-02 -6.85397468e-02
 -1.30427669e-01 -1.92856383e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.5855 s, v_trunc (Latent to Reduced) = 0.1143, dec (Reduced to Full) = 0.7064, add (DA)= 0.0001decode = 0.8234 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.4091 s, inc stats = 7.4287, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95762796 2.86095799 3.43659404 3.08690017 2.47128244]
u_DA:    [3.89667616 1.94781211 3.02848367 1.6722805  2.6939586 ]
ref_MAE: [0.11717356 0.6991776  0.89765926 1.23434672 0.09464873]
da_MAE:  [0.0609518  0.91314588 0.40811038 1.41461967 0.22267617]
% 18.302143477137115 da_MAE 0.0061378971456739475 ref_MAE 0.007512923113174061
u_c taken from control states: [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
u_c before reduction of space:  [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
data[u_c] post encoding of state:  [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
J_b = 0.0, J_o = 486302.3219459745
J_b = 0.5, J_o = 10096260.784188362
J_b = 0.00639651480737372, J_o = 327420.8425560721
J_b = 0.016487423420383503, J_o = 245946.04851900268
J_b = 0.01919017079677581, J_o = 216938.85159469128
J_b = 0.03468447779716598, J_o = 168482.31722642493
J_b = 0.041366650751662466, J_o = 156282.16199651553
J_b = 0.06669532391291681, J_o = 131217.9975027293
J_b = 0.09473622534444824, J_o = 120278.79154586581
J_b = 0.11856310347237717, J_o = 113560.89749588717
J_b = 0.11846352846922513, J_o = 110743.86333068743
J_b = 0.1205631841416692, J_o = 108406.0365295032
J_b = 0.1343253401903228, J_o = 105966.2913763638
J_b = 0.15452049348317728, J_o = 103600.3536149486
J_b = 0.16581025015278747, J_o = 102295.82570778948
J_b = 0.17683189746125252, J_o = 101213.21013697953
J_b = 0.19694141884690156, J_o = 101348.02411700331
J_b = 0.18594838616246853, J_o = 100599.63551790098
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
W_opt:  [ 0.01088045  0.00049282  0.00110411  0.00417734  0.00919998  0.00590279
 -0.01522895 -0.0638298  -0.1367149  -0.21363832]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.4644 s, v_trunc (Latent to Reduced) = 0.1086, dec (Reduced to Full) = 1.1940, add (DA)= 0.0001decode = 1.3048 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.7693 s, inc stats = 7.8376, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9574981  2.85944181 3.43614634 3.08813201 2.46974923]
u_DA:    [3.89448752 1.95444639 3.01449411 1.6639062  2.68017196]
ref_MAE: [0.1170437  0.69766141 0.89721156 1.23557856 0.09311552]
da_MAE:  [0.06301058 0.90499541 0.42165223 1.42422582 0.21042273]
% 18.59156689029601 da_MAE 0.0061111151342107 ref_MAE 0.007506734745742511
u_c taken from control states: [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
u_c before reduction of space:  [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
data[u_c] post encoding of state:  [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
J_b = 0.0, J_o = 442273.16802463646
J_b = 0.5000000000000001, J_o = 11750464.020008354
J_b = 0.0048866096074125735, J_o = 304519.1109428605
J_b = 0.012805962095053955, J_o = 213910.88535898726
J_b = 0.019144673944971886, J_o = 180344.7485694251
J_b = 0.03133635414911659, J_o = 145226.5669833173
J_b = 0.03897894617074105, J_o = 130625.29667802816
J_b = 0.05776072929452772, J_o = 109718.75377334733
J_b = 0.07891231449964382, J_o = 99787.54743030769
J_b = 0.10146640542254605, J_o = 93871.94650999378
J_b = 0.10153335017586526, J_o = 90218.12920928116
J_b = 0.10474537073832624, J_o = 87549.92427187532
J_b = 0.11419731796816839, J_o = 85073.4068088796
J_b = 0.14248468931044583, J_o = 83007.22448497574
J_b = 0.15586249447039935, J_o = 80189.75823667421
J_b = 0.1555093370662127, J_o = 79552.3291892815
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
W_opt:  [ 0.01785805  0.01040113  0.00662649  0.00571449  0.00612717 -0.00347317
 -0.02933118 -0.07528665 -0.13856487 -0.20312518]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.7248 s, v_trunc (Latent to Reduced) = 0.1765, dec (Reduced to Full) = 1.2812, add (DA)= 0.0001decode = 1.4607 s, unnorm = 0.0006 s, TOTAL = unnormalising + decoding + minimising = 7.1861 s, inc stats = 7.2154, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95734745 2.8581581  3.43565384 3.08878952 2.46688677]
u_DA:    [3.89621419 1.94453041 3.02266302 1.67019443 2.68452729]
ref_MAE: [0.11689305 0.6963777  0.89671906 1.23623607 0.09025305]
da_MAE:  [0.06113326 0.91362768 0.41299083 1.4185951  0.21764053]
% 18.633924858399844 da_MAE 0.006102999582036697 ref_MAE 0.007500668517457354
u_c taken from control states: [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
u_c before reduction of space:  [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
data[u_c] post encoding of state:  [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
J_b = 0.0, J_o = 411812.14439992624
J_b = 0.5000000000000001, J_o = 13106961.045303086
J_b = 0.004042178001924782, J_o = 286677.5725489858
J_b = 0.010574028664598827, J_o = 195583.715686053
J_b = 0.01931675772103909, J_o = 153517.488985183
J_b = 0.02850067840904271, J_o = 128171.83451886296
J_b = 0.03610599212161292, J_o = 112505.83102759026
J_b = 0.049779983253813026, J_o = 95852.31952710354
J_b = 0.06612214810836146, J_o = 84551.34977238245
J_b = 0.09448389251685026, J_o = 79474.72240234292
J_b = 0.1008795672604561, J_o = 74207.31269926528
J_b = 0.09721909332992108, J_o = 72638.4084434041
J_b = 0.10097668401532221, J_o = 70043.3402229668
J_b = 0.11858756405784338, J_o = 68070.51032635642
J_b = 0.1331344488584866, J_o = 66365.90655539761
J_b = 0.14410608197394917, J_o = 66949.42181851964
J_b = 0.13705988179198922, J_o = 66068.58585967403
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
W_opt:  [ 0.0103827   0.01331652  0.01115351  0.00941524  0.00803033 -0.00372979
 -0.03178666 -0.0798325  -0.1413071  -0.20291776]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.9843 s, v_trunc (Latent to Reduced) = 0.1586, dec (Reduced to Full) = 0.5296, add (DA)= 0.0001decode = 0.6904 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.6749 s, inc stats = 7.6966, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95717471 2.85714928 3.43511298 3.08877384 2.46294677]
u_DA:    [3.8975878  1.94734243 3.02870173 1.6834638  2.67224793]
ref_MAE: [0.11672031 0.69536889 0.89617819 1.23622039 0.08631306]
da_MAE:  [0.0595869  0.90980685 0.40641125 1.40531004 0.20930116]
% 18.5858333831555 da_MAE 0.006102425100068189 ref_MAE 0.007495532231862954
u_c taken from control states: [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
u_c before reduction of space:  [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
data[u_c] post encoding of state:  [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
J_b = 0.0, J_o = 391282.38148114755
J_b = 0.49999999999999994, J_o = 14244314.42669598
J_b = 0.0035035700153666486, J_o = 274693.1891740085
J_b = 0.009098775201478912, J_o = 185585.70824849326
J_b = 0.019504298339574008, J_o = 135542.79992680324
J_b = 0.027212281587018102, J_o = 114891.16779461931
J_b = 0.03499420965810384, J_o = 99277.06718895491
J_b = 0.04727673334172707, J_o = 84201.19441803786
J_b = 0.0635787603111674, J_o = 73306.27715938057
J_b = 0.09315775731725028, J_o = 72483.20531455775
J_b = 0.07743741547743001, J_o = 68801.94844772038
J_b = 0.08668515601814782, J_o = 64843.153820904365
J_b = 0.09087778589227102, J_o = 62708.39002615286
J_b = 0.10222534529379954, J_o = 59694.20272195821
J_b = 0.12315425479218181, J_o = 58239.603322765906
J_b = 0.12477792597178537, J_o = 56314.85233978347
J_b = 0.1281490567209547, J_o = 56172.32840549895
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
W_opt:  [ 0.00784747  0.01307969  0.01351639  0.01293316  0.01000924 -0.00271272
 -0.03266127 -0.0828594  -0.14478622 -0.20557983]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.3973 s, v_trunc (Latent to Reduced) = 0.1345, dec (Reduced to Full) = 0.3000, add (DA)= 0.0001decode = 0.4370 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.8344 s, inc stats = 6.8745, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95697784 2.85640887 3.43452062 3.08803483 2.45821844]
u_DA:    [3.89711662 1.94233511 3.02387702 1.65563062 2.67814078]
ref_MAE: [0.11652344 0.69462848 0.89558584 1.23548138 0.08158473]
da_MAE:  [0.05986122 0.91407376 0.4106436  1.43240421 0.21992234]
% 18.336544387729617 da_MAE 0.006118153195034032 ref_MAE 0.007491910731873004
u_c taken from control states: [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
u_c before reduction of space:  [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
data[u_c] post encoding of state:  [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
J_b = 0.0, J_o = 377757.8794706167
J_b = 0.5000000000000002, J_o = 14682240.884426553
J_b = 0.003347006495311734, J_o = 263269.25928082236
J_b = 0.008664642192538888, J_o = 174376.67225099145
J_b = 0.01980114312640749, J_o = 120666.54518737242
J_b = 0.027015700236814696, J_o = 101564.26732601604
J_b = 0.03503290254620285, J_o = 85836.66039233442
J_b = 0.04698539119391893, J_o = 71282.00644809725
J_b = 0.06396522181340791, J_o = 62323.736338266564
J_b = 0.08094281439501803, J_o = 56476.17252266455
J_b = 0.08000542561066042, J_o = 53585.907131798
J_b = 0.08330516579118974, J_o = 50991.024921177006
J_b = 0.09140272713729135, J_o = 48820.26169649009
J_b = 0.11706824462654224, J_o = 47448.82056253316
J_b = 0.12422222226102478, J_o = 44700.98063918232
J_b = 0.12397949645514889, J_o = 44210.1446711097
J_b = 0.12372728442317957, J_o = 43986.538733044734
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
W_opt:  [-2.04601438e-04  4.71866790e-03  7.76102692e-03  1.05857753e-02
  1.02224042e-02  3.63620075e-05 -2.78179910e-02 -7.78270101e-02
 -1.42228762e-01 -2.07486716e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.4470 s, v_trunc (Latent to Reduced) = 0.1033, dec (Reduced to Full) = 0.2966, add (DA)= 0.0001decode = 0.4023 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.8496 s, inc stats = 6.8688, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95675496 2.85585573 3.43387888 3.08659972 2.45306202]
u_DA:    [3.88890916 1.91967102 3.00287697 1.56157287 2.73103163]
ref_MAE: [0.11630056 0.69407533 0.8949441  1.23404627 0.07642831]
da_MAE:  [0.0678458  0.93618471 0.43100191 1.52502684 0.27796961]
% 17.859907764716056 da_MAE 0.006151831934667927 ref_MAE 0.007489438795669331
u_c taken from control states: [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
u_c before reduction of space:  [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
data[u_c] post encoding of state:  [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
J_b = 0.0, J_o = 377995.62999276415
J_b = 0.4999999999999999, J_o = 14534251.231964529
J_b = 0.003418649425011718, J_o = 262026.58607334594
J_b = 0.008869230762747685, J_o = 172081.87694965716
J_b = 0.019901997016379774, J_o = 119270.55936641309
J_b = 0.02715997994721109, J_o = 99896.62804116857
J_b = 0.03553399258351786, J_o = 83440.55253834501
J_b = 0.04806648764406254, J_o = 68435.91762625323
J_b = 0.06607099757171131, J_o = 60728.780271282085
J_b = 0.07506089517392622, J_o = 54057.353234737566
J_b = 0.07757797519857217, J_o = 51189.00777532575
J_b = 0.08539305109047633, J_o = 47984.1283523093
J_b = 0.10010589601826428, J_o = 45245.95807156051
J_b = 0.11792414167721327, J_o = 42916.09974436564
J_b = 0.1219403108425717, J_o = 41721.08843446027
J_b = 0.13062022624963415, J_o = 42301.53215419145
J_b = 0.12523754146528895, J_o = 41221.444128378454
J_b = 0.12734591951612653, J_o = 40685.61853626377
J_b = 0.12926764767404833, J_o = 40388.0132622779
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
W_opt:  [-0.00077439  0.00347466  0.00751218  0.01082355  0.01087055  0.00200047
 -0.02410868 -0.07424246 -0.14062988 -0.21006568]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.0067 s, v_trunc (Latent to Reduced) = 0.1147, dec (Reduced to Full) = 0.2229, add (DA)= 0.0001decode = 0.3399 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.3467 s, inc stats = 7.3656, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95651069 2.85540571 3.43319822 3.08457918 2.44799337]
u_DA:    [3.89026262 1.91950706 3.00394043 1.56988991 2.72172375]
ref_MAE: [0.11605629 0.69362532 0.89426344 1.23202573 0.07135966]
da_MAE:  [0.06624807 0.93589866 0.4292578  1.51468927 0.27373037]
% 17.77694591142457 da_MAE 0.0061573858467013735 ref_MAE 0.00748863675152261
u_c taken from control states: [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
u_c before reduction of space:  [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
data[u_c] post encoding of state:  [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
J_b = 0.0, J_o = 385548.8680414957
J_b = 0.5, J_o = 14094548.512500545
J_b = 0.0036369598295878276, J_o = 265323.27186060906
J_b = 0.009468683410605812, J_o = 173396.18367580598
J_b = 0.0199070415257727, J_o = 123904.36702989413
J_b = 0.027560269809322423, J_o = 103090.27088626666
J_b = 0.03621925519618026, J_o = 85788.42192841556
J_b = 0.04959759911327601, J_o = 69976.8237080443
J_b = 0.06795086609972664, J_o = 62404.75942599033
J_b = 0.07468834585993255, J_o = 55648.45763821151
J_b = 0.07829959171911012, J_o = 52399.81845131792
J_b = 0.0867126821402611, J_o = 49163.97203289503
J_b = 0.10310850306473873, J_o = 45674.25905881554
J_b = 0.12891225084804186, J_o = 44042.113618038995
J_b = 0.1257653983683715, J_o = 42337.40434628456
J_b = 0.12553069683321746, J_o = 42436.47275399587
J_b = 0.12561439280272552, J_o = 42011.109888228006
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
W_opt:  [ 0.00710743  0.00854507  0.00896136  0.00868486  0.0055001  -0.00510581
 -0.02982467 -0.07512606 -0.13511156 -0.19855034]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.6830 s, v_trunc (Latent to Reduced) = 0.1217, dec (Reduced to Full) = 0.3093, add (DA)= 0.0001decode = 0.4333 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.1165 s, inc stats = 7.1264, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95625104 2.8549381  3.43248729 3.0820369  2.44344662]
u_DA:    [3.89246762 1.92337111 3.0017468  1.57794008 2.71892123]
ref_MAE: [0.11579664 0.6931577  0.8935525  1.22948345 0.06681291]
da_MAE:  [0.06378342 0.93156699 0.43074049 1.50409682 0.27547461]
% 17.810134044524574 da_MAE 0.006155247996935718 ref_MAE 0.007489059539615492
\% improve_point: 13.04, mse_ref_points: 3.486536501664882e-05, mse_da_points: 3.0318281394604273e-05, % improve_overlap: 13.04, mse_ref_overlap: 0.90811, mse_da_overlap: 0.78970
DA - - L2: 148528.43, L1: 8274.20, % Improve: 18.08%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.789, time(s): 11.3590s,
u_c taken from control states: [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
u_c before reduction of space:  [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
data[u_c] post encoding of state:  [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
J_b = 0.0, J_o = 395917.65132133296
J_b = 0.5, J_o = 13664231.805980138
J_b = 0.0039069828417750765, J_o = 269973.39492879313
J_b = 0.010178067934826262, J_o = 176059.42492517686
J_b = 0.019833520798781257, J_o = 130268.16412205252
J_b = 0.028082004093021636, J_o = 107318.37903676546
J_b = 0.0369154795641109, J_o = 89330.12978062812
J_b = 0.05113841973878727, J_o = 72659.56794358132
J_b = 0.06934287578937287, J_o = 64827.99161826752
J_b = 0.07574960252199325, J_o = 58170.45161816303
J_b = 0.08021369043091477, J_o = 54577.66166984427
J_b = 0.08918962760758428, J_o = 51201.32476215883
J_b = 0.10738591494107934, J_o = 47580.7865673805
J_b = 0.13139714302839484, J_o = 45660.22092650815
J_b = 0.12809474701631532, J_o = 44251.97995020468
J_b = 0.12719767331423631, J_o = 44255.43198841077
J_b = 0.12758755053127477, J_o = 43834.52030852754
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
W_opt:  [ 0.00694957  0.00839703  0.00844306  0.00726652  0.00319927 -0.00800698
 -0.03209666 -0.07505123 -0.1321808  -0.194315  ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.3603 s, v_trunc (Latent to Reduced) = 0.1138, dec (Reduced to Full) = 0.2631, add (DA)= 0.0001decode = 0.3794 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.7398 s, inc stats = 6.7544, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9559738  2.85430624 3.43174682 3.07902499 2.43950125]
u_DA:    [3.89166994 1.91964525 2.99428419 1.56517054 2.72188462]
ref_MAE: [0.1155194  0.69252584 0.89281204 1.22647154 0.06286754]
da_MAE:  [0.06430386 0.93466099 0.43746263 1.51385445 0.28238337]
% 17.67910786060075 da_MAE 0.006166339747930371 ref_MAE 0.007490613363966601
u_c taken from control states: [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
u_c before reduction of space:  [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
data[u_c] post encoding of state:  [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
J_b = 0.0, J_o = 405354.56460075633
J_b = 0.5000000000000002, J_o = 13265030.791984936
J_b = 0.00420453680499707, J_o = 272929.5869048451
J_b = 0.01092528025341522, J_o = 177705.88019021176
J_b = 0.019618332852970318, J_o = 135865.34839396883
J_b = 0.02864533885289404, J_o = 110117.82634700518
J_b = 0.03745355134628539, J_o = 91902.84960030287
J_b = 0.052457580398272544, J_o = 74434.06545424425
J_b = 0.07020100809130174, J_o = 66335.99178270569
J_b = 0.07713252643045129, J_o = 59849.03486507642
J_b = 0.08247259344352759, J_o = 55978.245124805515
J_b = 0.09207704640505429, J_o = 52483.01243316279
J_b = 0.11209508702119017, J_o = 49556.4138547132
J_b = 0.12430699331958012, J_o = 47001.251763312575
J_b = 0.12645212688228138, J_o = 45978.415562919196
J_b = 0.1340210504827778, J_o = 46745.633464484505
J_b = 0.12909520599658683, J_o = 45548.145005842336
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
W_opt:  [ 0.0079026   0.00866343  0.00855972  0.00712131  0.00249798 -0.01024933
 -0.03546087 -0.07743196 -0.13212408 -0.19167821]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.1074 s, v_trunc (Latent to Reduced) = 0.1019, dec (Reduced to Full) = 0.2411, add (DA)= 0.0002decode = 0.3453 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.4529 s, inc stats = 7.4703, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95567803 2.85347245 3.4309813  3.07562723 2.43622151]
u_DA:    [3.89136176 1.91724653 2.9926639  1.56153907 2.719314  ]
ref_MAE: [0.11522363 0.69169206 0.89204652 1.22307378 0.0595878 ]
da_MAE:  [0.06431627 0.93622593 0.4383174  1.51408816 0.28309248]
% 17.51965861318381 da_MAE 0.006180763324588455 ref_MAE 0.007493619959211759
u_c taken from control states: [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
u_c before reduction of space:  [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
data[u_c] post encoding of state:  [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
J_b = 0.0, J_o = 413739.5931587501
J_b = 0.5000000000000001, J_o = 12990269.69931791
J_b = 0.004484356805331445, J_o = 274588.0743201203
J_b = 0.011575701338584224, J_o = 178844.45937435207
J_b = 0.019309748916718078, J_o = 140307.68471609973
J_b = 0.029247380684179067, J_o = 111225.14437359314
J_b = 0.03790908604084709, J_o = 93220.45225701321
J_b = 0.05364472446508958, J_o = 75128.79642071249
J_b = 0.07075597978466211, J_o = 66954.34376063621
J_b = 0.07824337679146288, J_o = 60748.04194544611
J_b = 0.08447189939598547, J_o = 56696.35951854602
J_b = 0.09458717511955562, J_o = 53280.403190715726
J_b = 0.11378058924417725, J_o = 50570.90964452525
J_b = 0.12037000768565034, J_o = 48479.41119755772
J_b = 0.12485882047659878, J_o = 47275.45725530992
J_b = 0.13492309864705673, J_o = 49209.619030957765
J_b = 0.12724291142154748, J_o = 47026.82811945957
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
W_opt:  [ 0.01088248  0.010152    0.00903821  0.00716515  0.00198789 -0.01229395
 -0.03888799 -0.08056059 -0.13285986 -0.18870837]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.9334 s, v_trunc (Latent to Reduced) = 0.1022, dec (Reduced to Full) = 0.2960, add (DA)= 0.0001decode = 0.4011 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.3347 s, inc stats = 7.3666, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95536993 2.85230978 3.43020345 3.07199115 2.43379607]
u_DA:    [3.89175586 1.9186722  2.99639402 1.57172172 2.70486787]
ref_MAE: [0.11491553 0.69052938 0.89126866 1.2194377  0.05716236]
da_MAE:  [0.06361407 0.93363758 0.43380943 1.50026943 0.2710718 ]
% 17.462316485685623 da_MAE 0.0061882871487470015 ref_MAE 0.0074975294741265385
u_c taken from control states: [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
u_c before reduction of space:  [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
data[u_c] post encoding of state:  [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
J_b = 0.0, J_o = 421369.1862364438
J_b = 0.5000000000000003, J_o = 12841512.765549466
J_b = 0.004721640750909775, J_o = 275788.1381536456
J_b = 0.012075537649775186, J_o = 180085.49933998627
J_b = 0.018996604055522417, J_o = 143811.34831633916
J_b = 0.02993736490954077, J_o = 111024.57329763622
J_b = 0.03842362496373181, J_o = 93525.40729533834
J_b = 0.05482009022221944, J_o = 75042.84666430808
J_b = 0.07125612331903426, J_o = 66912.67937006286
J_b = 0.07936400416335021, J_o = 61055.10128659549
J_b = 0.08662697824437816, J_o = 56946.41344464659
J_b = 0.09681397655200462, J_o = 53911.63549222678
J_b = 0.10953122316171682, J_o = 51231.82820263661
J_b = 0.11850918827596021, J_o = 49414.42557225178
J_b = 0.13065368733438662, J_o = 47553.592962462106
J_b = 0.1486992601481546, J_o = 54459.947861471126
J_b = 0.13310795712667367, J_o = 47331.78993734784
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
W_opt:  [ 0.01147323  0.01088099  0.01086668  0.01011783  0.00576583 -0.00883521
 -0.03697698 -0.0816863  -0.13697772 -0.1957814 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.3507 s, v_trunc (Latent to Reduced) = 0.1017, dec (Reduced to Full) = 0.2734, add (DA)= 0.0001decode = 0.3773 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.7282 s, inc stats = 6.7340, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95505368 2.85072188 3.42942295 3.06825367 2.43221142]
u_DA:    [3.89216018 1.92278646 2.99154659 1.58531744 2.68631526]
ref_MAE: [0.11459928 0.68894149 0.89048816 1.21570022 0.05557771]
da_MAE:  [0.06289349 0.92793543 0.43787635 1.48293624 0.25410384]
% 17.483345051585903 da_MAE 0.006190122133982511 ref_MAE 0.007501663922092228
u_c taken from control states: [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
u_c before reduction of space:  [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
data[u_c] post encoding of state:  [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
J_b = 0.0, J_o = 427109.34104212554
J_b = 0.5000000000000002, J_o = 12858200.71696471
J_b = 0.004871112000988639, J_o = 276215.61822720827
J_b = 0.012323628175751767, J_o = 180760.79999094334
J_b = 0.018712906642950427, J_o = 145449.21504007772
J_b = 0.030570935724249775, J_o = 109227.22854333835
J_b = 0.038906812456645574, J_o = 92250.1203668519
J_b = 0.05547964690381718, J_o = 73853.7264053426
J_b = 0.07106292281265804, J_o = 65794.11140254686
J_b = 0.08031345081355597, J_o = 60166.69167415466
J_b = 0.0891397573493333, J_o = 56156.09423015023
J_b = 0.0984281668835979, J_o = 53662.80964725166
J_b = 0.10421329110630498, J_o = 51663.96767494633
J_b = 0.11499408004034742, J_o = 49474.64812002597
J_b = 0.12394376006777447, J_o = 48130.16473323746
J_b = 0.14212259425096238, J_o = 62213.74085039006
J_b = 0.1255049826204688, J_o = 47934.248835527906
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
W_opt:  [ 0.01294032  0.01317613  0.01323417  0.01103212  0.00506968 -0.0109313
 -0.040213   -0.0849353  -0.13825728 -0.19259977]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.9988 s, v_trunc (Latent to Reduced) = 0.1507, dec (Reduced to Full) = 0.2567, add (DA)= 0.0001decode = 0.4102 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 6.4093 s, inc stats = 6.4397, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95473103 2.84870643 3.42864671 3.06454671 2.43135803]
u_DA:    [3.89229971 1.91612034 3.01557277 1.58839757 2.68342465]
ref_MAE: [0.11427663 0.68692603 0.88971193 1.21199326 0.05472432]
da_MAE:  [0.06243132 0.93258609 0.41307394 1.47614914 0.25206662]
% 17.561520441228453 da_MAE 0.006187586469103427 ref_MAE 0.0075057018302869235
u_c taken from control states: [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
u_c before reduction of space:  [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
data[u_c] post encoding of state:  [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
J_b = 0.0, J_o = 430647.3419680752
J_b = 0.5, J_o = 13031635.892384991
J_b = 0.00490040953360752, J_o = 276657.64589854266
J_b = 0.012270856829908382, J_o = 181520.2703209866
J_b = 0.01845554678817457, J_o = 146008.810245448
J_b = 0.030963754157201775, J_o = 107335.28411294665
J_b = 0.039216645442630364, J_o = 90591.32168725927
J_b = 0.055146184367282185, J_o = 72849.32765386357
J_b = 0.0696624638747578, J_o = 64829.030442242816
J_b = 0.08127358385552017, J_o = 58971.17696740941
J_b = 0.09159439401746008, J_o = 54974.62999809034
J_b = 0.10262490172399978, J_o = 53088.77121872148
J_b = 0.10305783286774954, J_o = 51306.054874895344
J_b = 0.10751710426004676, J_o = 49768.511459301255
J_b = 0.11490582589543029, J_o = 48569.51503448701
J_b = 0.1289749499335057, J_o = 47118.44787701256
J_b = 0.15041085670395085, J_o = 47417.23846440411
J_b = 0.13817792469697882, J_o = 46449.5480730366
J_b = 0.1383607867882103, J_o = 46155.85877184549
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
W_opt:  [ 0.00714416  0.01131118  0.01842404  0.01856044  0.01398521 -0.00125557
 -0.03248386 -0.08329954 -0.14509048 -0.20965698]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.3256 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.2720, add (DA)= 0.0001decode = 0.3783 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.7041 s, inc stats = 7.7255, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95440808 2.84627661 3.42788343 3.0610232  2.43125483]
u_DA:    [3.89337758 1.92160434 3.005335   1.6124073  2.66822861]
ref_MAE: [0.11395368 0.68449621 0.88894865 1.20846975 0.05462112]
da_MAE:  [0.06103049 0.92467226 0.42254843 1.4486159  0.23697378]
% 17.7143238144854 da_MAE 0.00617911296235132 ref_MAE 0.007509342146524255
u_c taken from control states: [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
u_c before reduction of space:  [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
data[u_c] post encoding of state:  [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
J_b = 0.0, J_o = 432544.75002526806
J_b = 0.49999999999999994, J_o = 13172670.131260006
J_b = 0.004900286960460478, J_o = 276859.11493887857
J_b = 0.01217937602800874, J_o = 182180.02834913082
J_b = 0.018248745655272205, J_o = 146359.99614944716
J_b = 0.031324836369846315, J_o = 105648.78114180166
J_b = 0.03956255654578374, J_o = 89005.27597711545
J_b = 0.05481093676850248, J_o = 71988.44021421859
J_b = 0.06846601256308474, J_o = 64204.521160835975
J_b = 0.08181085749750014, J_o = 58186.530280832085
J_b = 0.0922951417571609, J_o = 54231.62549024765
J_b = 0.10280122777671136, J_o = 52280.88657375192
J_b = 0.10303108401703198, J_o = 50611.95813915829
J_b = 0.10711487404200139, J_o = 49144.097753691065
J_b = 0.1149965146824043, J_o = 47887.83566035329
J_b = 0.12941218379089903, J_o = 49332.44924892998
J_b = 0.11934202936630794, J_o = 47405.73925111421
J_b = 0.13139236678336122, J_o = 46360.099352924124
J_b = 0.13675149166167036, J_o = 45718.738204124376
J_b = 0.1407136016766658, J_o = 45121.029767636646
J_b = 0.1445067003395973, J_o = 44637.662361990675
J_b = 0.15710170091887843, J_o = 43870.26096175724
J_b = 0.17037162684916254, J_o = 43496.5469490433
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
W_opt:  [-0.0114325  -0.00492038  0.01678332  0.02632527  0.02944225  0.02121066
 -0.00705101 -0.0664231  -0.14575235 -0.23927676]
----------------------------- DA Assimilate ----------------------
minCostFunction = 8.2699 s, v_trunc (Latent to Reduced) = 0.1027, dec (Reduced to Full) = 0.2814, add (DA)= 0.0002decode = 0.3871 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 8.6573 s, inc stats = 8.6625, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9540897  2.84349198 3.42713651 3.05779888 2.43187065]
u_DA:    [3.89458993 1.92935056 3.01713173 1.6335229  2.65713535]
ref_MAE: [0.1136353  0.68171159 0.88820173 1.20524543 0.05523694]
da_MAE:  [0.05949978 0.91414143 0.41000479 1.42427598 0.22526469]
% 17.616560643049393 da_MAE 0.006188526307253596 ref_MAE 0.007511857183383636
u_c taken from control states: [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
u_c before reduction of space:  [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
data[u_c] post encoding of state:  [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
J_b = 0.0, J_o = 433266.1971025304
J_b = 0.5000000000000002, J_o = 13221176.795674589
J_b = 0.004907357421214347, J_o = 276743.27824188094
J_b = 0.012141423137599767, J_o = 182767.40188130087
J_b = 0.01806701176186101, J_o = 147014.29347828336
J_b = 0.03164806128958633, J_o = 104574.18412380555
J_b = 0.03984701559391595, J_o = 88155.16923626416
J_b = 0.05469011520973722, J_o = 71689.33513216299
J_b = 0.06792312485900087, J_o = 64308.70239626678
J_b = 0.0812476838360553, J_o = 58523.51511301254
J_b = 0.09109436870367502, J_o = 54789.95655725234
J_b = 0.09754766160381537, J_o = 52332.324301354136
J_b = 0.10105930219855654, J_o = 50741.052224596366
J_b = 0.11459032884448066, J_o = 48105.668036189585
J_b = 0.13112031743932548, J_o = 47634.480633838684
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
W_opt:  [ 0.013212    0.01471392  0.02013526  0.01969833  0.01277344 -0.00488758
 -0.0371227  -0.08713789 -0.14645883 -0.20649978]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.6161 s, v_trunc (Latent to Reduced) = 0.1017, dec (Reduced to Full) = 0.4223, add (DA)= 0.0002decode = 0.5262 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.1426 s, inc stats = 6.1849, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95377645 2.84046469 3.42640554 3.05495551 2.43305632]
u_DA:    [3.89831978 1.93220695 3.03138626 1.66279765 2.67234552]
ref_MAE: [0.11332205 0.67868429 0.88747075 1.20240206 0.05642261]
da_MAE:  [0.05545667 0.90825774 0.39501927 1.39215785 0.2392892 ]
% 17.906312545029788 da_MAE 0.0061679484778960495 ref_MAE 0.007513304212676857
u_c taken from control states: [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
u_c before reduction of space:  [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
data[u_c] post encoding of state:  [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
J_b = 0.0, J_o = 433630.10415202327
J_b = 0.5000000000000002, J_o = 13126578.768498082
J_b = 0.0049450308282167135, J_o = 276928.4760113148
J_b = 0.012212259767351545, J_o = 184242.1042245883
J_b = 0.017859557324472548, J_o = 149314.62126865936
J_b = 0.031960044258541556, J_o = 105174.21572895991
J_b = 0.04003800433570223, J_o = 89327.76286138549
J_b = 0.05520431899365714, J_o = 72839.41106905042
J_b = 0.0688814594973595, J_o = 65871.58571637965
J_b = 0.08031835769307931, J_o = 60366.4748443268
J_b = 0.08920294456980671, J_o = 56455.217506184024
J_b = 0.0986034763922919, J_o = 53929.29862407345
J_b = 0.10410234925752503, J_o = 52003.15980259601
J_b = 0.11400923653605848, J_o = 49958.86495812597
J_b = 0.1254250026938953, J_o = 48607.0938075696
J_b = 0.14656086124047932, J_o = 49807.11450360046
J_b = 0.13260974186251132, J_o = 47958.980087132666
J_b = 0.13573252786888154, J_o = 47475.60317671021
J_b = 0.1380361544232446, J_o = 47015.92910878219
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
W_opt:  [ 0.00648716  0.01620067  0.02392254  0.0243783   0.01878277  0.0026323
 -0.02933857 -0.08180245 -0.14633617 -0.21369198]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.2220 s, v_trunc (Latent to Reduced) = 0.1264, dec (Reduced to Full) = 0.4111, add (DA)= 0.0001decode = 0.5399 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.7621 s, inc stats = 7.7859, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95347048 2.83729307 3.42569139 3.05255973 2.43470276]
u_DA:    [3.89753549 1.93165293 3.0422646  1.68088587 2.66035896]
ref_MAE: [0.11301608 0.67551267 0.8867566  1.20000628 0.05806905]
da_MAE:  [0.055935   0.90564014 0.38342679 1.37167385 0.2256562 ]
% 18.05593936176603 da_MAE 0.006156962331434385 ref_MAE 0.007513616342026418
u_c taken from control states: [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
u_c before reduction of space:  [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
data[u_c] post encoding of state:  [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
J_b = 0.0, J_o = 435626.5082206713
J_b = 0.49999999999999983, J_o = 12851888.560741238
J_b = 0.005049428646813387, J_o = 278695.47832978505
J_b = 0.012473138840749012, J_o = 188001.873000709
J_b = 0.01763897396239052, J_o = 154705.79480751487
J_b = 0.032486898860425543, J_o = 108152.5638683417
J_b = 0.04038137879531563, J_o = 93427.50167846303
J_b = 0.05682315626832007, J_o = 76252.0199326093
J_b = 0.07202855555892676, J_o = 69463.64316054677
J_b = 0.08245480300712497, J_o = 64231.962998135576
J_b = 0.08982450325512038, J_o = 60607.94981565057
J_b = 0.09987071237660179, J_o = 57922.96627447088
J_b = 0.11033001966014461, J_o = 55668.447495779634
J_b = 0.11861629436412506, J_o = 53967.522469379925
J_b = 0.1331839720434572, J_o = 52552.67681919396
J_b = 0.14619042490026907, J_o = 52769.46040681032
J_b = 0.13895263521655354, J_o = 51825.184204599274
J_b = 0.13796861875699917, J_o = 51475.07989335124
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
W_opt:  [-0.0016328   0.0147457   0.02616453  0.02721631  0.02013832  0.00265485
 -0.02957465 -0.08174616 -0.14600004 -0.21209481]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.7644 s, v_trunc (Latent to Reduced) = 0.1025, dec (Reduced to Full) = 0.4434, add (DA)= 0.0001decode = 0.5480 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 8.3125 s, inc stats = 8.3300, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95317354 2.83404184 3.42498917 3.0505911  2.43667811]
u_DA:    [3.89834128 1.93006801 3.05167633 1.67708877 2.66606044]
ref_MAE: [0.11271914 0.67226144 0.88605439 1.19803765 0.0600444 ]
da_MAE:  [0.05483226 0.90397383 0.37331284 1.37350233 0.22938233]
% 17.993650259375144 da_MAE 0.006160672346750377 ref_MAE 0.007512433325267814
\% improve_point: 12.55, mse_ref_points: 3.467014939660186e-05, mse_da_points: 3.031742018968772e-05, % improve_overlap: 12.55, mse_ref_overlap: 0.90303, mse_da_overlap: 0.78968
DA - - L2: 101315.43, L1: 6829.50, % Improve: 17.96%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.789, time(s): 10.0658s,
u_c taken from control states: [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
u_c before reduction of space:  [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
data[u_c] post encoding of state:  [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
J_b = 0.0, J_o = 436647.75381468446
J_b = 0.49999999999999994, J_o = 12579882.03272965
J_b = 0.00513491065254226, J_o = 280237.66123829904
J_b = 0.01269147986744676, J_o = 191936.25845487637
J_b = 0.017380128209932576, J_o = 160221.73036346535
J_b = 0.032898458394920845, J_o = 111479.15162799056
J_b = 0.04065683213099491, J_o = 97938.1032735543
J_b = 0.05827695334470527, J_o = 80225.36474504393
J_b = 0.07489679931881184, J_o = 72379.60156019028
J_b = 0.09115510750422488, J_o = 67351.75892016017
J_b = 0.09888226508503034, J_o = 64332.76941629907
J_b = 0.10222311378532309, J_o = 62241.015027891044
J_b = 0.10888900325871718, J_o = 60171.953093757365
J_b = 0.12649062867475314, J_o = 58037.44618137038
J_b = 0.13918539821350687, J_o = 56495.04367554233
J_b = 0.14504681803061506, J_o = 56645.80304609968
J_b = 0.14175893971696868, J_o = 56169.22435771684
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
W_opt:  [-0.00786396  0.01090243  0.02672396  0.03195794  0.02575824  0.00692161
 -0.02639353 -0.07997279 -0.14606911 -0.2133794 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.5773 s, v_trunc (Latent to Reduced) = 0.1095, dec (Reduced to Full) = 1.4617, add (DA)= 0.0001decode = 1.5742 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.1517 s, inc stats = 7.2245, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95288051 2.83074972 3.42428479 3.04890962 2.43870025]
u_DA:    [3.89959111 1.93296866 3.06141442 1.6856514  2.65538412]
ref_MAE: [0.11242611 0.66896932 0.88535    1.19635617 0.06206654]
da_MAE:  [0.0532894  0.89778106 0.36287037 1.36325822 0.21668387]
% 18.147037401934913 da_MAE 0.006147265128942255 ref_MAE 0.007510131501443748
u_c taken from control states: [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
u_c before reduction of space:  [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
data[u_c] post encoding of state:  [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
J_b = 0.0, J_o = 440336.5541202225
J_b = 0.5000000000000002, J_o = 12209078.208492495
J_b = 0.005285435372795642, J_o = 283727.19715821376
J_b = 0.013071740704380795, J_o = 198251.41815591985
J_b = 0.01716622945097243, J_o = 168179.40952283744
J_b = 0.03382715021677797, J_o = 115965.24394891379
J_b = 0.04156671817371326, J_o = 103863.05389057376
J_b = 0.060408372905288506, J_o = 86984.65438185411
J_b = 0.083602966822326, J_o = 84917.00135025183
J_b = 0.08211405984582738, J_o = 76684.79605104498
J_b = 0.08349171418189845, J_o = 74334.1821574244
J_b = 0.09202953598947136, J_o = 71462.56231960666
J_b = 0.10587339297754511, J_o = 68101.79478115024
J_b = 0.13967668685201898, J_o = 64373.35920139106
J_b = 0.17237656859821507, J_o = 66542.12690442355
J_b = 0.15060062875701177, J_o = 63368.72038729795
J_b = 0.1545430097615913, J_o = 62499.62574787235
J_b = 0.15205176915479213, J_o = 62226.118000266695
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
W_opt:  [-0.01267417  0.0056006   0.02275895  0.0335292   0.03177281  0.01484064
 -0.01869762 -0.07504526 -0.14580812 -0.21918533]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.7012 s, v_trunc (Latent to Reduced) = 0.1805, dec (Reduced to Full) = 1.1155, add (DA)= 0.0001decode = 1.2983 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.9997 s, inc stats = 8.0120, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95258008 2.82745615 3.42355969 3.04730262 2.44038488]
u_DA:    [3.90081371 1.93971143 3.05434599 1.71036565 2.64391428]
ref_MAE: [0.11212568 0.66567576 0.88462491 1.19474917 0.06375117]
da_MAE:  [0.05176637 0.88774473 0.3692137  1.33693697 0.20352939]
% 18.47270698662853 da_MAE 0.006120232132825347 ref_MAE 0.0075069733172933315
u_c taken from control states: [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
u_c before reduction of space:  [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
data[u_c] post encoding of state:  [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
J_b = 0.0, J_o = 443552.85971898853
J_b = 0.5000000000000001, J_o = 11895404.783962479
J_b = 0.00540140629990025, J_o = 287375.5739642658
J_b = 0.013391579443887637, J_o = 204017.07839717023
J_b = 0.017093080443818926, J_o = 174887.69871957556
J_b = 0.03453213798051309, J_o = 120772.89793965404
J_b = 0.042193115000090736, J_o = 109568.80562197466
J_b = 0.06136536346672904, J_o = 94089.04199635139
J_b = 0.0870531527278198, J_o = 93866.66038517165
J_b = 0.07286224171315848, J_o = 88807.30863816754
J_b = 0.07992823791978151, J_o = 84378.77216084221
J_b = 0.08962825346556777, J_o = 80204.99255976365
J_b = 0.09979279628484551, J_o = 77256.95649760016
J_b = 0.12438469441720952, J_o = 74084.82246450777
J_b = 0.14495747881156548, J_o = 71840.53110345101
J_b = 0.13951029234253184, J_o = 70730.8273817898
J_b = 0.13968230614259788, J_o = 70055.16059727987
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
W_opt:  [-0.00959429  0.00426355  0.01571462  0.02537546  0.0257704   0.01230214
 -0.01910106 -0.07265932 -0.13966989 -0.20789027]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.1538 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.3951, add (DA)= 0.0001decode = 0.5008 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.6547 s, inc stats = 6.6620, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95226516 2.82420282 3.42280081 3.04558442 2.44160603]
u_DA:    [3.89996457 1.93883385 3.05534963 1.70664323 2.65877124]
ref_MAE: [0.11181076 0.66242242 0.88386603 1.19303096 0.06497232]
da_MAE:  [0.0523006  0.88536897 0.36745118 1.33894118 0.21716521]
% 18.4434918270893 da_MAE 0.0061195708228625485 ref_MAE 0.00750347330943625
u_c taken from control states: [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
u_c before reduction of space:  [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
data[u_c] post encoding of state:  [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
J_b = 0.0, J_o = 439184.6747701004
J_b = 0.49999999999999983, J_o = 11865288.604269922
J_b = 0.005324908352188158, J_o = 285851.3921195755
J_b = 0.013287632416758899, J_o = 202071.5658799246
J_b = 0.017216163360440257, J_o = 172676.4196016034
J_b = 0.03400461912509013, J_o = 120711.35883376787
J_b = 0.041677060206482694, J_o = 109224.8061245009
J_b = 0.06017375617116663, J_o = 92918.40862048599
J_b = 0.08342720360405785, J_o = 92216.89916493846
J_b = 0.07096098746364776, J_o = 88261.99365577806
J_b = 0.08096451266676216, J_o = 83344.7594312893
J_b = 0.08896260617455477, J_o = 80006.55265839155
J_b = 0.09944948069430438, J_o = 76880.60541962214
J_b = 0.12017869504397505, J_o = 74104.54096976858
J_b = 0.13671732678386503, J_o = 71860.59407216297
J_b = 0.1367351648844596, J_o = 70812.0074302036
J_b = 0.1379080430595041, J_o = 72970.85266834461
J_b = 0.13691911770212223, J_o = 70482.9022669561
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
W_opt:  [-0.00414312  0.00459465  0.01020608  0.01884435  0.02211463  0.01097575
 -0.01851298 -0.07033051 -0.13660125 -0.20312028]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.5350 s, v_trunc (Latent to Reduced) = 0.1146, dec (Reduced to Full) = 0.2189, add (DA)= 0.0001decode = 0.3357 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.8708 s, inc stats = 6.8984, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95193239 2.82102874 3.42200182 3.04362282 2.44248364]
u_DA:    [3.90026089 1.94829489 3.05301921 1.72372936 2.65203078]
ref_MAE: [0.11147799 0.65924834 0.88306704 1.19106937 0.06584993]
da_MAE:  [0.0516715  0.87273385 0.3689826  1.31989346 0.20954714]
% 18.40124678326438 da_MAE 0.006120323964737733 ref_MAE 0.007500511617477111
u_c taken from control states: [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
u_c before reduction of space:  [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
data[u_c] post encoding of state:  [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
J_b = 0.0, J_o = 436908.0926628353
J_b = 0.5000000000000001, J_o = 12113089.828749005
J_b = 0.005081997323596047, J_o = 288258.78845530044
J_b = 0.01277706267946285, J_o = 202511.02264847682
J_b = 0.017418674616885153, J_o = 171750.57691255113
J_b = 0.03256047604536144, J_o = 125059.04128258154
J_b = 0.04026511394650528, J_o = 112128.65121162264
J_b = 0.05837074403508036, J_o = 94342.04549797565
J_b = 0.0753743382139092, J_o = 86930.16652416781
J_b = 0.08769864632838677, J_o = 82424.95356341681
J_b = 0.09335440703941457, J_o = 79731.91986454457
J_b = 0.1013425032788865, J_o = 77211.32709578864
J_b = 0.11276296931770644, J_o = 75147.32160050876
J_b = 0.12455071346739635, J_o = 73277.08789971135
J_b = 0.1353063969348981, J_o = 71994.91241776408
J_b = 0.14650716760823362, J_o = 75363.13634110164
J_b = 0.1372963866908011, J_o = 71792.47111000962
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
W_opt:  [-0.00085454  0.00415082  0.00695988  0.01388622  0.01735861  0.00762411
 -0.01896048 -0.06837709 -0.13469007 -0.20149368]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8075 s, v_trunc (Latent to Reduced) = 0.1029, dec (Reduced to Full) = 0.2468, add (DA)= 0.0001decode = 0.3519 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1596 s, inc stats = 5.1774, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95157343 2.81802471 3.42115443 3.04130215 2.44305344]
u_DA:    [3.89967235 1.94983073 3.04108761 1.70821913 2.66255869]
ref_MAE: [0.11111903 0.65624432 0.88221965 1.1887487  0.06641973]
da_MAE:  [0.05190108 0.86819399 0.38006682 1.33308302 0.21950525]
% 18.37099241309384 da_MAE 0.006121361440706835 ref_MAE 0.007499002648280074
u_c taken from control states: [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
u_c before reduction of space:  [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
data[u_c] post encoding of state:  [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
J_b = 0.0, J_o = 428000.09478548425
J_b = 0.5000000000000001, J_o = 12802862.002433442
J_b = 0.004595483169610254, J_o = 287281.9909204206
J_b = 0.01165361040189638, J_o = 198056.02687367494
J_b = 0.017896337903558806, J_o = 162760.99546506975
J_b = 0.030502078666239323, J_o = 124941.83279458244
J_b = 0.03841976332928286, J_o = 109212.39875218278
J_b = 0.05333254161647839, J_o = 92299.86850758496
J_b = 0.0670769693426028, J_o = 84538.20303904153
J_b = 0.08484957326099793, J_o = 79508.51365385677
J_b = 0.08803806777847487, J_o = 76388.93493350976
J_b = 0.0895438855489624, J_o = 74459.16811929955
J_b = 0.09537356218330635, J_o = 72530.24649129859
J_b = 0.1145756544121064, J_o = 70099.81491689631
J_b = 0.129061388443745, J_o = 68569.47919971649
J_b = 0.13402305999315056, J_o = 69364.15067498767
J_b = 0.1308494018684942, J_o = 68128.79253130374
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
W_opt:  [ 0.00506047  0.00708554  0.0075912   0.01211364  0.01308773  0.00213105
 -0.02376702 -0.07100578 -0.13457329 -0.19860626]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.9860 s, v_trunc (Latent to Reduced) = 0.1615, dec (Reduced to Full) = 1.4444, add (DA)= 0.0002decode = 1.6082 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 7.5944 s, inc stats = 7.6067, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95118557 2.81525519 3.42025215 3.03859826 2.44359222]
u_DA:    [3.899812   1.94994456 3.04004294 1.71418436 2.65897617]
ref_MAE: [0.11073117 0.6534748  0.88131737 1.18604481 0.06695851]
da_MAE:  [0.05137357 0.86531063 0.38020921 1.3244139  0.21538395]
% 18.39780080381765 da_MAE 0.006119503920043835 ref_MAE 0.0074991899487068326
u_c taken from control states: [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
u_c before reduction of space:  [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
data[u_c] post encoding of state:  [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
J_b = 0.0, J_o = 418468.5125032787
J_b = 0.5, J_o = 13504211.476879172
J_b = 0.004189173522934238, J_o = 284263.0723699404
J_b = 0.010650394094055148, J_o = 193564.7710548331
J_b = 0.018309426545924257, J_o = 152897.3148917873
J_b = 0.02929493301035429, J_o = 120558.27150781466
J_b = 0.03767064480643123, J_o = 103169.61006952688
J_b = 0.050771574927469997, J_o = 87643.49177162579
J_b = 0.06345001267369085, J_o = 79055.86372253016
J_b = 0.08535324116734219, J_o = 74673.22011250335
J_b = 0.0864842410950903, J_o = 70263.12886871464
J_b = 0.08577076955789195, J_o = 68833.58617775442
J_b = 0.09057749714789105, J_o = 66814.01882861464
J_b = 0.10760367822207897, J_o = 65423.104362616636
J_b = 0.11221301647988399, J_o = 63594.2694542509
J_b = 0.11948585770555291, J_o = 63022.75821277948
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
W_opt:  [ 0.01037261  0.01044513  0.00841007  0.00997965  0.00803113 -0.00482158
 -0.03155107 -0.07648834 -0.13479699 -0.19252692]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5107 s, v_trunc (Latent to Reduced) = 0.1047, dec (Reduced to Full) = 0.1757, add (DA)= 0.0001decode = 0.2827 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7935 s, inc stats = 4.8068, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95077111 2.81273131 3.41929737 3.03554934 2.44458092]
u_DA:    [3.89854877 1.95478976 3.02913867 1.70615671 2.6645076 ]
ref_MAE: [0.11031671 0.65095091 0.88036258 1.18299589 0.06794721]
da_MAE:  [0.05222235 0.85794155 0.39015869 1.32939264 0.21992667]
% 18.29980525916124 da_MAE 0.006128667588893203 ref_MAE 0.007501411236942523
u_c taken from control states: [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
u_c before reduction of space:  [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
data[u_c] post encoding of state:  [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
J_b = 0.0, J_o = 408962.09741750825
J_b = 0.5000000000000001, J_o = 14168320.008441914
J_b = 0.0038676675232168782, J_o = 279810.9687207608
J_b = 0.009811294960074568, J_o = 189165.77600670443
J_b = 0.018549610020322273, J_o = 143499.68600405307
J_b = 0.0285313112168818, J_o = 114486.505063831
J_b = 0.03727861475589271, J_o = 96281.75922907807
J_b = 0.04977291651760062, J_o = 81323.05809399013
J_b = 0.06268822915957195, J_o = 72247.71492029703
J_b = 0.08453485303911328, J_o = 67741.11813521074
J_b = 0.08626935148005685, J_o = 63213.015658585246
J_b = 0.08560107208616043, J_o = 61791.98096046448
J_b = 0.09120254639027896, J_o = 59585.97985957702
J_b = 0.10946875797302127, J_o = 59070.867422291376
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
W_opt:  [ 0.01128688  0.01151593  0.00884899  0.00792952  0.00392754 -0.0096996
 -0.03616075 -0.07881759 -0.13308869 -0.18600005]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.0550 s, v_trunc (Latent to Reduced) = 0.1087, dec (Reduced to Full) = 0.2258, add (DA)= 0.0001decode = 0.3373 s, unnorm = 0.0006 s, TOTAL = unnormalising + decoding + minimising = 4.3929 s, inc stats = 4.3982, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95032256 2.81042572 3.41828653 3.03219616 2.44637526]
u_DA:    [3.89859183 1.94274069 3.04092435 1.66784366 2.66856347]
ref_MAE: [0.10986816 0.64864532 0.87935174 1.17964271 0.06974155]
da_MAE:  [0.05173073 0.86768503 0.37736218 1.36435249 0.22218821]
% 18.130305646764487 da_MAE 0.00614508854434192 ref_MAE 0.007505938055452218
u_c taken from control states: [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
u_c before reduction of space:  [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
data[u_c] post encoding of state:  [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
J_b = 0.0, J_o = 403953.14525563555
J_b = 0.5, J_o = 14701604.634608103
J_b = 0.003661870829074042, J_o = 277617.5134836867
J_b = 0.009246752164063494, J_o = 187358.12321981002
J_b = 0.018680114138958454, J_o = 137899.21340546978
J_b = 0.028136663370759263, J_o = 110579.67947270082
J_b = 0.03718359086209462, J_o = 91869.91274555498
J_b = 0.049618906000320415, J_o = 76970.07071420865
J_b = 0.06324052222976027, J_o = 67576.57766860962
J_b = 0.08544227089572223, J_o = 63109.4323212198
J_b = 0.08610236155807607, J_o = 58589.36047852283
J_b = 0.08544783677530873, J_o = 57058.42428708071
J_b = 0.09052120473212964, J_o = 55021.44535076608
J_b = 0.10800268940228638, J_o = 53453.189993681124
J_b = 0.11381536519296635, J_o = 51524.382769803306
J_b = 0.12107689398663729, J_o = 51175.78556567616
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
W_opt:  [ 0.01223595  0.01350417  0.01201957  0.01070523  0.00666156 -0.00686556
 -0.03426012 -0.07989123 -0.13897702 -0.19803415]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5185 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1820, add (DA)= 0.0001decode = 0.2882 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8069 s, inc stats = 4.8196, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94983413 2.80829687 3.41722299 3.02859144 2.4491964 ]
u_DA:    [3.89591201 1.94851958 3.00669836 1.66368605 2.67256459]
ref_MAE: [0.10937972 0.64651647 0.87828821 1.17603799 0.07256269]
da_MAE:  [0.05392212 0.85977729 0.41052463 1.3649054  0.22336819]
% 18.0882251776266 da_MAE 0.006153490047529583 ref_MAE 0.007512338807056122
u_c taken from control states: [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
u_c before reduction of space:  [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
data[u_c] post encoding of state:  [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
J_b = 0.0, J_o = 403659.0168663482
J_b = 0.5000000000000002, J_o = 14907354.829780798
J_b = 0.003616693040654603, J_o = 277245.39474336745
J_b = 0.009104609436789628, J_o = 186745.97508363315
J_b = 0.01874340446059137, J_o = 135980.30902001885
J_b = 0.028057194124235733, J_o = 109036.12680482742
J_b = 0.03724805172680406, J_o = 90034.9077799457
J_b = 0.04985069627068926, J_o = 74946.18922018692
J_b = 0.06404428426916568, J_o = 65372.784630438975
J_b = 0.08632620771936955, J_o = 60577.76886691341
J_b = 0.08681053404727189, J_o = 56161.82271020149
J_b = 0.08651592821349628, J_o = 54483.20805186672
J_b = 0.09195426333051318, J_o = 52418.71516955819
J_b = 0.10886325442571508, J_o = 50184.72128172543
J_b = 0.1204965952016973, J_o = 48331.57952191333
J_b = 0.1297031542366666, J_o = 48249.23305213175
J_b = 0.1252434375908319, J_o = 47880.04771456716
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
W_opt:  [ 0.01251789  0.01389928  0.01387753  0.01214698  0.00790283 -0.00568768
 -0.03356281 -0.08046379 -0.14101318 -0.2019732 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0196 s, v_trunc (Latent to Reduced) = 0.1050, dec (Reduced to Full) = 0.1795, add (DA)= 0.0001decode = 0.2868 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3065 s, inc stats = 5.3219, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94930238 2.80626043 3.41611379 3.02479853 2.45284428]
u_DA:    [3.89483327 1.93954435 3.01008128 1.63869792 2.68173856]
ref_MAE: [0.10884798 0.64448003 0.87717901 1.17224508 0.07621056]
da_MAE:  [0.05446911 0.86671608 0.40603251 1.38610061 0.22889428]
% 17.992755975972006 da_MAE 0.006167193368485882 ref_MAE 0.007520303165753143
\% improve_point: 12.57, mse_ref_points: 3.462635133254889e-05, mse_da_points: 3.02718839056707e-05, % improve_overlap: 12.57, mse_ref_overlap: 0.90190, mse_da_overlap: 0.78851
DA - - L2: 77295.43, L1: 6095.66, % Improve: 18.04%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.788, time(s): 9.0979s,
u_c taken from control states: [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
u_c before reduction of space:  [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
data[u_c] post encoding of state:  [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
J_b = 0.0, J_o = 405984.5752358541
J_b = 0.49999999999999994, J_o = 14964804.617113302
J_b = 0.003646337535567903, J_o = 277943.0610279763
J_b = 0.00915506565256414, J_o = 186764.89495356503
J_b = 0.018764504756421527, J_o = 135912.67847187642
J_b = 0.028102111508734547, J_o = 108740.35002005285
J_b = 0.03733060851035128, J_o = 89571.58237970558
J_b = 0.050003671632765784, J_o = 74387.73186558929
J_b = 0.06436072140772686, J_o = 64732.58212150726
J_b = 0.08670436610027778, J_o = 59558.92568714435
J_b = 0.08777941554578893, J_o = 55157.72622513583
J_b = 0.0878720315223169, J_o = 53353.16780559675
J_b = 0.09358430730573575, J_o = 51282.91606311227
J_b = 0.11071014609054391, J_o = 48827.562644247075
J_b = 0.12429395700466205, J_o = 47063.92882223173
J_b = 0.1328696241961079, J_o = 46878.51809876502
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
W_opt:  [ 0.01336479  0.01472725  0.01594738  0.01410881  0.01004438 -0.00363491
 -0.03216885 -0.08141294 -0.14494    -0.20910065]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7622 s, v_trunc (Latent to Reduced) = 0.1045, dec (Reduced to Full) = 0.1869, add (DA)= 0.0001decode = 0.2937 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0560 s, inc stats = 5.0712, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94871461 2.80424376 3.41496207 3.02085712 2.45680241]
u_DA:    [3.89457662 1.93455113 3.00533269 1.63201502 2.68700231]
ref_MAE: [0.1082602  0.64246336 0.87602729 1.16830367 0.08016869]
da_MAE:  [0.05413798 0.86969263 0.40962939 1.3888421  0.2301999 ]
% 17.849486074879355 da_MAE 0.0061856305355345274 ref_MAE 0.007529630966365794
u_c taken from control states: [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
u_c before reduction of space:  [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
data[u_c] post encoding of state:  [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
J_b = 0.0, J_o = 409353.9934722316
J_b = 0.49999999999999994, J_o = 15036006.77167967
J_b = 0.003681009956554025, J_o = 279365.7132788178
J_b = 0.009210707250685452, J_o = 187453.4103293498
J_b = 0.018773032819438523, J_o = 136498.90308476545
J_b = 0.02817869981888788, J_o = 108928.82637690789
J_b = 0.037451123669278, J_o = 89562.54579657884
J_b = 0.0501383228069523, J_o = 74342.11986240157
J_b = 0.06451135452658734, J_o = 64586.762628962344
J_b = 0.08724615100216063, J_o = 59101.65908602504
J_b = 0.08907650133371302, J_o = 54584.506024211114
J_b = 0.0894842918984829, J_o = 52694.83186270525
J_b = 0.09536917227034149, J_o = 50643.36292074845
J_b = 0.11346830479603663, J_o = 48513.62323255274
J_b = 0.12348399996689548, J_o = 46610.29755167251
J_b = 0.13084797488051622, J_o = 46350.51322983278
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
W_opt:  [ 0.01425615  0.01604122  0.01711077  0.01430379  0.00933339 -0.00489947
 -0.03330022 -0.082074   -0.14450077 -0.2072797 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8073 s, v_trunc (Latent to Reduced) = 0.1019, dec (Reduced to Full) = 0.1955, add (DA)= 0.0001decode = 0.3000 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1075 s, inc stats = 5.1209, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94805628 2.80220795 3.41376748 3.01678332 2.460672  ]
u_DA:    [3.89426754 1.93011884 3.00981327 1.625425   2.69177963]
ref_MAE: [0.10760188 0.64042755 0.87483269 1.16422987 0.08403829]
da_MAE:  [0.05378874 0.87208911 0.4039542  1.39135833 0.23110763]
% 17.749110359479985 da_MAE 0.006201479451007169 ref_MAE 0.007539711093838525
u_c taken from control states: [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
u_c before reduction of space:  [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
data[u_c] post encoding of state:  [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
J_b = 0.0, J_o = 413548.24398767506
J_b = 0.5000000000000001, J_o = 15089031.423081951
J_b = 0.003721078636935351, J_o = 281557.916254671
J_b = 0.009277011633395452, J_o = 189079.89125316998
J_b = 0.018720867985733834, J_o = 138338.7304215258
J_b = 0.02824213496357731, J_o = 110192.13935985978
J_b = 0.037529678356820695, J_o = 90665.25923472813
J_b = 0.05017781911731484, J_o = 75468.37982991399
J_b = 0.06443414541963477, J_o = 65619.5562305799
J_b = 0.08785733315919414, J_o = 59876.24044917643
J_b = 0.09050083920022009, J_o = 55114.521785062185
J_b = 0.09121285944124065, J_o = 53187.86693588775
J_b = 0.09731127766189497, J_o = 51143.66971514355
J_b = 0.11727704705633522, J_o = 49999.669107776455
J_b = 0.12102526690512314, J_o = 47613.03932887872
J_b = 0.12542626852622923, J_o = 47139.61856131928
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
W_opt:  [ 0.01516858  0.01751402  0.01803328  0.01381912  0.0074665  -0.00758917
 -0.0356737  -0.0825951  -0.14208574 -0.20192109]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4710 s, v_trunc (Latent to Reduced) = 0.1033, dec (Reduced to Full) = 0.2104, add (DA)= 0.0001decode = 0.3159 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7871 s, inc stats = 4.8000, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94733038 2.80007076 3.41253993 3.01265139 2.46425221]
u_DA:    [3.8938773  1.92665765 3.014081   1.61659699 2.69568642]
ref_MAE: [0.10687598 0.63829036 0.87360515 1.16009794 0.0876185 ]
da_MAE:  [0.05345308 0.87341311 0.39845893 1.39605439 0.23143421]
% 17.691364477044623 da_MAE 0.006215307869287206 ref_MAE 0.007551222092065655
u_c taken from control states: [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
u_c before reduction of space:  [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
data[u_c] post encoding of state:  [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
J_b = 0.0, J_o = 418518.3464779303
J_b = 0.5, J_o = 15075714.588335339
J_b = 0.0037792214605168895, J_o = 284415.0661650746
J_b = 0.00939313424034634, J_o = 191507.75519545496
J_b = 0.01861941403632598, J_o = 141528.1801613131
J_b = 0.02833641640018814, J_o = 112532.3693176055
J_b = 0.037630665092388806, J_o = 92849.23216319665
J_b = 0.05028282555171071, J_o = 77630.70275704093
J_b = 0.06444127189378433, J_o = 67677.70765877349
J_b = 0.08874389064403077, J_o = 61678.56846793134
J_b = 0.09225200150903683, J_o = 56587.0390253215
J_b = 0.09319261251757298, J_o = 54664.953114614436
J_b = 0.09971773503883884, J_o = 52465.8307503322
J_b = 0.11823780422638776, J_o = 50777.1789523735
J_b = 0.1297661988474232, J_o = 48636.244976466005
J_b = 0.13087216600280918, J_o = 48008.54313282923
J_b = 0.13710924611878636, J_o = 47226.03761420914
J_b = 0.14656166413024044, J_o = 47654.143575619426
J_b = 0.14073293628541597, J_o = 46817.90160917658
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
W_opt:  [ 6.59109740e-03  1.36499775e-02  1.90200605e-02  1.62736079e-02
  1.25467139e-02  1.20353746e-04 -2.64773326e-02 -7.68160016e-02
 -1.44696355e-01 -2.17105510e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3721 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.2057, add (DA)= 0.0001decode = 0.3123 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.6845 s, inc stats = 5.6958, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94656003 2.79769652 3.41130549 3.00860393 2.46767119]
u_DA:    [3.88975485 1.91684847 3.00604744 1.57718434 2.70207453]
ref_MAE: [0.10610563 0.63591612 0.87237071 1.15605048 0.09103748]
da_MAE:  [0.05680518 0.88084805 0.40525806 1.43141959 0.23440334]
% 17.477132373298407 da_MAE 0.006240776300076574 ref_MAE 0.007562481139539643
u_c taken from control states: [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
u_c before reduction of space:  [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
data[u_c] post encoding of state:  [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
J_b = 0.0, J_o = 423413.02492138394
J_b = 0.49999999999999983, J_o = 15011869.267290976
J_b = 0.0038509972443977916, J_o = 287132.5920549894
J_b = 0.009548808925192826, J_o = 193843.93618764807
J_b = 0.018512879097010933, J_o = 144916.6133441041
J_b = 0.028476964945023903, J_o = 114914.56652749755
J_b = 0.037774640652230726, J_o = 95091.7801725354
J_b = 0.050489887270675556, J_o = 79790.66237775139
J_b = 0.06463496950443505, J_o = 69739.57596060932
J_b = 0.08994144016718449, J_o = 63685.07401746728
J_b = 0.0939004767757662, J_o = 58307.770545243264
J_b = 0.09423440854976962, J_o = 56398.46240528851
J_b = 0.10032563187955586, J_o = 54255.045860117025
J_b = 0.12001600098012483, J_o = 53307.14012429648
J_b = 0.12256391472691165, J_o = 50913.69073462453
J_b = 0.127157050756383, J_o = 50352.815614607796
J_b = 0.13091509327780557, J_o = 49822.002445356695
J_b = 0.13279580812461367, J_o = 49552.4730200443
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
W_opt:  [ 0.01333384  0.01937078  0.02303242  0.0172367   0.00924168 -0.00682813
 -0.03526433 -0.08347771 -0.14541475 -0.20883425]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0513 s, v_trunc (Latent to Reduced) = 0.1031, dec (Reduced to Full) = 0.2213, add (DA)= 0.0001decode = 0.3274 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3789 s, inc stats = 5.3937, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94575895 2.79501179 3.4100744  3.0047426  2.47092416]
u_DA:    [3.89075308 1.91732999 3.01027586 1.58256764 2.7032198 ]
ref_MAE: [0.10530455 0.63323139 0.87113961 1.15218915 0.09429045]
da_MAE:  [0.05500586 0.8776818  0.39979853 1.42217495 0.23229564]
% 17.429900351318693 da_MAE 0.0062530290889832585 ref_MAE 0.00757299448055483
u_c taken from control states: [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
u_c before reduction of space:  [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
data[u_c] post encoding of state:  [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
J_b = 0.0, J_o = 427685.2912292315
J_b = 0.5000000000000002, J_o = 14919474.232737321
J_b = 0.003922619253611627, J_o = 289517.8340786823
J_b = 0.009707829395241967, J_o = 196106.85919605684
J_b = 0.018369541766750295, J_o = 148475.99154464234
J_b = 0.028602241339830834, J_o = 117403.12550071483
J_b = 0.03790362307637078, J_o = 97455.75181547337
J_b = 0.0507973639186756, J_o = 81960.0427316138
J_b = 0.06510112900687799, J_o = 71800.22925739763
J_b = 0.09161043340076187, J_o = 65974.84493336391
J_b = 0.09489950187564151, J_o = 60250.31836115179
J_b = 0.09445537937011518, J_o = 58328.99627575843
J_b = 0.10016233566104846, J_o = 56114.01516398467
J_b = 0.11625520454355709, J_o = 53684.9887833964
J_b = 0.12996848071229353, J_o = 51995.2429968194
J_b = 0.1402378655780297, J_o = 51758.96070175001
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
W_opt:  [ 0.01663645  0.02316611  0.02868166  0.02203918  0.01189997 -0.006295
 -0.03655642 -0.08641794 -0.14973205 -0.21433283]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5592 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1777, add (DA)= 0.0001decode = 0.2848 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.8441 s, inc stats = 4.8567, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94493466 2.7920876  3.40884207 3.00116618 2.47389692]
u_DA:    [3.89623151 1.93135125 3.00005973 1.63404707 2.6775442 ]
ref_MAE: [0.10448026 0.6303072  0.86990729 1.14861273 0.09726321]
da_MAE:  [0.04870315 0.86073635 0.40878234 1.36711911 0.20364727]
% 17.673861488769358 da_MAE 0.006246403270563206 ref_MAE 0.0075873876553934246
u_c taken from control states: [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
u_c before reduction of space:  [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
data[u_c] post encoding of state:  [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
J_b = 0.0, J_o = 430268.6954337411
J_b = 0.4999999999999998, J_o = 14831292.029902628
J_b = 0.003970137375512521, J_o = 291122.4596340088
J_b = 0.009812465360403085, J_o = 198038.0434113008
J_b = 0.018183445192723423, J_o = 151702.74017159067
J_b = 0.028640475163335895, J_o = 119736.2601634627
J_b = 0.0379557653203506, J_o = 99679.1582577106
J_b = 0.05114904998220368, J_o = 83878.89360336163
J_b = 0.06580999921334581, J_o = 73603.34519055505
J_b = 0.09325764083052084, J_o = 67912.71998390554
J_b = 0.09525513221447748, J_o = 61949.294801092845
J_b = 0.09478624624894622, J_o = 60000.50144907011
J_b = 0.10065453252621354, J_o = 57722.45203087652
J_b = 0.11515240736253879, J_o = 54821.52381822305
J_b = 0.13896946932382745, J_o = 54505.748975705494
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
W_opt:  [ 0.01861992  0.02522082  0.03136932  0.02509742  0.01383434 -0.00627826
 -0.03773188 -0.08771127 -0.15008684 -0.21339034]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2355 s, v_trunc (Latent to Reduced) = 0.1085, dec (Reduced to Full) = 0.1947, add (DA)= 0.0001decode = 0.3055 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.5411 s, inc stats = 4.5536, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94410183 2.78901632 3.40762096 2.99799387 2.47655864]
u_DA:    [3.89489369 1.91676435 3.01833554 1.62085191 2.68105135]
ref_MAE: [0.10364743 0.62723592 0.86868618 1.14544042 0.09992493]
da_MAE:  [0.04920814 0.87225197 0.38928542 1.37714196 0.20449271]
% 17.77947881539064 da_MAE 0.006251894427497086 ref_MAE 0.007603812694716124
u_c taken from control states: [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
u_c before reduction of space:  [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
data[u_c] post encoding of state:  [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
J_b = 0.0, J_o = 430923.14867054636
J_b = 0.49999999999999983, J_o = 14785130.219419807
J_b = 0.003978913597999899, J_o = 291889.3645469862
J_b = 0.009828105386092977, J_o = 199404.8233147008
J_b = 0.018012856633825996, J_o = 153917.77272152313
J_b = 0.028581710833889395, J_o = 121498.35136366972
J_b = 0.03791604957641997, J_o = 101359.66804351097
J_b = 0.051417214962756155, J_o = 85258.42010968774
J_b = 0.06655344655617527, J_o = 74861.45959851072
J_b = 0.09434630561033672, J_o = 68960.68280341262
J_b = 0.0954781183299398, J_o = 63101.36033927165
J_b = 0.09532104908064636, J_o = 61093.116648910596
J_b = 0.10124346380760764, J_o = 58839.84144954157
J_b = 0.11592831647667785, J_o = 55734.51379634542
J_b = 0.14167434465261206, J_o = 58192.76954732725
J_b = 0.12369933099412549, J_o = 54852.972141142774
J_b = 0.14052918329491088, J_o = 53530.16852023925
J_b = 0.1422408298203423, J_o = 53096.68521211692
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
W_opt:  [ 0.01699057  0.02730349  0.03372321  0.02792548  0.01623275 -0.00528244
 -0.03810804 -0.08942121 -0.1523062  -0.21618004]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1676 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.2041, add (DA)= 0.0002decode = 0.3120 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.4799 s, inc stats = 5.4932, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94328189 2.78588968 3.40643176 2.99535641 2.4789957 ]
u_DA:    [3.89685613 1.92813386 3.02311264 1.64578115 2.67227879]
ref_MAE: [0.10282749 0.62410929 0.86749698 1.14280296 0.10236199]
da_MAE:  [0.04642576 0.85775583 0.38331912 1.34957525 0.19328308]
% 17.976249014337316 da_MAE 0.006247952703001015 ref_MAE 0.007617248209110949
u_c taken from control states: [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
u_c before reduction of space:  [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
data[u_c] post encoding of state:  [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
J_b = 0.0, J_o = 429845.071477477
J_b = 0.5000000000000001, J_o = 14723761.826752476
J_b = 0.0039609244782440635, J_o = 292088.9026853898
J_b = 0.009792421690021131, J_o = 200612.2035847495
J_b = 0.01782037961311845, J_o = 155984.6254008428
J_b = 0.02840743515788686, J_o = 123498.73795995652
J_b = 0.03773556463967082, J_o = 103363.68743467238
J_b = 0.05163366909663006, J_o = 86877.87968555395
J_b = 0.06741340328687294, J_o = 76354.75806791405
J_b = 0.09485590732351329, J_o = 69928.3080591693
J_b = 0.09583262463413515, J_o = 64480.68775420076
J_b = 0.0962310936856495, J_o = 62362.60630316524
J_b = 0.10222262211287875, J_o = 60177.60596021774
J_b = 0.11809191308344495, J_o = 56893.75751262701
J_b = 0.14166283576603403, J_o = 60621.28145168255
J_b = 0.12407952243821023, J_o = 56148.572030753305
J_b = 0.1406874984705597, J_o = 54697.40139010849
J_b = 0.14521647195538687, J_o = 54073.75517206895
J_b = 0.15601480732479006, J_o = 53543.42246061126
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
W_opt:  [ 0.00303344  0.02668722  0.04048472  0.03651928  0.02598856  0.00557249
 -0.02748678 -0.08368783 -0.15433591 -0.22961879]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.4191 s, v_trunc (Latent to Reduced) = 0.1062, dec (Reduced to Full) = 0.1898, add (DA)= 0.0001decode = 0.2985 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.7178 s, inc stats = 5.7313, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94249599 2.78278491 3.40529443 2.99336342 2.48133689]
u_DA:    [3.89869031 1.93708132 3.01638107 1.6865946  2.64740016]
ref_MAE: [0.10204159 0.62100451 0.86635964 1.14080997 0.10470317]
da_MAE:  [0.04380568 0.84570359 0.38891335 1.30676882 0.16606328]
% 18.219648536203906 da_MAE 0.006238066927389028 ref_MAE 0.007627830910155235
u_c taken from control states: [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
u_c before reduction of space:  [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
data[u_c] post encoding of state:  [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
J_b = 0.0, J_o = 429180.20691050903
J_b = 0.5000000000000001, J_o = 14551308.923942884
J_b = 0.003960330549555724, J_o = 293102.2451003529
J_b = 0.009820929448690546, J_o = 202900.69868283602
J_b = 0.017601213470419, J_o = 159786.53315894053
J_b = 0.028212638546146234, J_o = 127288.96114784175
J_b = 0.03743809066642672, J_o = 107394.2230969583
J_b = 0.05188998011128125, J_o = 90369.50601977811
J_b = 0.06845388003935106, J_o = 79771.80815216749
J_b = 0.09486407360686085, J_o = 72665.35097731453
J_b = 0.09653826759081643, J_o = 67731.65294754937
J_b = 0.09789119133710986, J_o = 65416.73730325907
J_b = 0.10423282511053147, J_o = 63275.84472469885
J_b = 0.12226564550427764, J_o = 59770.77193624462
J_b = 0.14741208844980278, J_o = 65077.04251634002
J_b = 0.1277387041371404, J_o = 59113.58680601529
J_b = 0.14191485761712358, J_o = 57908.5629764192
J_b = 0.14553226305420083, J_o = 57370.38688822089
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
W_opt:  [ 0.0045929   0.03063445  0.04324691  0.03785261  0.02345898 -0.00038026
 -0.03521958 -0.08933041 -0.15335821 -0.21801803]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3559 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1865, add (DA)= 0.0001decode = 0.2937 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6497 s, inc stats = 5.6577, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94176834 2.77972456 3.4042264  2.99210838 2.48381561]
u_DA:    [3.89963632 1.93375613 3.03740756 1.67439174 2.65525046]
ref_MAE: [0.10131394 0.61794416 0.86529161 1.13955493 0.10718189]
da_MAE:  [0.04213202 0.84596842 0.36681883 1.31771663 0.17143486]
% 18.25179180181473 da_MAE 0.006241803405463636 ref_MAE 0.0076354008767157274
\% improve_point: 12.60, mse_ref_points: 3.47766175949086e-05, mse_da_points: 3.0393749198615813e-05, % improve_overlap: 12.60, mse_ref_overlap: 0.90583, mse_da_overlap: 0.79169
DA - - L2: 62529.73, L1: 5529.98, % Improve: 17.99%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.791, time(s): 8.3417s,
u_c taken from control states: [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
u_c before reduction of space:  [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
data[u_c] post encoding of state:  [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
J_b = 0.0, J_o = 427734.25647887815
J_b = 0.5, J_o = 14362722.917933885
J_b = 0.00396089758546952, J_o = 293438.2310037989
J_b = 0.009862449208805432, J_o = 204355.53347882722
J_b = 0.017442879422851852, J_o = 162621.57421660115
J_b = 0.027996664235830422, J_o = 130444.70047494971
J_b = 0.03702222727685007, J_o = 111018.6971335874
J_b = 0.051845798255153605, J_o = 93624.14620737139
J_b = 0.0690269723013265, J_o = 83009.26703645813
J_b = 0.09454517522248716, J_o = 75476.87091972763
J_b = 0.09699672685051698, J_o = 70840.78646046126
J_b = 0.09923596027191976, J_o = 68352.87593881453
J_b = 0.10606110766110884, J_o = 66201.90061278902
J_b = 0.12642973082205225, J_o = 62755.21619668798
J_b = 0.14915029757994144, J_o = 63689.387514466594
J_b = 0.13521148540968703, J_o = 61764.25192494323
J_b = 0.14451813071568442, J_o = 60907.515275809055
J_b = 0.1449445534553571, J_o = 60596.7297069482
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
W_opt:  [-0.00023834  0.02813832  0.04253791  0.0406053   0.02746389  0.00281899
 -0.03306949 -0.0880076  -0.15194866 -0.21585708]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0281 s, v_trunc (Latent to Reduced) = 0.1025, dec (Reduced to Full) = 0.2093, add (DA)= 0.0001decode = 0.3139 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3422 s, inc stats = 5.3551, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94111966 2.77670414 3.40322547 2.99163227 2.48666347]
u_DA:    [3.90107744 1.9386285  3.03832155 1.69467604 2.64393863]
ref_MAE: [0.10066526 0.61492374 0.86429069 1.13907882 0.11002975]
da_MAE:  [0.04004222 0.83807564 0.36490392 1.29695622 0.15727516]
% 18.249551635266236 da_MAE 0.006246682157374296 ref_MAE 0.00764115950716797
u_c taken from control states: [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
u_c before reduction of space:  [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
data[u_c] post encoding of state:  [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
J_b = 0.0, J_o = 424837.5046910527
J_b = 0.4999999999999998, J_o = 14197203.664802723
J_b = 0.0039396807764166646, J_o = 292896.3247919158
J_b = 0.00986175467915174, J_o = 204796.3878169229
J_b = 0.017363836014991915, J_o = 163993.114782379
J_b = 0.02770255367946456, J_o = 132726.3407442548
J_b = 0.03647592222080122, J_o = 113897.31380250957
J_b = 0.05141776102055346, J_o = 96353.75482866069
J_b = 0.0690211792379328, J_o = 85723.63977418152
J_b = 0.09421050363256575, J_o = 78052.27964322924
J_b = 0.09690864975784587, J_o = 73567.70648678008
J_b = 0.09953121985387514, J_o = 71013.44607661053
J_b = 0.10670124378198657, J_o = 68828.98346173837
J_b = 0.12887504158771965, J_o = 65645.36595637843
J_b = 0.1460249889800806, J_o = 64954.30808017487
J_b = 0.14488266306593423, J_o = 63603.51881461154
J_b = 0.1432197013526503, J_o = 63389.69453117018
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
W_opt:  [-0.00336819  0.02431832  0.03861808  0.04025689  0.03052448  0.00673197
 -0.02947619 -0.08518539 -0.14931186 -0.21258051]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7716 s, v_trunc (Latent to Reduced) = 0.1041, dec (Reduced to Full) = 0.1939, add (DA)= 0.0001decode = 0.3001 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0718 s, inc stats = 5.0844, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94054796 2.77375261 3.40228196 2.99187276 2.48984431]
u_DA:    [3.9023524  1.94200293 3.03945515 1.71356041 2.63025957]
ref_MAE: [0.10009356 0.61197221 0.86334717 1.13931931 0.1132106 ]
da_MAE:  [0.03819555 0.83174968 0.3628268  1.27831235 0.14041526]
% 18.261137936280587 da_MAE 0.006253566927753367 ref_MAE 0.007650665509483613
u_c taken from control states: [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
u_c before reduction of space:  [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
data[u_c] post encoding of state:  [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
J_b = 0.0, J_o = 420644.87212672975
J_b = 0.5, J_o = 14027011.712456325
J_b = 0.003908571129222685, J_o = 291433.6398334444
J_b = 0.009849790998039405, J_o = 204168.19036755766
J_b = 0.01735794910436702, J_o = 164055.34839234973
J_b = 0.02736725344035938, J_o = 134123.8215739941
J_b = 0.03587506911935787, J_o = 115931.59050691538
J_b = 0.0508569609651477, J_o = 98281.07216158854
J_b = 0.06883354223879491, J_o = 87584.5736058789
J_b = 0.09428581982236518, J_o = 80000.72352060187
J_b = 0.09653999002246728, J_o = 75624.70484474917
J_b = 0.0988976566929423, J_o = 73129.25655000453
J_b = 0.1061644694329729, J_o = 70904.8395075941
J_b = 0.12894256462184195, J_o = 67705.01921679871
J_b = 0.1463358331018596, J_o = 66927.48485960717
J_b = 0.1454115183973159, J_o = 65609.77641838968
J_b = 0.14368011396411304, J_o = 65388.87593412853
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
W_opt:  [-0.00627407  0.01996064  0.03465214  0.03864094  0.03232873  0.01053334
 -0.02517014 -0.08180015 -0.14712483 -0.211018  ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7956 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1968, add (DA)= 0.0001decode = 0.3032 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0991 s, inc stats = 5.1074, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94003601 2.77092732 3.40138429 2.99270336 2.49308591]
u_DA:    [3.90283795 1.94266413 3.03879697 1.72482392 2.62067437]
ref_MAE: [0.09958161 0.60914692 0.86244951 1.14014991 0.1164522 ]
da_MAE:  [0.03719807 0.82826319 0.36258732 1.26787944 0.12758846]
% 18.206588035345078 da_MAE 0.006265446259179327 ref_MAE 0.007660086685082646
u_c taken from control states: [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
u_c before reduction of space:  [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
data[u_c] post encoding of state:  [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
J_b = 0.0, J_o = 415863.1966152444
J_b = 0.5000000000000001, J_o = 13908457.516971901
J_b = 0.0038699656746171342, J_o = 289132.73458733637
J_b = 0.00981772285792817, J_o = 202228.83801279834
J_b = 0.017464700459327912, J_o = 162214.19401168393
J_b = 0.02707978338123379, J_o = 133822.73360097216
J_b = 0.03539880661918584, J_o = 116106.17482116562
J_b = 0.050293252672455845, J_o = 98447.56720341218
J_b = 0.06839049874798855, J_o = 87557.98476414086
J_b = 0.09541664819863366, J_o = 80476.26183536222
J_b = 0.09619600771292837, J_o = 76026.54081252491
J_b = 0.09714202352252448, J_o = 73823.0742129257
J_b = 0.10389628278710508, J_o = 71549.57127774003
J_b = 0.1247536695447149, J_o = 67990.54984518905
J_b = 0.15094059240193608, J_o = 69071.41108127507
J_b = 0.13471040742016133, J_o = 66929.6663360016
J_b = 0.1464915258105205, J_o = 66025.86857629761
J_b = 0.1463347443628351, J_o = 65702.74183096019
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
W_opt:  [-0.0088461   0.01490691  0.03075431  0.03648503  0.03302332  0.01346573
 -0.02143647 -0.0787087  -0.14589992 -0.21165977]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1113 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.1753, add (DA)= 0.0001decode = 0.2825 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3940 s, inc stats = 5.4076, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93957172 2.76828194 3.40052114 2.99399729 2.4961908 ]
u_DA:    [3.90304913 1.94087108 3.03923547 1.72680179 2.61795966]
ref_MAE: [0.09911732 0.60650154 0.86158636 1.14144384 0.11955709]
da_MAE:  [0.03652259 0.82741086 0.36128567 1.26719551 0.12176886]
% 18.123018561022953 da_MAE 0.006279863050079077 ref_MAE 0.007669876123559174
u_c taken from control states: [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
u_c before reduction of space:  [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
data[u_c] post encoding of state:  [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
J_b = 0.0, J_o = 411907.6643964993
J_b = 0.5000000000000001, J_o = 13837269.150015876
J_b = 0.003821151862419672, J_o = 287567.2160292684
J_b = 0.009755248831944046, J_o = 200802.83075828146
J_b = 0.01763188920137114, J_o = 160456.5302012402
J_b = 0.026841272480315214, J_o = 133621.93210447382
J_b = 0.03506301722999237, J_o = 116214.12891859887
J_b = 0.049772756317281626, J_o = 98657.03847288681
J_b = 0.06773248636389351, J_o = 87516.1727618562
J_b = 0.0967493212432137, J_o = 81306.15548948891
J_b = 0.0960803153663812, J_o = 76527.03590952541
J_b = 0.09537824710312823, J_o = 74668.82187555484
J_b = 0.10152905858301511, J_o = 72308.629442111
J_b = 0.12052469967062518, J_o = 69152.60168878688
J_b = 0.14220505168037145, J_o = 68017.58448603128
J_b = 0.14753211258891075, J_o = 67022.69114116066
J_b = 0.14254878640541724, J_o = 66612.76564469132
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
W_opt:  [-0.00657647  0.01175827  0.02644327  0.03223424  0.02987222  0.01161277
 -0.02224528 -0.07730603 -0.14311294 -0.20709682]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7511 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1597, add (DA)= 0.0001decode = 0.2657 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0169 s, inc stats = 5.0297, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93914523 2.7658555  3.39968518 2.99564192 2.49916722]
u_DA:    [3.90292645 1.93947435 3.0391222  1.73150122 2.61943451]
ref_MAE: [0.09869083 0.6040751  0.8607504  1.14308847 0.12253351]
da_MAE:  [0.03621878 0.82638115 0.36056298 1.2641407  0.12026729]
% 18.04449504306184 da_MAE 0.0062937924452083505 ref_MAE 0.007679523722677683
u_c taken from control states: [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
u_c before reduction of space:  [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
data[u_c] post encoding of state:  [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
J_b = 0.0, J_o = 407885.73850500607
J_b = 0.5000000000000001, J_o = 13843466.325052818
J_b = 0.003765496247406606, J_o = 285452.67669929273
J_b = 0.009660169158628648, J_o = 198463.4399932079
J_b = 0.01787434548665612, J_o = 157151.80111157012
J_b = 0.02672420587018888, J_o = 131677.08644375697
J_b = 0.03500244167011817, J_o = 114285.56981118002
J_b = 0.049508887839747114, J_o = 96904.63232738251
J_b = 0.0671889846068565, J_o = 85722.19927384
J_b = 0.09577183242128046, J_o = 79596.7176140637
J_b = 0.0958108339540024, J_o = 74935.1906585324
J_b = 0.09522619186430395, J_o = 73081.66341597789
J_b = 0.10144402176084218, J_o = 70852.3881588894
J_b = 0.12497481821379637, J_o = 69181.67069953162
J_b = 0.1298608613428872, J_o = 66870.63830520122
J_b = 0.13600353570077015, J_o = 66525.40952798373
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
W_opt:  [-0.00112526  0.01343035  0.02318583  0.02689897  0.02382339  0.00582453
 -0.02728907 -0.07915434 -0.14188474 -0.20215221]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4907 s, v_trunc (Latent to Reduced) = 0.1041, dec (Reduced to Full) = 0.1869, add (DA)= 0.0001decode = 0.2932 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7841 s, inc stats = 4.7916, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93874457 2.76368301 3.398866   2.99749349 2.50195261]
u_DA:    [3.90254826 1.93999783 3.03398357 1.7349198  2.62671752]
ref_MAE: [0.09829017 0.60190261 0.85993122 1.14494004 0.12531889]
da_MAE:  [0.03619631 0.82368517 0.36488243 1.26257369 0.12476491]
% 17.934785808296677 da_MAE 0.006309758531153577 ref_MAE 0.007688712682104332
u_c taken from control states: [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
u_c before reduction of space:  [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
data[u_c] post encoding of state:  [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
J_b = 0.0, J_o = 405250.84672407625
J_b = 0.5, J_o = 13847725.668900978
J_b = 0.003753649212526813, J_o = 283180.71842258034
J_b = 0.009659989639347506, J_o = 195389.0004616766
J_b = 0.018169802556960258, J_o = 153116.70985647693
J_b = 0.02681982780366631, J_o = 128410.75560710888
J_b = 0.03522053112951105, J_o = 110888.05541187953
J_b = 0.04956248411216538, J_o = 93709.70618864929
J_b = 0.06683501605417541, J_o = 82963.79234846188
J_b = 0.0921753398620011, J_o = 76471.5748957433
J_b = 0.09354820997549708, J_o = 72360.02072888461
J_b = 0.09473431019361948, J_o = 70306.10995071154
J_b = 0.10174766936624272, J_o = 68220.45511680987
J_b = 0.12689485317350568, J_o = 66665.7266360571
J_b = 0.12950047256732736, J_o = 64442.849585801094
J_b = 0.1333526959968861, J_o = 64120.304003081474
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
W_opt:  [ 0.00140849  0.01437818  0.02172667  0.02382576  0.01912105  0.00083304
 -0.03119341 -0.08144849 -0.1434652  -0.20343022]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5184 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1892, add (DA)= 0.0001decode = 0.2961 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 4.8148 s, inc stats = 4.8279, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93835657 2.76179847 3.39805086 2.99939743 2.50437555]
u_DA:    [3.90070206 1.93902829 3.02597811 1.73414495 2.63795838]
ref_MAE: [0.09790217 0.60001807 0.85911608 1.14684398 0.12774184]
da_MAE:  [0.03765451 0.82277017 0.37207276 1.26525248 0.13358283]
% 17.885284769228733 da_MAE 0.00632149185321638 ref_MAE 0.007698366651398305
u_c taken from control states: [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
u_c before reduction of space:  [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
data[u_c] post encoding of state:  [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
J_b = 0.0, J_o = 410015.39697466244
J_b = 0.49999999999999994, J_o = 13469951.118960433
J_b = 0.003937647741464855, J_o = 284970.92920881166
J_b = 0.010192925375966467, J_o = 195370.09547029826
J_b = 0.018550594991944905, J_o = 154336.64830440996
J_b = 0.027520264037653792, J_o = 128730.81410125658
J_b = 0.03609855541459603, J_o = 110941.40050155544
J_b = 0.05099123596201328, J_o = 93284.03121043352
J_b = 0.06823923632410057, J_o = 83398.22186942458
J_b = 0.08746386616648702, J_o = 76604.33741197512
J_b = 0.09144281883233206, J_o = 73125.74758176679
J_b = 0.09473678993496884, J_o = 70809.61663778775
J_b = 0.10145326435102626, J_o = 68828.90734770271
J_b = 0.12360573392409104, J_o = 65941.00899028785
J_b = 0.13603134006569317, J_o = 65066.744591375114
J_b = 0.1368163870322989, J_o = 63867.116291111124
J_b = 0.13689828624233785, J_o = 63530.4526788364
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
W_opt:  [-2.62962872e-05  1.25855384e-02  1.96119982e-02  2.17722890e-02
  1.62039618e-02 -1.94748809e-03 -3.32405816e-02 -8.33751462e-02
 -1.47272281e-01 -2.10310147e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7153 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1780, add (DA)= 0.0002decode = 0.2838 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.9993 s, inc stats = 5.0050, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93797206 2.76025246 3.39722972 3.00122915 2.50634349]
u_DA:    [3.89672724 1.92550847 3.0249918  1.69165627 2.66268059]
ref_MAE: [0.09751765 0.59847207 0.85829493 1.1486757  0.12970978]
da_MAE:  [0.04124482 0.834744   0.37223791 1.30957288 0.1563371 ]
% 17.725053421808134 da_MAE 0.006342613066179179 ref_MAE 0.007709045499229018
u_c taken from control states: [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
u_c before reduction of space:  [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
data[u_c] post encoding of state:  [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
J_b = 0.0, J_o = 411131.0425244837
J_b = 0.5000000000000001, J_o = 13839721.941198535
J_b = 0.0038385852359778053, J_o = 286132.9163614521
J_b = 0.009909445541762079, J_o = 195046.05684244205
J_b = 0.018995674507041965, J_o = 150468.36243007577
J_b = 0.02768782149645012, J_o = 125796.33654915015
J_b = 0.03665120556279527, J_o = 107299.69368027055
J_b = 0.05143500768576282, J_o = 89766.73884015437
J_b = 0.06902126235883492, J_o = 79816.83748531312
J_b = 0.08708700082635228, J_o = 72822.1784088838
J_b = 0.09184173196132689, J_o = 69215.9868904234
J_b = 0.096479441357968, J_o = 66681.48704081567
J_b = 0.10370224607439857, J_o = 64659.115032700094
J_b = 0.12448570442396527, J_o = 61718.43648406405
J_b = 0.1386166450547483, J_o = 61317.424110522436
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
W_opt:  [ 0.00551481  0.01465524  0.01936721  0.0204519   0.01337651 -0.00548424
 -0.0370486  -0.08716619 -0.1510025  -0.21379078]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2719 s, v_trunc (Latent to Reduced) = 0.1056, dec (Reduced to Full) = 0.1741, add (DA)= 0.0001decode = 0.2820 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.5541 s, inc stats = 4.5668, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9375834  2.75909416 3.39639638 3.00289321 2.50781074]
u_DA:    [3.89405804 1.90916012 3.02710824 1.66091433 2.6786243 ]
ref_MAE: [0.097129   0.59731376 0.8574616  1.15033976 0.13117703]
da_MAE:  [0.04352535 0.84993404 0.36928814 1.34197888 0.17081356]
% 17.701710483190112 da_MAE 0.0063533188531005895 ref_MAE 0.007719867436373496
u_c taken from control states: [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
u_c before reduction of space:  [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
data[u_c] post encoding of state:  [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
J_b = 0.0, J_o = 411559.36813321884
J_b = 0.5, J_o = 14327621.223226946
J_b = 0.003707900626890542, J_o = 286888.5448932479
J_b = 0.009523103166679137, J_o = 194697.67767256036
J_b = 0.0194248364544228, J_o = 145739.17235556917
J_b = 0.027820555492286365, J_o = 122068.28196840646
J_b = 0.037073261225349735, J_o = 103133.78105400123
J_b = 0.05166180709934149, J_o = 85792.52379032937
J_b = 0.06990483885336847, J_o = 75437.80059564917
J_b = 0.08875515824452838, J_o = 68080.71432067534
J_b = 0.09428169298089266, J_o = 64213.79374036187
J_b = 0.09999594588749439, J_o = 61444.03159071863
J_b = 0.10768068023000028, J_o = 59364.763587706904
J_b = 0.12804341829227414, J_o = 56422.08363110147
J_b = 0.14267384055530988, J_o = 55905.94593193398
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
W_opt:  [ 0.00917403  0.01533089  0.01918334  0.01992259  0.01259876 -0.00654564
 -0.03883693 -0.09018443 -0.15483405 -0.21822891]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4830 s, v_trunc (Latent to Reduced) = 0.1124, dec (Reduced to Full) = 0.1985, add (DA)= 0.0001decode = 0.3131 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7963 s, inc stats = 52.1629, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9371823  2.75836606 3.39554487 3.00430921 2.50870118]
u_DA:    [3.8930927  1.90694587 3.02540336 1.64570106 2.679076  ]
ref_MAE: [0.0967279  0.59658566 0.85661009 1.15175576 0.13206747]
da_MAE:  [0.0440896  0.85142018 0.37014152 1.35860815 0.17037482]
% 17.688587713415977 da_MAE 0.006363635452256182 ref_MAE 0.007731170290335783
\% improve_point: 12.70, mse_ref_points: 3.49696078940064e-05, mse_da_points: 3.052650098969752e-05, % improve_overlap: 12.70, mse_ref_overlap: 0.91087, mse_da_overlap: 0.79516
DA - - L2: 52724.69, L1: 5238.54, % Improve: 17.99%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.795, time(s): 8.5707s,
u_c taken from control states: [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
u_c before reduction of space:  [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
data[u_c] post encoding of state:  [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
J_b = 0.0, J_o = 417933.575503013
J_b = 0.5, J_o = 14426841.175554823
J_b = 0.0037368958660082686, J_o = 291346.7761921973
J_b = 0.009585576271793812, J_o = 197444.40233772315
J_b = 0.0198444316120793, J_o = 146606.00624809816
J_b = 0.028307069986010947, J_o = 122797.6675992923
J_b = 0.03773679056380346, J_o = 103558.25051195684
J_b = 0.052458698433143006, J_o = 86041.10502141921
J_b = 0.07124778622608545, J_o = 75319.49122670159
J_b = 0.09094032808948345, J_o = 67542.92457272526
J_b = 0.09760246276856865, J_o = 63359.30984134118
J_b = 0.10469303071674811, J_o = 60335.22126064154
J_b = 0.11271690766236403, J_o = 58201.742886157364
J_b = 0.131587154059729, J_o = 55329.4049256175
J_b = 0.14766537725858292, J_o = 54618.219294643655
J_b = 0.15134346043631652, J_o = 52979.399387496676
J_b = 0.1499638492797298, J_o = 52590.204220264146
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
W_opt:  [ 0.00882866  0.01514241  0.01880566  0.02004849  0.013445   -0.00515191
 -0.03765984 -0.09084824 -0.15798256 -0.22404075]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7489 s, v_trunc (Latent to Reduced) = 0.1467, dec (Reduced to Full) = 0.1954, add (DA)= 0.0001decode = 0.3443 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0933 s, inc stats = 5.1062, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93676869 2.75806816 3.39467217 3.00543937 2.509108  ]
u_DA:    [3.89302628 1.91362926 3.01470715 1.64349087 2.6765747 ]
ref_MAE: [0.09631429 0.59628776 0.85573739 1.15288592 0.13247429]
da_MAE:  [0.04374241 0.8444389  0.37996502 1.3619485  0.1674667 ]
% 17.659573910128927 da_MAE 0.006375463536713685 ref_MAE 0.007742810961112999
u_c taken from control states: [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
u_c before reduction of space:  [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
data[u_c] post encoding of state:  [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
J_b = 0.0, J_o = 424471.16300831083
J_b = 0.5000000000000002, J_o = 14424872.74514565
J_b = 0.00379679135916266, J_o = 295718.6627076476
J_b = 0.009734735374070163, J_o = 200260.77446279384
J_b = 0.020173189415667245, J_o = 148449.791887709
J_b = 0.028799468552903596, J_o = 124192.38047378509
J_b = 0.038306382238436264, J_o = 104799.234601047
J_b = 0.05303894418794011, J_o = 87236.11341681253
J_b = 0.07182847732806306, J_o = 76320.7454036406
J_b = 0.09243345252691926, J_o = 68310.97847037515
J_b = 0.09975015724249069, J_o = 63913.417278342386
J_b = 0.10751078457278249, J_o = 60766.282435250265
J_b = 0.11564480721110823, J_o = 58642.937077160816
J_b = 0.13311464497690506, J_o = 55910.66864824047
J_b = 0.14908044526652323, J_o = 54759.70744727443
J_b = 0.15641424068119184, J_o = 53383.88335536054
J_b = 0.15340672464807908, J_o = 53036.53560312514
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
W_opt:  [ 0.00811452  0.01652121  0.02031262  0.02149313  0.01492873 -0.00332382
 -0.03606656 -0.09070605 -0.15909574 -0.22654761]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7825 s, v_trunc (Latent to Reduced) = 0.1044, dec (Reduced to Full) = 0.1796, add (DA)= 0.0001decode = 0.2863 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0690 s, inc stats = 5.0817, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93634497 2.75813076 3.3937798  3.0062726  2.50919532]
u_DA:    [3.89355352 1.91538343 3.01410264 1.63812423 2.6799473 ]
ref_MAE: [0.09589057 0.59635037 0.85484501 1.15371915 0.13256161]
da_MAE:  [0.04279146 0.84274733 0.37967716 1.36814838 0.17075197]
% 17.65845110379246 da_MAE 0.006385173500867439 ref_MAE 0.007754497682471364
u_c taken from control states: [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
u_c before reduction of space:  [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
data[u_c] post encoding of state:  [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
J_b = 0.0, J_o = 429079.52791344305
J_b = 0.5000000000000001, J_o = 14425665.321157373
J_b = 0.0038370761161380424, J_o = 298850.96316178906
J_b = 0.009833026859243293, J_o = 202367.18566757813
J_b = 0.020411148424921255, J_o = 149704.7587694642
J_b = 0.02922684246455575, J_o = 124943.80666858655
J_b = 0.03875227391416926, J_o = 105524.67343170692
J_b = 0.05333907221764568, J_o = 88101.40833631091
J_b = 0.07172489584859215, J_o = 77161.40369630285
J_b = 0.09322603486983205, J_o = 69179.74630121121
J_b = 0.1002287147006767, J_o = 64730.9719298477
J_b = 0.10763219409660713, J_o = 61608.771958522935
J_b = 0.11596031159837351, J_o = 59556.57431788164
J_b = 0.13260079695654992, J_o = 56977.5982372765
J_b = 0.14666888430545716, J_o = 55485.67230708753
J_b = 0.15833074897029722, J_o = 54595.486237070305
J_b = 0.1529930047195275, J_o = 54164.809272879866
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
W_opt:  [ 0.00714108  0.01563437  0.02156005  0.02332382  0.01647369 -0.00173365
 -0.0346885  -0.0898424  -0.15866543 -0.22689215]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7742 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1833, add (DA)= 0.0002decode = 0.2902 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0645 s, inc stats = 5.0772, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93590339 2.75847828 3.3928678  3.00678617 2.50894246]
u_DA:    [3.89410116 1.91801195 3.01364019 1.62170528 2.68244274]
ref_MAE: [0.09544899 0.59669788 0.85393301 1.15423272 0.13230875]
da_MAE:  [0.04180223 0.84046633 0.37922761 1.38508089 0.17350028]
% 17.637789349528695 da_MAE 0.0063961882648740235 ref_MAE 0.007765925919616416
u_c taken from control states: [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
u_c before reduction of space:  [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
data[u_c] post encoding of state:  [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
J_b = 0.0, J_o = 431541.385266014
J_b = 0.4999999999999999, J_o = 14570639.157368748
J_b = 0.0038035514046962635, J_o = 301257.40790287504
J_b = 0.009728920019653014, J_o = 204411.08405222336
J_b = 0.02063989614939273, J_o = 149685.21915470422
J_b = 0.02959988934047346, J_o = 124646.82860615582
J_b = 0.03916108825075789, J_o = 105259.93725280334
J_b = 0.05341656989200378, J_o = 88203.70003738433
J_b = 0.07124269605903219, J_o = 77297.09508226078
J_b = 0.09401222224019164, J_o = 69636.08671311176
J_b = 0.09949174342558348, J_o = 65187.655657121766
J_b = 0.10570859911545562, J_o = 62183.52584039568
J_b = 0.11475225337016019, J_o = 60215.19301681072
J_b = 0.13201412051405226, J_o = 57779.14141816521
J_b = 0.14158368054779216, J_o = 56327.42985831092
J_b = 0.15682028564296463, J_o = 56710.16602822302
J_b = 0.14789494847218826, J_o = 55776.385903292794
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
W_opt:  [ 0.01324417  0.01486439  0.02109813  0.02384837  0.01648489 -0.00250025
 -0.03575505 -0.08998239 -0.15720374 -0.2231055 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7604 s, v_trunc (Latent to Reduced) = 0.1061, dec (Reduced to Full) = 0.2034, add (DA)= 0.0002decode = 0.3118 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0724 s, inc stats = 5.0852, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93543533 2.7590151  3.39193568 3.00696751 2.50828746]
u_DA:    [3.89502362 1.92446142 3.01277615 1.61473841 2.6877448 ]
ref_MAE: [0.09498093 0.5972347  0.85300089 1.15441406 0.13165375]
da_MAE:  [0.04041171 0.83455368 0.37915952 1.3922291  0.17945734]
% 17.5306702332005 da_MAE 0.0064138604400800076 ref_MAE 0.0077772675711281205
u_c taken from control states: [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
u_c before reduction of space:  [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
data[u_c] post encoding of state:  [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
J_b = 0.0, J_o = 432188.92202527414
J_b = 0.5000000000000001, J_o = 14799510.750912298
J_b = 0.0037301879026532237, J_o = 302620.79905764386
J_b = 0.009513551472464386, J_o = 205869.88175374863
J_b = 0.02084534499013437, J_o = 148432.57484698968
J_b = 0.029935624592321092, J_o = 123203.88207816856
J_b = 0.03954423810763316, J_o = 103864.94015819926
J_b = 0.05348984430660893, J_o = 87170.60827710817
J_b = 0.07087456297510984, J_o = 76233.27014062111
J_b = 0.09545210270942389, J_o = 69258.71439745084
J_b = 0.09849044972719986, J_o = 64680.14331087691
J_b = 0.10261432076288632, J_o = 61964.88310523225
J_b = 0.11110547326191039, J_o = 59735.17283811228
J_b = 0.1361200584660926, J_o = 57148.19256354935
J_b = 0.15175445160752157, J_o = 55967.1074127429
J_b = 0.146800670272065, J_o = 55700.75545327297
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
W_opt:  [ 0.01795059  0.01164188  0.01447655  0.02144747  0.01801261  0.00054054
 -0.03186497 -0.08584334 -0.15454264 -0.22343072]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4446 s, v_trunc (Latent to Reduced) = 0.1027, dec (Reduced to Full) = 0.1685, add (DA)= 0.0001decode = 0.2735 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7182 s, inc stats = 4.7310, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93494478 2.75961269 3.39098855 3.00684171 2.50730475]
u_DA:    [3.89348695 1.91605852 3.01566755 1.58255592 2.70384856]
ref_MAE: [0.09449038 0.5978323  0.85205377 1.15428826 0.13067104]
da_MAE:  [0.04145783 0.84355418 0.375321   1.42428579 0.19654381]
% 17.291048169988976 da_MAE 0.006441926460939997 ref_MAE 0.007788668963161177
u_c taken from control states: [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
u_c before reduction of space:  [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
data[u_c] post encoding of state:  [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
J_b = 0.0, J_o = 431704.26801978203
J_b = 0.5, J_o = 14969408.843303405
J_b = 0.00367223385610621, J_o = 302846.3449373377
J_b = 0.009344970415434587, J_o = 206347.52117765017
J_b = 0.020967908601220383, J_o = 146975.97141351295
J_b = 0.030138058472563112, J_o = 121686.72010655007
J_b = 0.03965921424125115, J_o = 102617.22878990143
J_b = 0.05324855376920181, J_o = 86321.29999351979
J_b = 0.07019566719255688, J_o = 75344.00980236231
J_b = 0.09669658999787566, J_o = 69491.58568962775
J_b = 0.09726051711286172, J_o = 64490.56877579948
J_b = 0.09852132332852079, J_o = 62245.16721645039
J_b = 0.1063038708154078, J_o = 60088.95493113701
J_b = 0.1295946276863371, J_o = 59262.022717944
J_b = 0.13069683302460505, J_o = 56755.31261913506
J_b = 0.13343759115911275, J_o = 56241.11348808493
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
W_opt:  [ 0.02956075  0.0207071   0.01262907  0.01471726  0.01284239 -0.00411093
 -0.03610449 -0.0860882  -0.14839336 -0.20978682]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5558 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.2059, add (DA)= 0.0001decode = 0.3135 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.8695 s, inc stats = 4.8758, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93443316 2.76013066 3.3900313  3.00642704 2.50599876]
u_DA:    [3.89698284 1.9322375  3.01520582 1.61960547 2.68886203]
ref_MAE: [0.09397876 0.59835026 0.85109651 1.15387359 0.12936505]
da_MAE:  [0.03745032 0.82789316 0.37482547 1.38682156 0.18286327]
% 17.435290378880484 da_MAE 0.006440418612976499 ref_MAE 0.00780044966249004
u_c taken from control states: [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
u_c before reduction of space:  [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
data[u_c] post encoding of state:  [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
J_b = 0.0, J_o = 431751.6529962821
J_b = 0.4999999999999997, J_o = 15007105.500564065
J_b = 0.003649699668293952, J_o = 303434.3498630124
J_b = 0.009285505210453295, J_o = 207194.61909693893
J_b = 0.020996791977277975, J_o = 147268.7038589906
J_b = 0.030188100704534867, J_o = 122048.3188154261
J_b = 0.03949604832377096, J_o = 103429.13581162282
J_b = 0.05272583558464244, J_o = 87515.50519390767
J_b = 0.0692738057618879, J_o = 76518.0099075393
J_b = 0.09723732321534771, J_o = 71918.30088579674
J_b = 0.09588859340464267, J_o = 66218.05442948846
J_b = 0.09547320954613346, J_o = 64313.78178231088
J_b = 0.1027156200709632, J_o = 61973.50219182375
J_b = 0.12262067481107489, J_o = 60685.764336537904
J_b = 0.12732831923683874, J_o = 58464.953962346335
J_b = 0.13275270645513046, J_o = 57986.05616671855
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
W_opt:  [ 0.02566726  0.0250054   0.01661885  0.01170964  0.0107222  -0.0030735
 -0.03399728 -0.08353998 -0.1459024  -0.20826857]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5074 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1882, add (DA)= 0.0001decode = 0.2946 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8022 s, inc stats = 4.8149, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93389619 2.76047015 3.38906364 3.0057245  2.50425932]
u_DA:    [3.89812224 1.93697724 3.01757229 1.63682432 2.68024254]
ref_MAE: [0.09344178 0.59868976 0.85012886 1.15317105 0.12762561]
da_MAE:  [0.03577395 0.82349291 0.37149135 1.36890018 0.17598322]
% 17.432782075671444 da_MAE 0.006450618231648389 ref_MAE 0.00781256580252016
u_c taken from control states: [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
u_c before reduction of space:  [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
data[u_c] post encoding of state:  [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
J_b = 0.0, J_o = 431371.3863827207
J_b = 0.5000000000000002, J_o = 14919585.904321877
J_b = 0.003655529016186847, J_o = 303596.48730282794
J_b = 0.009318280210437459, J_o = 207638.71669843473
J_b = 0.020957185748631778, J_o = 148330.58332645535
J_b = 0.030130263954088212, J_o = 123254.94687043902
J_b = 0.039209386576348516, J_o = 105082.10215461525
J_b = 0.052172746878085735, J_o = 89442.34782077096
J_b = 0.06841518140313875, J_o = 78462.924030968
J_b = 0.09711631511106722, J_o = 74664.72193481895
J_b = 0.09483193454575277, J_o = 68437.31662890487
J_b = 0.09384139558408025, J_o = 66703.5918658769
J_b = 0.10085834155726754, J_o = 64242.73702745298
J_b = 0.11937876535904045, J_o = 62758.460790666664
J_b = 0.12559889783406306, J_o = 60671.27808963192
J_b = 0.1325246009956308, J_o = 60255.973222160304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
W_opt:  [ 0.02058381  0.02362967  0.02268551  0.01388212  0.00909037 -0.00389067
 -0.03329029 -0.08200162 -0.14410899 -0.20694813]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7538 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1894, add (DA)= 0.0001decode = 0.2965 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0505 s, inc stats = 5.0607, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93333252 2.76055827 3.38808597 3.00474399 2.50200569]
u_DA:    [3.8987264  1.94028795 3.01936292 1.64944087 2.67409368]
ref_MAE: [0.09287812 0.59877787 0.84915119 1.15219054 0.12537198]
da_MAE:  [0.03460612 0.82027032 0.36872305 1.35530312 0.17208798]
% 17.3770826312295 da_MAE 0.0064650276409587435 ref_MAE 0.007824739003227657
u_c taken from control states: [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
u_c before reduction of space:  [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
data[u_c] post encoding of state:  [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
J_b = 0.0, J_o = 429558.931268497
J_b = 0.5, J_o = 14754575.38786304
J_b = 0.003678814835353837, J_o = 302335.095520696
J_b = 0.009407890690193805, J_o = 206699.3326467794
J_b = 0.02086309771984632, J_o = 148792.2517308943
J_b = 0.02997992062499559, J_o = 123928.61352671222
J_b = 0.03885456591272529, J_o = 106134.09715589226
J_b = 0.05165314477880111, J_o = 90652.72241805049
J_b = 0.06767230233643891, J_o = 79699.8311676035
J_b = 0.09675735527306056, J_o = 75948.8879666622
J_b = 0.0947437760956576, J_o = 69613.06432503543
J_b = 0.09356573920105717, J_o = 67920.5836144931
J_b = 0.10051348940553131, J_o = 65437.35975833281
J_b = 0.11946171499066789, J_o = 63979.000750037456
J_b = 0.12499728457479899, J_o = 61907.76270116642
J_b = 0.13204836601461845, J_o = 61515.355744730885
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
W_opt:  [ 0.01982067  0.02102757  0.02449109  0.01749608  0.00921305 -0.00603394
 -0.03472942 -0.08189474 -0.14288388 -0.20524145]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.6051 s, v_trunc (Latent to Reduced) = 0.1109, dec (Reduced to Full) = 0.1725, add (DA)= 0.0001decode = 0.2859 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.8912 s, inc stats = 4.8965, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93274409 2.76029769 3.38710393 3.00351568 2.49922582]
u_DA:    [3.89890308 1.9423878  3.02357036 1.6595481  2.66965073]
ref_MAE: [0.09228969 0.59851729 0.84816915 1.15096223 0.12259211]
da_MAE:  [0.03384102 0.81790989 0.36353357 1.34396758 0.17042491]
% 17.375174769453768 da_MAE 0.006475106418772526 ref_MAE 0.007836756568870408
u_c taken from control states: [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
u_c before reduction of space:  [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
data[u_c] post encoding of state:  [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
J_b = 0.0, J_o = 425914.8132532878
J_b = 0.5, J_o = 14573053.307827681
J_b = 0.003697281382478933, J_o = 299574.4765448184
J_b = 0.00948689886087193, J_o = 204608.9623257697
J_b = 0.02065160741150138, J_o = 148690.33237704958
J_b = 0.029641204717915905, J_o = 124183.01368188724
J_b = 0.03831951092602019, J_o = 106733.13151948072
J_b = 0.05100795835522427, J_o = 91349.84555088863
J_b = 0.06684850899781965, J_o = 80441.66568462265
J_b = 0.09597410537041513, J_o = 76050.29953660029
J_b = 0.09532605493510743, J_o = 70023.51571108747
J_b = 0.09427780131415807, J_o = 68284.61157864303
J_b = 0.10114509832593253, J_o = 65911.94414453012
J_b = 0.12129417801623466, J_o = 64485.69690552956
J_b = 0.1249549649847681, J_o = 62562.67213116365
J_b = 0.13139943469248494, J_o = 62162.74846431098
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
W_opt:  [ 0.01997581  0.02199834  0.02493443  0.0188272   0.0096359  -0.00808869
 -0.03735265 -0.08345822 -0.14276455 -0.2036334 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4639 s, v_trunc (Latent to Reduced) = 0.1033, dec (Reduced to Full) = 0.1862, add (DA)= 0.0002decode = 0.2917 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7557 s, inc stats = 4.7636, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93212621 2.7596687  3.38611754 3.00204374 2.49577772]
u_DA:    [3.89836064 1.94442729 3.02966993 1.67547663 2.66327254]
ref_MAE: [0.09167181 0.59788831 0.84718276 1.14949029 0.11914401]
da_MAE:  [0.03376556 0.81524141 0.35644761 1.3265671  0.16749481]
% 17.436050732017307 da_MAE 0.00648028497704671 ref_MAE 0.007848806936321888
\% improve_point: 12.71, mse_ref_points: 3.519515298370806e-05, mse_da_points: 3.071940426863694e-05, % improve_overlap: 12.71, mse_ref_overlap: 0.91676, mse_da_overlap: 0.80019
DA - - L2: 45582.22, L1: 4990.55, % Improve: 17.92%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.800, time(s): 8.0612s,
u_c taken from control states: [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
u_c before reduction of space:  [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
data[u_c] post encoding of state:  [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
J_b = 0.0, J_o = 422336.31515130005
J_b = 0.5000000000000001, J_o = 14340720.344232403
J_b = 0.0037395277040699975, J_o = 296469.660723247
J_b = 0.009623033870789003, J_o = 202370.29938622814
J_b = 0.020268205748019887, J_o = 149519.67721340744
J_b = 0.029134833254377625, J_o = 125218.98708503535
J_b = 0.03759339979055184, J_o = 108076.71434974202
J_b = 0.05025701867364695, J_o = 92690.29543815779
J_b = 0.06596835821937541, J_o = 81863.1988870364
J_b = 0.09495917728774166, J_o = 76544.31882149985
J_b = 0.09578145077359383, J_o = 70897.63044439965
J_b = 0.09559233214445077, J_o = 69057.32431680548
J_b = 0.10363262380444851, J_o = 66472.06964075124
J_b = 0.12167752098280606, J_o = 64155.73900006899
J_b = 0.13962946973599472, J_o = 62851.97698686293
J_b = 0.1401893704950199, J_o = 62533.75056264435
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
W_opt:  [ 0.01696097  0.02352193  0.02845721  0.02195829  0.01273212 -0.00599846
 -0.03606303 -0.08411617 -0.14633741 -0.21147955]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5104 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1741, add (DA)= 0.0001decode = 0.2813 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7918 s, inc stats = 4.8081, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93148284 2.75868746 3.38513012 3.00036735 2.49167953]
u_DA:    [3.89659599 1.93549086 3.04242526 1.68051993 2.67180889]
ref_MAE: [0.09102844 0.59690706 0.84619533 1.1478139  0.11504582]
da_MAE:  [0.03488686 0.8231966  0.34270486 1.31984742 0.18012936]
% 17.495221417974605 da_MAE 0.006485370340221769 ref_MAE 0.007860599654569197
u_c taken from control states: [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
u_c before reduction of space:  [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
data[u_c] post encoding of state:  [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
J_b = 0.0, J_o = 420402.1349773324
J_b = 0.5, J_o = 14059499.740846252
J_b = 0.00382843320756772, J_o = 293815.896034611
J_b = 0.009865670473926152, J_o = 200533.00437281805
J_b = 0.01973976409098013, J_o = 151758.37166579277
J_b = 0.028577189773152874, J_o = 127202.99818155525
J_b = 0.03684175060469291, J_o = 110226.2724126078
J_b = 0.04968206945401929, J_o = 94621.52082984489
J_b = 0.0654823185393498, J_o = 84010.93963746532
J_b = 0.09347353727325437, J_o = 77873.57561856646
J_b = 0.09519034391926467, J_o = 72855.03153315825
J_b = 0.09517774143274949, J_o = 70848.68281844794
J_b = 0.10207417914496826, J_o = 68611.84021730401
J_b = 0.12397610127904937, J_o = 67046.64243691575
J_b = 0.12844654351847534, J_o = 64975.36172865797
J_b = 0.1334405644037226, J_o = 64633.44660200036
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
W_opt:  [ 0.02027852  0.02756259  0.03080104  0.0221826   0.01045328 -0.01066741
 -0.04188233 -0.08871367 -0.14709582 -0.20606008]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5251 s, v_trunc (Latent to Reduced) = 0.1045, dec (Reduced to Full) = 0.2308, add (DA)= 0.0001decode = 0.3422 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 4.8679 s, inc stats = 4.8740, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93082942 2.7573624  3.38415054 2.9985557  2.48715691]
u_DA:    [3.89904707 1.94535794 3.04755919 1.72196963 2.66001573]
ref_MAE: [0.09037502 0.595582   0.84521576 1.14600225 0.1105232 ]
da_MAE:  [0.03178235 0.81200446 0.33659135 1.27658608 0.17285882]
% 17.73588286174541 da_MAE 0.006475707462359929 ref_MAE 0.007871849461991716
u_c taken from control states: [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
u_c before reduction of space:  [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
data[u_c] post encoding of state:  [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
J_b = 0.0, J_o = 423140.88591794606
J_b = 0.5000000000000001, J_o = 13719280.18198516
J_b = 0.0039985623295338115, J_o = 293650.15159982484
J_b = 0.010298359050180653, J_o = 200680.59022543722
J_b = 0.019214595048434226, J_o = 156523.2169236783
J_b = 0.02826245707676819, J_o = 130831.8513570471
J_b = 0.03641673146282785, J_o = 113819.04042019865
J_b = 0.04983136134621562, J_o = 97587.9418336108
J_b = 0.06610564567805881, J_o = 87228.34251799736
J_b = 0.09101190560635346, J_o = 79898.4794119029
J_b = 0.09571553899157424, J_o = 75479.97645292986
J_b = 0.09780660688392939, J_o = 73105.03160015009
J_b = 0.10479746632297042, J_o = 70928.19038352279
J_b = 0.12504882356086391, J_o = 68138.26547993335
J_b = 0.13890646696802386, J_o = 67255.27248580779
J_b = 0.14041574327252218, J_o = 66149.4678000394
J_b = 0.1401510935307173, J_o = 65882.81626428336
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
W_opt:  [ 0.01674918  0.02800949  0.03366199  0.02473183  0.01254094 -0.0096709
 -0.04229593 -0.09158606 -0.15269555 -0.21406839]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7643 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1780, add (DA)= 0.0002decode = 0.2842 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0487 s, inc stats = 5.0613, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93017055 2.7557472  3.38318099 2.99664174 2.4822923 ]
u_DA:    [3.89910801 1.93708692 3.04887542 1.71248233 2.67208667]
ref_MAE: [0.08971615 0.59396681 0.8442462  1.14408829 0.10565859]
da_MAE:  [0.03106255 0.81866028 0.33430557 1.28415941 0.18979437]
% 17.668688168739916 da_MAE 0.0064897455372065664 ref_MAE 0.00788247556471279
u_c taken from control states: [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
u_c before reduction of space:  [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
data[u_c] post encoding of state:  [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
J_b = 0.0, J_o = 431791.9381570879
J_b = 0.4999999999999999, J_o = 13269434.055960244
J_b = 0.00429927901446758, J_o = 296273.99235921196
J_b = 0.011047705825478659, J_o = 202891.58862983782
J_b = 0.018843129621051457, J_o = 163615.90919943427
J_b = 0.02852799045679096, J_o = 135369.73392351024
J_b = 0.036635634880902775, J_o = 118314.87809417727
J_b = 0.051352572700009966, J_o = 100793.60789831184
J_b = 0.06861199116305525, J_o = 90597.3464849512
J_b = 0.08935244485587905, J_o = 82555.91607779375
J_b = 0.0985064487337975, J_o = 78178.99774961143
J_b = 0.10453006385618072, J_o = 75375.9706989339
J_b = 0.11036211160460782, J_o = 73409.23538546044
J_b = 0.1285754657681264, J_o = 70418.00960877257
J_b = 0.1472905691470683, J_o = 73186.39492698108
J_b = 0.13372297160007032, J_o = 69763.97884632697
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
W_opt:  [ 0.01833853  0.03046624  0.03532648  0.02560356  0.01133784 -0.01248818
 -0.04579245 -0.09421607 -0.15195913 -0.20805645]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5391 s, v_trunc (Latent to Reduced) = 0.1053, dec (Reduced to Full) = 0.1977, add (DA)= 0.0001decode = 0.3053 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.8445 s, inc stats = 4.8571, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92951115 2.75393726 3.38222197 2.994665   2.47720928]
u_DA:    [3.90153929 1.93284884 3.05537748 1.72284892 2.66425617]
ref_MAE: [0.08905675 0.59215686 0.84328719 1.14211155 0.10057557]
da_MAE:  [0.02797186 0.82108842 0.32684449 1.27181608 0.18704688]
% 17.834168100038884 da_MAE 0.006484682993442713 ref_MAE 0.007892189299973219
u_c taken from control states: [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
u_c before reduction of space:  [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
data[u_c] post encoding of state:  [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
J_b = 0.0, J_o = 444723.8531262102
J_b = 0.49999999999999994, J_o = 12850055.943585718
J_b = 0.004665876257233913, J_o = 301238.7473890643
J_b = 0.011935742059037649, J_o = 207112.70614721364
J_b = 0.01869123027332781, J_o = 171693.9079348813
J_b = 0.029360843238321898, J_o = 139737.90468747745
J_b = 0.03751653753953704, J_o = 122800.49666246347
J_b = 0.05444763471768219, J_o = 103474.25714750652
J_b = 0.07330333764918401, J_o = 93389.52498924517
J_b = 0.0886280990125892, J_o = 85605.93764495399
J_b = 0.10198202592389886, J_o = 80705.52739773682
J_b = 0.11303857313358248, J_o = 78206.99910706998
J_b = 0.11535409112852976, J_o = 76320.87064044714
J_b = 0.12479766256554763, J_o = 73940.22996401812
J_b = 0.1341581270674454, J_o = 72451.96974909326
J_b = 0.1602690465725116, J_o = 78102.63205627956
J_b = 0.1390143734756608, J_o = 72034.57457534524
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
W_opt:  [ 0.01360372  0.03048281  0.03802563  0.02881494  0.01326421 -0.01150946
 -0.04522938 -0.09492002 -0.15389176 -0.21151871]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9751 s, v_trunc (Latent to Reduced) = 0.1120, dec (Reduced to Full) = 0.1602, add (DA)= 0.0001decode = 0.2744 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2496 s, inc stats = 5.2550, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92885948 2.75202884 3.38127572 2.99267812 2.47212177]
u_DA:    [3.90367455 1.94028133 3.03657022 1.74709541 2.65103768]
ref_MAE: [0.08840508 0.59024844 0.84234093 1.14012467 0.09548806]
da_MAE:  [0.02518493 0.81174751 0.3447055  1.24558271 0.17891591]
% 17.8593915003883 da_MAE 0.006489862676582772 ref_MAE 0.007900918674851857
u_c taken from control states: [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
u_c before reduction of space:  [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
data[u_c] post encoding of state:  [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
J_b = 0.0, J_o = 459891.7789785882
J_b = 0.4999999999999999, J_o = 12527453.446089981
J_b = 0.0050401527373331485, J_o = 307683.3986623229
J_b = 0.01280765436732075, J_o = 212857.26743631746
J_b = 0.018687532734928885, J_o = 179980.2918855326
J_b = 0.03059678070697233, J_o = 143402.30216956962
J_b = 0.03888731988507846, J_o = 126815.60529202907
J_b = 0.058815817451887735, J_o = 105667.34964712201
J_b = 0.0797265545618157, J_o = 95661.78617794898
J_b = 0.08991364518714019, J_o = 88774.16469865845
J_b = 0.1035114402955017, J_o = 83263.71994005152
J_b = 0.11658143388218067, J_o = 81349.89578065684
J_b = 0.12198577167745017, J_o = 78962.7878019884
J_b = 0.12954955184785139, J_o = 77112.77491834908
J_b = 0.13756233716573757, J_o = 75777.59940632225
J_b = 0.15460955245372948, J_o = 74673.00214900135
J_b = 0.16504259917709857, J_o = 73306.65062233528
J_b = 0.16124428395614568, J_o = 72956.57252338463
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
W_opt:  [ 0.00082406  0.02893143  0.04521474  0.03817007  0.0224817  -0.00276281
 -0.03642684 -0.09095337 -0.15862978 -0.22870097]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9924 s, v_trunc (Latent to Reduced) = 0.1057, dec (Reduced to Full) = 0.1873, add (DA)= 0.0001decode = 0.2952 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2877 s, inc stats = 5.3004, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92821768 2.75013289 3.38034302 2.99072603 2.46717717]
u_DA:    [3.90343589 1.93736    3.03863298 1.73280458 2.6416202 ]
ref_MAE: [0.08776328 0.58835249 0.84140823 1.13817258 0.09054346]
da_MAE:  [0.02478179 0.81277289 0.34171003 1.25792145 0.17444303]
% 18.03120594141693 da_MAE 0.006482653475372392 ref_MAE 0.007908684701081782
u_c taken from control states: [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
u_c before reduction of space:  [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
data[u_c] post encoding of state:  [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
J_b = 0.0, J_o = 472826.0113448702
J_b = 0.4999999999999998, J_o = 12343438.1901288
J_b = 0.0053273790014878525, J_o = 313444.09788250603
J_b = 0.013435538074589455, J_o = 218528.90219875437
J_b = 0.018658482361455658, J_o = 187099.78148084658
J_b = 0.03175802914495265, J_o = 146039.8445893036
J_b = 0.04018709509859596, J_o = 129979.45114751335
J_b = 0.06279528558607186, J_o = 107542.8860615001
J_b = 0.08660635799772168, J_o = 98006.40093929185
J_b = 0.0927165525018407, J_o = 91643.71049846441
J_b = 0.10248197194315761, J_o = 86834.25703627845
J_b = 0.11297634326533255, J_o = 83932.67944111282
J_b = 0.14340815665573442, J_o = 83780.42309681309
J_b = 0.12716710294281716, J_o = 81892.03243690358
J_b = 0.1398455156350314, J_o = 79763.5575776646
J_b = 0.1444342780163367, J_o = 78744.82531983568
J_b = 0.1561576228234599, J_o = 79088.1267466081
J_b = 0.14929890851962763, J_o = 78174.79818249198
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
W_opt:  [ 0.00978981  0.03136683  0.04357677  0.03553562  0.01837999 -0.00855489
 -0.0428407  -0.09386723 -0.1541351  -0.21386995]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.2042 s, v_trunc (Latent to Reduced) = 0.1050, dec (Reduced to Full) = 0.2114, add (DA)= 0.0001decode = 0.3191 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.5234 s, inc stats = 5.5362, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92757809 2.74838944 3.37941998 2.98883206 2.46234823]
u_DA:    [3.90568592 1.94490945 3.03522947 1.76208861 2.62726862]
ref_MAE: [0.08712369 0.58660904 0.8404852  1.13627861 0.08571452]
da_MAE:  [0.02189217 0.80347999 0.34419051 1.22674345 0.16492038]
% 18.14708524282551 da_MAE 0.006479140280301662 ref_MAE 0.00791558895553412
u_c taken from control states: [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
u_c before reduction of space:  [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
data[u_c] post encoding of state:  [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
J_b = 0.0, J_o = 480178.3175596113
J_b = 0.5000000000000002, J_o = 12336154.685592512
J_b = 0.0054672529764185325, J_o = 316257.19380633894
J_b = 0.013685875894693215, J_o = 221472.2447430872
J_b = 0.018560770933694834, J_o = 190539.22918888068
J_b = 0.03242367854147258, J_o = 146547.87571671544
J_b = 0.04088023184085052, J_o = 130888.35040346341
J_b = 0.06490383608640192, J_o = 107675.89282883004
J_b = 0.09129528671485343, J_o = 99000.16113017073
J_b = 0.0950764772699438, J_o = 92467.39752537213
J_b = 0.10124855999966934, J_o = 88583.53598659651
J_b = 0.11083591132842059, J_o = 85845.9811428563
J_b = 0.13701226579802447, J_o = 84805.06114450138
J_b = 0.13719364432612588, J_o = 81598.59592943509
J_b = 0.13760190114266677, J_o = 80809.99400629426
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
W_opt:  [ 0.01598136  0.03370461  0.04135537  0.03231317  0.01484693 -0.01251236
 -0.04679961 -0.09494665 -0.14923307 -0.20095722]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.1816 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.1808, add (DA)= 0.0001decode = 0.2865 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.4682 s, inc stats = 4.4812, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92694327 2.74689826 3.3785102  2.98706884 2.45774389]
u_DA:    [3.90556235 1.94106496 3.05699744 1.76289079 2.62839708]
ref_MAE: [0.08648887 0.58511786 0.83957541 1.13451539 0.08111018]
da_MAE:  [0.02138092 0.8058333  0.32151276 1.22417805 0.17065319]
% 18.35581365199125 da_MAE 0.006467498584553088 ref_MAE 0.007921566585262229
u_c taken from control states: [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
u_c before reduction of space:  [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
data[u_c] post encoding of state:  [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
J_b = 0.0, J_o = 481957.62667255895
J_b = 0.49999999999999994, J_o = 12497229.850857727
J_b = 0.00543689767866215, J_o = 316877.78100059065
J_b = 0.013529578524946613, J_o = 222215.3487339296
J_b = 0.01838398653752724, J_o = 191066.8117124142
J_b = 0.03231526823941355, J_o = 146634.50532196136
J_b = 0.04063317531706724, J_o = 131062.50246018733
J_b = 0.0647001219347281, J_o = 107717.91739123399
J_b = 0.09102831394057012, J_o = 99243.1642339812
J_b = 0.09488547613948502, J_o = 92667.01421608287
J_b = 0.10048779080126403, J_o = 88945.48085054563
J_b = 0.10997134816190429, J_o = 86324.03687089664
J_b = 0.13224054024839269, J_o = 84171.78373747725
J_b = 0.13552207107791836, J_o = 81981.10168311602
J_b = 0.13818944512811274, J_o = 80920.06887900604
J_b = 0.14460533027670774, J_o = 80337.5838499578
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
W_opt:  [ 0.00642229  0.03278812  0.04436335  0.03565567  0.01831554 -0.00979778
 -0.04515028 -0.09685491 -0.15490005 -0.2109757 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7779 s, v_trunc (Latent to Reduced) = 0.1052, dec (Reduced to Full) = 0.1960, add (DA)= 0.0001decode = 0.3033 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0814 s, inc stats = 5.0871, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92632745 2.74568866 3.37762437 2.98554036 2.45361818]
u_DA:    [3.90556246 1.94185742 3.051431   1.77140679 2.62152149]
ref_MAE: [0.08587305 0.58390826 0.83868959 1.13298691 0.07698447]
da_MAE:  [0.02076499 0.80383124 0.32619337 1.21413358 0.16790331]
% 18.391182302637013 da_MAE 0.006468937405390716 ref_MAE 0.007926762803230448
u_c taken from control states: [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
u_c before reduction of space:  [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
data[u_c] post encoding of state:  [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
J_b = 0.0, J_o = 479337.7450120823
J_b = 0.5000000000000001, J_o = 12912914.398303911
J_b = 0.005194809786050247, J_o = 317079.88457093854
J_b = 0.012880922520584776, J_o = 221871.13801273445
J_b = 0.018233228376167098, J_o = 189068.9785087799
J_b = 0.03140229720029178, J_o = 147261.80361122437
J_b = 0.039596986387424114, J_o = 130880.87293297282
J_b = 0.061488087148709666, J_o = 108445.15009842326
J_b = 0.08461441766856165, J_o = 99451.21049084775
J_b = 0.09160405894302076, J_o = 92827.12917449251
J_b = 0.09905691781286562, J_o = 88551.8449398471
J_b = 0.1088218406350902, J_o = 85825.12322701934
J_b = 0.12679239443775164, J_o = 82883.73325772076
J_b = 0.13493047849845657, J_o = 81003.3505075869
J_b = 0.14351422832051006, J_o = 79383.08384035416
J_b = 0.15441373759189403, J_o = 89227.39638935655
J_b = 0.1445805567227418, J_o = 79215.23837728238
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
W_opt:  [ 0.00218183  0.03266306  0.04759548  0.0387951   0.02006441 -0.00896345
 -0.04505164 -0.09842097 -0.1575996  -0.21372566]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9853 s, v_trunc (Latent to Reduced) = 0.1032, dec (Reduced to Full) = 0.2011, add (DA)= 0.0001decode = 0.3066 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2921 s, inc stats = 5.2977, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92572808 2.74479837 3.37676221 2.98428214 2.4499543 ]
u_DA:    [3.9039741  1.93236062 3.07385506 1.74473404 2.63411261]
ref_MAE: [0.08527367 0.58301797 0.83782743 1.13172869 0.07332059]
da_MAE:  [0.02175397 0.81243775 0.30290715 1.2395481  0.18415831]
% 18.396009265119417 da_MAE 0.0064723648617198625 ref_MAE 0.007931431788363915
\% improve_point: 12.65, mse_ref_points: 3.548769883269102e-05, mse_da_points: 3.099928054534546e-05, % improve_overlap: 12.65, mse_ref_overlap: 0.92439, mse_da_overlap: 0.80749
DA - - L2: 40427.22, L1: 4870.71, % Improve: 17.93%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.807, time(s): 7.6907s,
u_c taken from control states: [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
u_c before reduction of space:  [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
data[u_c] post encoding of state:  [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
J_b = 0.0, J_o = 471905.02440472797
J_b = 0.5000000000000003, J_o = 13466593.487163704
J_b = 0.004853136149514402, J_o = 314823.57079421397
J_b = 0.01201417756316656, J_o = 218924.0224484203
J_b = 0.018201999705358775, J_o = 183016.42085257565
J_b = 0.030346404294345944, J_o = 144813.82633100788
J_b = 0.03871344805553391, J_o = 127015.75279036397
J_b = 0.0572029511623071, J_o = 106376.99463141338
J_b = 0.07728987440456205, J_o = 96786.43548380409
J_b = 0.0906647263937134, J_o = 89308.77806811075
J_b = 0.09883849964848082, J_o = 84871.6125527191
J_b = 0.10850344185955334, J_o = 81837.08315162841
J_b = 0.11916324910498642, J_o = 79297.37396281137
J_b = 0.1305976513335282, J_o = 77170.97228465547
J_b = 0.14528351152384195, J_o = 75181.57195169994
J_b = 0.16425759465308035, J_o = 77262.89713375807
J_b = 0.1505446259760326, J_o = 74713.04625008165
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
W_opt:  [-0.00328114  0.02929602  0.04862051  0.04308577  0.02517537 -0.00461921
 -0.04131533 -0.09823934 -0.1622846  -0.22309814]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9064 s, v_trunc (Latent to Reduced) = 0.1066, dec (Reduced to Full) = 0.1863, add (DA)= 0.0001decode = 0.2952 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2017 s, inc stats = 5.2130, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92513842 2.7442818  3.37591942 2.98331164 2.44664595]
u_DA:    [3.90510829 1.93806064 3.06102666 1.7782734  2.61136256]
ref_MAE: [0.08468402 0.5825014  0.83698464 1.13075819 0.07001224]
da_MAE:  [0.02003013 0.80622115 0.31489276 1.20503824 0.16471661]
% 18.477189185173078 da_MAE 0.006469607924235128 ref_MAE 0.007935948061126557
u_c taken from control states: [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
u_c before reduction of space:  [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
data[u_c] post encoding of state:  [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
J_b = 0.0, J_o = 463380.3962931584
J_b = 0.5000000000000002, J_o = 14018455.875225095
J_b = 0.004525875232402438, J_o = 311849.7716492732
J_b = 0.011191285946692565, J_o = 215788.90711067978
J_b = 0.01825747256745921, J_o = 176075.1030322156
J_b = 0.029545299697326822, J_o = 140850.17759784719
J_b = 0.03828939237352397, J_o = 121704.00672565767
J_b = 0.054747416862998874, J_o = 102497.61492025295
J_b = 0.0731580502783896, J_o = 92136.89003112812
J_b = 0.09350115737466924, J_o = 84153.1999534332
J_b = 0.09846145996204379, J_o = 79890.7007097473
J_b = 0.10477397860997947, J_o = 76717.70435743818
J_b = 0.11353262374974091, J_o = 74519.65179038963
J_b = 0.13104862508238216, J_o = 71858.87751746044
J_b = 0.14409530187270891, J_o = 71042.30089405087
J_b = 0.1486664594847925, J_o = 69859.66581927122
J_b = 0.1458400056697075, J_o = 69554.31828951638
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
W_opt:  [-0.00065531  0.02633886  0.04143451  0.0386202   0.02476596 -0.00324278
 -0.03949924 -0.0964846  -0.16087232 -0.22147064]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8811 s, v_trunc (Latent to Reduced) = 0.1065, dec (Reduced to Full) = 0.1825, add (DA)= 0.0001decode = 0.2918 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1731 s, inc stats = 5.1862, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92455714 2.74415506 3.37509882 2.98265846 2.44365566]
u_DA:    [3.90300038 1.93884992 3.06543971 1.75632734 2.6202267 ]
ref_MAE: [0.08410274 0.58237467 0.83616403 1.130105   0.06702195]
da_MAE:  [0.02155676 0.80530514 0.30965911 1.22633112 0.17657104]
% 18.34147098109899 da_MAE 0.006484143497359049 ref_MAE 0.007940558782118403
u_c taken from control states: [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
u_c before reduction of space:  [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
data[u_c] post encoding of state:  [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
J_b = 0.0, J_o = 453612.85955077613
J_b = 0.5, J_o = 14561953.410676964
J_b = 0.00422546362129279, J_o = 307524.86841979966
J_b = 0.010435975508748623, J_o = 211747.85592305282
J_b = 0.018382854108517515, J_o = 167805.969490039
J_b = 0.02891327670505572, J_o = 135262.67830304272
J_b = 0.037975272811347875, J_o = 115280.1421850639
J_b = 0.0532230437912327, J_o = 97150.43917102377
J_b = 0.07091042148024405, J_o = 86230.75695070511
J_b = 0.09581128560631928, J_o = 78713.71035887673
J_b = 0.0971044455502935, J_o = 74164.33226041465
J_b = 0.09977582644669682, J_o = 71493.32094419962
J_b = 0.10708317372823066, J_o = 69309.21146253406
J_b = 0.12775369329125025, J_o = 65853.09681122247
J_b = 0.151653272711645, J_o = 67455.5122149457
J_b = 0.13601327657132686, J_o = 64933.96156037776
J_b = 0.144628695051039, J_o = 64167.76743056573
J_b = 0.14470931223320618, J_o = 63870.15414565679
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
W_opt:  [ 0.00210268  0.0252844   0.0367567   0.03363774  0.02350318 -0.00115035
 -0.03686983 -0.09395365 -0.15963636 -0.22142389]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0268 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1883, add (DA)= 0.0001decode = 0.2949 s, unnorm = 0.0006 s, TOTAL = unnormalising + decoding + minimising = 5.3223 s, inc stats = 5.3393, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92397928 2.74441606 3.37430267 2.98233001 2.44083538]
u_DA:    [3.90273442 1.93972057 3.05904257 1.75417177 2.62106535]
ref_MAE: [0.08352488 0.58263566 0.83536788 1.12977656 0.06420167]
da_MAE:  [0.02124486 0.80469549 0.31526009 1.22815825 0.18022997]
% 18.185840635608162 da_MAE 0.00650063154660805 ref_MAE 0.00794560696719367
u_c taken from control states: [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
u_c before reduction of space:  [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
data[u_c] post encoding of state:  [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
J_b = 0.0, J_o = 446332.869446348
J_b = 0.49999999999999967, J_o = 15026261.89186882
J_b = 0.00398175945262695, J_o = 305000.7802042603
J_b = 0.009822140424210073, J_o = 209935.80558375004
J_b = 0.01851381050804365, J_o = 162152.66031166262
J_b = 0.028469875462739765, J_o = 131734.5991677958
J_b = 0.0377042509500528, J_o = 111474.76271532789
J_b = 0.052314855800844634, J_o = 93982.99120975699
J_b = 0.06999583018631096, J_o = 82667.41971528325
J_b = 0.09743784977670306, J_o = 75819.49652520486
J_b = 0.09648741278229103, J_o = 70820.4931236832
J_b = 0.09752011481915612, J_o = 68483.83744886969
J_b = 0.10410943749800915, J_o = 66285.87858620203
J_b = 0.12323121504665276, J_o = 62686.40941563716
J_b = 0.14753703493293677, J_o = 66574.25287330968
J_b = 0.12957629395447987, J_o = 61813.64012283825
J_b = 0.1450831486934294, J_o = 60844.06223738966
J_b = 0.14692537948957954, J_o = 60311.8959508897
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
W_opt:  [ 0.00177831  0.02139299  0.03392181  0.03104548  0.02402861  0.00287959
 -0.03226908 -0.09029491 -0.15849721 -0.22345919]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0926 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1694, add (DA)= 0.0001decode = 0.2761 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3688 s, inc stats = 5.3815, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92340902 2.74504147 3.37353624 2.98234935 2.43815919]
u_DA:    [3.90163864 1.9385516  3.0581802  1.74021121 2.6261075 ]
ref_MAE: [0.08295462 0.58326107 0.83460145 1.1297959  0.06152548]
da_MAE:  [0.02177038 0.80648986 0.31535604 1.24213814 0.18794831]
% 18.076038218239876 da_MAE 0.006513705230125567 ref_MAE 0.00795091581078273
u_c taken from control states: [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
u_c before reduction of space:  [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
data[u_c] post encoding of state:  [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
J_b = 0.0, J_o = 440903.2462928241
J_b = 0.5000000000000001, J_o = 15259604.395364836
J_b = 0.0038308427675299117, J_o = 303273.20586904476
J_b = 0.00945722567952612, J_o = 209141.15069747512
J_b = 0.018584474568754887, J_o = 159197.00839553156
J_b = 0.028171461899704396, J_o = 130248.40405101197
J_b = 0.03736867784616937, J_o = 110219.39745080977
J_b = 0.05169278352590493, J_o = 93030.32782815816
J_b = 0.06955753260353176, J_o = 81462.76945054754
J_b = 0.09870998185692684, J_o = 75168.58598925584
J_b = 0.09633176153874484, J_o = 69803.55539792674
J_b = 0.09654542780638951, J_o = 67660.86016173223
J_b = 0.10293404069093735, J_o = 65397.83878235202
J_b = 0.12110302900175378, J_o = 61823.002808084704
J_b = 0.1465434438311977, J_o = 64290.11358741892
J_b = 0.12895313841347142, J_o = 60811.8472276369
J_b = 0.14713045745408704, J_o = 59902.378374164065
J_b = 0.14764718586732045, J_o = 59182.07966981954
J_b = 0.14690047795815003, J_o = 58908.371856510304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
W_opt:  [ 0.00033539  0.01653897  0.03089047  0.02947574  0.02402635  0.00479036
 -0.02908106 -0.08665417 -0.15588066 -0.2232116 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3356 s, v_trunc (Latent to Reduced) = 0.1044, dec (Reduced to Full) = 0.1789, add (DA)= 0.0001decode = 0.2855 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6212 s, inc stats = 5.6324, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92286238 2.74596868 3.37280446 2.98276285 2.43580646]
u_DA:    [3.90062469 1.93732273 3.05380714 1.72641996 2.63201092]
ref_MAE: [0.08240798 0.58418828 0.83386967 1.1302094  0.05917275]
da_MAE:  [0.02223768 0.80864595 0.31899731 1.25634289 0.19620447]
% 17.96851150255186 da_MAE 0.006526713978888224 ref_MAE 0.00795635200389087
u_c taken from control states: [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
u_c before reduction of space:  [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
data[u_c] post encoding of state:  [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
J_b = 0.0, J_o = 434946.3900004159
J_b = 0.5000000000000001, J_o = 15363970.078708116
J_b = 0.00372048665398783, J_o = 300699.3234878844
J_b = 0.009207290095399246, J_o = 207564.0534472633
J_b = 0.018637921194182398, J_o = 156308.44714387073
J_b = 0.02793490477780658, J_o = 128590.07709059524
J_b = 0.037012370658560716, J_o = 108982.81154769122
J_b = 0.05114543786536453, J_o = 92002.23121686942
J_b = 0.06908783710298556, J_o = 80231.60932246677
J_b = 0.10008647975212223, J_o = 74689.52544051823
J_b = 0.09636377223715079, J_o = 68795.79933738385
J_b = 0.09587485180316309, J_o = 66847.80188909115
J_b = 0.10220608127845071, J_o = 64460.97448248944
J_b = 0.11930203284385428, J_o = 60943.8416723524
J_b = 0.14794430230526026, J_o = 60740.24197221143
J_b = 0.13300443117448904, J_o = 59560.04587091581
J_b = 0.15543406768729282, J_o = 59149.54951000035
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
W_opt:  [ 0.00174245  0.01674946  0.03169137  0.03113835  0.02614752  0.00679247
 -0.02741242 -0.08588914 -0.15751889 -0.22832699]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1286 s, v_trunc (Latent to Reduced) = 0.1119, dec (Reduced to Full) = 0.1890, add (DA)= 0.0001decode = 0.3031 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4319 s, inc stats = 5.4389, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9223578  2.74708172 3.37210801 2.98360705 2.43400274]
u_DA:    [3.90216328 1.94140318 3.04273828 1.75204963 2.62020241]
ref_MAE: [0.0819034  0.58530132 0.83317322 1.1310536  0.05736903]
da_MAE:  [0.02019452 0.80567854 0.32936973 1.23155742 0.18619968]
% 18.026365870696658 da_MAE 0.006526564618934886 ref_MAE 0.007961785137694435
u_c taken from control states: [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
u_c before reduction of space:  [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
data[u_c] post encoding of state:  [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
J_b = 0.0, J_o = 428009.20262601523
J_b = 0.5000000000000003, J_o = 15395435.636207145
J_b = 0.0036315524957652233, J_o = 296962.6165666392
J_b = 0.009021051859626412, J_o = 204732.39844863839
J_b = 0.018718868149601026, J_o = 152530.26206576242
J_b = 0.027735982006829685, J_o = 126023.76519444965
J_b = 0.03666575856154905, J_o = 106914.6595336157
J_b = 0.050634790146758764, J_o = 90111.15832120948
J_b = 0.06852216343352509, J_o = 78155.34849204685
J_b = 0.10139024805407382, J_o = 73697.00511658014
J_b = 0.09654244968753421, J_o = 67009.96066053546
J_b = 0.09543449244301826, J_o = 65259.00956566903
J_b = 0.10193907285545105, J_o = 62663.83699125115
J_b = 0.11810278919640722, J_o = 59345.059439063116
J_b = 0.15576177014379866, J_o = 60806.09825206152
J_b = 0.13181248155491104, J_o = 58115.38765522056
J_b = 0.14630355409350948, J_o = 57120.50241857807
J_b = 0.15394522175434644, J_o = 56716.05922666964
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
W_opt:  [-1.11170837e-04  1.36927367e-02  2.84496316e-02  2.82177327e-02
  2.35985137e-02  4.90283925e-03 -2.85974797e-02 -8.58311867e-02
 -1.56402587e-01 -2.26479006e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0492 s, v_trunc (Latent to Reduced) = 0.1512, dec (Reduced to Full) = 0.2092, add (DA)= 0.0001decode = 0.3633 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 5.4129 s, inc stats = 5.4259, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92189685 2.7482563  3.3714445  2.98482663 2.43267036]
u_DA:    [3.89969422 1.93159299 3.05021299 1.70124115 2.64975882]
ref_MAE: [0.08144245 0.5864759  0.83250972 1.13227318 0.05603665]
da_MAE:  [0.02220262 0.81666332 0.32123151 1.28358548 0.21708846]
% 17.818857878449485 da_MAE 0.006547557247550435 ref_MAE 0.00796722590915837
u_c taken from control states: [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
u_c before reduction of space:  [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
data[u_c] post encoding of state:  [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
J_b = 0.0, J_o = 420807.35831177165
J_b = 0.5, J_o = 15346491.118973615
J_b = 0.0035714425762075307, J_o = 292508.37861536944
J_b = 0.008914311258526937, J_o = 201016.0753035903
J_b = 0.018803157632534553, J_o = 148430.16622407836
J_b = 0.027561499450449115, J_o = 123030.80665957772
J_b = 0.03634239740427367, J_o = 104405.14173536064
J_b = 0.05021055103864955, J_o = 87703.9180972337
J_b = 0.0679791852480366, J_o = 75568.32383239389
J_b = 0.1019991594071377, J_o = 72077.62175600672
J_b = 0.09734928344782155, J_o = 64639.25394108283
J_b = 0.0956888075169226, J_o = 63025.738053497305
J_b = 0.10283426750374544, J_o = 60168.605723214925
J_b = 0.11967473317712231, J_o = 57718.428147875224
J_b = 0.13706899894457483, J_o = 55590.9104049958
J_b = 0.14488938372306182, J_o = 55229.520302019
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
W_opt:  [ 0.00423571  0.01457995  0.02649016  0.02548073  0.01971707  0.00080434
 -0.03221733 -0.08671675 -0.15291166 -0.21769722]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5312 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.2084, add (DA)= 0.0001decode = 0.3150 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8463 s, inc stats = 4.8598, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9214674  2.74953686 3.37080836 2.98633923 2.43163117]
u_DA:    [3.9015642  1.94125951 3.04193265 1.73654358 2.62602644]
ref_MAE: [0.081013   0.58775646 0.83187358 1.13378578 0.05499746]
da_MAE:  [0.0199032  0.80827735 0.32887571 1.24979565 0.19439527]
% 17.89572498868798 da_MAE 0.0065458545178143914 ref_MAE 0.007972611069170915
u_c taken from control states: [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
u_c before reduction of space:  [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
data[u_c] post encoding of state:  [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
J_b = 0.0, J_o = 413955.5730535509
J_b = 0.4999999999999998, J_o = 15224362.482446756
J_b = 0.003545707134489901, J_o = 287657.5949687919
J_b = 0.008896438871902874, J_o = 196649.2001508043
J_b = 0.01886884088886453, J_o = 144334.28113657772
J_b = 0.02740784772617955, J_o = 119833.21730250985
J_b = 0.03606928754009779, J_o = 101581.77159711628
J_b = 0.04992496470611233, J_o = 84884.77762939707
J_b = 0.0675535440517559, J_o = 72646.78732056373
J_b = 0.1007643691670795, J_o = 68569.73813394022
J_b = 0.0994169474926114, J_o = 61649.48099921243
J_b = 0.09713949708579966, J_o = 60022.52028465204
J_b = 0.10417685687666929, J_o = 57175.186135404365
J_b = 0.1265604849388886, J_o = 55667.50826809801
J_b = 0.13057173832172872, J_o = 53492.72787157882
J_b = 0.13802373770531978, J_o = 53262.80780957487
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
W_opt:  [ 0.00610429  0.01376562  0.02344433  0.02243953  0.01630963 -0.00237719
 -0.03460365 -0.08690715 -0.15020654 -0.21192399]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4862 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1693, add (DA)= 0.0001decode = 0.2761 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7624 s, inc stats = 4.7749, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92106759 2.75092824 3.37019613 2.98806585 2.430809  ]
u_DA:    [3.9008529  1.94031676 3.04135407 1.71789846 2.63437253]
ref_MAE: [0.08061318 0.58914785 0.83126135 1.1355124  0.05417529]
da_MAE:  [0.02021468 0.81061149 0.32884206 1.27016739 0.20356353]
% 17.826021769692836 da_MAE 0.00655569303076544 ref_MAE 0.00797782116911992
u_c taken from control states: [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
u_c before reduction of space:  [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
data[u_c] post encoding of state:  [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
J_b = 0.0, J_o = 408447.9389021333
J_b = 0.5000000000000001, J_o = 15099199.703405814
J_b = 0.003545282946381527, J_o = 283186.8431061258
J_b = 0.008931919990320001, J_o = 192340.19913151133
J_b = 0.01891107646010686, J_o = 140595.0146677065
J_b = 0.02726943488352317, J_o = 116759.69124975111
J_b = 0.03584667122607855, J_o = 98755.02683009315
J_b = 0.04966139575589037, J_o = 82103.4483406174
J_b = 0.06703598780104934, J_o = 70043.23224994999
J_b = 0.09860676834758655, J_o = 64688.700203114175
J_b = 0.09992148935425021, J_o = 58759.255024488404
J_b = 0.09861980680566375, J_o = 57002.93403500841
J_b = 0.10795925802110871, J_o = 53890.230474707365
J_b = 0.1285489366362722, J_o = 52846.67409867421
J_b = 0.1345418385605395, J_o = 50714.07863611153
J_b = 0.13911658405298544, J_o = 50102.83601864136
J_b = 0.14745679382947366, J_o = 50343.37214332206
J_b = 0.14257785527526343, J_o = 49801.398702524275
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
W_opt:  [ 0.00443754  0.01154465  0.02103557  0.02166541  0.01687151 -0.000623
 -0.03228652 -0.085655   -0.15150152 -0.21727681]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0964 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.2150, add (DA)= 0.0001decode = 0.3231 s, unnorm = 0.0005 s, TOTAL = unnormalising + decoding + minimising = 5.4200 s, inc stats = 5.4316, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92069404 2.75243413 3.36960224 2.98986908 2.42994432]
u_DA:    [3.89752927 1.92545251 3.04717595 1.66225037 2.65807405]
ref_MAE: [0.08023964 0.59065374 0.83066746 1.13731563 0.05331061]
da_MAE:  [0.02316476 0.82698163 0.32242629 1.32761871 0.22812973]
% 17.716513682943827 da_MAE 0.006568767698149475 ref_MAE 0.007983093561250655
\% improve_point: 12.56, mse_ref_points: 3.580367588735654e-05, mse_da_points: 3.130779125303347e-05, % improve_overlap: 12.56, mse_ref_overlap: 0.93263, mse_da_overlap: 0.81554
DA - - L2: 36252.97, L1: 4713.61, % Improve: 17.94%, DA_MAE: 0.01, mse_ref: 0.93, mse_DA: 0.815, time(s): 7.4250s,
u_c taken from control states: [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
u_c before reduction of space:  [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
data[u_c] post encoding of state:  [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
J_b = 0.0, J_o = 405566.03422581253
J_b = 0.49999999999999994, J_o = 14983748.567200352
J_b = 0.003572902475444632, J_o = 280197.6883097909
J_b = 0.009025496950479666, J_o = 189068.8637239124
J_b = 0.01895606562542793, J_o = 138016.76788190307
J_b = 0.027202614377372807, J_o = 114530.87962274191
J_b = 0.035757193530179615, J_o = 96593.6344595903
J_b = 0.04954014593966714, J_o = 79990.4150132053
J_b = 0.06664926577787442, J_o = 68429.3005446627
J_b = 0.09676927017077964, J_o = 63219.913323739645
J_b = 0.09637153770497593, J_o = 57754.0962142599
J_b = 0.09504366594461304, J_o = 55971.322289929216
J_b = 0.10219534143848134, J_o = 53379.41958837387
J_b = 0.1255765444012884, J_o = 51900.11320697058
J_b = 0.12876158431597284, J_o = 49755.08671984896
J_b = 0.13450228507456555, J_o = 49446.870248923
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
W_opt:  [ 0.00990468  0.01410638  0.01925078  0.01885827  0.01311059 -0.00428934
 -0.03506303 -0.08594004 -0.14810375 -0.20954734]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5088 s, v_trunc (Latent to Reduced) = 0.1044, dec (Reduced to Full) = 0.1781, add (DA)= 0.0001decode = 0.2849 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7938 s, inc stats = 4.8101, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92034331 2.75401291 3.36901949 2.9916208  2.42879723]
u_DA:    [3.90013815 1.93936096 3.04487259 1.70435015 2.64021167]
ref_MAE: [0.07988891 0.59223251 0.83008471 1.13906735 0.05216352]
da_MAE:  [0.02020515 0.81465195 0.3241469  1.28727064 0.21141444]
% 17.859613794146398 da_MAE 0.006561796943689741 ref_MAE 0.007988514842437063
u_c taken from control states: [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
u_c before reduction of space:  [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
data[u_c] post encoding of state:  [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
J_b = 0.0, J_o = 406561.039048323
J_b = 0.49999999999999983, J_o = 14832906.527880572
J_b = 0.003650530057032184, J_o = 279523.68858394533
J_b = 0.009234502803324229, J_o = 187555.91907016543
J_b = 0.018995497618817307, J_o = 137638.68065629012
J_b = 0.027265340431491532, J_o = 113978.54379615282
J_b = 0.035819727100855625, J_o = 95976.38408280595
J_b = 0.04960190909675466, J_o = 79386.2557141472
J_b = 0.066401154159544, J_o = 68463.40074878318
J_b = 0.0931805799131305, J_o = 62571.53658221658
J_b = 0.09328961969837571, J_o = 57972.45908848409
J_b = 0.09311718559208589, J_o = 56035.191981447024
J_b = 0.10043252643326617, J_o = 53539.19511715771
J_b = 0.12162111386212222, J_o = 51378.77350142117
J_b = 0.13200402183707585, J_o = 49367.354387267
J_b = 0.13831269430881776, J_o = 49121.31958966241
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
W_opt:  [ 0.0110407   0.01482194  0.01876875  0.01863142  0.01326352 -0.00342886
 -0.033807   -0.08564207 -0.14962814 -0.2135938 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5034 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1716, add (DA)= 0.0001decode = 0.2787 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7822 s, inc stats = 4.7912, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92000547 2.75556063 3.36844018 2.99319085 2.42727717]
u_DA:    [3.90008127 1.93730371 3.04507465 1.69884402 2.64433117]
ref_MAE: [0.07955107 0.59378023 0.82950539 1.1406374  0.05064345]
da_MAE:  [0.0199242  0.81825691 0.32336552 1.29434682 0.217054  ]
% 17.860252771746566 da_MAE 0.006567023959837647 ref_MAE 0.007994940551239975
u_c taken from control states: [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
u_c before reduction of space:  [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
data[u_c] post encoding of state:  [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
J_b = 0.0, J_o = 410741.346637494
J_b = 0.4999999999999998, J_o = 14694579.914716193
J_b = 0.003762642792238562, J_o = 280687.4371521155
J_b = 0.009514638323942887, J_o = 187397.9848110188
J_b = 0.019059189436844513, J_o = 138598.47673064042
J_b = 0.027485583789337263, J_o = 114274.21087202936
J_b = 0.036087978499065615, J_o = 96053.67419113043
J_b = 0.04993347331506321, J_o = 79395.23761631103
J_b = 0.06643098505198759, J_o = 68962.77965679762
J_b = 0.09000115475663466, J_o = 62485.49852176242
J_b = 0.09170049234131036, J_o = 58404.49703894176
J_b = 0.09302549975970603, J_o = 56233.46835908651
J_b = 0.10039336686615283, J_o = 53906.589227534816
J_b = 0.12129476541235729, J_o = 51106.01771299927
J_b = 0.13613469759256563, J_o = 49897.89156504964
J_b = 0.13808404514751996, J_o = 49051.394167693186
J_b = 0.13627938924197858, J_o = 48813.13837671305
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
W_opt:  [ 0.01047314  0.01444412  0.01739497  0.01687847  0.01157262 -0.00447847
 -0.03390768 -0.08499116 -0.14867975 -0.21277651]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9953 s, v_trunc (Latent to Reduced) = 0.1124, dec (Reduced to Full) = 0.2023, add (DA)= 0.0002decode = 0.3171 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3125 s, inc stats = 5.3229, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91966918 2.75710264 3.3678523  2.99443614 2.42516509]
u_DA:    [3.89892232 1.93089526 3.04698029 1.67626438 2.65705042]
ref_MAE: [0.07921477 0.59532225 0.82891751 1.14188269 0.04853138]
da_MAE:  [0.02074685 0.82620739 0.32087201 1.31817176 0.23188533]
% 17.8141816522209 da_MAE 0.006575734938976115 ref_MAE 0.008001057933316558
u_c taken from control states: [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
u_c before reduction of space:  [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
data[u_c] post encoding of state:  [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
J_b = 0.0, J_o = 417399.40598875016
J_b = 0.49999999999999983, J_o = 14544576.790376794
J_b = 0.003912765320232501, J_o = 283082.92183887266
J_b = 0.00988079231823464, J_o = 187990.11303390673
J_b = 0.01918407977284658, J_o = 140249.26302518975
J_b = 0.027916568970350008, J_o = 114757.99698079444
J_b = 0.03660491605077615, J_o = 96217.2155897579
J_b = 0.050578893483086675, J_o = 79394.485225066
J_b = 0.06676377360137363, J_o = 69195.6670720181
J_b = 0.08879448233792087, J_o = 62499.17909388962
J_b = 0.09158491101981536, J_o = 58530.56327501401
J_b = 0.0937190448062388, J_o = 56234.81791431284
J_b = 0.10101873137535408, J_o = 54015.7916251352
J_b = 0.12149036638049464, J_o = 51278.870315007916
J_b = 0.13434510110273115, J_o = 50303.11693158155
J_b = 0.1349769350519747, J_o = 49366.15347818021
J_b = 0.13437817086171788, J_o = 49148.64991424482
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
W_opt:  [ 0.01216795  0.01623723  0.01824295  0.01648176  0.01008209 -0.00647878
 -0.03576605 -0.08590349 -0.14828721 -0.21089674]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8146 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1678, add (DA)= 0.0001decode = 0.2743 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0891 s, inc stats = 5.0947, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91932592 2.75866795 3.36724538 2.99524076 2.42232338]
u_DA:    [3.89945924 1.9317226  3.04748095 1.68015585 2.65951734]
ref_MAE: [0.07887152 0.59688756 0.8283106  1.14268731 0.04568967]
da_MAE:  [0.01986668 0.82694536 0.31976443 1.31508491 0.23719396]
% 17.783943079646114 da_MAE 0.006582817368288373 ref_MAE 0.008006729603519447
u_c taken from control states: [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
u_c before reduction of space:  [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
data[u_c] post encoding of state:  [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
J_b = 0.0, J_o = 425960.0447532175
J_b = 0.5000000000000001, J_o = 14356947.051267695
J_b = 0.004101707241869811, J_o = 286397.2105082906
J_b = 0.010342654505241381, J_o = 189127.4906842876
J_b = 0.019386416606398015, J_o = 142432.81787842643
J_b = 0.028574489479265542, J_o = 115312.51256837453
J_b = 0.03734705784743427, J_o = 96464.49097045793
J_b = 0.05150912403149594, J_o = 79383.7379396081
J_b = 0.06743329802033246, J_o = 69167.46194214051
J_b = 0.08973386477646575, J_o = 62375.97061997535
J_b = 0.09312720030927003, J_o = 58297.051878777915
J_b = 0.09520620653823458, J_o = 56003.74382748866
J_b = 0.1021815216215831, J_o = 53863.21235714873
J_b = 0.12119879607619961, J_o = 51265.33517480787
J_b = 0.13311602550977894, J_o = 50381.515515043466
J_b = 0.13407732044574264, J_o = 49468.22232099211
J_b = 0.1335809763286158, J_o = 49250.411914124335
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
W_opt:  [ 0.01431859  0.01809181  0.01974149  0.01673628  0.00906888 -0.00816432
 -0.03780164 -0.08742145 -0.14864319 -0.20962953]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7823 s, v_trunc (Latent to Reduced) = 0.1044, dec (Reduced to Full) = 0.1811, add (DA)= 0.0001decode = 0.2877 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0701 s, inc stats = 5.0755, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91897064 2.76024014 3.36661658 2.9955774  2.41881164]
u_DA:    [3.89992922 1.93290742 3.04629444 1.68244314 2.66021782]
ref_MAE: [0.07851624 0.59845974 0.82768179 1.14302395 0.04217793]
da_MAE:  [0.01904141 0.82733272 0.32032214 1.31313427 0.24140618]
% 17.74199745615175 da_MAE 0.0065904680577501115 ref_MAE 0.00801194759651137
u_c taken from control states: [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
u_c before reduction of space:  [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
data[u_c] post encoding of state:  [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
J_b = 0.0, J_o = 436404.4762274171
J_b = 0.5000000000000001, J_o = 14202172.668837618
J_b = 0.004295104325359566, J_o = 291246.11223606835
J_b = 0.010808899491467969, J_o = 191605.40728284276
J_b = 0.01967357595687619, J_o = 145405.99433911205
J_b = 0.02941804632122831, J_o = 116368.73028668293
J_b = 0.03832067170450348, J_o = 97164.17411913021
J_b = 0.05271860906842011, J_o = 79766.42861277735
J_b = 0.06856103467140469, J_o = 69355.72280893404
J_b = 0.09224765885350601, J_o = 62394.255179808155
J_b = 0.09613217140341318, J_o = 58047.02917415386
J_b = 0.09799518997333581, J_o = 55766.265545311144
J_b = 0.10467224440946714, J_o = 53704.21833552771
J_b = 0.12323016911682896, J_o = 51486.75336192812
J_b = 0.1316831222581057, J_o = 50247.36136891345
J_b = 0.1346243032992392, J_o = 49616.41698890423
J_b = 0.13420485053803552, J_o = 49366.63253418871
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
W_opt:  [ 0.01734774  0.01934181  0.02080547  0.01703845  0.00859299 -0.00925295
 -0.03952872 -0.08916071 -0.1496061  -0.20917114]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8473 s, v_trunc (Latent to Reduced) = 0.1058, dec (Reduced to Full) = 0.1497, add (DA)= 0.0001decode = 0.2576 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1051 s, inc stats = 5.1106, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91860107 2.76179185 3.36596814 2.99549997 2.41479181]
u_DA:    [3.90025247 1.93508378 3.04327712 1.67798287 2.66090759]
ref_MAE: [0.07814667 0.60001145 0.82703336 1.14294652 0.0381581 ]
da_MAE:  [0.0183486  0.82670807 0.32269102 1.3175171  0.24611577]
% 17.647314181178093 da_MAE 0.0066016385871873265 ref_MAE 0.008016300284013938
u_c taken from control states: [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
u_c before reduction of space:  [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
data[u_c] post encoding of state:  [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
J_b = 0.0, J_o = 447281.6241116872
J_b = 0.5, J_o = 14069344.181266854
J_b = 0.004471871753569134, J_o = 297030.4679135499
J_b = 0.011232223293003307, J_o = 195314.70808128454
J_b = 0.019949474243454876, J_o = 149394.49247339234
J_b = 0.0302860464553457, J_o = 118353.8565965036
J_b = 0.03934274395878997, J_o = 98787.91106028075
J_b = 0.0540636942904588, J_o = 80994.28237775552
J_b = 0.07007577820834862, J_o = 70305.45259733521
J_b = 0.09544583860858777, J_o = 63031.917987001274
J_b = 0.09980181565624288, J_o = 58303.02005659424
J_b = 0.10201925083168409, J_o = 56002.71249554638
J_b = 0.10881559382450337, J_o = 54033.065208601976
J_b = 0.12892609587996498, J_o = 52762.127113962575
J_b = 0.13037117145484775, J_o = 50976.791334321286
J_b = 0.13281946954404314, J_o = 50683.1392853305
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
W_opt:  [ 0.02356476  0.0219608   0.02104632  0.01608823  0.00679962 -0.01189124
 -0.04273748 -0.0912096  -0.1491848  -0.20536989]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5349 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1767, add (DA)= 0.0001decode = 0.2836 s, unnorm = 0.0004 s, TOTAL = unnormalising + decoding + minimising = 4.8190 s, inc stats = 4.8322, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91821823 2.76322836 3.36530777 2.99513916 2.41054747]
u_DA:    [3.90140558 1.94023983 3.04154443 1.68859296 2.65327582]
ref_MAE: [0.07776383 0.60144797 0.82637298 1.14258571 0.03391376]
da_MAE:  [0.01681265 0.82298853 0.32376334 1.3065462  0.24272834]
% 17.633664131000884 da_MAE 0.006605089984070654 ref_MAE 0.008019162093814428
u_c taken from control states: [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
u_c before reduction of space:  [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
data[u_c] post encoding of state:  [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
J_b = 0.0, J_o = 457075.7658654966
J_b = 0.4999999999999998, J_o = 13984307.884159593
J_b = 0.004612661640908839, J_o = 302610.3014480521
J_b = 0.011557779286490537, J_o = 199403.75243369967
J_b = 0.02012112737297561, J_o = 153755.58656825268
J_b = 0.030983931183263758, J_o = 120896.44738410892
J_b = 0.040165992448852654, J_o = 101039.73129842844
J_b = 0.055213425943877056, J_o = 82864.2501269109
J_b = 0.0715556374935486, J_o = 71899.4942210591
J_b = 0.09844350107457261, J_o = 64372.418692871615
J_b = 0.1029419463759696, J_o = 59282.77869895967
J_b = 0.10534027922671499, J_o = 57007.18695312641
J_b = 0.11249703303545736, J_o = 54873.02445849934
J_b = 0.1307296511763491, J_o = 52426.06743002767
J_b = 0.1486165402559853, J_o = 51958.863973393425
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
W_opt:  [ 0.02443386  0.02218838  0.02196749  0.01771468  0.01054003 -0.00663958
 -0.03814032 -0.09030275 -0.15438317 -0.21858974]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2432 s, v_trunc (Latent to Reduced) = 0.1050, dec (Reduced to Full) = 0.1867, add (DA)= 0.0001decode = 0.2938 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.5372 s, inc stats = 4.5411, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91782988 2.76450396 3.36464846 2.99468599 2.40648166]
u_DA:    [3.90363271 1.94420482 3.03462099 1.68811991 2.64308015]
ref_MAE: [0.07737547 0.60272357 0.82571368 1.14213254 0.02984795]
da_MAE:  [0.01419717 0.82029914 0.33002748 1.30656608 0.23659849]
% 17.628919633908037 da_MAE 0.006606373341896419 ref_MAE 0.008020258217489558
u_c taken from control states: [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
u_c before reduction of space:  [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
data[u_c] post encoding of state:  [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
J_b = 0.0, J_o = 464867.1660373667
J_b = 0.5000000000000002, J_o = 13915532.935933772
J_b = 0.004732455037677314, J_o = 306802.2491598876
J_b = 0.011824663604221599, J_o = 202656.3908206168
J_b = 0.020174909610017305, J_o = 157566.52418172534
J_b = 0.03150146038101473, J_o = 123043.63507613445
J_b = 0.040743039010998315, J_o = 103042.87323025597
J_b = 0.05606971745627687, J_o = 84565.88093783661
J_b = 0.07271375376319864, J_o = 73465.01538203421
J_b = 0.10039929973515975, J_o = 65942.23890638768
J_b = 0.10473569223107146, J_o = 60806.27097585112
J_b = 0.10606870619106078, J_o = 58593.70383235735
J_b = 0.11228814068110639, J_o = 56638.02986757706
J_b = 0.13122323834660599, J_o = 55357.52702283039
J_b = 0.13362230726087018, J_o = 53560.20751517845
J_b = 0.13693300790869403, J_o = 53247.800946328236
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
W_opt:  [ 0.02939175  0.02449679  0.02091679  0.01396861  0.00488575 -0.01277046
 -0.0433356  -0.09120138 -0.14874856 -0.20548153]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4714 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.1858, add (DA)= 0.0001decode = 0.2918 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7633 s, inc stats = 4.7765, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91744512 2.76560497 3.36400138 2.99432735 2.40288123]
u_DA:    [3.90145493 1.94733708 3.03009059 1.68241096 2.65344494]
ref_MAE: [0.07699072 0.60382457 0.8250666  1.1417739  0.02624752]
da_MAE:  [0.01599018 0.81826789 0.33391079 1.31191638 0.25056371]
% 17.543032724695045 da_MAE 0.006612609425953647 ref_MAE 0.008019467177195174
u_c taken from control states: [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
u_c before reduction of space:  [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
data[u_c] post encoding of state:  [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
J_b = 0.0, J_o = 469506.4676752015
J_b = 0.5000000000000001, J_o = 13850263.401349843
J_b = 0.004841041023274816, J_o = 308210.6363228156
J_b = 0.012054801664895596, J_o = 203662.99121107018
J_b = 0.020105014671689597, J_o = 159526.1947287075
J_b = 0.031857961649932695, J_o = 123401.44112276754
J_b = 0.04106318921979153, J_o = 103468.58581870652
J_b = 0.05660378798407566, J_o = 84810.2421460954
J_b = 0.07340124195034946, J_o = 73803.74336294217
J_b = 0.10082042904565072, J_o = 66485.82107841148
J_b = 0.1046403064539014, J_o = 61474.84615550511
J_b = 0.1050390760472795, J_o = 59295.43229904381
J_b = 0.11074964958228761, J_o = 57260.264815431365
J_b = 0.12595604993691498, J_o = 54721.87235166152
J_b = 0.14030530067372954, J_o = 54042.48515584673
J_b = 0.14391158315928054, J_o = 53021.54110742822
J_b = 0.14120268357238797, J_o = 52810.22460223565
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
W_opt:  [ 0.02934254  0.0245164   0.02081864  0.01376555  0.00517718 -0.01113508
 -0.04073658 -0.0893327  -0.14892607 -0.20896007]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7808 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1994, add (DA)= 0.0001decode = 0.3059 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0868 s, inc stats = 5.0981, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91707436 2.76654448 3.36337476 2.99420772 2.39994813]
u_DA:    [3.9003788  1.9489133  3.02953372 1.68675286 2.65345818]
ref_MAE: [0.07661996 0.60476409 0.82443998 1.14165427 0.02331442]
da_MAE:  [0.01669556 0.81763118 0.33384104 1.30745486 0.25351005]
% 17.577127911648947 da_MAE 0.006607623424334322 ref_MAE 0.008016735230060234
\% improve_point: 12.44, mse_ref_points: 3.6146594121086654e-05, mse_da_points: 3.165657309711382e-05, % improve_overlap: 12.44, mse_ref_overlap: 0.94157, mse_da_overlap: 0.82463
DA - - L2: 32836.25, L1: 4589.95, % Improve: 17.92%, DA_MAE: 0.01, mse_ref: 0.94, mse_DA: 0.824, time(s): 7.1799s,
u_c taken from control states: [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
u_c before reduction of space:  [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
data[u_c] post encoding of state:  [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
J_b = 0.0, J_o = 471150.0210319433
J_b = 0.5, J_o = 13908740.088067288
J_b = 0.00487690069379485, J_o = 307821.3029583995
J_b = 0.01208995715914635, J_o = 203191.1452247413
J_b = 0.019974729841586263, J_o = 159381.58014968535
J_b = 0.0319314453417377, J_o = 122350.38562181353
J_b = 0.0410876972414512, J_o = 102443.35487786916
J_b = 0.056573933351170315, J_o = 83891.45435685327
J_b = 0.07332110606225264, J_o = 73068.46990134337
J_b = 0.10007840474528149, J_o = 65976.70374957047
J_b = 0.10276614429742358, J_o = 60989.68359802196
J_b = 0.10328905187346547, J_o = 58794.16967637774
J_b = 0.1093517682102624, J_o = 56655.212113424626
J_b = 0.12446334104180788, J_o = 53791.321996632236
J_b = 0.14372473508293926, J_o = 55051.78478065399
J_b = 0.1311964831181292, J_o = 53012.61467806608
J_b = 0.14245386665558885, J_o = 52089.292048943855
J_b = 0.1438046161569004, J_o = 51756.73329268765
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
W_opt:  [ 0.02965027  0.02592298  0.02107068  0.01365932  0.00505123 -0.01070685
 -0.03967426 -0.08865525 -0.14941934 -0.21130675]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1805 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1895, add (DA)= 0.0001decode = 0.2964 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.4772 s, inc stats = 5.4828, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91672335 2.76734226 3.36277538 2.99444796 2.39784992]
u_DA:    [3.90089675 1.94657709 3.03670759 1.68915275 2.65493175]
ref_MAE: [0.07626895 0.60556186 0.8238406  1.14189451 0.02121621]
da_MAE:  [0.0158266  0.82076517 0.32606779 1.30529522 0.25708183]
% 17.670505894471255 da_MAE 0.006596398161194773 ref_MAE 0.008012193239933681
u_c taken from control states: [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
u_c before reduction of space:  [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
data[u_c] post encoding of state:  [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
J_b = 0.0, J_o = 469532.2721185129
J_b = 0.4999999999999999, J_o = 14096750.417739872
J_b = 0.00481586678220754, J_o = 306223.9072995477
J_b = 0.01188555258561548, J_o = 201905.90235292402
J_b = 0.019810636887080367, J_o = 157546.81933494855
J_b = 0.03169575579598735, J_o = 120554.66124208254
J_b = 0.040849488873265095, J_o = 100498.95305324683
J_b = 0.05600225372592186, J_o = 82343.65423499458
J_b = 0.07245642143598532, J_o = 71711.89098611863
J_b = 0.09846490512200097, J_o = 64651.62013006915
J_b = 0.10020922043724678, J_o = 59720.609059562994
J_b = 0.10142697814449582, J_o = 57406.50451058443
J_b = 0.10789892732786065, J_o = 55242.10966408478
J_b = 0.12461300772707051, J_o = 52037.0306909606
J_b = 0.14758213009553395, J_o = 55220.41907062415
J_b = 0.13073119960976676, J_o = 51336.92630466807
J_b = 0.1424887903321021, J_o = 50350.62792318622
J_b = 0.14454239164306287, J_o = 49961.57419472728
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
W_opt:  [ 0.02662878  0.0264143   0.02222417  0.01457828  0.00554597 -0.01030143
 -0.03907541 -0.08823902 -0.14986666 -0.21307998]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0886 s, v_trunc (Latent to Reduced) = 0.1029, dec (Reduced to Full) = 0.1900, add (DA)= 0.0001decode = 0.2953 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 5.3842 s, inc stats = 5.3895, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91639489 2.76799759 3.36220782 2.99512792 2.396612  ]
u_DA:    [3.9016581  1.94284602 3.04833469 1.6926386  2.6486035 ]
ref_MAE: [0.07594049 0.6062172  0.82327303 1.14257447 0.01997829]
da_MAE:  [0.01473679 0.82515158 0.31387312 1.30248932 0.25199151]
% 17.83471857076654 da_MAE 0.00657830427532541 ref_MAE 0.00800618480323847
u_c taken from control states: [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
u_c before reduction of space:  [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
data[u_c] post encoding of state:  [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
J_b = 0.0, J_o = 464424.82591649285
J_b = 0.4999999999999999, J_o = 14441562.562622752
J_b = 0.004632519978164632, J_o = 304052.84254053934
J_b = 0.011399790690527973, J_o = 200268.0774119037
J_b = 0.019740840042556634, J_o = 153718.43807542624
J_b = 0.031191424231958417, J_o = 118133.673046716
J_b = 0.040467152615776165, J_o = 97660.53455352578
J_b = 0.05502974564553675, J_o = 80156.02453330118
J_b = 0.07104125223351039, J_o = 69585.8349240165
J_b = 0.09680385360681093, J_o = 62659.958547355534
J_b = 0.09761106916619268, J_o = 57692.04169543977
J_b = 0.09907672887350535, J_o = 55327.75628867781
J_b = 0.10560703315155703, J_o = 53169.42748308713
J_b = 0.12339613146942316, J_o = 49716.69691388252
J_b = 0.1461663532251891, J_o = 54463.42497358321
J_b = 0.12850514974862468, J_o = 49064.420594342366
J_b = 0.14266654771391749, J_o = 47843.035951309415
J_b = 0.14631256256183844, J_o = 47311.9243238752
J_b = 0.1541980274173528, J_o = 46464.37161249064
J_b = 0.15967753952642091, J_o = 45877.84935128729
J_b = 0.1596157960758396, J_o = 45582.460306103036
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
W_opt:  [ 0.00880054  0.01863768  0.02215241  0.01908532  0.01379138  0.00227053
 -0.02381638 -0.07751942 -0.15045621 -0.23118859]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.8990 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1749, add (DA)= 0.0001decode = 0.2810 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.1802 s, inc stats = 6.2086, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91608823 2.76849594 3.36166969 2.99625791 2.39604189]
u_DA:    [3.9011754  1.94265651 3.04884811 1.70767307 2.62579533]
ref_MAE: [0.07563383 0.60671554 0.82273491 1.14370446 0.01940818]
da_MAE:  [0.01491283 0.82583943 0.31282158 1.28858485 0.22975344]
% 17.904702254037044 da_MAE 0.006566945515287744 ref_MAE 0.007999173759754924
u_c taken from control states: [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
u_c before reduction of space:  [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
data[u_c] post encoding of state:  [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
J_b = 0.0, J_o = 457610.1590947684
J_b = 0.5, J_o = 14804131.06223258
J_b = 0.0044180676347850304, J_o = 301491.89306936646
J_b = 0.0108596368924007, J_o = 198469.9920528151
J_b = 0.019773598396515983, J_o = 148983.33804391747
J_b = 0.0307239533527697, J_o = 115195.08083717803
J_b = 0.040167423566412314, J_o = 94356.78455267566
J_b = 0.05432887851865695, J_o = 77323.51894777233
J_b = 0.07019369364534718, J_o = 66726.27149637157
J_b = 0.09566642528879643, J_o = 59986.31931452691
J_b = 0.09576210349126436, J_o = 55060.88885535829
J_b = 0.09718742916660575, J_o = 52714.91355806779
J_b = 0.10364232300916561, J_o = 50589.75108217447
J_b = 0.12178732092333494, J_o = 47131.91325785773
J_b = 0.1466848298784157, J_o = 50848.76699418244
J_b = 0.1283551359456059, J_o = 46273.91215565517
J_b = 0.14268989073004565, J_o = 45466.90116255751
J_b = 0.1441021203278303, J_o = 44876.359868698695
J_b = 0.1428743245322163, J_o = 44636.70180171116
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
W_opt:  [ 0.01173584  0.0200992   0.02275859  0.01939558  0.01075131 -0.00606349
 -0.03566719 -0.08612092 -0.14976318 -0.21576109]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3647 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1770, add (DA)= 0.0001decode = 0.2830 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.6478 s, inc stats = 5.6517, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91580024 2.76887555 3.36115342 2.99777853 2.39585421]
u_DA:    [3.90092702 1.94041878 3.05542942 1.68778266 2.6442913 ]
ref_MAE: [0.07534584 0.60709516 0.82221863 1.14522508 0.0192205 ]
da_MAE:  [0.01487322 0.82845677 0.305724   1.30999587 0.24843709]
% 17.89483722082789 da_MAE 0.006561527062004685 ref_MAE 0.007991613243192022
u_c taken from control states: [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
u_c before reduction of space:  [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
data[u_c] post encoding of state:  [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
J_b = 0.0, J_o = 450836.82543403114
J_b = 0.5, J_o = 15090148.509837614
J_b = 0.0042319620746066235, J_o = 298991.3521654528
J_b = 0.01040657069132113, J_o = 196850.07482751616
J_b = 0.019870006702160187, J_o = 144583.64110322378
J_b = 0.03039800230068915, J_o = 112443.7967857787
J_b = 0.03996314078350446, J_o = 91478.3089519532
J_b = 0.05394683610245621, J_o = 74672.28387119043
J_b = 0.06997405743026172, J_o = 63984.580478767246
J_b = 0.09537202947496771, J_o = 57426.42588603422
J_b = 0.09483371312792443, J_o = 52584.590099211244
J_b = 0.09606166255216814, J_o = 50302.12785658105
J_b = 0.1023973925087579, J_o = 48211.87743951631
J_b = 0.1204215078622642, J_o = 44802.31647242575
J_b = 0.14650865887828898, J_o = 48886.9963943062
J_b = 0.12709796889568134, J_o = 43948.80702575689
J_b = 0.1403545678780167, J_o = 43202.69247669635
J_b = 0.14326239028490204, J_o = 42599.46405534592
J_b = 0.14126595439186604, J_o = 42383.89661410899
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
W_opt:  [ 0.00819512  0.01779906  0.02100802  0.01990437  0.01251989 -0.00447955
 -0.03474277 -0.0859461  -0.14958201 -0.21520895]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3532 s, v_trunc (Latent to Reduced) = 0.1105, dec (Reduced to Full) = 0.1796, add (DA)= 0.0001decode = 0.2922 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6456 s, inc stats = 5.6553, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91552792 2.76915985 3.36065243 2.99959935 2.39582438]
u_DA:    [3.90025377 1.93904563 3.0540433  1.67813335 2.64836844]
ref_MAE: [0.07507352 0.60737945 0.82171765 1.1470459  0.01919067]
da_MAE:  [0.01527415 0.83011422 0.30660913 1.32146601 0.25254406]
% 17.871582228115642 da_MAE 0.006556820378183665 ref_MAE 0.007983619502320804
u_c taken from control states: [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
u_c before reduction of space:  [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
data[u_c] post encoding of state:  [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
J_b = 0.0, J_o = 445041.2572374558
J_b = 0.4999999999999998, J_o = 15293187.03323677
J_b = 0.004085824925191651, J_o = 296929.6608039115
J_b = 0.010060596246525546, J_o = 195632.25958242192
J_b = 0.01998817763991842, J_o = 141100.84296767236
J_b = 0.030155021385002433, J_o = 110438.68113258202
J_b = 0.03972678405427598, J_o = 89649.22584367235
J_b = 0.05353515526291156, J_o = 73043.14182140431
J_b = 0.06975013363143716, J_o = 62248.21572188964
J_b = 0.09557128226694234, J_o = 55931.5968122905
J_b = 0.09436418963852683, J_o = 51075.30796109961
J_b = 0.09522014545995618, J_o = 48900.023941929656
J_b = 0.10141947038993655, J_o = 46812.2610767844
J_b = 0.11907268960661105, J_o = 43435.68970598083
J_b = 0.14515706316075921, J_o = 47269.64254502785
J_b = 0.12588945845563418, J_o = 42578.5999514767
J_b = 0.1395007326781086, J_o = 41796.14211535321
J_b = 0.14330778487738285, J_o = 41198.79648445398
J_b = 0.1408702877735517, J_o = 40976.71390065444
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
W_opt:  [ 0.00697636  0.01669899  0.01915975  0.01901644  0.01307993 -0.00301861
 -0.03336793 -0.08545165 -0.14955392 -0.21539909]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.7323 s, v_trunc (Latent to Reduced) = 0.1119, dec (Reduced to Full) = 0.1809, add (DA)= 0.0001decode = 0.2951 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.0276 s, inc stats = 6.0372, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91526598 2.76939843 3.36015762 3.00159    2.39568216]
u_DA:    [3.89957985 1.93709957 3.05021703 1.66901762 2.65385197]
ref_MAE: [0.07481158 0.60761803 0.82122283 1.14903655 0.01904845]
da_MAE:  [0.01568613 0.83229886 0.30994058 1.33257238 0.25816981]
% 17.816572042773135 da_MAE 0.006554807718505551 ref_MAE 0.007975826613021134
\% improve_point: 12.37, mse_ref_points: 3.635055790904895e-05, mse_da_points: 3.1862340057992244e-05, % improve_overlap: 12.37, mse_ref_overlap: 0.94689, mse_da_overlap: 0.82999
DA - - L2: 31086.99, L1: 4529.63, % Improve: 17.91%, DA_MAE: 0.01, mse_ref: 0.95, mse_DA: 0.829, time(s): 7.0993s,
Results of DA at 2020-08-28 13:32:35.342387. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              17.876673      0.007516  ...  92.969451     9.194512
1              17.942485      0.007520  ...   9.938516     9.917689
2              18.140516      0.007523  ...   6.940689     6.893282
3              18.194590      0.007526  ...   7.587941     7.566707
4              17.700434      0.007529  ...   7.055943     7.028601
..                   ...           ...  ...        ...          ...
102            17.834719      0.008006  ...   5.393920     5.384238
103            17.904702      0.007999  ...   6.212772     6.180156
104            17.894837      0.007992  ...   5.655104     5.647755
105            17.871582      0.007984  ...   5.659597     5.645601
106            17.816572      0.007976  ...   6.040756     6.027619

[107 rows x 20 columns]
------------------------- Ended at 2020-08-28 13:32:36.591070 -------------------- 

