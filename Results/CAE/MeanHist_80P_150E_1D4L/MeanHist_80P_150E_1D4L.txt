Path ['/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/mredstone/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/', '/Users/maxime/IndividualProject/code/Data_Assimilation/src/']

------------------------- Simulation Started at 2020-08-27 17:32:33.051999 ------------------- 

data fp  /home/mredstone/unstructuredCAE/data/subdomain_8/
domain, other, pickle, dim 8 ['6'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | MeanHist_80P_150E_1D4L                                                       |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_8/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
When creating TucodecEncode1D, inputSize =  16206 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
Number of parameters: 35153615
------------------------------ Training subdomain 8 at 2020-08-27 17:32:38.600627. ------------------------------
Loading data started 2020-08-27 17:32:38.600721
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
shape of mean (16206,) and std (16206,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7f509f5a8400>
Loading data finished 2020-08-27 17:32:46.798848
Loop AE Train begins at  17:32:46.802063
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [1/150], TRAIN: -loss:19502.11, av_diff: 0.93, time taken (m): 0.02m
epoch [1/150], TEST: -loss:18948.6528, time taken(m): 0.00m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [6/150], TRAIN: -loss:737.27, av_diff: 0.07, time taken (m): 0.02m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [11/150], TRAIN: -loss:161.66, av_diff: 0.02, time taken (m): 0.02m
epoch [11/150], TEST: -loss:2321.4479, time taken(m): 0.00m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [16/150], TRAIN: -loss:60.42, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [21/150], TRAIN: -loss:35.68, av_diff: 0.00, time taken (m): 0.02m
epoch [21/150], TEST: -loss:499.8770, time taken(m): 0.00m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [26/150], TRAIN: -loss:30.73, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [31/150], TRAIN: -loss:31.91, av_diff: 0.01, time taken (m): 0.02m
epoch [31/150], TEST: -loss:224.9279, time taken(m): 0.00m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [36/150], TRAIN: -loss:32.74, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [41/150], TRAIN: -loss:32.47, av_diff: 0.01, time taken (m): 0.02m
epoch [41/150], TEST: -loss:225.8568, time taken(m): 0.00m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [46/150], TRAIN: -loss:34.20, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [51/150], TRAIN: -loss:41.31, av_diff: 0.02, time taken (m): 0.02m
epoch [51/150], TEST: -loss:228.0961, time taken(m): 0.00m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [56/150], TRAIN: -loss:40.46, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [61/150], TRAIN: -loss:42.53, av_diff: 0.02, time taken (m): 0.02m
epoch [61/150], TEST: -loss:230.8904, time taken(m): 0.00m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [66/150], TRAIN: -loss:43.25, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [71/150], TRAIN: -loss:43.75, av_diff: 0.02, time taken (m): 0.02m
epoch [71/150], TEST: -loss:205.8144, time taken(m): 0.00m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [76/150], TRAIN: -loss:39.48, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [81/150], TRAIN: -loss:35.28, av_diff: 0.02, time taken (m): 0.02m
epoch [81/150], TEST: -loss:213.4319, time taken(m): 0.00m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [86/150], TRAIN: -loss:34.27, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [91/150], TRAIN: -loss:32.24, av_diff: 0.01, time taken (m): 0.02m
epoch [91/150], TEST: -loss:226.8699, time taken(m): 0.00m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [96/150], TRAIN: -loss:31.31, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [101/150], TRAIN: -loss:30.95, av_diff: 0.01, time taken (m): 0.02m
epoch [101/150], TEST: -loss:255.0081, time taken(m): 0.00m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [106/150], TRAIN: -loss:35.80, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [111/150], TRAIN: -loss:36.95, av_diff: 0.02, time taken (m): 0.02m
epoch [111/150], TEST: -loss:217.5325, time taken(m): 0.00m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [116/150], TRAIN: -loss:46.67, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [121/150], TRAIN: -loss:49.28, av_diff: 0.03, time taken (m): 0.02m
epoch [121/150], TEST: -loss:212.1280, time taken(m): 0.00m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [126/150], TRAIN: -loss:48.94, av_diff: 0.03, time taken (m): 0.02m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [131/150], TRAIN: -loss:65.51, av_diff: 0.04, time taken (m): 0.02m
epoch [131/150], TEST: -loss:212.4586, time taken(m): 0.00m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [136/150], TRAIN: -loss:61.84, av_diff: 0.04, time taken (m): 0.02m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [141/150], TRAIN: -loss:33.36, av_diff: 0.02, time taken (m): 0.02m
epoch [141/150], TEST: -loss:234.0387, time taken(m): 0.00m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [146/150], TRAIN: -loss:16.05, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
epoch [150/150], TRAIN: -loss:18.54, av_diff: 0.00, time taken (m): 0.02m
epoch [150/150], TEST: -loss:192.3532, time taken(m): 0.00m
Loop AE Train Ends at  17:35:49.438931
------------------------------ DA subdomain 8 at 2020-08-27 17:35:49.501328. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
shape of mean (16206,) and std (16206,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 16206) , test_X = (107, 16206), X = (537, 16206)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
shape of mean (16206,) and std (16206,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting mean historical data
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
Shape of w_0 =  (429,)
minCostFunction = 0.0271 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1319, add (DA)= 0.0001decode = 0.1324 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1596 s, inc stats = 19.2382, 
minCostFunction = 0.0231 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1322, add (DA)= 0.0002decode = 0.1329 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1561 s, inc stats = 0.1677, 
minCostFunction = 0.0242 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1372, add (DA)= 0.0001decode = 0.1377 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1620 s, inc stats = 0.1717, 
minCostFunction = 0.0298 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1242 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1541 s, inc stats = 0.1676, 
minCostFunction = 0.0248 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1316, add (DA)= 0.0001decode = 0.1322 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1571 s, inc stats = 0.1706, 
minCostFunction = 0.0233 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1329, add (DA)= 0.0001decode = 0.1334 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1568 s, inc stats = 0.1704, 
minCostFunction = 0.0308 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1315, add (DA)= 0.0001decode = 0.1321 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1630 s, inc stats = 0.1764, 
minCostFunction = 0.0310 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1318, add (DA)= 0.0001decode = 0.1324 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1634 s, inc stats = 0.1768, 
minCostFunction = 0.0233 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1317, add (DA)= 0.0001decode = 0.1323 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1557 s, inc stats = 0.1632, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1307, add (DA)= 0.0001decode = 0.1313 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1547 s, inc stats = 0.1669, 
minCostFunction = 0.0237 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1241, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1484 s, inc stats = 0.1555, 
DA - - L2: 229.12, L1: 858.78, % Improve: 62.96%, DA_MAE: 0.01, mse_ref: 0.04, mse_DA: 0.014, time(s): 1.9937s,
\% improve_point: 61.03, mse_ref_points: 2.2559370428275446e-06, mse_da_points: 8.900547336056444e-07, % improve_overlap: 62.49, mse_ref_overlap: 0.02804, mse_da_overlap: 0.01059
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1220, add (DA)= 0.0001decode = 0.1225 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1453 s, inc stats = 0.1573, 
minCostFunction = 0.0309 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1240, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1556 s, inc stats = 0.1625, 
minCostFunction = 0.0237 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1302, add (DA)= 0.0001decode = 0.1308 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1547 s, inc stats = 0.1683, 
minCostFunction = 0.0235 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1314, add (DA)= 0.0001decode = 0.1319 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1555 s, inc stats = 0.1690, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1325, add (DA)= 0.0001decode = 0.1330 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1565 s, inc stats = 0.1623, 
minCostFunction = 0.0318 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1390, add (DA)= 0.0001decode = 0.1395 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1714 s, inc stats = 0.1847, 
minCostFunction = 0.0273 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1335, add (DA)= 0.0001decode = 0.1341 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1614 s, inc stats = 0.1678, 
minCostFunction = 0.0355 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1313, add (DA)= 0.0001decode = 0.1318 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1674 s, inc stats = 0.1809, 
minCostFunction = 0.0355 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1365, add (DA)= 0.0001decode = 0.1370 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1726 s, inc stats = 0.1800, 
minCostFunction = 0.0251 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1330, add (DA)= 0.0001decode = 0.1335 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1587 s, inc stats = 0.1731, 
DA - - L2: 420.22, L1: 1218.96, % Improve: 36.32%, DA_MAE: 0.01, mse_ref: 0.03, mse_DA: 0.020, time(s): 1.1266s,
\% improve_point: 28.08, mse_ref_points: 1.8754003806679073e-06, mse_da_points: 1.2082858671465583e-06, % improve_overlap: 41.12, mse_ref_overlap: 0.02452, mse_da_overlap: 0.01356
minCostFunction = 0.0235 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1345, add (DA)= 0.0001decode = 0.1351 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1586 s, inc stats = 0.1735, 
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1391, add (DA)= 0.0001decode = 0.1397 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1625 s, inc stats = 0.1760, 
minCostFunction = 0.0304 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1415, add (DA)= 0.0002decode = 0.1422 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1728 s, inc stats = 0.1832, 
minCostFunction = 0.0550 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1328, add (DA)= 0.0001decode = 0.1340 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1891 s, inc stats = 0.2013, 
minCostFunction = 0.0248 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1362, add (DA)= 0.0001decode = 0.1368 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1616 s, inc stats = 0.1736, 
minCostFunction = 0.0241 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1313, add (DA)= 0.0001decode = 0.1319 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1560 s, inc stats = 0.1686, 
minCostFunction = 0.0276 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1313, add (DA)= 0.0001decode = 0.1319 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1595 s, inc stats = 0.1730, 
minCostFunction = 0.0250 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1214, add (DA)= 0.0001decode = 0.1220 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1471 s, inc stats = 0.1592, 
minCostFunction = 0.0280 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1349, add (DA)= 0.0001decode = 0.1355 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1636 s, inc stats = 0.1770, 
minCostFunction = 0.0215 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1345 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1560 s, inc stats = 0.1677, 
DA - - L2: 573.95, L1: 1454.91, % Improve: 37.98%, DA_MAE: 0.01, mse_ref: 0.03, mse_DA: 0.019, time(s): 0.8205s,
\% improve_point: 26.81, mse_ref_points: 1.7201198188311993e-06, mse_da_points: 1.147468787561453e-06, % improve_overlap: 41.64, mse_ref_overlap: 0.02332, mse_da_overlap: 0.01295
minCostFunction = 0.0294 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1316, add (DA)= 0.0001decode = 0.1322 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1617 s, inc stats = 0.1674, 
minCostFunction = 0.0239 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1344 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1584 s, inc stats = 0.1708, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1247, add (DA)= 0.0001decode = 0.1253 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1488 s, inc stats = 0.1575, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1244, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1484 s, inc stats = 0.1604, 
minCostFunction = 0.0236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1305, add (DA)= 0.0001decode = 0.1311 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1547 s, inc stats = 0.1680, 
minCostFunction = 0.0238 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1325, add (DA)= 0.0001decode = 0.1331 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1570 s, inc stats = 0.1705, 
minCostFunction = 0.0235 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1234, add (DA)= 0.0001decode = 0.1240 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1476 s, inc stats = 0.1609, 
minCostFunction = 0.0241 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1374, add (DA)= 0.0001decode = 0.1380 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1622 s, inc stats = 0.1756, 
minCostFunction = 0.0237 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1370, add (DA)= 0.0001decode = 0.1376 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1614 s, inc stats = 0.1750, 
minCostFunction = 0.0237 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1232, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1475 s, inc stats = 0.1545, 
DA - - L2: 793.71, L1: 1713.89, % Improve: 39.38%, DA_MAE: 0.01, mse_ref: 0.03, mse_DA: 0.021, time(s): 0.6615s,
\% improve_point: 30.16, mse_ref_points: 2.0093060615593753e-06, mse_da_points: 1.3153479345976725e-06, % improve_overlap: 42.60, mse_ref_overlap: 0.02685, mse_da_overlap: 0.01513
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1261, add (DA)= 0.0002decode = 0.1268 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1504 s, inc stats = 0.1618, 
minCostFunction = 0.0261 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1328, add (DA)= 0.0001decode = 0.1334 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1596 s, inc stats = 0.1733, 
minCostFunction = 0.0226 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1321, add (DA)= 0.0001decode = 0.1326 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1553 s, inc stats = 0.1688, 
minCostFunction = 0.0315 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1368, add (DA)= 0.0001decode = 0.1374 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1690 s, inc stats = 0.1827, 
minCostFunction = 0.0279 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1263, add (DA)= 0.0001decode = 0.1269 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1549 s, inc stats = 0.1684, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1309, add (DA)= 0.0001decode = 0.1314 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1549 s, inc stats = 0.1607, 
minCostFunction = 0.0232 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1330, add (DA)= 0.0001decode = 0.1336 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1569 s, inc stats = 0.1608, 
minCostFunction = 0.0235 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1324, add (DA)= 0.0001decode = 0.1330 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1566 s, inc stats = 0.1656, 
minCostFunction = 0.0245 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1372, add (DA)= 0.0001decode = 0.1378 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1623 s, inc stats = 0.1745, 
minCostFunction = 0.0242 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1304, add (DA)= 0.0001decode = 0.1310 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1553 s, inc stats = 0.1690, 
DA - - L2: 1293.96, L1: 2067.81, % Improve: 35.29%, DA_MAE: 0.01, mse_ref: 0.05, mse_DA: 0.039, time(s): 0.5653s,
\% improve_point: 27.38, mse_ref_points: 3.221484364129604e-06, mse_da_points: 2.408817879901587e-06, % improve_overlap: 37.65, mse_ref_overlap: 0.04142, mse_da_overlap: 0.02861
minCostFunction = 0.0226 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1213, add (DA)= 0.0001decode = 0.1219 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1445 s, inc stats = 0.1581, 
minCostFunction = 0.0238 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1285, add (DA)= 0.0001decode = 0.1291 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1530 s, inc stats = 0.1662, 
minCostFunction = 0.0240 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1308, add (DA)= 0.0001decode = 0.1314 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1555 s, inc stats = 0.1625, 
minCostFunction = 0.0364 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1245, add (DA)= 0.0001decode = 0.1251 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1616 s, inc stats = 0.1750, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1472 s, inc stats = 0.1638, 
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1223 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1450 s, inc stats = 0.1494, 
minCostFunction = 0.0255 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1215, add (DA)= 0.0001decode = 0.1221 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1477 s, inc stats = 0.1563, 
minCostFunction = 0.0233 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1357, add (DA)= 0.0001decode = 0.1363 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1596 s, inc stats = 0.1653, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1323, add (DA)= 0.0001decode = 0.1328 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1563 s, inc stats = 0.1618, 
minCostFunction = 0.0534 s, v_trunc (Latent to Reduced) = 0.0012, dec (Reduced to Full) = 0.1314, add (DA)= 0.0001decode = 0.1328 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1863 s, inc stats = 19.3456, 
DA - - L2: 1736.02, L1: 2382.39, % Improve: 32.46%, DA_MAE: 0.02, mse_ref: 0.06, mse_DA: 0.050, time(s): 0.8140s,
\% improve_point: 25.46, mse_ref_points: 3.9865537709573335e-06, mse_da_points: 3.1048823794473785e-06, % improve_overlap: 33.79, mse_ref_overlap: 0.05376, mse_da_overlap: 0.04035
minCostFunction = 0.0237 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1227, add (DA)= 0.0001decode = 0.1233 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1472 s, inc stats = 0.1606, 
minCostFunction = 0.0328 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1305, add (DA)= 0.0001decode = 0.1311 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1640 s, inc stats = 0.1777, 
minCostFunction = 0.0239 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1344 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1584 s, inc stats = 0.1723, 
minCostFunction = 0.0318 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1331, add (DA)= 0.0002decode = 0.1338 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1657 s, inc stats = 0.1780, 
minCostFunction = 0.0238 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1344 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1583 s, inc stats = 0.1719, 
minCostFunction = 0.0239 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1477 s, inc stats = 0.1612, 
minCostFunction = 0.0236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1329, add (DA)= 0.0001decode = 0.1335 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1572 s, inc stats = 0.1693, 
minCostFunction = 0.0235 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1350, add (DA)= 0.0001decode = 0.1355 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1591 s, inc stats = 0.1731, 
minCostFunction = 0.0240 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1228, add (DA)= 0.0001decode = 0.1234 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1475 s, inc stats = 0.1611, 
minCostFunction = 0.0267 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1356, add (DA)= 0.0001decode = 0.1361 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1630 s, inc stats = 0.1762, 
DA - - L2: 2120.92, L1: 2633.52, % Improve: 30.21%, DA_MAE: 0.02, mse_ref: 0.07, mse_DA: 0.059, time(s): 0.7237s,
\% improve_point: 23.80, mse_ref_points: 4.534062502031193e-06, mse_da_points: 3.6248562312018716e-06, % improve_overlap: 30.70, mse_ref_overlap: 0.06341, mse_da_overlap: 0.04985
minCostFunction = 0.0242 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1225, add (DA)= 0.0001decode = 0.1231 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1474 s, inc stats = 0.1567, 
minCostFunction = 0.0225 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1334, add (DA)= 0.0001decode = 0.1339 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1565 s, inc stats = 0.1690, 
minCostFunction = 0.0305 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1388, add (DA)= 0.0001decode = 0.1394 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1699 s, inc stats = 0.1754, 
minCostFunction = 0.0238 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1219, add (DA)= 0.0001decode = 0.1225 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1464 s, inc stats = 0.1580, 
minCostFunction = 0.0238 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1251, add (DA)= 0.0001decode = 0.1257 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1496 s, inc stats = 0.1627, 
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1325, add (DA)= 0.0001decode = 0.1331 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1558 s, inc stats = 0.1615, 
minCostFunction = 0.0237 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1223, add (DA)= 0.0001decode = 0.1229 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1466 s, inc stats = 0.1523, 
minCostFunction = 0.0313 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1222, add (DA)= 0.0001decode = 0.1228 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1542 s, inc stats = 0.1619, 
minCostFunction = 0.0236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1216, add (DA)= 0.0001decode = 0.1222 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1458 s, inc stats = 0.1595, 
minCostFunction = 0.0229 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1362, add (DA)= 0.0002decode = 0.1368 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1599 s, inc stats = 0.1659, 
DA - - L2: 2514.98, L1: 2857.07, % Improve: 28.15%, DA_MAE: 0.02, mse_ref: 0.08, mse_DA: 0.066, time(s): 0.6547s,
\% improve_point: 21.79, mse_ref_points: 4.955875660212499e-06, mse_da_points: 4.08595058424022e-06, % improve_overlap: 27.94, mse_ref_overlap: 0.07135, mse_da_overlap: 0.05816
minCostFunction = 0.0232 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1306, add (DA)= 0.0001decode = 0.1311 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1545 s, inc stats = 0.1681, 
minCostFunction = 0.0242 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1223 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1466 s, inc stats = 0.1601, 
minCostFunction = 0.0226 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1356, add (DA)= 0.0001decode = 0.1361 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1589 s, inc stats = 0.1724, 
minCostFunction = 0.0240 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1343, add (DA)= 0.0002decode = 0.1350 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1591 s, inc stats = 0.1728, 
minCostFunction = 0.0226 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1237, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1470 s, inc stats = 0.1587, 
minCostFunction = 0.0245 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1355, add (DA)= 0.0001decode = 0.1360 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1606 s, inc stats = 0.1726, 
minCostFunction = 0.0241 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1347, add (DA)= 0.0001decode = 0.1353 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1595 s, inc stats = 0.1730, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1347, add (DA)= 0.0001decode = 0.1353 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1587 s, inc stats = 0.1724, 
minCostFunction = 0.0274 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1512 s, inc stats = 0.1647, 
minCostFunction = 0.0236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1335, add (DA)= 0.0001decode = 0.1341 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1577 s, inc stats = 0.1671, 
DA - - L2: 2941.68, L1: 3072.46, % Improve: 26.18%, DA_MAE: 0.03, mse_ref: 0.09, mse_DA: 0.075, time(s): 0.6015s,
\% improve_point: 19.65, mse_ref_points: 5.414844296634659e-06, mse_da_points: 4.617277874348403e-06, % improve_overlap: 25.45, mse_ref_overlap: 0.07948, mse_da_overlap: 0.06690
minCostFunction = 0.0235 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1342, add (DA)= 0.0001decode = 0.1348 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1585 s, inc stats = 0.1649, 
minCostFunction = 0.0228 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1228, add (DA)= 0.0001decode = 0.1234 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1462 s, inc stats = 0.1596, 
minCostFunction = 0.0225 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1229, add (DA)= 0.0001decode = 0.1234 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1460 s, inc stats = 0.1598, 
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0009, dec (Reduced to Full) = 0.1381, add (DA)= 0.0001decode = 0.1391 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1619 s, inc stats = 0.1736, 
minCostFunction = 0.0236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1217, add (DA)= 0.0001decode = 0.1223 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1460 s, inc stats = 0.1547, 
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1354, add (DA)= 0.0001decode = 0.1360 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1588 s, inc stats = 0.1654, 
minCostFunction = 0.0328 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1317, add (DA)= 0.0001decode = 0.1323 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1652 s, inc stats = 0.1787, 
minCostFunction = 0.0227 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1237, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1470 s, inc stats = 0.1547, 
minCostFunction = 0.0236 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1214, add (DA)= 0.0001decode = 0.1220 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1457 s, inc stats = 0.1574, 
minCostFunction = 0.0234 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1215, add (DA)= 0.0001decode = 0.1221 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1455 s, inc stats = 0.1572, 
DA - - L2: 3301.07, L1: 3250.60, % Improve: 24.74%, DA_MAE: 0.03, mse_ref: 0.09, mse_DA: 0.081, time(s): 0.5583s,
\% improve_point: 17.90, mse_ref_points: 5.724376246191642e-06, mse_da_points: 4.989894033793362e-06, % improve_overlap: 23.41, mse_ref_overlap: 0.08537, mse_da_overlap: 0.07337
minCostFunction = 0.0233 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1337, add (DA)= 0.0001decode = 0.1343 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1576 s, inc stats = 0.1698, 
minCostFunction = 0.0293 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1299, add (DA)= 0.0001decode = 0.1305 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1600 s, inc stats = 0.1735, 
minCostFunction = 0.0225 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1382, add (DA)= 0.0001decode = 0.1388 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1614 s, inc stats = 0.1683, 
minCostFunction = 0.0280 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1361, add (DA)= 0.0001decode = 0.1367 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1648 s, inc stats = 0.1772, 
minCostFunction = 0.0232 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1249, add (DA)= 0.0001decode = 0.1255 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1488 s, inc stats = 0.1614, 
minCostFunction = 0.0230 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1252, add (DA)= 0.0001decode = 0.1257 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1488 s, inc stats = 0.1623, 
DA - - L2: 3521.45, L1: 3352.87, % Improve: 24.06%, DA_MAE: 0.03, mse_ref: 0.09, mse_DA: 0.083, time(s): 0.5366s,
\% improve_point: 17.18, mse_ref_points: 5.8540618251705225e-06, mse_da_points: 5.137491767761863e-06, % improve_overlap: 22.46, mse_ref_overlap: 0.08806, mse_da_overlap: 0.07625
Results of DA at 2020-08-27 17:37:35.884437. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              72.764341      0.012622  ...  20.220058     0.159634
1              68.216136      0.013497  ...   0.170419     0.156148
2              64.107660      0.014444  ...   0.174422     0.162020
3              60.565756      0.015342  ...   0.169634     0.154106
4              58.578132      0.015883  ...   0.173366     0.157099
..                   ...           ...  ...        ...          ...
102            12.624607      0.046607  ...   0.175521     0.159958
103            12.596017      0.046824  ...   0.170382     0.161397
104            12.564376      0.047023  ...   0.179946     0.164781
105            12.548025      0.047157  ...   0.163397     0.148792
106            12.547638      0.047203  ...   0.165199     0.148758

[107 rows x 20 columns]
data fp  /home/mredstone/unstructuredCAE/data/subdomain_6/
domain, other, pickle, dim 6 ['8'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | MeanHist_80P_150E_1D4L                                                       |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_6/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
When creating TucodecEncode1D, inputSize =  26032 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
Number of parameters: 55287089
------------------------------ Training subdomain 6 at 2020-08-27 17:37:45.468556. ------------------------------
Loading data started 2020-08-27 17:37:45.468644
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7f509ecfa710>
Loading data finished 2020-08-27 17:37:58.807672
Loop AE Train begins at  17:37:58.810765
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [1/150], TRAIN: -loss:8514.89, av_diff: 0.33, time taken (m): 0.02m
epoch [1/150], TEST: -loss:98744.1562, time taken(m): 0.00m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [6/150], TRAIN: -loss:2511.36, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [11/150], TRAIN: -loss:1951.13, av_diff: 0.02, time taken (m): 0.02m
epoch [11/150], TEST: -loss:98131.2637, time taken(m): 0.00m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [16/150], TRAIN: -loss:1793.50, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [21/150], TRAIN: -loss:1466.81, av_diff: 0.01, time taken (m): 0.02m
epoch [21/150], TEST: -loss:98114.3604, time taken(m): 0.00m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [26/150], TRAIN: -loss:958.04, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [31/150], TRAIN: -loss:1254.41, av_diff: 0.01, time taken (m): 0.02m
epoch [31/150], TEST: -loss:97675.8008, time taken(m): 0.00m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [36/150], TRAIN: -loss:670.11, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [41/150], TRAIN: -loss:545.99, av_diff: 0.00, time taken (m): 0.02m
epoch [41/150], TEST: -loss:97790.2510, time taken(m): 0.00m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [46/150], TRAIN: -loss:508.43, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [51/150], TRAIN: -loss:452.04, av_diff: 0.00, time taken (m): 0.02m
epoch [51/150], TEST: -loss:97268.3604, time taken(m): 0.00m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [56/150], TRAIN: -loss:330.75, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [61/150], TRAIN: -loss:199.65, av_diff: 0.00, time taken (m): 0.02m
epoch [61/150], TEST: -loss:96976.6133, time taken(m): 0.00m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [66/150], TRAIN: -loss:214.81, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [71/150], TRAIN: -loss:256.06, av_diff: 0.01, time taken (m): 0.02m
epoch [71/150], TEST: -loss:97086.9141, time taken(m): 0.00m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [76/150], TRAIN: -loss:210.88, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [81/150], TRAIN: -loss:235.27, av_diff: 0.01, time taken (m): 0.02m
epoch [81/150], TEST: -loss:96788.1904, time taken(m): 0.00m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [86/150], TRAIN: -loss:217.59, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [91/150], TRAIN: -loss:161.07, av_diff: 0.01, time taken (m): 0.02m
epoch [91/150], TEST: -loss:96867.0532, time taken(m): 0.00m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [96/150], TRAIN: -loss:140.67, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [101/150], TRAIN: -loss:134.44, av_diff: 0.01, time taken (m): 0.02m
epoch [101/150], TEST: -loss:96667.1362, time taken(m): 0.00m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [106/150], TRAIN: -loss:98.50, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [111/150], TRAIN: -loss:94.81, av_diff: 0.01, time taken (m): 0.02m
epoch [111/150], TEST: -loss:96363.2666, time taken(m): 0.00m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [116/150], TRAIN: -loss:63.76, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [121/150], TRAIN: -loss:56.03, av_diff: 0.00, time taken (m): 0.03m
epoch [121/150], TEST: -loss:96337.7500, time taken(m): 0.00m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [126/150], TRAIN: -loss:64.42, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [131/150], TRAIN: -loss:53.51, av_diff: 0.01, time taken (m): 0.02m
epoch [131/150], TEST: -loss:96325.7920, time taken(m): 0.00m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [136/150], TRAIN: -loss:51.15, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [141/150], TRAIN: -loss:46.93, av_diff: 0.01, time taken (m): 0.02m
epoch [141/150], TEST: -loss:96148.3867, time taken(m): 0.00m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [146/150], TRAIN: -loss:46.18, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
epoch [150/150], TRAIN: -loss:42.89, av_diff: 0.01, time taken (m): 0.03m
epoch [150/150], TEST: -loss:96277.4805, time taken(m): 0.00m
Loop AE Train Ends at  17:41:49.709209
------------------------------ DA subdomain 6 at 2020-08-27 17:41:49.797665. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 26032) , test_X = (107, 26032), X = (537, 26032)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
shape of mean (26032,) and std (26032,)
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting mean historical data
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
Shape of w_0 =  (429,)
minCostFunction = 0.0555 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1349, add (DA)= 0.0001decode = 0.1356 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1912 s, inc stats = 48.0331, 
minCostFunction = 0.0268 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1368, add (DA)= 0.0001decode = 0.1374 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1644 s, inc stats = 0.1773, 
minCostFunction = 0.0250 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1266, add (DA)= 0.0001decode = 0.1272 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1523 s, inc stats = 0.1657, 
minCostFunction = 0.0445 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1344, add (DA)= 0.0001decode = 0.1350 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1796 s, inc stats = 0.1920, 
minCostFunction = 0.0417 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1368, add (DA)= 0.0001decode = 0.1374 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1792 s, inc stats = 0.1919, 
minCostFunction = 0.0546 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1329, add (DA)= 0.0001decode = 0.1335 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1883 s, inc stats = 0.2017, 
minCostFunction = 0.0206 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1310, add (DA)= 0.0001decode = 0.1316 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1523 s, inc stats = 0.1657, 
minCostFunction = 0.0264 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1244, add (DA)= 0.0001decode = 0.1250 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1515 s, inc stats = 0.1646, 
minCostFunction = 0.0224 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1379, add (DA)= 0.0001decode = 0.1385 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1610 s, inc stats = 0.1740, 
minCostFunction = 0.0438 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1254, add (DA)= 0.0001decode = 0.1260 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1699 s, inc stats = 0.1834, 
minCostFunction = 0.0399 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1331, add (DA)= 0.0001decode = 0.1337 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1737 s, inc stats = 0.1854, 
DA - - L2: 199216.78, L1: 11714.88, % Improve: 78.08%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.044, time(s): 4.6271s,
\% improve_point: 79.08, mse_ref_points: 8.162003865993753e-06, mse_da_points: 1.7084053831216563e-06, % improve_overlap: 79.11, mse_ref_overlap: 0.21247, mse_da_overlap: 0.04440
minCostFunction = 0.0272 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1341, add (DA)= 0.0001decode = 0.1347 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1621 s, inc stats = 0.1754, 
minCostFunction = 0.0420 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1404, add (DA)= 0.0001decode = 0.1410 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1831 s, inc stats = 0.1960, 
minCostFunction = 0.1048 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1225, add (DA)= 0.0001decode = 0.1238 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2289 s, inc stats = 0.2422, 
minCostFunction = 0.0326 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1253, add (DA)= 0.0002decode = 0.1260 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1587 s, inc stats = 0.1645, 
minCostFunction = 0.0424 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1242 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1668 s, inc stats = 0.1759, 
minCostFunction = 0.0515 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1240, add (DA)= 0.0001decode = 0.1246 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1763 s, inc stats = 0.1896, 
minCostFunction = 0.0464 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1249, add (DA)= 0.0001decode = 0.1255 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1721 s, inc stats = 0.1773, 
minCostFunction = 0.0364 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1245, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1617 s, inc stats = 0.1735, 
minCostFunction = 0.0413 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1247, add (DA)= 0.0001decode = 0.1253 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1667 s, inc stats = 0.1777, 
minCostFunction = 0.0377 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1245, add (DA)= 0.0001decode = 0.1251 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1629 s, inc stats = 0.1763, 
DA - - L2: 168018.91, L1: 10393.44, % Improve: 79.81%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.041, time(s): 2.5128s,
\% improve_point: 80.52, mse_ref_points: 7.984749960522767e-06, mse_da_points: 1.5599250771031653e-06, % improve_overlap: 80.60, mse_ref_overlap: 0.20783, mse_da_overlap: 0.04044
minCostFunction = 0.0443 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1338, add (DA)= 0.0001decode = 0.1344 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1789 s, inc stats = 0.1920, 
minCostFunction = 0.0316 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1402, add (DA)= 0.0001decode = 0.1408 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1725 s, inc stats = 0.1784, 
minCostFunction = 0.0497 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1260, add (DA)= 0.0001decode = 0.1266 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1765 s, inc stats = 0.1889, 
minCostFunction = 0.0589 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1399, add (DA)= 0.0001decode = 0.1405 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1994 s, inc stats = 0.2127, 
minCostFunction = 0.0455 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1394, add (DA)= 0.0001decode = 0.1400 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1856 s, inc stats = 0.2102, 
minCostFunction = 0.0597 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1384, add (DA)= 0.0001decode = 0.1391 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1988 s, inc stats = 0.2107, 
minCostFunction = 0.0700 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1279, add (DA)= 0.0001decode = 0.1285 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1986 s, inc stats = 0.2121, 
minCostFunction = 0.0417 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1327, add (DA)= 0.0001decode = 0.1333 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1751 s, inc stats = 0.1964, 
minCostFunction = 0.0510 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1345, add (DA)= 0.0001decode = 0.1352 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1864 s, inc stats = 0.1994, 
minCostFunction = 0.0611 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1361, add (DA)= 0.0001decode = 0.1367 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1979 s, inc stats = 0.2095, 
DA - - L2: 116432.25, L1: 9448.45, % Improve: 80.40%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.039, time(s): 1.7678s,
\% improve_point: 80.88, mse_ref_points: 7.910012560614941e-06, mse_da_points: 1.5161332412933747e-06, % improve_overlap: 81.00, mse_ref_overlap: 0.20586, mse_da_overlap: 0.03921
minCostFunction = 0.0403 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1385, add (DA)= 0.0001decode = 0.1391 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1796 s, inc stats = 0.1906, 
minCostFunction = 0.0411 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1408, add (DA)= 0.0001decode = 0.1414 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1827 s, inc stats = 0.1936, 
minCostFunction = 0.0435 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1378, add (DA)= 0.0001decode = 0.1384 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1820 s, inc stats = 0.1950, 
minCostFunction = 0.0493 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1356, add (DA)= 0.0001decode = 0.1362 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1856 s, inc stats = 0.1986, 
minCostFunction = 0.0570 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1361, add (DA)= 0.0001decode = 0.1367 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1938 s, inc stats = 0.2053, 
minCostFunction = 0.0528 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1324, add (DA)= 0.0001decode = 0.1330 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1859 s, inc stats = 0.1993, 
minCostFunction = 0.0687 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1232, add (DA)= 0.0001decode = 0.1238 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1927 s, inc stats = 0.2052, 
minCostFunction = 0.0389 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1225, add (DA)= 0.0001decode = 0.1230 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1621 s, inc stats = 0.1701, 
minCostFunction = 0.0406 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1344, add (DA)= 0.0001decode = 0.1351 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1758 s, inc stats = 0.1892, 
minCostFunction = 0.0447 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1371, add (DA)= 0.0001decode = 0.1377 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1825 s, inc stats = 0.1959, 
DA - - L2: 90155.31, L1: 8749.68, % Improve: 80.74%, DA_MAE: 0.00, mse_ref: 0.21, mse_DA: 0.040, time(s): 1.3846s,
\% improve_point: 80.74, mse_ref_points: 7.946701020050124e-06, mse_da_points: 1.5350442074590102e-06, % improve_overlap: 80.91, mse_ref_overlap: 0.20679, mse_da_overlap: 0.03959
minCostFunction = 0.1154 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1179, add (DA)= 0.0001decode = 0.1192 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2347 s, inc stats = 0.2404, 
minCostFunction = 0.0661 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1371, add (DA)= 0.0001decode = 0.1377 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2040 s, inc stats = 0.2103, 
minCostFunction = 0.0409 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1246, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1662 s, inc stats = 0.1776, 
minCostFunction = 0.0840 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1242, add (DA)= 0.0001decode = 0.1248 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2089 s, inc stats = 0.2166, 
minCostFunction = 0.0598 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1231, add (DA)= 0.0001decode = 0.1237 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1836 s, inc stats = 0.1971, 
minCostFunction = 0.0307 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1306, add (DA)= 0.0001decode = 0.1312 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1620 s, inc stats = 0.1754, 
minCostFunction = 0.0561 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1326, add (DA)= 0.0001decode = 0.1332 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1894 s, inc stats = 0.2029, 
minCostFunction = 0.1060 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1246, add (DA)= 0.0001decode = 0.1252 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2314 s, inc stats = 0.2383, 
minCostFunction = 0.0698 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1355, add (DA)= 0.0001decode = 0.1361 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2061 s, inc stats = 0.2196, 
minCostFunction = 0.0424 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1242 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1668 s, inc stats = 0.1759, 
DA - - L2: 73845.91, L1: 8254.40, % Improve: 78.22%, DA_MAE: 0.00, mse_ref: 0.22, mse_DA: 0.054, time(s): 1.1538s,
\% improve_point: 76.12, mse_ref_points: 8.33451961454621e-06, mse_da_points: 2.0745841735959212e-06, % improve_overlap: 76.30, mse_ref_overlap: 0.21685, mse_da_overlap: 0.05358
minCostFunction = 0.0791 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1230, add (DA)= 0.0001decode = 0.1236 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2028 s, inc stats = 0.2161, 
minCostFunction = 0.0545 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1236, add (DA)= 0.0001decode = 0.1242 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1789 s, inc stats = 0.1862, 
minCostFunction = 0.0736 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1334, add (DA)= 0.0001decode = 0.1340 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2078 s, inc stats = 0.2212, 
minCostFunction = 0.1068 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1244, add (DA)= 0.0001decode = 0.1257 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2326 s, inc stats = 0.2462, 
minCostFunction = 0.0539 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1309, add (DA)= 0.0001decode = 0.1315 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1856 s, inc stats = 0.1978, 
minCostFunction = 0.0750 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1237, add (DA)= 0.0001decode = 0.1243 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1994 s, inc stats = 0.2052, 
minCostFunction = 0.0403 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1233, add (DA)= 0.0001decode = 0.1239 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1644 s, inc stats = 0.1780, 
minCostFunction = 0.0462 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1274, add (DA)= 0.0001decode = 0.1280 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1743 s, inc stats = 0.1877, 
minCostFunction = 0.0507 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1363, add (DA)= 0.0002decode = 0.1369 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 0.1879 s, inc stats = 0.2006, 
minCostFunction = 0.0492 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1370, add (DA)= 0.0002decode = 0.1377 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1871 s, inc stats = 47.7840, 
DA - - L2: 63011.54, L1: 7946.85, % Improve: 75.98%, DA_MAE: 0.00, mse_ref: 0.23, mse_DA: 0.066, time(s): 1.7786s,
\% improve_point: 72.40, mse_ref_points: 8.707829174779674e-06, mse_da_points: 2.5449758602210674e-06, % improve_overlap: 72.56, mse_ref_overlap: 0.22656, mse_da_overlap: 0.06585
minCostFunction = 0.0355 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1295, add (DA)= 0.0002decode = 0.1302 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 0.1660 s, inc stats = 0.1728, 
minCostFunction = 0.0407 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1343, add (DA)= 0.0001decode = 0.1349 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1758 s, inc stats = 0.1893, 
minCostFunction = 0.0501 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1235, add (DA)= 0.0001decode = 0.1241 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1744 s, inc stats = 0.1849, 
minCostFunction = 0.0435 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1238, add (DA)= 0.0001decode = 0.1244 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1681 s, inc stats = 0.1816, 
minCostFunction = 0.0426 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1229, add (DA)= 0.0001decode = 0.1235 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1662 s, inc stats = 0.1714, 
minCostFunction = 0.0503 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1369, add (DA)= 0.0001decode = 0.1375 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1880 s, inc stats = 0.1999, 
minCostFunction = 0.0429 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1379, add (DA)= 0.0001decode = 0.1385 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1815 s, inc stats = 0.1918, 
minCostFunction = 0.0399 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1357, add (DA)= 0.0001decode = 0.1363 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1763 s, inc stats = 0.1817, 
minCostFunction = 0.0448 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1346, add (DA)= 0.0001decode = 0.1352 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1802 s, inc stats = 0.1937, 
minCostFunction = 0.0324 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1317, add (DA)= 0.0001decode = 0.1324 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1649 s, inc stats = 0.1734, 
DA - - L2: 55071.14, L1: 7738.07, % Improve: 74.18%, DA_MAE: 0.00, mse_ref: 0.23, mse_DA: 0.074, time(s): 1.5544s,
\% improve_point: 70.03, mse_ref_points: 8.992561675798104e-06, mse_da_points: 2.857499305819074e-06, % improve_overlap: 70.20, mse_ref_overlap: 0.23395, mse_da_overlap: 0.07395
minCostFunction = 0.0437 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1373, add (DA)= 0.0001decode = 0.1379 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1818 s, inc stats = 0.1950, 
minCostFunction = 0.0377 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1361, add (DA)= 0.0001decode = 0.1373 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1751 s, inc stats = 0.1885, 
minCostFunction = 0.0593 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1387, add (DA)= 0.0001decode = 0.1399 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1993 s, inc stats = 0.2119, 
minCostFunction = 0.0440 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1320, add (DA)= 0.0001decode = 0.1326 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1767 s, inc stats = 0.1892, 
minCostFunction = 0.0696 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1339, add (DA)= 0.0001decode = 0.1345 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.2043 s, inc stats = 0.2098, 
minCostFunction = 0.0850 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1319, add (DA)= 0.0001decode = 0.1325 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2176 s, inc stats = 0.2247, 
minCostFunction = 0.0398 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1354, add (DA)= 0.0001decode = 0.1360 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1759 s, inc stats = 0.1890, 
minCostFunction = 0.0382 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1263, add (DA)= 0.0001decode = 0.1269 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1653 s, inc stats = 0.1787, 
minCostFunction = 0.0430 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1221, add (DA)= 0.0001decode = 0.1227 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1658 s, inc stats = 0.1795, 
minCostFunction = 0.0604 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1241, add (DA)= 0.0001decode = 0.1247 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1853 s, inc stats = 0.2035, 
DA - - L2: 49472.24, L1: 7672.80, % Improve: 73.25%, DA_MAE: 0.00, mse_ref: 0.24, mse_DA: 0.078, time(s): 1.3871s,
\% improve_point: 69.12, mse_ref_points: 9.19327380729071e-06, mse_da_points: 2.9945006796365795e-06, % improve_overlap: 69.32, mse_ref_overlap: 0.23914, mse_da_overlap: 0.07741
minCostFunction = 0.0313 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1347, add (DA)= 0.0001decode = 0.1353 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1667 s, inc stats = 0.1799, 
minCostFunction = 0.0440 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1263, add (DA)= 0.0001decode = 0.1269 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1710 s, inc stats = 0.1844, 
minCostFunction = 0.0571 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1263, add (DA)= 0.0001decode = 0.1269 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1841 s, inc stats = 0.1972, 
minCostFunction = 0.0468 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1219, add (DA)= 0.0001decode = 0.1225 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1695 s, inc stats = 0.1748, 
minCostFunction = 0.0402 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1362, add (DA)= 0.0001decode = 0.1369 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1772 s, inc stats = 0.1841, 
minCostFunction = 0.0424 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1303, add (DA)= 0.0001decode = 0.1309 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1735 s, inc stats = 0.1853, 
minCostFunction = 0.0563 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1249, add (DA)= 0.0001decode = 0.1255 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1819 s, inc stats = 0.1934, 
minCostFunction = 0.0655 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1310, add (DA)= 0.0001decode = 0.1316 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1972 s, inc stats = 0.2106, 
minCostFunction = 0.0398 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1383, add (DA)= 0.0001decode = 0.1389 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1788 s, inc stats = 0.1903, 
minCostFunction = 0.0512 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1366, add (DA)= 0.0001decode = 0.1373 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1886 s, inc stats = 0.2020, 
DA - - L2: 44734.58, L1: 7450.12, % Improve: 72.91%, DA_MAE: 0.00, mse_ref: 0.24, mse_DA: 0.079, time(s): 1.2558s,
\% improve_point: 69.03, mse_ref_points: 9.337354967549963e-06, mse_da_points: 3.0315515163292796e-06, % improve_overlap: 69.24, mse_ref_overlap: 0.24287, mse_da_overlap: 0.07832
minCostFunction = 0.0399 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1401, add (DA)= 0.0001decode = 0.1407 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1807 s, inc stats = 0.1902, 
minCostFunction = 0.0346 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1341, add (DA)= 0.0002decode = 0.1348 s, unnorm = 0.0003 s, TOTAL = unnormalising + decoding + minimising = 0.1697 s, inc stats = 0.1764, 
minCostFunction = 0.0738 s, v_trunc (Latent to Reduced) = 0.0011, dec (Reduced to Full) = 0.1194, add (DA)= 0.0001decode = 0.1206 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1945 s, inc stats = 0.2080, 
minCostFunction = 0.0606 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.0552, add (DA)= 0.0001decode = 0.0559 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1166 s, inc stats = 0.1236, 
minCostFunction = 0.0956 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1430, add (DA)= 0.0001decode = 0.1437 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.2394 s, inc stats = 0.2508, 
minCostFunction = 0.0457 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1374, add (DA)= 0.0001decode = 0.1380 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1838 s, inc stats = 0.1892, 
minCostFunction = 0.0556 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1271, add (DA)= 0.0001decode = 0.1277 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1834 s, inc stats = 0.1949, 
minCostFunction = 0.0507 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1329, add (DA)= 0.0001decode = 0.1335 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1843 s, inc stats = 0.1977, 
minCostFunction = 0.0310 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1392, add (DA)= 0.0001decode = 0.1399 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 0.1710 s, inc stats = 0.1836, 
minCostFunction = 0.0441 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1347, add (DA)= 0.0001decode = 0.1353 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1796 s, inc stats = 0.1915, 
DA - - L2: 40927.74, L1: 7370.37, % Improve: 72.55%, DA_MAE: 0.00, mse_ref: 0.25, mse_DA: 0.080, time(s): 1.1506s,
\% improve_point: 68.77, mse_ref_points: 9.469048767158467e-06, mse_da_points: 3.085915514143289e-06, % improve_overlap: 68.98, mse_ref_overlap: 0.24630, mse_da_overlap: 0.07973
minCostFunction = 0.0431 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1348, add (DA)= 0.0001decode = 0.1354 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1786 s, inc stats = 0.1918, 
minCostFunction = 0.0573 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1340, add (DA)= 0.0001decode = 0.1347 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1921 s, inc stats = 0.1978, 
minCostFunction = 0.0574 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1385, add (DA)= 0.0001decode = 0.1391 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1966 s, inc stats = 0.2042, 
minCostFunction = 0.0541 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1371, add (DA)= 0.0001decode = 0.1377 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1919 s, inc stats = 0.1971, 
minCostFunction = 0.0390 s, v_trunc (Latent to Reduced) = 0.0004, dec (Reduced to Full) = 0.1315, add (DA)= 0.0001decode = 0.1321 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1712 s, inc stats = 0.1822, 
minCostFunction = 0.0512 s, v_trunc (Latent to Reduced) = 0.0005, dec (Reduced to Full) = 0.1354, add (DA)= 0.0001decode = 0.1360 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 0.1874 s, inc stats = 0.2000, 
DA - - L2: 38970.26, L1: 7309.05, % Improve: 72.54%, DA_MAE: 0.00, mse_ref: 0.25, mse_DA: 0.081, time(s): 1.0972s,
\% improve_point: 68.76, mse_ref_points: 9.545959776422533e-06, mse_da_points: 3.1042033778073996e-06, % improve_overlap: 68.97, mse_ref_overlap: 0.24830, mse_da_overlap: 0.08022
Results of DA at 2020-08-27 17:45:06.939771. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              90.621848      0.001691  ...  49.072444     0.191202
1              86.317198      0.001697  ...   0.179423     0.164358
2              85.129650      0.001704  ...   0.168523     0.152312
3              84.823420      0.001711  ...   0.194050     0.179574
4              83.165564      0.001717  ...   0.194658     0.179246
..                   ...           ...  ...        ...          ...
102            71.798607      0.002206  ...   0.199858     0.192050
103            72.241900      0.002198  ...   0.206988     0.196624
104            72.573708      0.002188  ...   0.199231     0.191922
105            72.841086      0.002178  ...   0.184972     0.171237
106            72.935383      0.002168  ...   0.202940     0.187354

[107 rows x 20 columns]
------------------------- Ended at 2020-08-27 17:45:08.164092 -------------------- 

