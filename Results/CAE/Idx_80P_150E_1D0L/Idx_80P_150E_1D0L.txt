Path ['/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/mredstone/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/mredstone/unstructuredCAE/code/Data_Assimilation/src/', '/Users/maxime/IndividualProject/code/Data_Assimilation/src/']

------------------------- Simulation Started at 2020-08-28 13:51:57.480807 ------------------- 

data fp  /home/mredstone/unstructuredCAE/data/subdomain_8/
domain, other, pickle, dim 8 ['6'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_80P_150E_1D0L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_8/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
91, 85, 32, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
89, 83, 30, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
87, 81, 28, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
85, 79, 26, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
83, 77, 24, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
81, 75, 22, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
79, 73, 20, stride=(2, 2, 2, )  kernel_size=(3, 3, 2, )  padding=(0, 1, 1, )  
39, 37, 11, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 1, 0, )  
19, 19, 5, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 1, )  
9, 9, 3, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
5, 5, 2, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
OUT: 3, 3, 1, Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
When creating TucodecEncode1D, inputSize =  16206 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 16206, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  16206
DIM USED  1
Number of parameters: 567553
------------------------------ Training subdomain 8 at 2020-08-28 13:52:02.702817. ------------------------------
Loading data started 2020-08-28 13:52:02.702882
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (16206,) and std (16206,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fde67158160>
Loading data finished 2020-08-28 13:52:10.820997
Loop AE Train begins at  13:52:10.824511
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [1/150], TRAIN: -loss:15437.86, av_diff: 0.89, time taken (m): 0.03m
epoch [1/150], TEST: -loss:15452.5186, time taken(m): 0.01m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [6/150], TRAIN: -loss:5202.63, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [11/150], TRAIN: -loss:4220.17, av_diff: 0.01, time taken (m): 0.02m
epoch [11/150], TEST: -loss:8335.4382, time taken(m): 0.01m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [16/150], TRAIN: -loss:3859.81, av_diff: 0.02, time taken (m): 0.02m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [21/150], TRAIN: -loss:3591.12, av_diff: 0.01, time taken (m): 0.02m
epoch [21/150], TEST: -loss:4724.7231, time taken(m): 0.01m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [26/150], TRAIN: -loss:3354.82, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [31/150], TRAIN: -loss:3149.66, av_diff: 0.01, time taken (m): 0.03m
epoch [31/150], TEST: -loss:3684.0673, time taken(m): 0.01m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [36/150], TRAIN: -loss:2960.51, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [41/150], TRAIN: -loss:2783.70, av_diff: 0.01, time taken (m): 0.02m
epoch [41/150], TEST: -loss:3304.8753, time taken(m): 0.01m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [46/150], TRAIN: -loss:2653.79, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [51/150], TRAIN: -loss:2512.09, av_diff: 0.01, time taken (m): 0.02m
epoch [51/150], TEST: -loss:3053.1402, time taken(m): 0.01m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [56/150], TRAIN: -loss:2354.67, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [61/150], TRAIN: -loss:2281.45, av_diff: 0.01, time taken (m): 0.02m
epoch [61/150], TEST: -loss:2817.0530, time taken(m): 0.01m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [66/150], TRAIN: -loss:2162.55, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [71/150], TRAIN: -loss:2094.30, av_diff: 0.01, time taken (m): 0.03m
epoch [71/150], TEST: -loss:2665.9053, time taken(m): 0.01m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [76/150], TRAIN: -loss:1976.19, av_diff: 0.01, time taken (m): 0.02m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [81/150], TRAIN: -loss:1904.42, av_diff: 0.01, time taken (m): 0.03m
epoch [81/150], TEST: -loss:2508.2990, time taken(m): 0.01m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [86/150], TRAIN: -loss:1858.46, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [91/150], TRAIN: -loss:1754.84, av_diff: 0.00, time taken (m): 0.02m
epoch [91/150], TEST: -loss:2383.0129, time taken(m): 0.01m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [96/150], TRAIN: -loss:1712.72, av_diff: 0.00, time taken (m): 0.03m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [101/150], TRAIN: -loss:1657.95, av_diff: 0.00, time taken (m): 0.03m
epoch [101/150], TEST: -loss:2359.8376, time taken(m): 0.01m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [106/150], TRAIN: -loss:1606.85, av_diff: 0.00, time taken (m): 0.03m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [111/150], TRAIN: -loss:1542.25, av_diff: 0.00, time taken (m): 0.03m
epoch [111/150], TEST: -loss:2255.1727, time taken(m): 0.01m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [116/150], TRAIN: -loss:1528.51, av_diff: 0.00, time taken (m): 0.03m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [121/150], TRAIN: -loss:1445.19, av_diff: 0.00, time taken (m): 0.02m
epoch [121/150], TEST: -loss:2108.0980, time taken(m): 0.01m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [126/150], TRAIN: -loss:1414.61, av_diff: 0.00, time taken (m): 0.03m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [131/150], TRAIN: -loss:1382.09, av_diff: 0.00, time taken (m): 0.03m
epoch [131/150], TEST: -loss:2036.6605, time taken(m): 0.01m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [136/150], TRAIN: -loss:1325.84, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [141/150], TRAIN: -loss:1301.53, av_diff: 0.00, time taken (m): 0.03m
epoch [141/150], TEST: -loss:1965.8736, time taken(m): 0.01m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [146/150], TRAIN: -loss:1264.33, av_diff: 0.00, time taken (m): 0.02m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([3, 16206])
Shape of y output of model torch.Size([3, 16206]) and x = torch.Size([3, 16206])
data shape in one loop:  torch.Size([2, 16206])
Shape of y output of model torch.Size([2, 16206]) and x = torch.Size([2, 16206])
epoch [150/150], TRAIN: -loss:1257.23, av_diff: 0.00, time taken (m): 0.02m
epoch [150/150], TEST: -loss:2001.9417, time taken(m): 0.01m
Loop AE Train Ends at  13:56:07.848252
------------------------------ DA subdomain 8 at 2020-08-28 13:56:07.924398. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (16206,) and std (16206,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 16206) , test_X = (107, 16206), X = (537, 16206)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_8/X_80_1D_clustered.pickle
Shape read X:  (537, 16206)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (16206,) and std (16206,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
u_c before reduction of space:  [-1.07445013 -1.39747826 -1.43522087 -1.09659915 -1.96876959 -1.61903685
 -2.75738126 -1.9394162  -1.47525387 -1.19151468]
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
u_c taken from control states: [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
u_c before reduction of space:  [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
data[u_c] post encoding of state:  [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
Shape of w_0 =  (429,)
J_b = 0.0, J_o = 497798.6783390712
J_b = 0.49999999999999994, J_o = 16063088.096285501
J_b = 0.009537177757115557, J_o = 87594.15318236308
J_b = 0.010234428553257345, J_o = 69411.56247522209
J_b = 0.02200840567367399, J_o = 21803.50996612088
J_b = 0.026591793983623855, J_o = 16253.890192032834
J_b = 0.035513452619516994, J_o = 10586.070968611748
J_b = 0.043885313547816954, J_o = 8112.670085077781
J_b = 0.059853351220887016, J_o = 5901.005710031333
J_b = 0.06558626700544647, J_o = 4522.617115198577
J_b = 0.06879122466640254, J_o = 3793.181074783675
J_b = 0.07388483766978819, J_o = 3245.5056225373655
J_b = 0.08436801665217372, J_o = 2575.4992061551893
J_b = 0.09770021068997105, J_o = 2056.722408503918
J_b = 0.11085612231132057, J_o = 1714.1913912514078
J_b = 0.12037654995581953, J_o = 3175.6688922295757
J_b = 0.11179389357962961, J_o = 1691.2188826507006
J_b = 0.11391994650334457, J_o = 1581.9198417670239
J_b = 0.11646709303771156, J_o = 1468.9376312443198
J_b = 0.1213107572169381, J_o = 1352.3473613450312
J_b = 0.13491616783335847, J_o = 1374.1540413340813
J_b = 0.1272846767727122, J_o = 1275.46144480884
J_b = 0.1312115380276642, J_o = 1184.6326585109357
J_b = 0.13621783727125528, J_o = 1103.9887285234547
J_b = 0.139286594707805, J_o = 1060.0410607434758
J_b = 0.1478240216629306, J_o = 977.2833420055672
J_b = 0.1570970888880517, J_o = 952.1025319491919
J_b = 0.15327846758229174, J_o = 907.4817557562291
J_b = 0.1528129284548273, J_o = 893.6125666068383
J_b = 0.15232450899552363, J_o = 916.5667790687786
J_b = 0.15264732096493674, J_o = 886.9963271036646
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04025697 -1.27608345 -1.3077144  -1.05933011 -1.65202363 -1.44785507
 -2.05432394 -1.62481015 -1.31774762 -1.13914483]
W_opt:  [-0.02740864 -0.00473975  0.00640022  0.02319045  0.03348356  0.03043221
  0.00667732 -0.05091855 -0.13167882 -0.22695682]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.7980 s, v_trunc (Latent to Reduced) = 0.0838, dec (Reduced to Full) = 0.1888, add (DA)= 0.0001decode = 0.2756 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.0738 s, inc stats = 26.0668, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.59058452e-10 6.69536597e-10 7.99956401e-10 2.09955496e-10
 2.89497888e-09]
u_DA:    [-1.18103655e-09  7.66589241e-09  8.47821519e-09 -2.34144233e-09
  1.00431046e-08]
ref_MAE: [6.83736854e-09 9.82215903e-09 1.22599765e-08 8.33420675e-09
 1.75690108e-08]
da_MAE:  [1.34009500e-09 6.99635581e-09 7.67825879e-09 2.55139783e-09
 7.14812576e-09]
% 18.060425773993778 da_MAE 0.06463535150123799 ref_MAE 0.07888172731159229
u_c taken from control states: [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
u_c before reduction of space:  [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
data[u_c] post encoding of state:  [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
J_b = 0.0, J_o = 497896.81892732944
J_b = 0.49999999999999983, J_o = 16063281.521418046
J_b = 0.009536579738119907, J_o = 87720.41211967164
J_b = 0.010233907554566681, J_o = 69536.05052983847
J_b = 0.022008690234505763, J_o = 21921.693439175317
J_b = 0.026596965675431607, J_o = 16364.237757644625
J_b = 0.03554652971737666, J_o = 10676.959304576556
J_b = 0.043965271715792356, J_o = 8191.772941601026
J_b = 0.05999546676086991, J_o = 5977.412899455071
J_b = 0.06566800791394498, J_o = 4599.494142312593
J_b = 0.06884088188554294, J_o = 3871.5919939121586
J_b = 0.07392391126834155, J_o = 3324.5757862641567
J_b = 0.08441525728512408, J_o = 2653.7083402163535
J_b = 0.09768781026842742, J_o = 2138.6476160516995
J_b = 0.11056433682795412, J_o = 1799.5016066500918
J_b = 0.12009824750866226, J_o = 3257.357081729243
J_b = 0.11150259694748024, J_o = 1776.591894738037
J_b = 0.11373661713801672, J_o = 1666.928279640285
J_b = 0.11625818412356169, J_o = 1555.7595779118597
J_b = 0.12098896998920962, J_o = 1441.8265910161301
J_b = 0.13355434465591598, J_o = 1437.6451970326893
J_b = 0.12699779557063665, J_o = 1363.2528402372966
J_b = 0.13072683403265142, J_o = 1273.4878168760422
J_b = 0.13579934094686122, J_o = 1190.7986576852593
J_b = 0.1388727530230653, J_o = 1147.0009742979169
J_b = 0.14799664226026943, J_o = 1069.01114460393
J_b = 0.15573786400034814, J_o = 1025.323301394203
J_b = 0.15278336687728303, J_o = 995.3676010348531
J_b = 0.15230096902413276, J_o = 978.1483187016614
J_b = 0.152129672463469, J_o = 1003.5653227617883
J_b = 0.15223771515840817, J_o = 971.6615075726213
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04133682 -1.27831145 -1.30976758 -1.0600919  -1.65703607 -1.45109771
 -2.06855233 -1.62914745 -1.31833088 -1.14075503]
W_opt:  [-0.027187   -0.00479678  0.00610333  0.02287173  0.03355326  0.03060184
  0.00675343 -0.05082338 -0.13156336 -0.22703485]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.8203 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.1524, add (DA)= 0.0001decode = 0.2413 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.0617 s, inc stats = 7.0673, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.55941737e-10 6.62352071e-10 7.92173583e-10 2.07331885e-10
 2.86625852e-09]
u_DA:    [-1.18064087e-09  7.66808662e-09  8.48294542e-09 -2.33450641e-09
  1.00375023e-08]
ref_MAE: [6.84048526e-09 9.82934355e-09 1.22677594e-08 8.33683036e-09
 1.75977311e-08]
da_MAE:  [1.33658261e-09 7.00573455e-09 7.69077183e-09 2.54183830e-09
 7.17124376e-09]
% 17.851572918514893 da_MAE 0.06479733824313161 ref_MAE 0.07887836754178809
u_c taken from control states: [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
u_c before reduction of space:  [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
data[u_c] post encoding of state:  [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
J_b = 0.0, J_o = 498012.4472212023
J_b = 0.5000000000000001, J_o = 16063414.015119001
J_b = 0.00953554979004666, J_o = 87888.34676905008
J_b = 0.010233228021207057, J_o = 69695.43275999314
J_b = 0.02201204450162754, J_o = 22060.52527106203
J_b = 0.02660676978481881, J_o = 16492.830373684323
J_b = 0.035589228584053126, J_o = 10782.862340750416
J_b = 0.044056890981502825, J_o = 8285.71687647522
J_b = 0.06014063437264052, J_o = 6068.733548030608
J_b = 0.06575142075941914, J_o = 4691.583900103247
J_b = 0.06890041529504344, J_o = 3964.6985972610746
J_b = 0.0739743294992573, J_o = 3418.7008084345503
J_b = 0.08446697189210091, J_o = 2747.695339767152
J_b = 0.09765771368153037, J_o = 2237.333818417157
J_b = 0.1102115549254784, J_o = 1902.422977970829
J_b = 0.11978431396771154, J_o = 3358.9191477013255
J_b = 0.11115204582469028, J_o = 1879.564419795954
J_b = 0.11351029963294267, J_o = 1769.5970841395797
J_b = 0.11599150270471145, J_o = 1660.9336896794205
J_b = 0.12057336150825283, J_o = 1550.1224116080293
J_b = 0.13197955951501092, J_o = 1521.9660979433493
J_b = 0.13011452849760582, J_o = 1381.1071253171701
J_b = 0.13140457585444523, J_o = 1329.0830697999015
J_b = 0.1349667154564665, J_o = 1287.6968549152477
J_b = 0.13980227411267215, J_o = 1222.1486787876015
J_b = 0.15085862550385232, J_o = 1279.8918927586215
J_b = 0.14393402260738253, J_o = 1178.7143282046256
J_b = 0.15174241994440368, J_o = 1104.9023613055087
J_b = 0.15277583747018142, J_o = 1081.2206740756633
J_b = 0.1555799758106771, J_o = 1089.5327431201738
J_b = 0.15396277117099164, J_o = 1068.6660718365445
J_b = 0.15350588056359787, J_o = 1051.6637437646446
J_b = 0.15404647138644587, J_o = 1041.7508616525593
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04235405 -1.28059581 -1.31187059 -1.06078332 -1.66202414 -1.45433335
 -2.08299442 -1.63359356 -1.31960455 -1.14231669]
W_opt:  [-0.02755971 -0.00578822  0.00402528  0.02098189  0.03345923  0.03272083
  0.01088418 -0.0463825  -0.12924338 -0.2295666 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.9709 s, v_trunc (Latent to Reduced) = 0.0834, dec (Reduced to Full) = 0.1684, add (DA)= 0.0001decode = 0.2542 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.2252 s, inc stats = 7.2305, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.53005788e-10 6.54985772e-10 7.84201925e-10 2.04950663e-10
 2.83767774e-09]
u_DA:    [-1.20825488e-09  7.65792015e-09  8.52497475e-09 -2.37117227e-09
  9.98147049e-09]
ref_MAE: [6.84342121e-09 9.83670985e-09 1.22757310e-08 8.33921158e-09
 1.76263119e-08]
da_MAE:  [1.36126067e-09 7.00293437e-09 7.74077282e-09 2.57612293e-09
 7.14379275e-09]
% 17.61173703333737 da_MAE 0.06506745616382101 ref_MAE 0.07897660882855333
u_c taken from control states: [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
u_c before reduction of space:  [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
data[u_c] post encoding of state:  [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
J_b = 0.0, J_o = 498095.9526223198
J_b = 0.5, J_o = 16063751.279288545
J_b = 0.00953411932109738, J_o = 88038.42861084922
J_b = 0.010231969595681208, J_o = 69841.28463787881
J_b = 0.022014906263893675, J_o = 22189.08551153065
J_b = 0.026615522355016342, J_o = 16613.676485114825
J_b = 0.035616269661991745, J_o = 10891.58869498326
J_b = 0.0441087433001656, J_o = 8388.384416563675
J_b = 0.060217073970398695, J_o = 6171.776681976962
J_b = 0.06577818126743472, J_o = 4796.386931921265
J_b = 0.06889503675468617, J_o = 4072.0118245475724
J_b = 0.07394344151868192, J_o = 3528.336976429002
J_b = 0.0843836230263676, J_o = 2860.145098503225
J_b = 0.09745456296139245, J_o = 2354.3965632150157
J_b = 0.1097976228729851, J_o = 2023.0184765701342
J_b = 0.11932474453988899, J_o = 3471.904903692426
J_b = 0.11073297800026938, J_o = 2000.2919208969647
J_b = 0.11312763022986409, J_o = 1890.523284489313
J_b = 0.1155868496403812, J_o = 1783.1206762528836
J_b = 0.12008402905743343, J_o = 1674.262241175346
J_b = 0.1310446964905408, J_o = 1640.6787598461676
J_b = 0.12946183038093156, J_o = 1506.5840417416157
J_b = 0.13082608474115712, J_o = 1453.3827749184932
J_b = 0.13435717655185025, J_o = 1412.4836996283009
J_b = 0.13932171600284185, J_o = 1344.9085535619301
J_b = 0.1506976760831602, J_o = 1466.7493849430161
J_b = 0.14277187746075887, J_o = 1308.5443724062015
J_b = 0.15019133400204193, J_o = 1237.4710311289389
J_b = 0.15160028943018633, J_o = 1211.4994450166123
J_b = 0.1549721208772948, J_o = 1213.6089169845027
J_b = 0.15318446938141475, J_o = 1196.3178972103665
J_b = 0.15259168890096467, J_o = 1180.559636478664
J_b = 0.15284862348600212, J_o = 1171.2508863620476
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04330549 -1.28292664 -1.31403091 -1.06140937 -1.66698282 -1.45758002
 -2.09745439 -1.6381439  -1.32186581 -1.1438269 ]
W_opt:  [-0.02736341 -0.00556489  0.0043305   0.02103327  0.03359492  0.03253214
  0.01040963 -0.04680144 -0.12926393 -0.22911894]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.2310 s, v_trunc (Latent to Reduced) = 0.0915, dec (Reduced to Full) = 0.1562, add (DA)= 0.0001decode = 0.2500 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 7.4811 s, inc stats = 7.4936, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.50259704e-10 6.47469651e-10 7.76012997e-10 2.02794545e-10
 2.80926541e-09]
u_DA:    [-1.20589184e-09  7.65959329e-09  8.53382201e-09 -2.37048418e-09
  9.97817752e-09]
ref_MAE: [6.84616729e-09 9.84422597e-09 1.22839199e-08 8.34136770e-09
 1.76547243e-08]
da_MAE:  [1.35615154e-09 7.01212364e-09 7.75780901e-09 2.57327872e-09
 7.16891211e-09]
% 17.385655608428287 da_MAE 0.06539945716295097 ref_MAE 0.07916235085395533
u_c taken from control states: [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
u_c before reduction of space:  [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
data[u_c] post encoding of state:  [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
J_b = 0.0, J_o = 498226.99281357287
J_b = 0.4999999999999999, J_o = 16063817.4726885
J_b = 0.009534017255085223, J_o = 88176.40435121758
J_b = 0.010232050709235253, J_o = 69973.94633209213
J_b = 0.022030794402572277, J_o = 22269.797405219255
J_b = 0.026642731914481455, J_o = 16685.197130768745
J_b = 0.035641259692808604, J_o = 10967.505280048492
J_b = 0.04411907769008649, J_o = 8467.670122723714
J_b = 0.06021105481747319, J_o = 6257.316882802654
J_b = 0.06573607119850221, J_o = 4884.474814458633
J_b = 0.06880622284104161, J_o = 4164.1509063530675
J_b = 0.07381682696348249, J_o = 3623.3658367349517
J_b = 0.08413067801490992, J_o = 2962.1347796223586
J_b = 0.09702156956541749, J_o = 2461.1180451358423
J_b = 0.10928954446078411, J_o = 2132.3870807021576
J_b = 0.1186316369039606, J_o = 3562.406658527029
J_b = 0.11020805973288392, J_o = 2109.91080545073
J_b = 0.11250999124931532, J_o = 2001.1121297427667
J_b = 0.11497948463688552, J_o = 1892.8390808028362
J_b = 0.11949955420980571, J_o = 1783.8324985474221
J_b = 0.1309953472997764, J_o = 1766.7220555586575
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04418348 -1.28529425 -1.31624866 -1.06197533 -1.67190452 -1.46086821
 -2.11157291 -1.64277729 -1.32568996 -1.14528045]
W_opt:  [-0.01872264  0.00181821  0.01159078  0.02331446  0.02737684  0.01713671
 -0.01106785 -0.06471231 -0.13287657 -0.20817576]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5412 s, v_trunc (Latent to Reduced) = 0.0856, dec (Reduced to Full) = 0.1609, add (DA)= 0.0001decode = 0.2488 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7901 s, inc stats = 4.7997, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.47725615e-10 6.39834920e-10 7.67606400e-10 2.00845392e-10
 2.78106495e-09]
u_DA:    [-1.12751304e-09  7.72038088e-09  8.50461417e-09 -2.26047840e-09
  9.99927209e-09]
ref_MAE: [6.84870138e-09 9.85186070e-09 1.22923265e-08 8.34331685e-09
 1.76829247e-08]
da_MAE:  [1.27523865e-09 7.08054596e-09 7.73700777e-09 2.46132380e-09
 7.21820713e-09]
% 17.69614097445828 da_MAE 0.06533221391457286 ref_MAE 0.07937928389760926
u_c taken from control states: [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
u_c before reduction of space:  [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
data[u_c] post encoding of state:  [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
J_b = 0.0, J_o = 498367.981729844
J_b = 0.49999999999999994, J_o = 16063766.12024572
J_b = 0.009533877306779575, J_o = 88329.6274354257
J_b = 0.010232323339099925, J_o = 70115.67991852283
J_b = 0.022057305361397904, J_o = 22324.5522436851
J_b = 0.026686156294496912, J_o = 16726.829108479214
J_b = 0.035675667874968835, J_o = 11019.936679782875
J_b = 0.044119256196803854, J_o = 8528.200314597778
J_b = 0.060170583332955795, J_o = 6327.161702730455
J_b = 0.06566686357322504, J_o = 4957.1217486790565
J_b = 0.06868794137546759, J_o = 4240.959174859408
J_b = 0.07366310094541131, J_o = 3702.5693481984936
J_b = 0.08382900561151235, J_o = 3049.6432018661953
J_b = 0.09653359364378417, J_o = 2552.95145747703
J_b = 0.10878993243455631, J_o = 2226.1521191253323
J_b = 0.11791114650087135, J_o = 3632.9529255111624
J_b = 0.10969042132918448, J_o = 2203.8770530904635
J_b = 0.11185425030144366, J_o = 2096.185019237202
J_b = 0.114340886378119, J_o = 1986.2975653919398
J_b = 0.11891772182633731, J_o = 1875.6990948721423
J_b = 0.1314979449292984, J_o = 1894.307626691052
J_b = 0.12447938191390825, J_o = 1802.209212101262
J_b = 0.1282183524223729, J_o = 1715.1250133701412
J_b = 0.13308414437538654, J_o = 1635.0264901526461
J_b = 0.13630176402354757, J_o = 1588.828374063487
J_b = 0.14459581387335746, J_o = 1507.21841083792
J_b = 0.15367618096783725, J_o = 1481.1609226508635
J_b = 0.14985394838304747, J_o = 1438.5108781314468
J_b = 0.14930768462807975, J_o = 1424.6420603712481
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0449842  -1.28767208 -1.31852079 -1.06249331 -1.67678327 -1.46419749
 -2.12513574 -1.64745015 -1.33118031 -1.14665573]
W_opt:  [-0.02765946 -0.00503794  0.00640819  0.02284185  0.03433665  0.03092185
  0.00599865 -0.05188381 -0.13210193 -0.22669561]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.4228 s, v_trunc (Latent to Reduced) = 0.0859, dec (Reduced to Full) = 0.1661, add (DA)= 0.0001decode = 0.2543 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.6772 s, inc stats = 6.6827, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.45414566e-10 6.32167219e-10 7.58993678e-10 1.99061453e-10
 2.75311061e-09]
u_DA:    [-1.18898652e-09  7.65885099e-09  8.58398192e-09 -2.36021373e-09
  9.99698183e-09]
ref_MAE: [6.85101243e-09 9.85952840e-09 1.23009393e-08 8.34510079e-09
 1.77108791e-08]
da_MAE:  [1.33440109e-09 7.02668377e-09 7.82498824e-09 2.55927518e-09
 7.24387122e-09]
% 16.91912449110181 da_MAE 0.06608739403092144 ref_MAE 0.0795458565236753
u_c taken from control states: [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
u_c before reduction of space:  [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
data[u_c] post encoding of state:  [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
J_b = 0.0, J_o = 498506.7595142755
J_b = 0.49999999999999994, J_o = 16063619.306977462
J_b = 0.009534079556923607, J_o = 88465.57076936348
J_b = 0.01023295277733633, J_o = 70239.6183161572
J_b = 0.02208660691274349, J_o = 22354.24418944313
J_b = 0.026733210619077317, J_o = 16743.943691194047
J_b = 0.03570359461575649, J_o = 11055.128881623557
J_b = 0.04409655084158365, J_o = 8575.209043088422
J_b = 0.06009141024130488, J_o = 6385.258897024851
J_b = 0.06556797817195861, J_o = 5018.405396664758
J_b = 0.06853207120565913, J_o = 4307.254443021112
J_b = 0.0734670468363782, J_o = 3771.2068942581186
J_b = 0.08346418385677629, J_o = 3127.803487879935
J_b = 0.0959682264433999, J_o = 2635.4510319637466
J_b = 0.10825658251141743, J_o = 2310.416931308703
J_b = 0.11708889925691714, J_o = 3683.4983446134574
J_b = 0.10913607238974482, J_o = 2288.31105475746
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04571533 -1.29002839 -1.32083832 -1.06298787 -1.68161262 -1.46755892
 -2.13807335 -1.65212293 -1.33791026 -1.14793477]
W_opt:  [ 0.00912954  0.01812881  0.01668374  0.01416547  0.00493818 -0.01369316
 -0.04315729 -0.08731187 -0.13697729 -0.18696791]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7523 s, v_trunc (Latent to Reduced) = 0.0868, dec (Reduced to Full) = 0.1749, add (DA)= 0.0001decode = 0.2642 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0165 s, inc stats = 4.0297, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.43304370e-10 6.24568914e-10 7.50208833e-10 1.97358192e-10
 2.72543930e-09]
u_DA:    [-1.18548807e-09  7.63558308e-09  8.70180061e-09 -2.42377259e-09
  9.93294199e-09]
ref_MAE: [6.85312262e-09 9.86712671e-09 1.23097241e-08 8.34680405e-09
 1.77385504e-08]
da_MAE:  [1.32879244e-09 7.01101417e-09 7.95159177e-09 2.62113078e-09
 7.20750269e-09]
% 16.544465274288456 da_MAE 0.06646930968053867 ref_MAE 0.07964637683887532
u_c taken from control states: [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
u_c before reduction of space:  [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
data[u_c] post encoding of state:  [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
J_b = 0.0, J_o = 498659.430858052
J_b = 0.5, J_o = 16063525.080799498
J_b = 0.00953424493541926, J_o = 88616.27690416622
J_b = 0.010233523531833825, J_o = 70378.58515329086
J_b = 0.022120462562414227, J_o = 22385.432733060497
J_b = 0.026787780494284125, J_o = 16760.954060723307
J_b = 0.03573493127417754, J_o = 11093.739890618024
J_b = 0.04407283583299782, J_o = 8626.208977342318
J_b = 0.06001921046864394, J_o = 6448.3318820553495
J_b = 0.06547258043509575, J_o = 5084.327994337801
J_b = 0.06836487763892346, J_o = 4378.773405875267
J_b = 0.07326313132077536, J_o = 3843.828026771658
J_b = 0.08310003897038928, J_o = 3209.205485773369
J_b = 0.09543137991038733, J_o = 2720.018327052133
J_b = 0.10780635427689496, J_o = 2395.716354096517
J_b = 0.11633056069043313, J_o = 3727.0967509869542
J_b = 0.10866862735932803, J_o = 2373.5778315163957
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04637777 -1.29233693 -1.3231875  -1.06348161 -1.68638918 -1.4709528
 -2.15021535 -1.65675297 -1.34555983 -1.14910694]
W_opt:  [ 0.00934243  0.01831394  0.0168934   0.01417677  0.00471853 -0.01395379
 -0.04338762 -0.08750237 -0.137072   -0.18688985]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6738 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1523, add (DA)= 0.0001decode = 0.2408 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9147 s, inc stats = 3.9272, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.41392414e-10 6.17124672e-10 7.41304022e-10 1.95657765e-10
 2.69807043e-09]
u_DA:    [-1.18608330e-09  7.63367853e-09  8.70515578e-09 -2.43251330e-09
  9.93195020e-09]
ref_MAE: [6.85503458e-09 9.87457095e-09 1.23186289e-08 8.34850448e-09
 1.77659192e-08]
da_MAE:  [1.32747571e-09 7.01655386e-09 7.96385176e-09 2.62817107e-09
 7.23387977e-09]
% 16.469386503363427 da_MAE 0.06652636477192447 ref_MAE 0.07964309369594563
u_c taken from control states: [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
u_c before reduction of space:  [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
data[u_c] post encoding of state:  [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
J_b = 0.0, J_o = 498809.72716914513
J_b = 0.5000000000000001, J_o = 16063743.388879653
J_b = 0.009533701472746273, J_o = 88792.61332160956
J_b = 0.010233224918223758, J_o = 70546.85897016097
J_b = 0.022158577032099447, J_o = 22432.376060242845
J_b = 0.026851665091131998, J_o = 16790.35055859818
J_b = 0.03577314543774187, J_o = 11147.337328970101
J_b = 0.044057669525372385, J_o = 8690.56181233775
J_b = 0.05999020836307347, J_o = 6523.88059875112
J_b = 0.06542529456245738, J_o = 5160.231156559292
J_b = 0.06822808146928447, J_o = 4460.237232547746
J_b = 0.07310183496464455, J_o = 3923.76907008173
J_b = 0.08280507679652725, J_o = 3296.0316456903747
J_b = 0.0950160438308333, J_o = 2807.673058465728
J_b = 0.10758225627528549, J_o = 2482.039801588204
J_b = 0.11580111283728346, J_o = 3763.873275517821
J_b = 0.10843591116651209, J_o = 2459.492341738724
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04696925 -1.29457854 -1.32554524 -1.06399203 -1.69110796 -1.47437764
 -2.16134085 -1.66128677 -1.35377492 -1.150154  ]
W_opt:  [ 0.00957118  0.01854617  0.01712074  0.01420339  0.00445127 -0.01426001
 -0.04364393 -0.08773437 -0.13718507 -0.18679078]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6257 s, v_trunc (Latent to Reduced) = 0.0913, dec (Reduced to Full) = 0.1395, add (DA)= 0.0001decode = 0.2329 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8587 s, inc stats = 3.8709, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.39685243e-10 6.09896256e-10 7.32366769e-10 1.93899910e-10
 2.67103269e-09]
u_DA:    [-1.18846079e-09  7.63070128e-09  8.70885709e-09 -2.44294551e-09
  9.92872417e-09]
ref_MAE: [6.85674175e-09 9.88179937e-09 1.23275662e-08 8.35026233e-09
 1.77929570e-08]
da_MAE:  [1.32814604e-09 7.02080502e-09 7.97649032e-09 2.63684542e-09
 7.25769148e-09]
% 16.428353924081804 da_MAE 0.06643753720412947 ref_MAE 0.07949770086349173
u_c taken from control states: [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
u_c before reduction of space:  [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
data[u_c] post encoding of state:  [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
J_b = 0.0, J_o = 498926.3322833985
J_b = 0.4999999999999998, J_o = 16064422.147706907
J_b = 0.009531363019240213, J_o = 89014.16576486298
J_b = 0.010231110561242294, J_o = 70760.75147283712
J_b = 0.02219926811852126, J_o = 22511.43350956361
J_b = 0.02692262591587181, J_o = 16847.85494643642
J_b = 0.03582209573023555, J_o = 11227.285272835994
J_b = 0.04406009012475726, J_o = 8778.960487523738
J_b = 0.0600041546854199, J_o = 6622.215155850388
J_b = 0.06542392371687247, J_o = 5257.004120337443
J_b = 0.06813121505019182, J_o = 4561.938588789637
J_b = 0.07299449671960613, J_o = 4021.681032435984
J_b = 0.08260286844764224, J_o = 3398.3931809499945
J_b = 0.0947572748270283, J_o = 2908.4835862514465
J_b = 0.10758922232478157, J_o = 2579.708709997647
J_b = 0.11557118060278478, J_o = 3814.1327872361726
J_b = 0.10844596040665655, J_o = 2556.382363882891
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0474964  -1.29672695 -1.32789245 -1.06454649 -1.69576401 -1.47781695
 -2.1712865  -1.66568469 -1.36195738 -1.15106806]
W_opt:  [ 0.00984774  0.01876936  0.01729644  0.01417375  0.00416272 -0.01449172
 -0.04382225 -0.08785225 -0.13723229 -0.18671802]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6204 s, v_trunc (Latent to Reduced) = 0.0839, dec (Reduced to Full) = 0.1507, add (DA)= 0.0001decode = 0.2367 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8572 s, inc stats = 3.8697, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.38163792e-10 6.02968365e-10 7.23469436e-10 1.91990355e-10
 2.64435435e-09]
u_DA:    [-1.19258270e-09  7.62675724e-09  8.71206766e-09 -2.45512996e-09
  9.92387931e-09]
ref_MAE: [6.85826320e-09 9.88872726e-09 1.23364635e-08 8.35217189e-09
 1.78196353e-08]
da_MAE:  [1.33074649e-09 7.02378887e-09 7.98859822e-09 2.64712032e-09
 7.27952495e-09]
% 16.552272474517874 da_MAE 0.06613988306350863 ref_MAE 0.07925905836478499
u_c taken from control states: [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
u_c before reduction of space:  [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
data[u_c] post encoding of state:  [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
J_b = 0.0, J_o = 499042.5277949125
J_b = 0.5000000000000001, J_o = 16065323.918890364
J_b = 0.009528201047161977, J_o = 89271.59692518829
J_b = 0.010228172615964534, J_o = 71010.4006980398
J_b = 0.02224281915032789, J_o = 22614.540530718
J_b = 0.027000375936317614, J_o = 16925.408696143815
J_b = 0.03588667339531882, J_o = 11321.578345573686
J_b = 0.044096646843670984, J_o = 8876.43887899056
J_b = 0.06009482544996088, J_o = 6727.354712303002
J_b = 0.06549198332621047, J_o = 5358.288808839811
J_b = 0.06809458550719837, J_o = 4667.549344097254
J_b = 0.07296084523910126, J_o = 4121.286754001003
J_b = 0.08251964085333674, J_o = 3499.5970947872206
J_b = 0.09466618802444901, J_o = 3006.6489640453974
J_b = 0.10776697631854823, J_o = 2673.8722232468035
J_b = 0.11558060534889014, J_o = 3864.30205453557
J_b = 0.1086363694166772, J_o = 2649.500715278073
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04797741 -1.2987614  -1.33021122 -1.06517589 -1.70035316 -1.48124913
 -2.18013326 -1.6699295  -1.36958806 -1.15185208]
W_opt:  [ 0.00993376  0.01883661  0.0174625   0.01424973  0.00399861 -0.01467867
 -0.04399429 -0.08788554 -0.13717399 -0.18659603]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8738 s, v_trunc (Latent to Reduced) = 0.0917, dec (Reduced to Full) = 0.1847, add (DA)= 0.0001decode = 0.2786 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1525 s, inc stats = 4.1564, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.36775465e-10 5.96407949e-10 7.14679933e-10 1.89822694e-10
 2.61805933e-09]
u_DA:    [-1.19734387e-09  7.62189139e-09  8.71699716e-09 -2.46773318e-09
  9.91800783e-09]
ref_MAE: [6.85965153e-09 9.89528767e-09 1.23452530e-08 8.35433955e-09
 1.78459303e-08]
da_MAE:  [1.33411934e-09 7.02548344e-09 8.00231723e-09 2.65755588e-09
 7.29994849e-09]
% 16.71777637785698 da_MAE 0.06585937994826911 ref_MAE 0.07907975686033251
\% improve_point: 7.29, mse_ref_points: 1.0621773324976533e-05, mse_da_points: 9.847348651038759e-06, % improve_overlap: 16.42, mse_ref_overlap: 0.16551, mse_da_overlap: 0.13833
DA - - L2: 855.49, L1: 2105.32, % Improve: 17.11%, DA_MAE: 0.07, mse_ref: 0.17, mse_DA: 0.160, time(s): 7.7183s,
u_c taken from control states: [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
u_c before reduction of space:  [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
data[u_c] post encoding of state:  [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
J_b = 0.0, J_o = 499211.38859527267
J_b = 0.4999999999999998, J_o = 16066000.09324831
J_b = 0.009524770762867065, J_o = 89602.75418482805
J_b = 0.010225469481617405, J_o = 71321.18233660913
J_b = 0.022294155903657995, J_o = 22747.61908237691
J_b = 0.027090213844993258, J_o = 17027.00374398084
J_b = 0.035978385051933084, J_o = 11429.864475673256
J_b = 0.044179206940620566, J_o = 8983.335808962645
J_b = 0.06024820845402699, J_o = 6840.60587140937
J_b = 0.06560513326044969, J_o = 5467.45967954867
J_b = 0.06810334253665687, J_o = 4780.432201631768
J_b = 0.0729836859687254, J_o = 4226.730858737983
J_b = 0.08254228081606316, J_o = 3603.7303346018393
J_b = 0.09472884063473659, J_o = 3106.9662498378
J_b = 0.1080525131319214, J_o = 2768.9816090997215
J_b = 0.11586885180484288, J_o = 3938.738979229545
J_b = 0.10894574501328827, J_o = 2743.510650674012
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0484269  -1.30067324 -1.33247964 -1.06590581 -1.70487344 -1.48466659
 -2.18784944 -1.67400232 -1.37654258 -1.15252928]
W_opt:  [ 0.01009616  0.01888683  0.01755142  0.01437698  0.00397745 -0.01481499
 -0.04412121 -0.087895   -0.13716509 -0.18661629]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6064 s, v_trunc (Latent to Reduced) = 0.0838, dec (Reduced to Full) = 0.1722, add (DA)= 0.0001decode = 0.2585 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8649 s, inc stats = 3.8696, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.35478150e-10 5.90242914e-10 7.06081240e-10 1.87308876e-10
 2.59215896e-09]
u_DA:    [-1.20396438e-09  7.61591709e-09  8.72299263e-09 -2.47806439e-09
  9.91200793e-09]
ref_MAE: [6.86094884e-09 9.90145271e-09 1.23538517e-08 8.35685337e-09
 1.78718307e-08]
da_MAE:  [1.33944253e-09 7.02567418e-09 8.01691139e-09 2.66537327e-09
 7.31984898e-09]
% 16.964841081531937 da_MAE 0.06570368227868172 ref_MAE 0.07912754444559555
u_c taken from control states: [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
u_c before reduction of space:  [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
data[u_c] post encoding of state:  [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
J_b = 0.0, J_o = 499341.65095564333
J_b = 0.5, J_o = 16066921.326960385
J_b = 0.009519705551824693, J_o = 89971.55123071157
J_b = 0.01022132660679003, J_o = 71664.9667039031
J_b = 0.022345038114743653, J_o = 22906.896909829193
J_b = 0.027181547479147524, J_o = 17151.116527306294
J_b = 0.03608445717906164, J_o = 11551.697495616063
J_b = 0.04429344445774343, J_o = 9099.627985779582
J_b = 0.06044811486135219, J_o = 6961.635538223261
J_b = 0.06575366338908785, J_o = 5584.031614537196
J_b = 0.06815048693453131, J_o = 4900.4261916419755
J_b = 0.07304427866364152, J_o = 4339.507696012432
J_b = 0.08261593852522926, J_o = 3714.534058695257
J_b = 0.0948355381486726, J_o = 3214.7670474861316
J_b = 0.10831306197992763, J_o = 2871.368656228775
J_b = 0.11626645046285752, J_o = 4040.6102881455163
J_b = 0.10923673762927189, J_o = 2844.884303850697
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04886065 -1.3024575  -1.33467661 -1.06676095 -1.7093248  -1.48804063
 -2.19454006 -1.6778767  -1.38256325 -1.15310335]
W_opt:  [ 0.01042464  0.0193247   0.01764059  0.01421581  0.00363482 -0.01522531
 -0.04435876 -0.08792664 -0.13713491 -0.18658594]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7051 s, v_trunc (Latent to Reduced) = 0.0869, dec (Reduced to Full) = 0.1524, add (DA)= 0.0001decode = 0.2415 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9466 s, inc stats = 3.9611, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.34226233e-10 5.84489302e-10 6.97753412e-10 1.84363782e-10
 2.56665341e-09]
u_DA:    [-1.21153313e-09  7.60945017e-09  8.72995648e-09 -2.48658916e-09
  9.90687961e-09]
ref_MAE: [6.86220076e-09 9.90720632e-09 1.23621795e-08 8.35979846e-09
 1.78973362e-08]
da_MAE:  [1.34575937e-09 7.02496087e-09 8.03220307e-09 2.67095294e-09
 7.34022620e-09]
% 17.48621465301977 da_MAE 0.06547732884306245 ref_MAE 0.0793531996716943
u_c taken from control states: [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
u_c before reduction of space:  [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
data[u_c] post encoding of state:  [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
J_b = 0.0, J_o = 499414.2242642751
J_b = 0.5, J_o = 16068111.253057156
J_b = 0.009513799279187366, J_o = 90317.12279993927
J_b = 0.010216162846460257, J_o = 71990.43010317952
J_b = 0.022387002295736563, J_o = 23073.78473937772
J_b = 0.027261249119126016, J_o = 17283.386256075337
J_b = 0.03619191165979575, J_o = 11671.980302635595
J_b = 0.04442917412999665, J_o = 9210.324537527198
J_b = 0.06067246155921816, J_o = 7077.115055274552
J_b = 0.06589896584480932, J_o = 5695.752381030351
J_b = 0.06821179232961111, J_o = 5014.0547840495
J_b = 0.07313423137871092, J_o = 4445.3563921810955
J_b = 0.08277500422870242, J_o = 3815.221709860886
J_b = 0.09506934810312584, J_o = 3312.8798683192954
J_b = 0.10856097132988442, J_o = 2964.4853935562187
J_b = 0.11677956099802979, J_o = 4159.603287291873
J_b = 0.10951421117927562, J_o = 2937.384193896647
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04929823 -1.30411681 -1.33678577 -1.06772481 -1.71370833 -1.49133959
 -2.20047831 -1.68154876 -1.38726937 -1.15359075]
W_opt:  [ 0.01087029  0.01976097  0.0178109   0.0140852   0.00325116 -0.01564305
 -0.04462326 -0.08803214 -0.13711196 -0.18641049]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7319 s, v_trunc (Latent to Reduced) = 0.0859, dec (Reduced to Full) = 0.1713, add (DA)= 0.0001decode = 0.2592 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9912 s, inc stats = 4.0045, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.32963287e-10 5.79138594e-10 6.89758411e-10 1.81044255e-10
 2.54153660e-09]
u_DA:    [-1.21967510e-09  7.60206144e-09  8.73479967e-09 -2.48957307e-09
  9.90179090e-09]
ref_MAE: [6.86346371e-09 9.91255703e-09 1.23701745e-08 8.36311799e-09
 1.79224531e-08]
da_MAE:  [1.35263839e-09 7.02292285e-09 8.04504126e-09 2.67061733e-09
 7.36025430e-09]
% 18.19658847062034 da_MAE 0.06523724304850159 ref_MAE 0.07974880488336561
u_c taken from control states: [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
u_c before reduction of space:  [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
data[u_c] post encoding of state:  [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
J_b = 0.0, J_o = 499556.00503306254
J_b = 0.5000000000000001, J_o = 16069032.729703039
J_b = 0.009509003421216886, J_o = 90683.91748781114
J_b = 0.010212173350604923, J_o = 72335.5054659071
J_b = 0.0224302742381775, J_o = 23258.488398846515
J_b = 0.02734281270495392, J_o = 17431.887664135
J_b = 0.03631091958068473, J_o = 11801.691587048466
J_b = 0.044592437664964485, J_o = 9326.76337739251
J_b = 0.060936558260808404, J_o = 7198.910187864874
J_b = 0.06605375418849585, J_o = 5814.529207052987
J_b = 0.06827445075153014, J_o = 5135.466901638287
J_b = 0.0732189783035623, J_o = 4559.4565636157095
J_b = 0.08294627023949065, J_o = 3922.6707349600274
J_b = 0.09532890885764801, J_o = 3418.2056520931837
J_b = 0.10875059153548812, J_o = 3065.7746188396186
J_b = 0.11723661891802935, J_o = 4288.867446543494
J_b = 0.10973047171694204, J_o = 3038.20169587382
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.04975646 -1.3056658  -1.3387995  -1.06876495 -1.71802936 -1.4945437
 -2.20592054 -1.68503745 -1.39050716 -1.15401744]
W_opt:  [ 0.01154797  0.02018573  0.01791259  0.01389345  0.00282345 -0.01610866
 -0.04494246 -0.08818075 -0.13708456 -0.18616857]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6155 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1575, add (DA)= 0.0002decode = 0.2438 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8594 s, inc stats = 3.8708, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.31640723e-10 5.74143625e-10 6.82125159e-10 1.77462030e-10
 2.51677784e-09]
u_DA:    [-1.22724110e-09  7.59480207e-09  8.74073279e-09 -2.48908123e-09
  9.89793851e-09]
ref_MAE: [6.86478627e-09 9.91755200e-09 1.23778078e-08 8.36670021e-09
 1.79472118e-08]
da_MAE:  [1.35888182e-09 7.02065844e-09 8.05860763e-09 2.66654326e-09
 7.38116067e-09]
% 18.84051770944278 da_MAE 0.06517307152001721 ref_MAE 0.0803024732054014
u_c taken from control states: [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
u_c before reduction of space:  [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
data[u_c] post encoding of state:  [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
J_b = 0.0, J_o = 499732.1216023612
J_b = 0.5000000000000001, J_o = 16069403.33760836
J_b = 0.009506638866178344, J_o = 90975.95682439001
J_b = 0.010210534884706378, J_o = 72607.81491379892
J_b = 0.022471632934482334, J_o = 23385.5791980432
J_b = 0.027417881195691517, J_o = 17527.412212620293
J_b = 0.036419803292695084, J_o = 11880.363654694329
J_b = 0.04474109786188487, J_o = 9394.19281146529
J_b = 0.06115908604213597, J_o = 7274.593640037691
J_b = 0.06614972686139768, J_o = 5889.5873810744415
J_b = 0.06828067947109194, J_o = 5214.060926507211
J_b = 0.07323353609102753, J_o = 4632.754164923896
J_b = 0.08302853527781746, J_o = 3990.1869580875878
J_b = 0.09548002496086158, J_o = 3484.6861908188403
J_b = 0.10876887925971966, J_o = 3130.5067668912425
J_b = 0.11741337812224022, J_o = 4367.690212493495
J_b = 0.10976522932696149, J_o = 3102.6471053700716
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05024569 -1.3071297  -1.34070896 -1.06984641 -1.72229346 -1.49763929
 -2.21112943 -1.6883695  -1.39223261 -1.1544037 ]
W_opt:  [ 0.01206158  0.02041098  0.01794797  0.01377411  0.00248856 -0.01654926
 -0.04528191 -0.08831376 -0.13698607 -0.18580498]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6383 s, v_trunc (Latent to Reduced) = 0.0839, dec (Reduced to Full) = 0.1583, add (DA)= 0.0001decode = 0.2445 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8829 s, inc stats = 3.8909, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.30228709e-10 5.69423050e-10 6.74887187e-10 1.73737500e-10
 2.49234533e-09]
u_DA:    [-1.23280464e-09  7.58834764e-09  8.74840472e-09 -2.48682728e-09
  9.89820080e-09]
ref_MAE: [6.86619828e-09 9.92227257e-09 1.23850458e-08 8.37042474e-09
 1.79716443e-08]
da_MAE:  [1.36303334e-09 7.01892459e-09 8.07351753e-09 2.66056478e-09
 7.40585547e-09]
% 19.380592741000633 da_MAE 0.06515816958594149 ref_MAE 0.08082194077241622
u_c taken from control states: [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
u_c before reduction of space:  [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
data[u_c] post encoding of state:  [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
J_b = 0.0, J_o = 499909.49592280795
J_b = 0.49999999999999994, J_o = 16069419.525682067
J_b = 0.009506539666115577, J_o = 91162.64015403559
J_b = 0.010210803734110098, J_o = 72783.85600093316
J_b = 0.02250473180669351, J_o = 23453.683117223576
J_b = 0.027477156550709588, J_o = 17572.250551528796
J_b = 0.03649914439047446, J_o = 11916.662665701115
J_b = 0.04484333339197235, J_o = 9423.931066812027
J_b = 0.06130357349199638, J_o = 7314.093670650993
J_b = 0.06618171277665792, J_o = 5929.914488053464
J_b = 0.06822958842833093, J_o = 5258.804848329213
J_b = 0.07317242893753267, J_o = 4674.648055412055
J_b = 0.08299904396712485, J_o = 4027.9672041705226
J_b = 0.09551668049259626, J_o = 3520.466536387621
J_b = 0.10876053646272757, J_o = 3165.5708701625877
J_b = 0.11739243488479603, J_o = 4389.388336733055
J_b = 0.10976475201982984, J_o = 3137.4179846771212
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05076986 -1.30854187 -1.34250671 -1.07093283 -1.72650763 -1.50061612
 -2.21636789 -1.69158061 -1.39246637 -1.15477308]
W_opt:  [ 0.01203302  0.02035905  0.01801838  0.01388619  0.00241512 -0.0167522
 -0.04546616 -0.08840993 -0.1369662  -0.1856354 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6857 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.1394, add (DA)= 0.0001decode = 0.2278 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9136 s, inc stats = 3.9190, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.28715834e-10 5.64869274e-10 6.68072611e-10 1.69995865e-10
 2.46819887e-09]
u_DA:    [-1.23562528e-09  7.58352215e-09  8.75614443e-09 -2.48412254e-09
  9.90270755e-09]
ref_MAE: [6.86771116e-09 9.92682635e-09 1.23918603e-08 8.37416638e-09
 1.79957908e-08]
da_MAE:  [1.36434112e-09 7.01865288e-09 8.08807182e-09 2.65411841e-09
 7.43450868e-09]
% 19.746769935262908 da_MAE 0.06519421716109806 ref_MAE 0.08123563015284055
u_c taken from control states: [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
u_c before reduction of space:  [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
data[u_c] post encoding of state:  [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
J_b = 0.0, J_o = 500085.2027283798
J_b = 0.5000000000000001, J_o = 16069022.576841772
J_b = 0.009508455528880726, J_o = 91255.32262647132
J_b = 0.010212886007532517, J_o = 72871.34808291864
J_b = 0.02252653114686982, J_o = 23477.409749220416
J_b = 0.027514083147065285, J_o = 17583.51131668234
J_b = 0.036542990543056694, J_o = 11926.045836661866
J_b = 0.04489778605154296, J_o = 9430.095203830639
J_b = 0.06137676597604669, J_o = 7328.941591036314
J_b = 0.06616977922792716, J_o = 5945.936380045097
J_b = 0.06815793095476873, J_o = 5278.315155217631
J_b = 0.0730892185506263, J_o = 4692.807513309503
J_b = 0.08293098062913233, J_o = 4043.0516363249717
J_b = 0.09551336807285062, J_o = 3532.965740555623
J_b = 0.10876838615036641, J_o = 3178.7283112340856
J_b = 0.11723054173145962, J_o = 4367.975627195154
J_b = 0.10976885704934419, J_o = 3150.4184485246333
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0513296  -1.30993716 -1.34419543 -1.07198633 -1.73067827 -1.50347421
 -2.22183043 -1.69471769 -1.39139483 -1.15515569]
W_opt:  [ 0.01202922  0.0202157   0.01797878  0.01395169  0.00238283 -0.01680238
 -0.04549183 -0.08845711 -0.13700402 -0.1856376 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8972 s, v_trunc (Latent to Reduced) = 0.0827, dec (Reduced to Full) = 0.1524, add (DA)= 0.0001decode = 0.2376 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1348 s, inc stats = 4.1472, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.27100270e-10 5.60369945e-10 6.61671363e-10 1.66367653e-10
 2.44430185e-09]
u_DA:    [-1.23467979e-09  7.57945203e-09  8.76360579e-09 -2.48068291e-09
  9.91062340e-09]
ref_MAE: [6.86932672e-09 9.93132568e-09 1.23982616e-08 8.37779459e-09
 1.80196878e-08]
da_MAE:  [1.36178006e-09 7.01908208e-09 8.10193443e-09 2.64705056e-09
 7.46632155e-09]
% 19.999118068656934 da_MAE 0.06521530255092503 ref_MAE 0.08151822952013572
u_c taken from control states: [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
u_c before reduction of space:  [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
data[u_c] post encoding of state:  [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
J_b = 0.0, J_o = 500279.30015117634
J_b = 0.49999999999999994, J_o = 16068352.958627954
J_b = 0.009510633880775176, J_o = 91360.6065271385
J_b = 0.010215526652300369, J_o = 72964.36791142425
J_b = 0.02254668215270653, J_o = 23508.760548395236
J_b = 0.02754630819894578, J_o = 17603.90673499184
J_b = 0.0365832805459441, J_o = 11942.81222086685
J_b = 0.0449461045616763, J_o = 9444.744885851205
J_b = 0.06142319215626495, J_o = 7351.293857675968
J_b = 0.06614239738256213, J_o = 5970.221634813035
J_b = 0.06809234477976711, J_o = 5304.767731508183
J_b = 0.07302030716165318, J_o = 4718.035066869222
J_b = 0.08289533754429872, J_o = 4064.2553564032187
J_b = 0.09556844473587553, J_o = 3551.2500613529955
J_b = 0.10881569839615914, J_o = 3198.2894925135383
J_b = 0.11707975320165837, J_o = 4353.181177739671
J_b = 0.10980663580260837, J_o = 3169.9853896108298
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05191447 -1.3113496  -1.34577801 -1.07296789 -1.73480862 -1.5062321
 -2.22743374 -1.6978169  -1.38967225 -1.15556964]
W_opt:  [ 0.01212274  0.02005961  0.01789733  0.01392681  0.00232836 -0.01680054
 -0.0455127  -0.08855269 -0.13711519 -0.18568419]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7129 s, v_trunc (Latent to Reduced) = 0.0857, dec (Reduced to Full) = 0.1682, add (DA)= 0.0001decode = 0.2560 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9690 s, inc stats = 3.9743, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.25412209e-10 5.55815314e-10 6.55672412e-10 1.62987152e-10
 2.42063571e-09]
u_DA:    [-1.23396964e-09  7.57514741e-09  8.77024157e-09 -2.47613150e-09
  9.91733229e-09]
ref_MAE: [6.87101478e-09 9.93588031e-09 1.24042605e-08 8.38117509e-09
 1.80433540e-08]
da_MAE:  [1.35938185e-09 7.01933210e-09 8.11456916e-09 2.63911865e-09
 7.49669659e-09]
% 20.08071854380012 da_MAE 0.06530938628349697 ref_MAE 0.08171918602557766
u_c taken from control states: [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
u_c before reduction of space:  [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
data[u_c] post encoding of state:  [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
J_b = 0.0, J_o = 500393.7023001054
J_b = 0.5000000000000002, J_o = 16067951.791548908
J_b = 0.009511258941665119, J_o = 91456.55815450227
J_b = 0.010216662419424491, J_o = 73047.41875577159
J_b = 0.022557920671140163, J_o = 23551.343146972682
J_b = 0.027565301912360885, J_o = 17637.690947920528
J_b = 0.03661633839026748, J_o = 11967.11095904431
J_b = 0.045000727167682726, J_o = 9463.311507854585
J_b = 0.0614956057547586, J_o = 7373.451181713623
J_b = 0.06615501885462455, J_o = 5992.453100014596
J_b = 0.06808956439758343, J_o = 5326.600462071248
J_b = 0.07303752376407209, J_o = 4736.877268960543
J_b = 0.08300548918297966, J_o = 4075.6106924468704
J_b = 0.09584075848798126, J_o = 3557.999142827544
J_b = 0.10909370020218025, J_o = 3205.3595003122127
J_b = 0.11720380525524231, J_o = 4336.390210866466
J_b = 0.11007508605154596, J_o = 3177.1420305640313
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05250694 -1.31279731 -1.34726201 -1.07384449 -1.73890022 -1.50888512
 -2.23320293 -1.70089304 -1.38759986 -1.15600559]
W_opt:  [ 0.01225397  0.0198599   0.01782169  0.01396782  0.00242178 -0.01677757
 -0.04551961 -0.08864316 -0.1372391  -0.1857647 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6795 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1567, add (DA)= 0.0001decode = 0.2450 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9246 s, inc stats = 3.9301, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.23702220e-10 5.51146947e-10 6.50047190e-10 1.59968170e-10
 2.39719159e-09]
u_DA:    [-1.23433573e-09  7.56996135e-09  8.77599575e-09 -2.46891969e-09
  9.92268807e-09]
ref_MAE: [6.87272477e-09 9.94054868e-09 1.24098858e-08 8.38419407e-09
 1.80667981e-08]
da_MAE:  [1.35803795e-09 7.01881440e-09 8.12594856e-09 2.62888786e-09
 7.52549648e-09]
% 20.096579475520734 da_MAE 0.06534203251153303 ref_MAE 0.0817762644986078
u_c taken from control states: [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
u_c before reduction of space:  [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
data[u_c] post encoding of state:  [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
J_b = 0.0, J_o = 500480.1703745613
J_b = 0.4999999999999999, J_o = 16067581.170362294
J_b = 0.009511444863561284, J_o = 91545.51734949515
J_b = 0.01021740820044421, J_o = 73122.72212187853
J_b = 0.022561526365424016, J_o = 23607.314663437406
J_b = 0.027571417171125736, J_o = 17688.437778651816
J_b = 0.03663890800112227, J_o = 12004.802798338362
J_b = 0.045055676645102, J_o = 9492.12411724426
J_b = 0.06159004396173937, J_o = 7401.818304904822
J_b = 0.06620415394230447, J_o = 6019.3183594670445
J_b = 0.06813581116204125, J_o = 5351.7462691001565
J_b = 0.0731121332856571, J_o = 4758.515690736256
J_b = 0.0832055838010053, J_o = 4087.535813061541
J_b = 0.0962583141663956, J_o = 3563.3534240237313
J_b = 0.10957657446628112, J_o = 3210.578026510644
J_b = 0.11748784610811537, J_o = 4314.544836856068
J_b = 0.11054380213163728, J_o = 3182.497701959118
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05309784 -1.31428921 -1.3486629  -1.07459872 -1.74295275 -1.51142502
 -2.23931813 -1.70397151 -1.38513521 -1.15645869]
W_opt:  [ 0.01237553  0.01958482  0.01767469  0.01399519  0.00258651 -0.0167131
 -0.04543675 -0.0886369  -0.13725513 -0.18582174]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5949 s, v_trunc (Latent to Reduced) = 0.0835, dec (Reduced to Full) = 0.1535, add (DA)= 0.0001decode = 0.2394 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8343 s, inc stats = 3.8477, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.21996737e-10 5.46336076e-10 6.44736978e-10 1.57370604e-10
 2.37397129e-09]
u_DA:    [-1.23466603e-09  7.56423058e-09  8.78139023e-09 -2.46077509e-09
  9.92762104e-09]
ref_MAE: [6.87443026e-09 9.94535955e-09 1.24151960e-08 8.38679164e-09
 1.80900184e-08]
da_MAE:  [1.35666277e-09 7.01789450e-09 8.13665325e-09 2.61814570e-09
 7.55364975e-09]
% 20.03737473521745 da_MAE 0.06525398831338339 ref_MAE 0.08160561024266771
\% improve_point: 7.38, mse_ref_points: 1.0557733016337815e-05, mse_da_points: 9.777706998213393e-06, % improve_overlap: 14.32, mse_ref_overlap: 0.16421, mse_da_overlap: 0.14066
DA - - L2: 1081.27, L1: 2416.36, % Improve: 18.05%, DA_MAE: 0.07, mse_ref: 0.17, mse_DA: 0.158, time(s): 5.9219s,
u_c taken from control states: [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
u_c before reduction of space:  [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
data[u_c] post encoding of state:  [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
J_b = 0.0, J_o = 500544.7760987389
J_b = 0.49999999999999994, J_o = 16067325.9151857
J_b = 0.009511095363791345, J_o = 91636.41341285952
J_b = 0.010217608342002131, J_o = 73200.45580325574
J_b = 0.022560419223769074, J_o = 23679.099187033793
J_b = 0.027569042716957835, J_o = 17758.37642514039
J_b = 0.0366503681711037, J_o = 12062.466493704114
J_b = 0.04510012903278438, J_o = 9540.367345867906
J_b = 0.061685903347907516, J_o = 7446.280772951883
J_b = 0.06628228759354178, J_o = 6060.393180010586
J_b = 0.06822560205879341, J_o = 5389.775381524831
J_b = 0.07323615359646872, J_o = 4793.149759350588
J_b = 0.08344638578534386, J_o = 4113.479171053781
J_b = 0.09668727381421802, J_o = 3583.3128059771684
J_b = 0.11008208544556843, J_o = 3231.0536549763124
J_b = 0.11777224298109347, J_o = 4307.441133925714
J_b = 0.11103174637963643, J_o = 3203.1618564419823
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05367751 -1.31583049 -1.34999216 -1.07522336 -1.74696645 -1.51387365
 -2.2456642  -1.70708313 -1.38277896 -1.15695228]
W_opt:  [ 0.01245527  0.01945404  0.01763607  0.014036    0.00271442 -0.01665005
 -0.04544574 -0.08872454 -0.13741155 -0.18599814]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5888 s, v_trunc (Latent to Reduced) = 0.0834, dec (Reduced to Full) = 0.1570, add (DA)= 0.0001decode = 0.2425 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8314 s, inc stats = 3.8393, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.20323665e-10 5.41365981e-10 6.39698272e-10 1.55219341e-10
 2.35097350e-09]
u_DA:    [-1.23308746e-09  7.55914715e-09  8.78613582e-09 -2.45277420e-09
  9.93317832e-09]
ref_MAE: [6.87610333e-09 9.95032964e-09 1.24202347e-08 8.38894290e-09
 1.81130162e-08]
da_MAE:  [1.35341112e-09 7.01778117e-09 8.14643755e-09 2.60799354e-09
 7.58220482e-09]
% 19.87383107198697 da_MAE 0.06517728204478636 ref_MAE 0.08134331507019005
u_c taken from control states: [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
u_c before reduction of space:  [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
data[u_c] post encoding of state:  [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
J_b = 0.0, J_o = 500585.60316136375
J_b = 0.49999999999999983, J_o = 16067195.996403864
J_b = 0.009509630317292211, J_o = 91756.70568103364
J_b = 0.010216895864764913, J_o = 73302.60752528143
J_b = 0.022560260936938317, J_o = 23767.32029288987
J_b = 0.027566892240916862, J_o = 17845.785695802253
J_b = 0.036655936455049415, J_o = 12141.675163292308
J_b = 0.04512691196289646, J_o = 9612.861123765295
J_b = 0.061753082954471836, J_o = 7513.396718197599
J_b = 0.06636367244233887, J_o = 6123.287643726485
J_b = 0.06833155002872605, J_o = 5448.797705589672
J_b = 0.07337862022567117, J_o = 4849.219397189298
J_b = 0.08367018306303839, J_o = 4163.9285084303
J_b = 0.09702791258185543, J_o = 3629.5107542058704
J_b = 0.11050613819235754, J_o = 3278.1808209419905
J_b = 0.11801701043451512, J_o = 4333.534222421469
J_b = 0.11144087451034196, J_o = 3250.443260941335
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05423136 -1.31741599 -1.35126123 -1.07571881 -1.7509388  -1.516247
 -2.25205225 -1.71024238 -1.38106202 -1.15749016]
W_opt:  [ 0.01259631  0.01946547  0.01748068  0.01394478  0.00274016 -0.01659098
 -0.04544611 -0.08876716 -0.13756937 -0.18617163]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6879 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1420, add (DA)= 0.0001decode = 0.2302 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9182 s, inc stats = 3.9305, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.18725127e-10 5.36253265e-10 6.34887738e-10 1.53513023e-10
 2.32821264e-09]
u_DA:    [-1.23158183e-09  7.55437317e-09  8.78953934e-09 -2.44483488e-09
  9.93874789e-09]
ref_MAE: [6.87770187e-09 9.95544236e-09 1.24250452e-08 8.39064922e-09
 1.81357770e-08]
da_MAE:  [1.35030695e-09 7.01811990e-09 8.15465160e-09 2.59834791e-09
 7.61053526e-09]
% 19.788474640584933 da_MAE 0.06509672057207107 ref_MAE 0.08115631797348702
u_c taken from control states: [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
u_c before reduction of space:  [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
data[u_c] post encoding of state:  [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
J_b = 0.0, J_o = 500618.26853399817
J_b = 0.5000000000000001, J_o = 16067230.643293057
J_b = 0.009507689628025154, J_o = 91888.63678953119
J_b = 0.01021566051221188, J_o = 73417.28896448448
J_b = 0.022564544258692705, J_o = 23854.15035183505
J_b = 0.027572406408562615, J_o = 17930.19222790493
J_b = 0.03666399670898683, J_o = 12222.45310536272
J_b = 0.04514810826341617, J_o = 9688.394143388721
J_b = 0.061820721577828835, J_o = 7583.460046224431
J_b = 0.06646095872346976, J_o = 6187.96365974016
J_b = 0.06844268495664523, J_o = 5510.5933890328115
J_b = 0.07351359584056974, J_o = 4909.007827801431
J_b = 0.08382841663155136, J_o = 4221.965674644377
J_b = 0.09721593049019246, J_o = 3685.1218478373944
J_b = 0.11079008770435464, J_o = 3335.6264548713607
J_b = 0.11809219657747458, J_o = 4363.13081470122
J_b = 0.11171088403241546, J_o = 3307.8799029029256
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05474557 -1.31902463 -1.35248482 -1.07608942 -1.75486516 -1.51854546
 -2.2584112  -1.71345201 -1.38012932 -1.15804984]
W_opt:  [ 0.01243561  0.0194946   0.0173907   0.01393016  0.00287066 -0.01645596
 -0.0454623  -0.0888672  -0.13774678 -0.18634847]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6356 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1491, add (DA)= 0.0001decode = 0.2350 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8707 s, inc stats = 3.8764, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.17241019e-10 5.31065943e-10 6.30249576e-10 1.52236650e-10
 2.30571533e-09]
u_DA:    [-1.23000257e-09  7.55120871e-09  8.79247065e-09 -2.43901321e-09
  9.94264263e-09]
ref_MAE: [6.87918597e-09 9.96062968e-09 1.24296834e-08 8.39192559e-09
 1.81582743e-08]
da_MAE:  [1.34724359e-09 7.02014277e-09 8.16222108e-09 2.59124986e-09
 7.63692730e-09]
% 19.517079772531766 da_MAE 0.0652544038073198 ref_MAE 0.08107857371836384
u_c taken from control states: [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
u_c before reduction of space:  [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
data[u_c] post encoding of state:  [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
J_b = 0.0, J_o = 500668.0428991936
J_b = 0.49999999999999994, J_o = 16067297.732017606
J_b = 0.00950599188213324, J_o = 92024.83640381055
J_b = 0.010214585832959634, J_o = 73537.84929696887
J_b = 0.022575207515593877, J_o = 23929.93055494002
J_b = 0.027587954431896832, J_o = 18002.187186842453
J_b = 0.036673754970809325, J_o = 12298.011037285325
J_b = 0.04515609808352898, J_o = 9762.229393267224
J_b = 0.0618646075380478, J_o = 7653.768194680377
J_b = 0.06654539771105637, J_o = 6252.528100537937
J_b = 0.06853302736265525, J_o = 5572.933501656351
J_b = 0.07362375654078801, J_o = 4969.3129830357875
J_b = 0.08392627949246481, J_o = 4282.946642169637
J_b = 0.0972981932208937, J_o = 3744.4038303263555
J_b = 0.11099793151575803, J_o = 3396.8758618132865
J_b = 0.11809024443406707, J_o = 4391.774505023114
J_b = 0.11190970229700806, J_o = 3368.8610758095083
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05520838 -1.3206297  -1.35367617 -1.07635204 -1.75874114 -1.52078035
 -2.26458006 -1.71671571 -1.38022571 -1.15862043]
W_opt:  [ 0.01189708  0.01938291  0.01732136  0.01390748  0.00302547 -0.01622907
 -0.0453031  -0.08882285 -0.13779853 -0.18647773]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6838 s, v_trunc (Latent to Reduced) = 0.0911, dec (Reduced to Full) = 0.1492, add (DA)= 0.0001decode = 0.2423 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9263 s, inc stats = 3.9392, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.15905242e-10 5.25890154e-10 6.25733649e-10 1.51332210e-10
 2.28350666e-09]
u_DA:    [-1.22868824e-09  7.54881615e-09  8.79641823e-09 -2.43555962e-09
  9.94637754e-09]
ref_MAE: [6.88052175e-09 9.96580547e-09 1.24341993e-08 8.39283003e-09
 1.81804830e-08]
da_MAE:  [1.34459348e-09 7.02292600e-09 8.17068458e-09 2.58689183e-09
 7.66287088e-09]
% 19.17672221219285 da_MAE 0.06553807490204336 ref_MAE 0.08108811804701431
u_c taken from control states: [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
u_c before reduction of space:  [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
data[u_c] post encoding of state:  [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
J_b = 0.0, J_o = 500842.16941870074
J_b = 0.5, J_o = 16066802.587983897
J_b = 0.009506047737337438, J_o = 92213.67398084543
J_b = 0.010215637798178303, J_o = 73701.01621946535
J_b = 0.02260258977455939, J_o = 23999.21692513472
J_b = 0.027627000792459472, J_o = 18062.622501719194
J_b = 0.03670594396657714, J_o = 12364.923626551914
J_b = 0.045176097931383975, J_o = 9830.403915279123
J_b = 0.06189939486851428, J_o = 7721.930642459461
J_b = 0.06661053489294771, J_o = 6316.142874679397
J_b = 0.06859496332043338, J_o = 5635.136354933753
J_b = 0.07370211995397868, J_o = 5029.544441553147
J_b = 0.08396379727110659, J_o = 4345.927576000134
J_b = 0.09727602779314456, J_o = 3807.190989235978
J_b = 0.11106706248578788, J_o = 3461.564564926326
J_b = 0.11801053493862519, J_o = 4428.432788953689
J_b = 0.11197707700525857, J_o = 3433.1333470259015
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05561039 -1.32219647 -1.35484804 -1.07653293 -1.76256146 -1.52296561
 -2.27031252 -1.72003051 -1.38168361 -1.15919326]
W_opt:  [ 0.01154068  0.01933284  0.01729432  0.01384592  0.00313035 -0.01608235
 -0.04523458 -0.08885272 -0.13784646 -0.18654818]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7718 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1695, add (DA)= 0.0001decode = 0.2577 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0296 s, inc stats = 4.0337, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.14744936e-10 5.20837858e-10 6.21291542e-10 1.50709221e-10
 2.26161690e-09]
u_DA:    [-1.22819898e-09  7.54602957e-09  8.80339111e-09 -2.43388538e-09
  9.94973404e-09]
ref_MAE: [6.88168206e-09 9.97085776e-09 1.24386414e-08 8.39345302e-09
 1.82023728e-08]
da_MAE:  [1.34294391e-09 7.02519171e-09 8.18209957e-09 2.58459460e-09
 7.68811714e-09]
% 18.80155529800233 da_MAE 0.06593668898081867 ref_MAE 0.08120437432368267
u_c taken from control states: [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
u_c before reduction of space:  [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
data[u_c] post encoding of state:  [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
J_b = 0.0, J_o = 501070.00381920085
J_b = 0.5, J_o = 16066056.441259747
J_b = 0.009506943304433703, J_o = 92421.25265664709
J_b = 0.010217679844901403, J_o = 73878.7418169957
J_b = 0.022639243548246975, J_o = 24055.92197425246
J_b = 0.02767992252601906, J_o = 18106.85562383218
J_b = 0.03675312653424541, J_o = 12416.376102345006
J_b = 0.04520632221223605, J_o = 9884.96234530496
J_b = 0.06192221592344661, J_o = 7781.024322543886
J_b = 0.06663299165678055, J_o = 6373.232143509972
J_b = 0.06859871891152601, J_o = 5692.366675183208
J_b = 0.07371425082220932, J_o = 5085.145359665986
J_b = 0.08391981185652013, J_o = 4405.257719547942
J_b = 0.09714222433364691, J_o = 3867.9530179030803
J_b = 0.11095525683775971, J_o = 3523.998747307858
J_b = 0.11782876997730744, J_o = 4469.820223752947
J_b = 0.11187060806985585, J_o = 3495.1321606200395
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05595151 -1.32368371 -1.35601844 -1.07665535 -1.76632187 -1.52509403
 -2.27561111 -1.72338816 -1.38424263 -1.15974687]
W_opt:  [ 0.01152681  0.01929063  0.01719975  0.01371514  0.00309706 -0.01607381
 -0.04521344 -0.08881129 -0.13773798 -0.1863916 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7958 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.1743, add (DA)= 0.0001decode = 0.2631 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0589 s, inc stats = 4.0718, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.13760382e-10 5.16041998e-10 6.16855025e-10 1.50287603e-10
 2.24007040e-09]
u_DA:    [-1.22868136e-09  7.54214665e-09  8.81338930e-09 -2.43204609e-09
  9.95253931e-09]
ref_MAE: [6.88266661e-09 9.97565362e-09 1.24430779e-08 8.39387464e-09
 1.82239193e-08]
da_MAE:  [1.34244174e-09 7.02610465e-09 8.19653427e-09 2.58233369e-09
 7.71246891e-09]
% 18.465054765439792 da_MAE 0.06638506964800168 ref_MAE 0.08141916261429345
u_c taken from control states: [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
u_c before reduction of space:  [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
data[u_c] post encoding of state:  [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
J_b = 0.0, J_o = 501347.7775337309
J_b = 0.5, J_o = 16065173.401444886
J_b = 0.009508459192345301, J_o = 92651.94111632588
J_b = 0.010220396821497314, J_o = 74077.9175972519
J_b = 0.022682037844350196, J_o = 24116.422982763215
J_b = 0.02774299747246058, J_o = 18151.360877614694
J_b = 0.03681441471352035, J_o = 12466.322518022993
J_b = 0.04525523897222778, J_o = 9936.92273452732
J_b = 0.06196836680111578, J_o = 7839.490450985486
J_b = 0.06665608476466013, J_o = 6430.309854779348
J_b = 0.06858691049290591, J_o = 5750.827511826985
J_b = 0.07370268927459542, J_o = 5142.179446016511
J_b = 0.08384371997373813, J_o = 4466.262092825087
J_b = 0.09697081173417446, J_o = 3930.549592998269
J_b = 0.1108083696672403, J_o = 3587.4120439266158
J_b = 0.11767159738998396, J_o = 4515.597818963222
J_b = 0.11173732737931047, J_o = 3557.9643810457287
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0562412  -1.32505599 -1.35720499 -1.07673794 -1.77002047 -1.52716091
 -2.28058703 -1.72679211 -1.38740523 -1.16027072]
W_opt:  [ 0.01156755  0.01936412  0.01711598  0.01355281  0.00294594 -0.01613712
 -0.04521702 -0.08874246 -0.13754312 -0.18613115]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6577 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1790, add (DA)= 0.0001decode = 0.2671 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9249 s, inc stats = 3.9382, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.12924285e-10 5.11616873e-10 6.12357296e-10 1.50003159e-10
 2.21887809e-09]
u_DA:    [-1.23107674e-09  7.53786164e-09  8.82500293e-09 -2.43176527e-09
  9.95624348e-09]
ref_MAE: [6.88350271e-09 9.98007875e-09 1.24475756e-08 8.39415908e-09
 1.82451116e-08]
da_MAE:  [1.34400102e-09 7.02624477e-09 8.21264563e-09 2.58176843e-09
 7.73736539e-09]
% 18.22435176153611 da_MAE 0.0668427254035326 ref_MAE 0.08173915688031506
u_c taken from control states: [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
u_c before reduction of space:  [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
data[u_c] post encoding of state:  [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
J_b = 0.0, J_o = 501682.41168536217
J_b = 0.49999999999999994, J_o = 16064332.63501348
J_b = 0.009509950500004197, J_o = 92941.13864605504
J_b = 0.010223139068606007, J_o = 74334.08775879855
J_b = 0.0227305460447822, J_o = 24215.497672893733
J_b = 0.027816581510500402, J_o = 18229.46428206927
J_b = 0.03689770375923311, J_o = 12542.929145931086
J_b = 0.045344286519914116, J_o = 10010.844727882453
J_b = 0.062086004474406944, J_o = 7919.482813470257
J_b = 0.06673217328070088, J_o = 6507.239013619101
J_b = 0.0686222769268499, J_o = 5828.637763777074
J_b = 0.07374680052999742, J_o = 5217.3110879997475
J_b = 0.0838526323643341, J_o = 4543.4061918985035
J_b = 0.09691750585893792, J_o = 4008.513227932993
J_b = 0.11078448360509535, J_o = 3664.3987104970365
J_b = 0.11774359608529258, J_o = 4586.603518089534
J_b = 0.11173706887082781, J_o = 3634.30560526949
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05648518 -1.3262915  -1.35841939 -1.0767971  -1.77365682 -1.52917553
 -2.28517019 -1.73025007 -1.39106159 -1.16076404]
W_opt:  [ 0.01170407  0.01957807  0.01716571  0.01348038  0.00280399 -0.01622913
 -0.04523198 -0.08872669 -0.13746071 -0.18608015]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8366 s, v_trunc (Latent to Reduced) = 0.0857, dec (Reduced to Full) = 0.1686, add (DA)= 0.0001decode = 0.2563 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0930 s, inc stats = 4.1054, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.12220091e-10 5.07632790e-10 6.07753997e-10 1.49799423e-10
 2.19804247e-09]
u_DA:    [-1.23451739e-09  7.53253296e-09  8.83877427e-09 -2.43114780e-09
  9.96008631e-09]
ref_MAE: [6.88420690e-09 9.98406283e-09 1.24521789e-08 8.39436282e-09
 1.82659472e-08]
da_MAE:  [1.34673748e-09 7.02490017e-09 8.23102027e-09 2.58094722e-09
 7.76204384e-09]
% 18.073481603514328 da_MAE 0.06735027855980354 ref_MAE 0.08220815418258101
u_c taken from control states: [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
u_c before reduction of space:  [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
data[u_c] post encoding of state:  [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
J_b = 0.0, J_o = 501999.49290539185
J_b = 0.5000000000000001, J_o = 16063553.106988044
J_b = 0.009511136735328848, J_o = 93226.33016212219
J_b = 0.010225579499719339, J_o = 74586.15986425927
J_b = 0.02277974501345311, J_o = 24307.168514199544
J_b = 0.027892169550590068, J_o = 18298.84836282275
J_b = 0.036984653118181915, J_o = 12609.912247126253
J_b = 0.04543835334669592, J_o = 10074.910984883818
J_b = 0.06220560645101797, J_o = 7990.984576697743
J_b = 0.06679544210131176, J_o = 6576.712877025535
J_b = 0.06863380353156778, J_o = 5900.196819736938
J_b = 0.07375722402628036, J_o = 5286.716656841708
J_b = 0.08381904704557339, J_o = 4615.265754696942
J_b = 0.09680678012852721, J_o = 4081.856236834544
J_b = 0.11068932576289893, J_o = 3736.2307209191413
J_b = 0.11779423299912536, J_o = 4655.661919768531
J_b = 0.11167161355691348, J_o = 3705.437000123689
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05668707 -1.32738161 -1.35967187 -1.07684578 -1.77723022 -1.53113592
 -2.28935732 -1.73374194 -1.39501227 -1.16120956]
W_opt:  [ 0.01189764  0.01987829  0.01727944  0.01339661  0.00261317 -0.01635024
 -0.04529988 -0.08872878 -0.13738759 -0.18602709]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6644 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1750, add (DA)= 0.0001decode = 0.2637 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9282 s, inc stats = 3.9418, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.11637400e-10 5.04117536e-10 6.03006327e-10 1.49631762e-10
 2.17756750e-09]
u_DA:    [-1.23864343e-09  7.52765365e-09  8.85211497e-09 -2.43056317e-09
  9.96203710e-09]
ref_MAE: [6.88478959e-09 9.98757809e-09 1.24569266e-08 8.39453048e-09
 1.82864222e-08]
da_MAE:  [1.35028083e-09 7.02353611e-09 8.24910864e-09 2.58019493e-09
 7.78446960e-09]
% 18.002852734643714 da_MAE 0.06787411021278539 ref_MAE 0.08277618487522935
u_c taken from control states: [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
u_c before reduction of space:  [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
data[u_c] post encoding of state:  [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
J_b = 0.0, J_o = 502303.92822409293
J_b = 0.5000000000000001, J_o = 16062803.247691073
J_b = 0.009512324770745055, J_o = 93497.67826407331
J_b = 0.010227956113268443, J_o = 74826.09086299672
J_b = 0.022827113961366215, J_o = 24392.827542047144
J_b = 0.027965551138712703, J_o = 18362.022891690678
J_b = 0.03707436954510093, J_o = 12667.017138509045
J_b = 0.045545284363056424, J_o = 10126.604244860384
J_b = 0.0623504755896249, J_o = 8050.187019035462
J_b = 0.06686646682164359, J_o = 6634.240736671176
J_b = 0.06864339136732425, J_o = 5960.794253447875
J_b = 0.07375535674989324, J_o = 5345.8501023493845
J_b = 0.08377564962649114, J_o = 4676.26855348967
J_b = 0.09669780220819471, J_o = 4144.002518445201
J_b = 0.1106059946585646, J_o = 3796.45793594394
J_b = 0.11786553942017565, J_o = 4712.680160884012
J_b = 0.11162023738166828, J_o = 3764.9210298267276
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05685714 -1.32832727 -1.36097463 -1.0769025  -1.78074244 -1.53302543
 -2.29340342 -1.73725768 -1.39861989 -1.16159606]
W_opt:  [ 0.01217948  0.02005105  0.01729618  0.01334251  0.00255391 -0.01639318
 -0.04531233 -0.08871489 -0.13735797 -0.18599555]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6294 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1432, add (DA)= 0.0001decode = 0.2289 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8584 s, inc stats = 3.8707, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.11146534e-10 5.01068104e-10 5.98068109e-10 1.49436433e-10
 2.15744314e-09]
u_DA:    [-1.24237310e-09  7.52342015e-09  8.86426182e-09 -2.42891602e-09
  9.96533007e-09]
ref_MAE: [6.88528046e-09 9.99062752e-09 1.24618648e-08 8.39472581e-09
 1.83065465e-08]
da_MAE:  [1.35351963e-09 7.02235205e-09 8.26619371e-09 2.57835245e-09
 7.80788693e-09]
% 18.04673434534422 da_MAE 0.06832933655435192 ref_MAE 0.0833759777704113
\% improve_point: 7.62, mse_ref_points: 1.0631501349576348e-05, mse_da_points: 9.82129503158181e-06, % improve_overlap: 14.39, mse_ref_overlap: 0.16526, mse_da_overlap: 0.14146
DA - - L2: 1315.02, L1: 2667.97, % Improve: 18.29%, DA_MAE: 0.07, mse_ref: 0.17, mse_DA: 0.159, time(s): 5.2886s,
u_c taken from control states: [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
u_c before reduction of space:  [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
data[u_c] post encoding of state:  [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
J_b = 0.0, J_o = 502594.99282146513
J_b = 0.49999999999999994, J_o = 16062079.315684117
J_b = 0.00951375776946807, J_o = 93742.0963953149
J_b = 0.010230414269504174, J_o = 75043.37074144978
J_b = 0.022869177777975227, J_o = 24473.919770713772
J_b = 0.02803186458657707, J_o = 18421.27863515837
J_b = 0.03716276175898448, J_o = 12715.668320776193
J_b = 0.04566171707259129, J_o = 10167.303527221295
J_b = 0.06251498723366594, J_o = 8097.95261827616
J_b = 0.0669443039353708, J_o = 6680.452164567833
J_b = 0.06865946477841413, J_o = 6010.273110329253
J_b = 0.07375491960989115, J_o = 5394.536389932131
J_b = 0.08374478125020876, J_o = 4725.671431155133
J_b = 0.09662785811153607, J_o = 4193.8299445388775
J_b = 0.11056058820326232, J_o = 3844.7707527149946
J_b = 0.1179283266555383, J_o = 4754.085016741397
J_b = 0.11160146019492552, J_o = 3812.5781080171782
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05700694 -1.32914916 -1.36233276 -1.07698397 -1.78419697 -1.5348386
 -2.29751939 -1.7408024  -1.40150369 -1.1619355 ]
W_opt:  [ 0.0122348   0.02010651  0.01725623  0.01336009  0.00259562 -0.01637254
 -0.04529295 -0.08866782 -0.13730961 -0.18595113]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7430 s, v_trunc (Latent to Reduced) = 0.0867, dec (Reduced to Full) = 0.1514, add (DA)= 0.0001decode = 0.2404 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9835 s, inc stats = 3.9971, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.10714157e-10 4.98417793e-10 5.92919989e-10 1.49155827e-10
 2.13764929e-09]
u_DA:    [-1.24574700e-09  7.51900790e-09  8.87612173e-09 -2.42737726e-09
  9.96766609e-09]
ref_MAE: [6.88571284e-09 9.99327783e-09 1.24670130e-08 8.39500642e-09
 1.83263404e-08]
da_MAE:  [1.35646116e-09 7.02059011e-09 8.28320174e-09 2.57653309e-09
 7.83001680e-09]
% 18.087141561840035 da_MAE 0.06878931198273129 ref_MAE 0.08397864913316841
u_c taken from control states: [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
u_c before reduction of space:  [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
data[u_c] post encoding of state:  [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
J_b = 0.0, J_o = 502895.4200798108
J_b = 0.49999999999999983, J_o = 16061234.184101041
J_b = 0.009515473124297435, J_o = 93984.86941745313
J_b = 0.010233226522817667, J_o = 75257.35027608054
J_b = 0.02290981908627492, J_o = 24555.867327352393
J_b = 0.02809531198254616, J_o = 18481.99137140151
J_b = 0.03725089155921308, J_o = 12763.522090409717
J_b = 0.04578136555831185, J_o = 10206.514152030655
J_b = 0.0626814404935241, J_o = 8143.731553153508
J_b = 0.06702215421002822, J_o = 6724.981761846333
J_b = 0.06868050544015533, J_o = 6057.888632299666
J_b = 0.07375849755364496, J_o = 5441.719122496703
J_b = 0.0837284413001101, J_o = 4772.612520066097
J_b = 0.0966024788378769, J_o = 4240.140638853306
J_b = 0.11058529597794019, J_o = 3889.6327418678125
J_b = 0.11802421090610832, J_o = 4789.178013888721
J_b = 0.1116492078811804, J_o = 3856.8106831478835
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05714193 -1.32988888 -1.36374493 -1.07709754 -1.78759804 -1.53658062
 -2.3017501  -1.74438325 -1.40373769 -1.16225137]
W_opt:  [ 0.01214665  0.02012497  0.01718076  0.01339845  0.00269026 -0.01630731
 -0.04527164 -0.08863502 -0.13727559 -0.18596942]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6976 s, v_trunc (Latent to Reduced) = 0.0867, dec (Reduced to Full) = 0.1444, add (DA)= 0.0001decode = 0.2332 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9309 s, inc stats = 3.9361, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.10324570e-10 4.96032474e-10 5.87566990e-10 1.48764690e-10
 2.11816178e-09]
u_DA:    [-1.24802884e-09  7.51366346e-09  8.88697395e-09 -2.42494842e-09
  9.96875555e-09]
ref_MAE: [6.88610242e-09 9.99566315e-09 1.24723660e-08 8.39539755e-09
 1.83458279e-08]
da_MAE:  [1.35835341e-09 7.01763099e-09 8.29940696e-09 2.57371310e-09
 7.85059377e-09]
% 18.124611497565308 da_MAE 0.06927810840769603 ref_MAE 0.08461408205181944
u_c taken from control states: [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
u_c before reduction of space:  [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
data[u_c] post encoding of state:  [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
J_b = 0.0, J_o = 503179.67716028163
J_b = 0.5000000000000002, J_o = 16060445.486387465
J_b = 0.009516649268878373, J_o = 94237.15736162665
J_b = 0.01023556793450829, J_o = 75479.57894689865
J_b = 0.0229441399004043, J_o = 24661.8434278715
J_b = 0.028149479069852653, J_o = 18567.353265397425
J_b = 0.03733924792388276, J_o = 12828.080769417573
J_b = 0.04591922251819553, J_o = 10257.783758658368
J_b = 0.06289004733411328, J_o = 8198.424248219342
J_b = 0.06713954779092658, J_o = 6777.312463967506
J_b = 0.06875122601533547, J_o = 6112.141603130818
J_b = 0.07381843226111362, J_o = 5495.313537625639
J_b = 0.08380279223081669, J_o = 4823.438987313281
J_b = 0.09672230928619154, J_o = 4288.644608151628
J_b = 0.11078194091714777, J_o = 3936.7414554976854
J_b = 0.11824038590957622, J_o = 4825.5234052715505
J_b = 0.11186065899166349, J_o = 3903.4412106260493
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05727222 -1.33059588 -1.36520998 -1.07724594 -1.79095118 -1.53824078
 -2.30634206 -1.74800385 -1.40506485 -1.16255491]
W_opt:  [ 0.01195541  0.02007276  0.017168    0.01352883  0.00289291 -0.01615495
 -0.045215   -0.08862882 -0.13732005 -0.18609648]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6815 s, v_trunc (Latent to Reduced) = 0.0859, dec (Reduced to Full) = 0.1648, add (DA)= 0.0001decode = 0.2535 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9351 s, inc stats = 3.9398, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.09948503e-10 4.93752631e-10 5.82013591e-10 1.48253604e-10
 2.09894886e-09]
u_DA:    [-1.24694091e-09  7.50769358e-09  8.89685284e-09 -2.41979349e-09
  9.97237161e-09]
ref_MAE: [6.88647849e-09 9.99794299e-09 1.24779194e-08 8.39590864e-09
 1.83650408e-08]
da_MAE:  [1.35688941e-09 7.01394095e-09 8.31483925e-09 2.56804709e-09
 7.87342275e-09]
% 18.13761724141401 da_MAE 0.06977754273557135 ref_MAE 0.08523761510991794
u_c taken from control states: [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
u_c before reduction of space:  [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
data[u_c] post encoding of state:  [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
J_b = 0.0, J_o = 503446.6475612027
J_b = 0.4999999999999998, J_o = 16059588.345666576
J_b = 0.009517821289067644, J_o = 94473.72058543857
J_b = 0.010237938223799849, J_o = 75685.85405911358
J_b = 0.0229686859006241, J_o = 24780.288714033108
J_b = 0.028187688560125518, J_o = 18668.976732295836
J_b = 0.03741441777781005, J_o = 12904.988439451521
J_b = 0.046050485919866525, J_o = 10319.69935186717
J_b = 0.06309886408454708, J_o = 8259.669023243785
J_b = 0.06727609898477767, J_o = 6835.642375434153
J_b = 0.06886083573786239, J_o = 6170.928729257004
J_b = 0.07392303461133826, J_o = 5553.87410217574
J_b = 0.08394009082460584, J_o = 4877.916504374249
J_b = 0.09694581817444342, J_o = 4339.2702619711545
J_b = 0.11111667273104307, J_o = 3986.847423605775
J_b = 0.11850302686520932, J_o = 4860.704642464353
J_b = 0.11219770110043015, J_o = 3953.2335220177774
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05740562 -1.331324   -1.36672161 -1.07742442 -1.79426195 -1.53981432
 -2.31158267 -1.75167089 -1.40530504 -1.16285632]
W_opt:  [ 0.01169954  0.0198816   0.01709944  0.01361568  0.00311644 -0.01597963
 -0.0451498  -0.08863863 -0.13744455 -0.18632597]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7973 s, v_trunc (Latent to Reduced) = 0.1310, dec (Reduced to Full) = 0.1671, add (DA)= 0.0001decode = 0.3004 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0977 s, inc stats = 4.1099, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.09563501e-10 4.91404697e-10 5.76283580e-10 1.47638952e-10
 2.07997878e-09]
u_DA:    [-1.24605460e-09  7.50187401e-09  8.90598523e-09 -2.41490131e-09
  9.97406079e-09]
ref_MAE: [6.88686349e-09 1.00002909e-08 1.24836494e-08 8.39652329e-09
 1.83840109e-08]
da_MAE:  [1.35561810e-09 7.01046932e-09 8.32970165e-09 2.56254026e-09
 7.89408201e-09]
% 18.1538388105468 da_MAE 0.07023271777960181 ref_MAE 0.08581064372344942
u_c taken from control states: [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
u_c before reduction of space:  [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
data[u_c] post encoding of state:  [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
J_b = 0.0, J_o = 503622.3527487743
J_b = 0.5000000000000002, J_o = 16059010.464987628
J_b = 0.009517627437976187, J_o = 94679.15395905101
J_b = 0.0102388686125695, J_o = 75863.65967797232
J_b = 0.022978419191794407, J_o = 24911.127592261913
J_b = 0.02820319258529977, J_o = 18788.192089257187
J_b = 0.037468989713179975, J_o = 12995.707166323617
J_b = 0.046166241175321275, J_o = 10394.54504635763
J_b = 0.06328467673885331, J_o = 8331.581031608333
J_b = 0.06739157977114774, J_o = 6906.159524180125
J_b = 0.06896341390036163, J_o = 6241.352703242503
J_b = 0.0740196558094147, J_o = 5625.166026104442
J_b = 0.08407611931163478, J_o = 4944.829654149162
J_b = 0.09716787737904471, J_o = 4402.728977370549
J_b = 0.11142196186035432, J_o = 4050.5455689342507
J_b = 0.11872250467072648, J_o = 4917.218888541273
J_b = 0.11249432210558692, J_o = 4017.002879228146
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05754269 -1.33212379 -1.3682668  -1.0776211  -1.79753648 -1.54131463
 -2.31746437 -1.75539428 -1.40479029 -1.16318345]
W_opt:  [ 0.01158805  0.01966362  0.01691853  0.01358391  0.00326258 -0.01584731
 -0.0450612  -0.08860031 -0.13747958 -0.18648335]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6114 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1658, add (DA)= 0.0001decode = 0.2516 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8631 s, inc stats = 3.8698, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.09167886e-10 4.88825632e-10 5.70426386e-10 1.46961570e-10
 2.06121629e-09]
u_DA:    [-1.24574425e-09  7.49652380e-09  8.91332458e-09 -2.40885301e-09
  9.97359290e-09]
ref_MAE: [6.88725911e-09 1.00028700e-08 1.24895066e-08 8.39720067e-09
 1.84027734e-08]
da_MAE:  [1.35491214e-09 7.00769817e-09 8.34289820e-09 2.55581458e-09
 7.91237661e-09]
% 18.104597800995503 da_MAE 0.0708073610101547 ref_MAE 0.0864607280859235
u_c taken from control states: [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
u_c before reduction of space:  [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
data[u_c] post encoding of state:  [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
J_b = 0.0, J_o = 503580.82040205627
J_b = 0.5, J_o = 16059380.672900815
J_b = 0.009513852419587588, J_o = 94819.89863865507
J_b = 0.010235801179500986, J_o = 75988.49192466115
J_b = 0.022960619268149993, J_o = 25065.209330261016
J_b = 0.02817940697105492, J_o = 18938.389158711594
J_b = 0.03749049334131635, J_o = 13109.766683928474
J_b = 0.04626350544754522, J_o = 10489.82657307573
J_b = 0.0634498619176826, J_o = 8421.345906182058
J_b = 0.06747565975366379, J_o = 6996.538126512061
J_b = 0.06905284277799367, J_o = 6330.6343706781245
J_b = 0.0741064236702057, J_o = 5716.282020237002
J_b = 0.08423344831709903, J_o = 5029.615265554405
J_b = 0.09743845730811666, J_o = 4483.970737491913
J_b = 0.11173322936689681, J_o = 4132.469515612613
J_b = 0.11895824565784203, J_o = 5008.73315018761
J_b = 0.11278134522373794, J_o = 4099.658939146961
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05768692 -1.33303541 -1.36983668 -1.07782457 -1.8007809  -1.54273979
 -2.3241637  -1.75917847 -1.40350174 -1.16354882]
W_opt:  [ 0.01147438  0.01939424  0.0167741   0.01353155  0.00332544 -0.0157795
 -0.04496778 -0.08845016 -0.13730525 -0.18637043]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6740 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1523, add (DA)= 0.0001decode = 0.2402 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9142 s, inc stats = 3.9279, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.08751588e-10 4.85885982e-10 5.64475598e-10 1.46260814e-10
 2.04262631e-09]
u_DA:    [-1.24467077e-09  7.49060736e-09  8.91892331e-09 -2.39940860e-09
  9.97180741e-09]
ref_MAE: [6.88767541e-09 1.00058096e-08 1.24954573e-08 8.39790143e-09
 1.84213633e-08]
da_MAE:  [1.35342235e-09 7.00472138e-09 8.35444771e-09 2.54566942e-09
 7.92918110e-09]
% 17.901874291644685 da_MAE 0.07169136268353427 ref_MAE 0.08732399438473182
u_c taken from control states: [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
u_c before reduction of space:  [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
data[u_c] post encoding of state:  [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
J_b = 0.0, J_o = 503466.43787121354
J_b = 0.5, J_o = 16060143.404994238
J_b = 0.009507061749060363, J_o = 95029.78911783127
J_b = 0.010230071213408009, J_o = 76175.27976797415
J_b = 0.02292090880683825, J_o = 25331.58147689625
J_b = 0.02812321281282381, J_o = 19203.029694512385
J_b = 0.037512752900032253, J_o = 13310.561158045219
J_b = 0.04642174634654679, J_o = 10656.398729315304
J_b = 0.06375944282009721, J_o = 8569.842262027962
J_b = 0.06770502494272833, J_o = 7142.451743278371
J_b = 0.0693195593511405, J_o = 6471.57088325593
J_b = 0.07439243916240575, J_o = 5858.429518197861
J_b = 0.08468001135037835, J_o = 5159.830869140744
J_b = 0.09807749870302895, J_o = 4609.031242215804
J_b = 0.11238182917331689, J_o = 4257.196824212894
J_b = 0.11962889701436501, J_o = 5176.833731753539
J_b = 0.11339282037302041, J_o = 4225.932890091576
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05784147 -1.3340972  -1.37142308 -1.07802309 -1.80400078 -1.54409033
 -2.33190368 -1.7630303  -1.4013407  -1.16395956]
W_opt:  [ 0.0117319   0.0193023   0.01657223  0.01332723  0.00316768 -0.01583999
 -0.04481603 -0.08827165 -0.13718707 -0.18628941]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6907 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.1502, add (DA)= 0.0001decode = 0.2387 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9294 s, inc stats = 3.9357, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.08305532e-10 4.82462075e-10 5.58462189e-10 1.45577141e-10
 2.02417701e-09]
u_DA:    [-1.24429229e-09  7.48508071e-09  8.92153560e-09 -2.38597606e-09
  9.96835256e-09]
ref_MAE: [6.88812146e-09 1.00092335e-08 1.25014708e-08 8.39858510e-09
 1.84398126e-08]
da_MAE:  [1.35259783e-09 7.00261863e-09 8.36307341e-09 2.53155320e-09
 7.94417554e-09]
% 17.82986421943415 da_MAE 0.0726490788705408 ref_MAE 0.0884129960117738
u_c taken from control states: [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
u_c before reduction of space:  [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
data[u_c] post encoding of state:  [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
J_b = 0.0, J_o = 502978.9519271357
J_b = 0.4999999999999999, J_o = 16063429.362313887
J_b = 0.009490035853224287, J_o = 95313.93538454793
J_b = 0.010213601956907804, J_o = 76451.74748444761
J_b = 0.022829382375385555, J_o = 25815.409741793395
J_b = 0.02799915245337781, J_o = 19688.873331702922
J_b = 0.03752973304012217, J_o = 13681.037074587366
J_b = 0.04671518612533903, J_o = 10955.094447133892
J_b = 0.06445669607979121, J_o = 8827.296745550346
J_b = 0.06829081739505523, J_o = 7386.216627745636
J_b = 0.0699476583409621, J_o = 6706.08784319359
J_b = 0.07506473531934985, J_o = 6091.256748036818
J_b = 0.08568562435111751, J_o = 5368.92691670072
J_b = 0.0994437465643654, J_o = 4808.249051011158
J_b = 0.11382053245508081, J_o = 4451.624753196724
J_b = 0.12130224414605939, J_o = 5452.064908471243
J_b = 0.11480380003006234, J_o = 4422.146449133988
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05800483 -1.33534659 -1.37301318 -1.07820285 -1.80720251 -1.54537968
 -2.34067848 -1.76696401 -1.39857033 -1.1644344 ]
W_opt:  [ 0.01270733  0.01954713  0.01677277  0.01346461  0.0030585  -0.01615825
 -0.04521514 -0.08859196 -0.13743412 -0.18636921]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5765 s, v_trunc (Latent to Reduced) = 0.0834, dec (Reduced to Full) = 0.1517, add (DA)= 0.0001decode = 0.2372 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8137 s, inc stats = 3.8171, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.07834030e-10 4.78433214e-10 5.52434779e-10 1.44958044e-10
 2.00583168e-09]
u_DA:    [-1.24560594e-09  7.48138807e-09  8.91935892e-09 -2.36750847e-09
  9.95729879e-09]
ref_MAE: [6.88859296e-09 1.00132624e-08 1.25074982e-08 8.39920420e-09
 1.84581580e-08]
da_MAE:  [1.35343997e-09 7.00295486e-09 8.36692414e-09 2.51246652e-09
 7.95146711e-09]
% 18.003869991137233 da_MAE 0.07381563131317857 ref_MAE 0.09002331122846897
u_c taken from control states: [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
u_c before reduction of space:  [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
data[u_c] post encoding of state:  [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
J_b = 0.0, J_o = 502376.0912514555
J_b = 0.5000000000000001, J_o = 16068485.900958644
J_b = 0.009466021310645776, J_o = 95790.55592665845
J_b = 0.01018994182431808, J_o = 76927.53013382976
J_b = 0.02270789593623843, J_o = 26568.374591874202
J_b = 0.027837370914414707, J_o = 20443.00553525469
J_b = 0.03756423718273228, J_o = 14276.237686206305
J_b = 0.047147984228689224, J_o = 11446.579732540167
J_b = 0.0655166550454387, J_o = 9259.401821096815
J_b = 0.06920748171691798, J_o = 7793.774512382757
J_b = 0.07091324486852, J_o = 7099.0138315514305
J_b = 0.07612490495794665, J_o = 6476.178809941253
J_b = 0.08730116071582135, J_o = 5715.097434311938
J_b = 0.10170329690153421, J_o = 5135.47753405296
J_b = 0.11635421115172463, J_o = 4766.325009693295
J_b = 0.1244019722282303, J_o = 5889.946469142709
J_b = 0.11734111844947283, J_o = 4738.155888756905
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05817026 -1.33680769 -1.37460455 -1.07835134 -1.81038489 -1.54662867
 -2.35026777 -1.77098036 -1.39572663 -1.1649853 ]
W_opt:  [ 0.01400137  0.01987282  0.01688235  0.0136932   0.00284822 -0.01659547
 -0.04556682 -0.08879352 -0.13759838 -0.18666259]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6447 s, v_trunc (Latent to Reduced) = 0.0838, dec (Reduced to Full) = 0.1514, add (DA)= 0.0001decode = 0.2373 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8821 s, inc stats = 3.8896, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.07356564e-10 4.73721671e-10 5.46402527e-10 1.44446624e-10
 1.98759721e-09]
u_DA:    [-1.24642481e-09  7.47840660e-09  8.91682029e-09 -2.34860159e-09
  9.94434752e-09]
ref_MAE: [6.88907043e-09 1.00179740e-08 1.25135304e-08 8.39971562e-09
 1.84763925e-08]
da_MAE:  [1.35378138e-09 7.00468493e-09 8.37041776e-09 2.49304821e-09
 7.95675031e-09]
% 17.630760745437527 da_MAE 0.07592910634469953 ref_MAE 0.09218138595409424
u_c taken from control states: [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
u_c before reduction of space:  [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
data[u_c] post encoding of state:  [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
J_b = 0.0, J_o = 501873.60213461943
J_b = 0.49999999999999994, J_o = 16074767.483600928
J_b = 0.009439619801073676, J_o = 96460.16269610116
J_b = 0.010163175524074182, J_o = 77614.35365653048
J_b = 0.02257674593703758, J_o = 27562.238902129553
J_b = 0.027669286010910822, J_o = 21431.536054783133
J_b = 0.037645912461508856, J_o = 15067.992628035612
J_b = 0.04775470369375042, J_o = 12102.533455875802
J_b = 0.0669942076746056, J_o = 9845.612058655932
J_b = 0.07045909460287773, J_o = 8343.930313969136
J_b = 0.0721812584314306, J_o = 7631.60544387894
J_b = 0.07752496205784778, J_o = 6993.827526754884
J_b = 0.08945942195563952, J_o = 6179.164160660789
J_b = 0.10479419804869075, J_o = 5571.445257601115
J_b = 0.11992911001912433, J_o = 5183.3585432853
J_b = 0.12867596068180623, J_o = 6425.843055073299
J_b = 0.12095148412892927, J_o = 5155.4525091346
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05833008 -1.338481   -1.37619912 -1.0784587  -1.81354558 -1.54785192
 -2.3604192  -1.77506612 -1.39328797 -1.1656085 ]
W_opt:  [ 0.01536292  0.02023631  0.01714284  0.01408441  0.00268358 -0.01707532
 -0.04594615 -0.08886396 -0.1375834  -0.18694537]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6770 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1562, add (DA)= 0.0001decode = 0.2442 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9214 s, inc stats = 3.9296, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.06895271e-10 4.68325805e-10 5.40358129e-10 1.44076891e-10
 1.96948698e-09]
u_DA:    [-1.24898053e-09  7.47899513e-09  8.91896714e-09 -2.32790305e-09
  9.92613746e-09]
ref_MAE: [6.88953172e-09 1.00233698e-08 1.25195748e-08 8.40008535e-09
 1.84945027e-08]
da_MAE:  [1.35587580e-09 7.01066932e-09 8.37860901e-09 2.47197994e-09
 7.95665048e-09]
% 16.87422721852967 da_MAE 0.07884604409622742 ref_MAE 0.09485150207686621
\% improve_point: 7.84, mse_ref_points: 1.093467375116263e-05, mse_da_points: 1.0073354219810788e-05, % improve_overlap: 14.68, mse_ref_overlap: 0.16998, mse_da_overlap: 0.14494
DA - - L2: 1595.60, L1: 2940.45, % Improve: 18.19%, DA_MAE: 0.07, mse_ref: 0.18, mse_DA: 0.163, time(s): 4.9595s,
u_c taken from control states: [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
u_c before reduction of space:  [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
data[u_c] post encoding of state:  [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
J_b = 0.0, J_o = 501323.6228807684
J_b = 0.4999999999999998, J_o = 16082380.52909574
J_b = 0.009410616515875908, J_o = 97179.41167558004
J_b = 0.010132853020733933, J_o = 78374.2065573482
J_b = 0.0224411727687904, J_o = 28646.70960852169
J_b = 0.02750187721254783, J_o = 22508.470273444356
J_b = 0.03773457853232183, J_o = 15945.792685778024
J_b = 0.048398500690335, J_o = 12837.760726513368
J_b = 0.06859825990326064, J_o = 10509.959176850418
J_b = 0.07183375488835068, J_o = 8963.999957251672
J_b = 0.07358264187405716, J_o = 8229.117409910163
J_b = 0.07911693829679782, J_o = 7569.479893158999
J_b = 0.09193791114994412, J_o = 6693.044859140592
J_b = 0.10841751838938306, J_o = 6049.249227640212
J_b = 0.12431699318953904, J_o = 5637.005142077624
J_b = 0.13387034133152861, J_o = 6992.303604791889
J_b = 0.12540372728315136, J_o = 5608.37826377728
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05847928 -1.34034768 -1.37779483 -1.07852438 -1.81668007 -1.54906591
 -2.37083951 -1.77918698 -1.39170183 -1.16629584]
W_opt:  [ 0.0172494   0.02067426  0.01706495  0.01412251  0.00236776 -0.01746395
 -0.04620628 -0.08887754 -0.13748666 -0.18737588]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6656 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1583, add (DA)= 0.0001decode = 0.2466 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9124 s, inc stats = 3.9272, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.06464669e-10 4.62306412e-10 5.34309434e-10 1.43850693e-10
 1.95152696e-09]
u_DA:    [-1.25261937e-09  7.48097752e-09  8.92300419e-09 -2.30734163e-09
  9.91149155e-09]
ref_MAE: [6.88996232e-09 1.00293892e-08 1.25256235e-08 8.40031155e-09
 1.85124627e-08]
da_MAE:  [1.35908403e-09 7.01867111e-09 8.38869476e-09 2.45119232e-09
 7.95996459e-09]
% 16.22659208564514 da_MAE 0.0821532055007559 ref_MAE 0.09806597051028966
u_c taken from control states: [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
u_c before reduction of space:  [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
data[u_c] post encoding of state:  [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
J_b = 0.0, J_o = 501098.95798867155
J_b = 0.5000000000000001, J_o = 16088499.186084105
J_b = 0.009387944898711722, J_o = 97947.99667442661
J_b = 0.010109273858210404, J_o = 79170.56666523618
J_b = 0.0223520353943252, J_o = 29644.777100483618
J_b = 0.027398416702603384, J_o = 23492.54225610162
J_b = 0.03783765552866439, J_o = 16772.950411262544
J_b = 0.04894917638215477, J_o = 13550.328587630502
J_b = 0.06995328636095063, J_o = 11165.539629167513
J_b = 0.07302955315986284, J_o = 9577.609156250452
J_b = 0.07482242987246782, J_o = 8819.893974358805
J_b = 0.08055694821935414, J_o = 8138.412241016117
J_b = 0.09413328674523652, J_o = 7210.64106859306
J_b = 0.11158105783057644, J_o = 6534.42214122028
J_b = 0.12829466441020396, J_o = 6100.0870594940725
J_b = 0.13862367626224895, J_o = 7554.34410621484
J_b = 0.1294521934871479, J_o = 6070.369613447902
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0586121  -1.34237375 -1.37939176 -1.07855338 -1.81978306 -1.55029629
 -2.38098818 -1.7832994  -1.3917895  -1.16704412]
W_opt:  [ 0.01945701  0.02120715  0.01681944  0.01379597  0.0019201  -0.01782896
 -0.04641288 -0.088903   -0.13751811 -0.18780098]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8031 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1719, add (DA)= 0.0001decode = 0.2601 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0633 s, inc stats = 4.0701, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.06081310e-10 4.55773014e-10 5.28256124e-10 1.43750828e-10
 1.93374738e-09]
u_DA:    [-1.25492873e-09  7.48296492e-09  8.93026130e-09 -2.28982324e-09
  9.91057900e-09]
ref_MAE: [6.89034568e-09 1.00359226e-08 1.25316768e-08 8.40041141e-09
 1.85302423e-08]
da_MAE:  [1.36101004e-09 7.02719191e-09 8.40200518e-09 2.43357407e-09
 7.97683162e-09]
% 15.661521228458527 da_MAE 0.08546613719084008 ref_MAE 0.10133706279236224
u_c taken from control states: [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
u_c before reduction of space:  [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
data[u_c] post encoding of state:  [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
J_b = 0.0, J_o = 501140.28676214244
J_b = 0.5, J_o = 16092016.690653883
J_b = 0.009374520393600927, J_o = 98584.73469555109
J_b = 0.010095754528446526, J_o = 79812.09436643554
J_b = 0.022316259074729856, J_o = 30348.70306044694
J_b = 0.027363548063888063, J_o = 24180.550272028373
J_b = 0.03792126392549148, J_o = 17373.913172250173
J_b = 0.049268728956869456, J_o = 14091.754508627
J_b = 0.0706856010060371, J_o = 11677.564557547194
J_b = 0.07369516748918903, J_o = 10064.4757419571
J_b = 0.07555097375956346, J_o = 9289.201959426831
J_b = 0.08143903778956307, J_o = 8593.7964923586
J_b = 0.09542662620483039, J_o = 7640.217002965491
J_b = 0.11332748548509687, J_o = 6947.107468050718
J_b = 0.13050772901051827, J_o = 6500.121395574841
J_b = 0.14162059279848646, J_o = 8054.36131092
J_b = 0.13173056945589715, J_o = 6469.552505597029
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05873528 -1.34450112 -1.38099191 -1.07856206 -1.82285072 -1.55154319
 -2.39067405 -1.78739193 -1.39371733 -1.16782323]
W_opt:  [ 0.0219082   0.02190014  0.01627839  0.01285339  0.00111989 -0.01824796
 -0.04662421 -0.08886535 -0.13730678 -0.18770007]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7119 s, v_trunc (Latent to Reduced) = 0.0865, dec (Reduced to Full) = 0.1596, add (DA)= 0.0001decode = 0.2481 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9601 s, inc stats = 3.9685, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.05725784e-10 4.48912966e-10 5.22190579e-10 1.43720908e-10
 1.91617021e-09]
u_DA:    [-1.25534092e-09  7.48152646e-09  8.93636252e-09 -2.27549815e-09
  9.91489723e-09]
ref_MAE: [6.89070121e-09 1.00427827e-08 1.25377424e-08 8.40044133e-09
 1.85478194e-08]
da_MAE:  [1.36106671e-09 7.03261350e-09 8.41417194e-09 2.41921906e-09
 7.99872701e-09]
% 15.301656990476072 da_MAE 0.08848058939471305 ref_MAE 0.10446554944382304
u_c taken from control states: [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
u_c before reduction of space:  [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
data[u_c] post encoding of state:  [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
J_b = 0.0, J_o = 501228.68056058395
J_b = 0.5000000000000001, J_o = 16094133.203996781
J_b = 0.009366653428451057, J_o = 99022.28506023067
J_b = 0.010087892865183922, J_o = 80250.26844282557
J_b = 0.022307062894593048, J_o = 30788.09746217279
J_b = 0.02736023797940327, J_o = 24610.232707745967
J_b = 0.037948809328501254, J_o = 17783.564897720804
J_b = 0.0493240693137575, J_o = 14496.735491972348
J_b = 0.07073749332034979, J_o = 12081.889420911924
J_b = 0.07374983354745583, J_o = 10464.340951866383
J_b = 0.075688328783517, J_o = 9677.461902792053
J_b = 0.08167756219418568, J_o = 8976.704861953302
J_b = 0.0957713715033335, J_o = 8019.572015311387
J_b = 0.11371076409052211, J_o = 7322.572974491943
J_b = 0.1310263186077928, J_o = 6870.394018464824
J_b = 0.1430714695177718, J_o = 8545.80505762999
J_b = 0.1323173011697868, J_o = 6839.155899948561
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05885593 -1.34668249 -1.38259121 -1.07857257 -1.82587712 -1.55280103
 -2.39990805 -1.79143997 -1.397065   -1.16859018]
W_opt:  [ 0.02351435  0.02218229  0.01557097  0.01184502  0.00048848 -0.01830629
 -0.04638942 -0.08837653 -0.13676456 -0.18717105]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6961 s, v_trunc (Latent to Reduced) = 0.0836, dec (Reduced to Full) = 0.1488, add (DA)= 0.0001decode = 0.2345 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9307 s, inc stats = 3.9366, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.05377558e-10 4.41878790e-10 5.16128280e-10 1.43684712e-10
 1.89882950e-09]
u_DA:    [-1.25421789e-09  7.47733294e-09  8.93940318e-09 -2.26388601e-09
  9.92703840e-09]
ref_MAE: [6.89104944e-09 1.00498168e-08 1.25438047e-08 8.40047753e-09
 1.85651602e-08]
da_MAE:  [1.35959545e-09 7.03545415e-09 8.42327490e-09 2.40757072e-09
 8.02820891e-09]
% 15.022618751470434 da_MAE 0.09117834210806128 ref_MAE 0.1072971898738513
u_c taken from control states: [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
u_c before reduction of space:  [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
data[u_c] post encoding of state:  [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
J_b = 0.0, J_o = 501729.72335748025
J_b = 0.4999999999999999, J_o = 16092559.376203706
J_b = 0.009371008165447923, J_o = 99354.62776500883
J_b = 0.01009373218677334, J_o = 80543.17280630596
J_b = 0.02236757707997075, J_o = 30892.819076693577
J_b = 0.02744924088967164, J_o = 24693.11016420332
J_b = 0.038010582304220455, J_o = 17897.095923587436
J_b = 0.04923726878403636, J_o = 14653.213560104514
J_b = 0.0702555724596044, J_o = 12267.183333343026
J_b = 0.07329559143795118, J_o = 10666.315353489434
J_b = 0.07531259949492669, J_o = 9875.675875363942
J_b = 0.08132723623660684, J_o = 9179.541077310072
J_b = 0.09518768893117546, J_o = 8242.281778544471
J_b = 0.11269673930904094, J_o = 7558.0996966697985
J_b = 0.1296278193025609, J_o = 7110.578827398759
J_b = 0.14260846652099704, J_o = 8902.996023159372
J_b = 0.13098213955269486, J_o = 7078.81380030542
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05897181 -1.34889465 -1.3841858  -1.07860571 -1.82885912 -1.55407975
 -2.40845375 -1.79542757 -1.40177468 -1.16932542]
W_opt:  [ 2.40193167e-02  2.22828988e-02  1.51760073e-02  1.13150228e-02
  1.56825449e-04 -1.82506104e-02 -4.61784930e-02 -8.80350249e-02
 -1.36314931e-01 -1.86502820e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8957 s, v_trunc (Latent to Reduced) = 0.0911, dec (Reduced to Full) = 0.1495, add (DA)= 0.0001decode = 0.2427 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1385 s, inc stats = 4.1443, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.05043098e-10 4.34745352e-10 5.10083828e-10 1.43570601e-10
 1.88174317e-09]
u_DA:    [-1.25023843e-09  7.47076992e-09  8.94494001e-09 -2.25661426e-09
  9.94379015e-09]
ref_MAE: [6.89138390e-09 1.00569503e-08 1.25498491e-08 8.40059164e-09
 1.85822465e-08]
da_MAE:  [1.35528153e-09 7.03602457e-09 8.43485618e-09 2.40018486e-09
 8.06204698e-09]
% 15.092812023393464 da_MAE 0.09311841652715476 ref_MAE 0.10967082852020793
u_c taken from control states: [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
u_c before reduction of space:  [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
data[u_c] post encoding of state:  [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
J_b = 0.0, J_o = 502591.9969787906
J_b = 0.5, J_o = 16087742.96534965
J_b = 0.009386651555651548, J_o = 99565.22350977181
J_b = 0.010111986650136634, J_o = 80683.10839658935
J_b = 0.022492152569480176, J_o = 30675.140601372572
J_b = 0.027621867543277962, J_o = 24446.419504872098
J_b = 0.0380869455871533, J_o = 17737.932782520125
J_b = 0.048997613784410705, J_o = 14580.044279456954
J_b = 0.0693149125971446, J_o = 12247.353531141594
J_b = 0.07243128692275125, J_o = 10677.402346512084
J_b = 0.07451717425640005, J_o = 9889.788379480266
J_b = 0.08050006710976329, J_o = 9204.81004204328
J_b = 0.09384834947006532, J_o = 8306.392450422296
J_b = 0.11058846925169545, J_o = 7646.114355663045
J_b = 0.12694290050234353, J_o = 7208.623474581226
J_b = 0.14070239032155302, J_o = 9108.423983800752
J_b = 0.12834044425867536, J_o = 7176.554330059479
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05908455 -1.3510882  -1.38576738 -1.07868849 -1.83179223 -1.55538789
 -2.41605482 -1.79933389 -1.40771123 -1.17001616]
W_opt:  [ 0.02279397  0.0222197   0.01525598  0.01156283  0.00055028 -0.01777119
 -0.04592946 -0.08783462 -0.13605577 -0.18596529]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7215 s, v_trunc (Latent to Reduced) = 0.0865, dec (Reduced to Full) = 0.1486, add (DA)= 0.0001decode = 0.2372 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9588 s, inc stats = 3.9712, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.04717696e-10 4.27671876e-10 5.04088680e-10 1.43285485e-10
 1.86493696e-09]
u_DA:    [-1.24349613e-09  7.46223642e-09  8.95439684e-09 -2.25317463e-09
  9.96620574e-09]
ref_MAE: [6.89170930e-09 1.00640237e-08 1.25558443e-08 8.40087676e-09
 1.85990527e-08]
da_MAE:  [1.34821382e-09 7.03456454e-09 8.45030816e-09 2.39646011e-09
 8.10126877e-09]
% 15.225634132826553 da_MAE 0.09449933763962835 ref_MAE 0.11147159483055553
u_c taken from control states: [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
u_c before reduction of space:  [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
data[u_c] post encoding of state:  [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
J_b = 0.0, J_o = 503606.11160637374
J_b = 0.5000000000000001, J_o = 16081980.117647143
J_b = 0.00940502315214851, J_o = 99817.04133168168
J_b = 0.010133627626066701, J_o = 80846.3973315033
J_b = 0.022648886881918927, J_o = 30387.254902150617
J_b = 0.02783711903350806, J_o = 24126.0949422095
J_b = 0.038170013074520545, J_o = 17534.432376805773
J_b = 0.04868714842550977, J_o = 14482.23198327974
J_b = 0.06818582249792252, J_o = 12213.672123533417
J_b = 0.07140581094221586, J_o = 10679.009009069852
J_b = 0.07356039446365492, J_o = 9896.178257359066
J_b = 0.079507022525893, J_o = 9222.48025471408
J_b = 0.09226818335303322, J_o = 8368.557010707158
J_b = 0.10814114645190646, J_o = 7736.533923153984
J_b = 0.12384812011706127, J_o = 7310.746284192974
J_b = 0.13825151950246503, J_o = 9312.030384890266
J_b = 0.12527237522839477, J_o = 7278.515900374931
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0592013  -1.35317857 -1.38732662 -1.07884961 -1.83467397 -1.55672005
 -2.42264546 -1.80313244 -1.41427996 -1.17064007]
W_opt:  [ 0.02142008  0.02212128  0.01554382  0.01201059  0.00091928 -0.01752242
 -0.04580894 -0.08775328 -0.13595458 -0.18550668]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7152 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1516, add (DA)= 0.0001decode = 0.2398 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9551 s, inc stats = 3.9675, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.04380733e-10 4.20931145e-10 4.98178239e-10 1.42730588e-10
 1.84842510e-09]
u_DA:    [-1.23303103e-09  7.45345997e-09  8.96249263e-09 -2.25397850e-09
  9.99542311e-09]
ref_MAE: [6.89204626e-09 1.00707645e-08 1.25617547e-08 8.40143165e-09
 1.86155646e-08]
da_MAE:  [1.33741176e-09 7.03252883e-09 8.46431439e-09 2.39670908e-09
 8.14699801e-09]
% 15.665182107533543 da_MAE 0.09506732467791668 ref_MAE 0.11272606860802736
u_c taken from control states: [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
u_c before reduction of space:  [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
data[u_c] post encoding of state:  [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
J_b = 0.0, J_o = 504660.8683873367
J_b = 0.5000000000000002, J_o = 16076238.15853485
J_b = 0.009422254048191666, J_o = 100168.52076327377
J_b = 0.010154629506646766, J_o = 81096.3891580298
J_b = 0.022821661360580794, J_o = 30127.975340050187
J_b = 0.028079409935754314, J_o = 23822.387824551548
J_b = 0.03831165173469805, J_o = 17327.684781645978
J_b = 0.04849131529905255, J_o = 14367.873684928247
J_b = 0.06726335736859917, J_o = 12163.403046509693
J_b = 0.0705132830292439, J_o = 10661.452714809648
J_b = 0.07270286337205449, J_o = 9883.98146899549
J_b = 0.07861848295185558, J_o = 9218.560791303975
J_b = 0.09088588832962212, J_o = 8401.407582059077
J_b = 0.10605464410986994, J_o = 7793.4199425499155
J_b = 0.12121263767502269, J_o = 7376.653135478532
J_b = 0.13612133800819085, J_o = 9463.638330228396
J_b = 0.12265570751250304, J_o = 7344.211831852637
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05933486 -1.35509537 -1.38885151 -1.07911581 -1.83750493 -1.55806143
 -2.42839042 -1.80679905 -1.42057869 -1.17117834]
W_opt:  [ 0.01994658  0.02215681  0.01579877  0.01245704  0.00153927 -0.01713827
 -0.04578985 -0.08795814 -0.13635844 -0.18546323]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7061 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1622, add (DA)= 0.0001decode = 0.2505 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9567 s, inc stats = 3.9638, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.03995245e-10 4.14750148e-10 4.92397964e-10 1.41813817e-10
 1.83220418e-09]
u_DA:    [-1.22123165e-09  7.44467353e-09  8.96901319e-09 -2.25906117e-09
  1.00228523e-08]
ref_MAE: [6.89243175e-09 1.00769455e-08 1.25675350e-08 8.40234842e-09
 1.86317855e-08]
da_MAE:  [1.32522690e-09 7.02992338e-09 8.47661522e-09 2.40087499e-09
 8.19064808e-09]
% 16.038184796828308 da_MAE 0.09529218041764267 ref_MAE 0.11349466443412835
u_c taken from control states: [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
u_c before reduction of space:  [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
data[u_c] post encoding of state:  [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
J_b = 0.0, J_o = 505532.7696010066
J_b = 0.49999999999999994, J_o = 16071686.266982125
J_b = 0.009435245260056867, J_o = 100518.16724033705
J_b = 0.01017099033868593, J_o = 81355.14881397196
J_b = 0.02298179024178884, J_o = 29906.376036903643
J_b = 0.02831062443617617, J_o = 23551.29064732728
J_b = 0.0384821791798811, J_o = 17124.26678564128
J_b = 0.048417494540512175, J_o = 14232.975951412169
J_b = 0.06663465043714856, J_o = 12087.897603989757
J_b = 0.06981597135546966, J_o = 10613.94127937232
J_b = 0.07197338779721171, J_o = 9845.141964479439
J_b = 0.07783699188464774, J_o = 9186.260019913516
J_b = 0.08970118947341928, J_o = 8397.523878873546
J_b = 0.1042983332420623, J_o = 7809.881649350229
J_b = 0.11901311868406636, J_o = 7399.579597374236
J_b = 0.134245913194962, J_o = 9538.595566233947
J_b = 0.1204705193076662, J_o = 7366.826986854008
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05949581 -1.35680259 -1.39032365 -1.07949885 -1.84028697 -1.55940261
 -2.43343341 -1.81031205 -1.42613477 -1.17162466]
W_opt:  [ 0.01905394  0.02245908  0.01614684  0.01246473  0.0016653  -0.01695951
 -0.04577599 -0.08811412 -0.1366834  -0.1854474 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7533 s, v_trunc (Latent to Reduced) = 0.0728, dec (Reduced to Full) = 0.1660, add (DA)= 0.0001decode = 0.2409 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9943 s, inc stats = 3.9998, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.03530716e-10 4.09244947e-10 4.86817668e-10 1.40494641e-10
 1.81626363e-09]
u_DA:    [-1.21066265e-09  7.43530663e-09  8.97388711e-09 -2.26369387e-09
  1.00415077e-08]
ref_MAE: [6.89289628e-09 1.00824507e-08 1.25731153e-08 8.40366760e-09
 1.86477260e-08]
da_MAE:  [1.31419336e-09 7.02606168e-09 8.48706944e-09 2.40418851e-09
 8.22524404e-09]
% 16.30323577624074 da_MAE 0.09537668629611211 ref_MAE 0.11395504614865055
u_c taken from control states: [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
u_c before reduction of space:  [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
data[u_c] post encoding of state:  [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
J_b = 0.0, J_o = 506284.52196386515
J_b = 0.5, J_o = 16068468.676937751
J_b = 0.00944307110890963, J_o = 100973.69206095755
J_b = 0.010181944748381529, J_o = 81727.26031944471
J_b = 0.023116713978958738, J_o = 29859.849400766052
J_b = 0.028509697012702874, J_o = 23455.77614895533
J_b = 0.03866106774833134, J_o = 17063.41001107013
J_b = 0.04845395086069505, J_o = 14212.911972865386
J_b = 0.06632433532463676, J_o = 12111.82449421008
J_b = 0.06940684901896474, J_o = 10656.164644395732
J_b = 0.07151037427358968, J_o = 9894.589843163907
J_b = 0.07733487412797055, J_o = 9238.924292560736
J_b = 0.08891979534066319, J_o = 8470.02903656421
J_b = 0.10305168912035155, J_o = 7899.8298733412485
J_b = 0.11737767548091979, J_o = 7494.47000469304
J_b = 0.13286669926497252, J_o = 9676.4188239008
J_b = 0.11884629045799414, J_o = 7461.378972311922
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05969758 -1.35828302 -1.39173207 -1.08000281 -1.84302759 -1.56072433
 -2.43814308 -1.81366618 -1.43039353 -1.17197661]
W_opt:  [ 0.0185564   0.02329359  0.01682601  0.01215537  0.00130401 -0.01702755
 -0.04588165 -0.08820235 -0.13689318 -0.18532477]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7594 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.1779, add (DA)= 0.0001decode = 0.2670 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0264 s, inc stats = 4.0363, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.02948367e-10 4.04471064e-10 4.81478930e-10 1.38759006e-10
 1.80056035e-09]
u_DA:    [-1.19999731e-09  7.42362905e-09  8.97921020e-09 -2.26366595e-09
  1.00572663e-08]
ref_MAE: [6.89347863e-09 1.00872246e-08 1.25784540e-08 8.40540324e-09
 1.86634293e-08]
da_MAE:  [1.30294567e-09 7.01915798e-09 8.49773127e-09 2.40242496e-09
 8.25670592e-09]
% 16.697161569866342 da_MAE 0.09526978642199752 ref_MAE 0.11436559451920786
\% improve_point: 8.10, mse_ref_points: 1.1876968187108642e-05, mse_da_points: 1.0902403883056726e-05, % improve_overlap: 14.73, mse_ref_overlap: 0.18383, mse_da_overlap: 0.15659
DA - - L2: 2122.56, L1: 3327.80, % Improve: 17.71%, DA_MAE: 0.07, mse_ref: 0.19, mse_DA: 0.177, time(s): 4.7719s,
u_c taken from control states: [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
u_c before reduction of space:  [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
data[u_c] post encoding of state:  [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
J_b = 0.0, J_o = 506966.5957256225
J_b = 0.5000000000000001, J_o = 16065586.306598213
J_b = 0.009450682510006308, J_o = 101360.03614111443
J_b = 0.010192144409077335, J_o = 82044.31531833307
J_b = 0.02323416347582216, J_o = 29815.237179175805
J_b = 0.02868625189386744, J_o = 23363.026611739362
J_b = 0.038848306521748165, J_o = 16981.63461875661
J_b = 0.048566559547474394, J_o = 14155.485675501088
J_b = 0.0661829482025493, J_o = 12096.214845500373
J_b = 0.06908301384015464, J_o = 10659.093374161848
J_b = 0.07108248888228631, J_o = 9908.666173217784
J_b = 0.07683114287426511, J_o = 9257.262129719908
J_b = 0.08820218601240361, J_o = 8501.71342040494
J_b = 0.10196187102194029, J_o = 7947.02474854636
J_b = 0.1158547542112964, J_o = 7547.965035103933
J_b = 0.13126732280223508, J_o = 9703.747464397733
J_b = 0.11732496324047847, J_o = 7514.578294822369
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.05995413 -1.35956357 -1.39306342 -1.08063581 -1.84573509 -1.56201033
 -2.44301314 -1.81687292 -1.43290696 -1.17225518]
W_opt:  [ 0.01835084  0.02375871  0.01722991  0.01189158  0.00088826 -0.01730303
 -0.04595812 -0.08805184 -0.13669108 -0.18481873]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6051 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1467, add (DA)= 0.0001decode = 0.2325 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8376 s, inc stats = 3.8420, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.02207902e-10 4.00341711e-10 4.76432321e-10 1.36578941e-10
 1.78504688e-09]
u_DA:    [-1.19226478e-09  7.41442898e-09  8.98533672e-09 -2.26298443e-09
  1.00663973e-08]
ref_MAE: [6.89421909e-09 1.00913539e-08 1.25835006e-08 8.40758330e-09
 1.86789428e-08]
da_MAE:  [1.29447268e-09 7.01408727e-09 8.50890439e-09 2.39956337e-09
 8.28135037e-09]
% 16.909504820472026 da_MAE 0.09530406893778817 ref_MAE 0.11469912260345923
u_c taken from control states: [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
u_c before reduction of space:  [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
data[u_c] post encoding of state:  [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
J_b = 0.0, J_o = 507451.82346610806
J_b = 0.4999999999999999, J_o = 16064150.03808353
J_b = 0.009453681179174944, J_o = 101742.26671617622
J_b = 0.010197025506877767, J_o = 82376.0207539904
J_b = 0.023324391925445928, J_o = 29859.558453110774
J_b = 0.02883004973427454, J_o = 23359.438859751725
J_b = 0.03903874206855667, J_o = 16961.005802903823
J_b = 0.048765008803024285, J_o = 14137.365782466455
J_b = 0.06628180053814493, J_o = 12108.451349262441
J_b = 0.06898267322227172, J_o = 10681.060825874585
J_b = 0.07088315855330866, J_o = 9938.030491837946
J_b = 0.07658563492497461, J_o = 9287.011667413677
J_b = 0.08788725595471415, J_o = 8534.724426388173
J_b = 0.10144683924141074, J_o = 7990.026549230962
J_b = 0.11499931375054433, J_o = 7595.52589397917
J_b = 0.13022537346510363, J_o = 9694.190091885213
J_b = 0.11647506572587633, J_o = 7561.678299878741
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06026524 -1.36070553 -1.39430129 -1.08136756 -1.84841443 -1.56326958
 -2.44807783 -1.81994623 -1.43407587 -1.17250363]
W_opt:  [ 0.0185229   0.02423727  0.01755568  0.01170512  0.00058081 -0.01772215
 -0.04616397 -0.08800693 -0.13648322 -0.18442529]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7253 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.1693, add (DA)= 0.0001decode = 0.2578 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9831 s, inc stats = 3.9953, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.01309961e-10 3.96659282e-10 4.71740027e-10 1.34058826e-10
 1.76969470e-09]
u_DA:    [-1.18684575e-09  7.40572864e-09  8.99024769e-09 -2.25975090e-09
  1.00635052e-08]
ref_MAE: [6.89511703e-09 1.00950363e-08 1.25881929e-08 8.41010342e-09
 1.86942950e-08]
da_MAE:  [1.28815571e-09 7.00906936e-09 8.51850766e-09 2.39380973e-09
 8.29381053e-09]
% 16.935133250441694 da_MAE 0.09548114173564054 ref_MAE 0.11494768543181737
u_c taken from control states: [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
u_c before reduction of space:  [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
data[u_c] post encoding of state:  [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
J_b = 0.0, J_o = 507888.5235157286
J_b = 0.5000000000000001, J_o = 16063106.06372022
J_b = 0.009455626472958892, J_o = 102118.27132112638
J_b = 0.010200586921554376, J_o = 82708.55690121104
J_b = 0.02340491822679997, J_o = 29932.82703431591
J_b = 0.02896245959547122, J_o = 23384.247297086164
J_b = 0.039233915434347344, J_o = 16956.26580489777
J_b = 0.04900660360374307, J_o = 14124.50925169459
J_b = 0.0665055924030523, J_o = 12119.602534705286
J_b = 0.06900853389543771, J_o = 10696.814512599869
J_b = 0.07080809388543567, J_o = 9960.21992910054
J_b = 0.07646936711188008, J_o = 9308.343238131973
J_b = 0.0877518413234404, J_o = 8555.394567925012
J_b = 0.101185670148062, J_o = 8018.183270927113
J_b = 0.11444941521405248, J_o = 7627.570828145353
J_b = 0.12934664285486228, J_o = 9635.215206330178
J_b = 0.11593148794303423, J_o = 7593.146225591436
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06062779 -1.36176595 -1.39543909 -1.08215199 -1.85106888 -1.56451027
 -2.45321785 -1.82290438 -1.43448497 -1.17275954]
W_opt:  [ 1.87823489e-02  2.44574312e-02  1.79464276e-02  1.15146082e-02
  1.46676879e-04 -1.81177232e-02 -4.63373272e-02 -8.80074485e-02
 -1.36341961e-01 -1.83997915e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7183 s, v_trunc (Latent to Reduced) = 0.0839, dec (Reduced to Full) = 0.1673, add (DA)= 0.0001decode = 0.2532 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9716 s, inc stats = 3.9760, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [1.00263577e-10 3.93239796e-10 4.67427077e-10 1.31357262e-10
 1.75448519e-09]
u_DA:    [-1.18420539e-09  7.39732776e-09  8.99425582e-09 -2.25539245e-09
  1.00563387e-08]
ref_MAE: [6.89616342e-09 1.00984558e-08 1.25925059e-08 8.41280498e-09
 1.87095045e-08]
da_MAE:  [1.28446897e-09 7.00408797e-09 8.52682874e-09 2.38674971e-09
 8.30185350e-09]
% 17.06671647637274 da_MAE 0.09539957829751575 ref_MAE 0.11503171494510633
u_c taken from control states: [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
u_c before reduction of space:  [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
data[u_c] post encoding of state:  [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
J_b = 0.0, J_o = 508252.9533516045
J_b = 0.49999999999999994, J_o = 16062461.011262171
J_b = 0.009456637770619931, J_o = 102457.40676935407
J_b = 0.010202845579167284, J_o = 83014.0195188705
J_b = 0.023470981486974112, J_o = 30023.142002301378
J_b = 0.029075395655250174, J_o = 23429.209644051305
J_b = 0.03941584648553656, J_o = 16965.13810608794
J_b = 0.049259283232798046, J_o = 14118.109659156742
J_b = 0.06679862720312482, J_o = 12132.253693559032
J_b = 0.06910933007861024, J_o = 10710.41891921491
J_b = 0.07080594526955865, J_o = 9979.898631384856
J_b = 0.07642840201667855, J_o = 9325.989681841786
J_b = 0.08774471170049589, J_o = 8567.820847025601
J_b = 0.10117407308979745, J_o = 8033.388541233912
J_b = 0.11429527209629202, J_o = 7644.040131687912
J_b = 0.12878554236007037, J_o = 9535.612177507634
J_b = 0.11579002685035102, J_o = 7608.855547087189
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06104819 -1.36278598 -1.39647663 -1.08295471 -1.85370198 -1.56572469
 -2.45856883 -1.82575184 -1.43423559 -1.17304437]
W_opt:  [ 1.86376654e-02  2.45277272e-02  1.83705424e-02  1.15977269e-02
  6.61978422e-05 -1.82094720e-02 -4.63268847e-02 -8.79806399e-02
 -1.36273494e-01 -1.83819700e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5942 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1499, add (DA)= 0.0001decode = 0.2357 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8299 s, inc stats = 3.8351, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.90502069e-11 3.89950532e-10 4.63494194e-10 1.28592688e-10
 1.73939802e-09]
u_DA:    [-1.18459074e-09  7.38997632e-09  8.99770634e-09 -2.25150613e-09
  1.00424783e-08]
ref_MAE: [6.89737679e-09 1.01017451e-08 1.25964388e-08 8.41556955e-09
 1.87245916e-08]
da_MAE:  [1.28364095e-09 7.00002579e-09 8.53421214e-09 2.38009882e-09
 8.30308026e-09]
% 17.32193362895573 da_MAE 0.09511805212490218 ref_MAE 0.11504629498472968
u_c taken from control states: [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
u_c before reduction of space:  [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
data[u_c] post encoding of state:  [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
J_b = 0.0, J_o = 508618.8648019463
J_b = 0.4999999999999999, J_o = 16061512.453288173
J_b = 0.009458454850549742, J_o = 102764.85189427051
J_b = 0.010206006588904522, J_o = 83285.93374867592
J_b = 0.023528753899478404, J_o = 30105.782202477763
J_b = 0.029173253528995143, J_o = 23471.21887523043
J_b = 0.03958198619184766, J_o = 16969.025202308872
J_b = 0.049502650165371836, J_o = 14104.128675040189
J_b = 0.06711158842737908, J_o = 12130.05595402337
J_b = 0.0692703588930292, J_o = 10706.428166232661
J_b = 0.07088646662569431, J_o = 9980.116445545267
J_b = 0.07647958663385634, J_o = 9324.301909654567
J_b = 0.08783591183489584, J_o = 8560.72541036488
J_b = 0.10128081519444646, J_o = 8027.879964100802
J_b = 0.11427759272852737, J_o = 7640.510476097251
J_b = 0.1282700418830123, J_o = 9415.431137263578
J_b = 0.11577230677696339, J_o = 7604.857300334386
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06152889 -1.36380211 -1.39742105 -1.08374528 -1.8563189  -1.56690243
 -2.46438883 -1.82849703 -1.43320953 -1.17337223]
W_opt:  [ 1.85558635e-02  2.45030029e-02  1.86581168e-02  1.17544146e-02
  2.29281088e-05 -1.82723976e-02 -4.63390290e-02 -8.79448768e-02
 -1.36176628e-01 -1.83681494e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6803 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1576, add (DA)= 0.0001decode = 0.2458 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9262 s, inc stats = 3.9326, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.76627957e-11 3.86673885e-10 4.59914276e-10 1.25869968e-10
 1.72440351e-09]
u_DA:    [-1.18720977e-09  7.38422710e-09  8.99865437e-09 -2.24849841e-09
  1.00238857e-08]
ref_MAE: [6.89876420e-09 1.01050217e-08 1.26000187e-08 8.41829227e-09
 1.87395862e-08]
da_MAE:  [1.28487257e-09 6.99755321e-09 8.53874010e-09 2.37436838e-09
 8.29948221e-09]
% 17.507723298308505 da_MAE 0.09488168501818528 ref_MAE 0.11501887062869698
u_c taken from control states: [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
u_c before reduction of space:  [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
data[u_c] post encoding of state:  [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
J_b = 0.0, J_o = 508904.8249149032
J_b = 0.5000000000000001, J_o = 16060737.298602147
J_b = 0.009459491522670574, J_o = 103025.582277946
J_b = 0.010208258256727389, J_o = 83515.17455404128
J_b = 0.02357004982306189, J_o = 30194.858974139985
J_b = 0.029243597273563, J_o = 23528.95090509738
J_b = 0.03971151603323958, J_o = 16991.588198376077
J_b = 0.04970525995903758, J_o = 14109.04104786299
J_b = 0.06739524227056598, J_o = 12139.831073605761
J_b = 0.06944925652032943, J_o = 10712.843810984079
J_b = 0.07101337858008526, J_o = 9988.518688118316
J_b = 0.07659039521289907, J_o = 9331.202275184045
J_b = 0.08797943401027283, J_o = 8563.645241934844
J_b = 0.10141193670829365, J_o = 8032.849528448988
J_b = 0.11426458368323422, J_o = 7649.033201338805
J_b = 0.12773784230638863, J_o = 9327.464339624266
J_b = 0.1157414432955912, J_o = 7613.388726437663
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06206371 -1.36484786 -1.3982788  -1.08449817 -1.85892432 -1.56804692
 -2.47075184 -1.8311715  -1.43159504 -1.17376056]
W_opt:  [ 0.01875106  0.02453739  0.01879645  0.01169464 -0.00025198 -0.01850868
 -0.0463868  -0.0878338  -0.13593963 -0.18335284]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9624 s, v_trunc (Latent to Reduced) = 0.0913, dec (Reduced to Full) = 0.1596, add (DA)= 0.0001decode = 0.2531 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2156 s, inc stats = 4.2279, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.61191778e-11 3.83301686e-10 4.56662862e-10 1.23277038e-10
 1.70947493e-09]
u_DA:    [-1.19134957e-09  7.37975603e-09  8.99628384e-09 -2.24475086e-09
  1.00032331e-08]
ref_MAE: [6.90030782e-09 1.01083939e-08 1.26032701e-08 8.42088520e-09
 1.87545147e-08]
da_MAE:  [1.28746874e-09 6.99645435e-09 8.53962097e-09 2.36802790e-09
 8.29375815e-09]
% 17.644724829143268 da_MAE 0.09472189777960037 ref_MAE 0.1150161875885758
u_c taken from control states: [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
u_c before reduction of space:  [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
data[u_c] post encoding of state:  [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
J_b = 0.0, J_o = 509203.7024336536
J_b = 0.5, J_o = 16059643.465750797
J_b = 0.009460867818845333, J_o = 103290.55443877196
J_b = 0.010211163435032328, J_o = 83741.32114134786
J_b = 0.023607333169503076, J_o = 30289.532883305998
J_b = 0.029305500572011638, J_o = 23594.387160521794
J_b = 0.039834651670719735, J_o = 17018.669456042306
J_b = 0.049903314443133055, J_o = 14117.980806321466
J_b = 0.06767252981881218, J_o = 12149.656435868688
J_b = 0.06964111338630093, J_o = 10719.690097791188
J_b = 0.07117103475004063, J_o = 9995.808281685855
J_b = 0.07674198148209097, J_o = 9336.774964911194
J_b = 0.08818937085304598, J_o = 8563.659169267055
J_b = 0.10166322597640588, J_o = 8033.054201501073
J_b = 0.1143943924959746, J_o = 7652.425009510305
J_b = 0.12739694213383024, J_o = 9252.686610835155
J_b = 0.11584901327914675, J_o = 7616.950939649655
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06263969 -1.36594473 -1.39905453 -1.08519505 -1.86152179 -1.56916647
 -2.47760238 -1.83379986 -1.4297426  -1.17421706]
W_opt:  [ 0.01890552  0.02450691  0.01874706  0.01153072 -0.00043301 -0.01857368
 -0.0463116  -0.08762077 -0.13568156 -0.18311222]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6538 s, v_trunc (Latent to Reduced) = 0.0836, dec (Reduced to Full) = 0.1593, add (DA)= 0.0001decode = 0.2449 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8988 s, inc stats = 3.9044, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.44567615e-11 3.79764643e-10 4.53722408e-10 1.20876996e-10
 1.69459192e-09]
u_DA:    [-1.19854329e-09  7.37611183e-09  8.99118081e-09 -2.24138513e-09
  9.97968022e-09]
ref_MAE: [6.90197023e-09 1.01119310e-08 1.26062105e-08 8.42328525e-09
 1.87693977e-08]
da_MAE:  [1.29300005e-09 6.99634719e-09 8.53745840e-09 2.36226213e-09
 8.28508830e-09]
% 17.778592506935137 da_MAE 0.09455674725395626 ref_MAE 0.11500258890840788
u_c taken from control states: [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
u_c before reduction of space:  [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
data[u_c] post encoding of state:  [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
J_b = 0.0, J_o = 509550.7096409559
J_b = 0.5000000000000002, J_o = 16058119.454116914
J_b = 0.009463394730959312, J_o = 103557.42226431177
J_b = 0.010215459730306431, J_o = 83963.5857580602
J_b = 0.023644366805556503, J_o = 30380.508920478827
J_b = 0.02936610923986871, J_o = 23654.918078673854
J_b = 0.03996574791796739, J_o = 17033.890937727687
J_b = 0.05011873208209578, J_o = 14113.025333666921
J_b = 0.06797457612880886, J_o = 12141.582120698713
J_b = 0.06987425770563047, J_o = 10707.855882723783
J_b = 0.07139349155870432, J_o = 9981.588963822045
J_b = 0.07697908453158069, J_o = 9319.89151614259
J_b = 0.08852435742936969, J_o = 8538.919345274546
J_b = 0.10209881957242728, J_o = 8006.734975239873
J_b = 0.11470591793496009, J_o = 7629.191270175919
J_b = 0.1272981564457718, J_o = 9170.300092230731
J_b = 0.11613535100223146, J_o = 7594.0079090141035
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06324307 -1.36710031 -1.39975841 -1.08582565 -1.86411414 -1.57026345
 -2.48497533 -1.83640065 -1.42779043 -1.17473664]
W_opt:  [ 0.01897208  0.02439214  0.01863683  0.0115063  -0.00040769 -0.01851641
 -0.04635544 -0.08765231 -0.13564007 -0.18304695]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5847 s, v_trunc (Latent to Reduced) = 0.0834, dec (Reduced to Full) = 0.1504, add (DA)= 0.0001decode = 0.2358 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8206 s, inc stats = 3.8307, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.27152583e-11 3.76038309e-10 4.51054278e-10 1.18705230e-10
 1.67973821e-09]
u_DA:    [-1.20598955e-09  7.37351899e-09  8.98703576e-09 -2.23621296e-09
  9.95575647e-09]
ref_MAE: [6.90371174e-09 1.01156573e-08 1.26088787e-08 8.42545701e-09
 1.87842515e-08]
da_MAE:  [1.29870481e-09 6.99748068e-09 8.53598149e-09 2.35491819e-09
 8.27601826e-09]
% 17.92730871225926 da_MAE 0.0943629021673852 ref_MAE 0.114974787212175
u_c taken from control states: [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
u_c before reduction of space:  [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
data[u_c] post encoding of state:  [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
J_b = 0.0, J_o = 509908.0680824268
J_b = 0.49999999999999994, J_o = 16056665.81036356
J_b = 0.009466019966131679, J_o = 103828.07580027862
J_b = 0.01021970472784892, J_o = 84193.7624514921
J_b = 0.023672187051900707, J_o = 30508.861770413518
J_b = 0.029412237049990513, J_o = 23756.385458405304
J_b = 0.04008561528888806, J_o = 17086.35212463071
J_b = 0.05033262232175845, J_o = 14142.769156239194
J_b = 0.06829736939512811, J_o = 12162.9526644218
J_b = 0.07015145190903209, J_o = 10723.636736116921
J_b = 0.071682088621213, J_o = 9992.352544521993
J_b = 0.07730111330751138, J_o = 9327.370072525802
J_b = 0.08896569264039604, J_o = 8537.87004834745
J_b = 0.10265676479458612, J_o = 8003.572161448423
J_b = 0.11513379494940754, J_o = 7629.074967565812
J_b = 0.1274163803416442, J_o = 9134.076247947036
J_b = 0.1165382975713528, J_o = 7594.255058678346
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06385557 -1.36831361 -1.400405   -1.08638196 -1.86670135 -1.57134595
 -2.49279807 -1.83898589 -1.42595129 -1.17531074]
W_opt:  [ 0.0190965   0.02445443  0.01859332  0.01151927 -0.00041177 -0.01852
 -0.04649115 -0.08773827 -0.13566159 -0.18305976]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6920 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1522, add (DA)= 0.0001decode = 0.2404 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9325 s, inc stats = 3.9425, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [9.09474564e-11 3.72125834e-10 4.48603293e-10 1.16789300e-10
 1.66491394e-09]
u_DA:    [-1.21026009e-09  7.37119793e-09  8.98620748e-09 -2.22829992e-09
  9.93371110e-09]
ref_MAE: [6.90547954e-09 1.01195698e-08 1.26113297e-08 8.42737294e-09
 1.87990757e-08]
da_MAE:  [1.30120755e-09 6.99907210e-09 8.53760418e-09 2.34508922e-09
 8.26879715e-09]
% 18.07336453783949 da_MAE 0.09419576706537273 ref_MAE 0.11497575426355568
u_c taken from control states: [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
u_c before reduction of space:  [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
data[u_c] post encoding of state:  [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
J_b = 0.0, J_o = 510282.8211482262
J_b = 0.49999999999999983, J_o = 16055200.859488903
J_b = 0.0094690837933423, J_o = 104094.50784589966
J_b = 0.010224268444241534, J_o = 84422.68957474474
J_b = 0.023698153220930898, J_o = 30644.615011884445
J_b = 0.029455051684453053, J_o = 23866.721997697015
J_b = 0.040202720619778025, J_o = 17146.9983334429
J_b = 0.050549897283619236, J_o = 14178.990217351296
J_b = 0.06864014997145002, J_o = 12189.802935106796
J_b = 0.07044621691495259, J_o = 10744.334112732511
J_b = 0.07198166980837394, J_o = 10008.778190858176
J_b = 0.07762707541150178, J_o = 9340.893775073619
J_b = 0.08940334876433499, J_o = 8543.295038373217
J_b = 0.10319343080922619, J_o = 8007.929128143137
J_b = 0.11549974705709676, J_o = 7637.130034283533
J_b = 0.12743743557931309, J_o = 9095.584449401398
J_b = 0.11688089142257967, J_o = 7602.581529156419
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06446151 -1.36957359 -1.40101186 -1.08686098 -1.86928401 -1.57242195
 -2.50095771 -1.84156577 -1.42441283 -1.17592965]
W_opt:  [ 0.0192402   0.02452915  0.01854982  0.01169612 -0.00033482 -0.01863544
 -0.04683205 -0.08800057 -0.13577439 -0.18303061]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7310 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1696, add (DA)= 0.0001decode = 0.2581 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9892 s, inc stats = 23.0290, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.91985705e-11 3.68062815e-10 4.46302928e-10 1.15139571e-10
 1.65011577e-09]
u_DA:    [-1.21555182e-09  7.37057403e-09  8.98504616e-09 -2.22026782e-09
  9.91355572e-09]
ref_MAE: [6.90722842e-09 1.01236328e-08 1.26136300e-08 8.42902267e-09
 1.88138739e-08]
da_MAE:  [1.30475039e-09 7.00251122e-09 8.53874323e-09 2.33540739e-09
 8.26343995e-09]
% 18.168631069055603 da_MAE 0.09412681473680405 ref_MAE 0.11502534537364943
\% improve_point: 8.52, mse_ref_points: 1.2774427857187086e-05, mse_da_points: 1.1655935384384917e-05, % improve_overlap: 15.00, mse_ref_overlap: 0.19899, mse_da_overlap: 0.16882
DA - - L2: 2497.49, L1: 3612.50, % Improve: 17.68%, DA_MAE: 0.08, mse_ref: 0.21, mse_DA: 0.189, time(s): 4.9495s,
u_c taken from control states: [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
u_c before reduction of space:  [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
data[u_c] post encoding of state:  [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
J_b = 0.0, J_o = 510574.9442051032
J_b = 0.5, J_o = 16054364.663974214
J_b = 0.009469565652474574, J_o = 104391.52075020653
J_b = 0.01022615411207188, J_o = 84685.16977996737
J_b = 0.023713734883880965, J_o = 30837.925735061355
J_b = 0.029484240326273496, J_o = 24035.80828020032
J_b = 0.04031388374301339, J_o = 17259.968769235013
J_b = 0.05077462365898655, J_o = 14264.617591540955
J_b = 0.06900179025657406, J_o = 12263.686776869177
J_b = 0.07075957857617088, J_o = 10811.77054558049
J_b = 0.07231130477970527, J_o = 10070.299079841665
J_b = 0.0779943653467137, J_o = 9399.123714278217
J_b = 0.08990194529609885, J_o = 8592.472855756045
J_b = 0.10380771932026585, J_o = 8055.168855630301
J_b = 0.11597368273986902, J_o = 7687.375635836471
J_b = 0.12767274491377215, J_o = 9118.52985131261
J_b = 0.11733505985255703, J_o = 7653.113976044411
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06505457 -1.37085801 -1.40159434 -1.08727124 -1.87186454 -1.57348765
 -2.50960827 -1.84415249 -1.42293876 -1.1765777 ]
W_opt:  [ 0.01934015  0.02466241  0.01857103  0.01178321 -0.00031548 -0.01874993
 -0.04710741 -0.08822575 -0.13582765 -0.1829376 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7148 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1530, add (DA)= 0.0001decode = 0.2412 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9561 s, inc stats = 3.9691, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.74868470e-11 3.63921007e-10 4.44095001e-10 1.13726641e-10
 1.63532979e-09]
u_DA:    [-1.22053113e-09  7.36927934e-09  8.98361055e-09 -2.21172745e-09
  9.89362848e-09]
ref_MAE: [6.90894015e-09 1.01277746e-08 1.26158379e-08 8.43043560e-09
 1.88286599e-08]
da_MAE:  [1.30801798e-09 7.00535834e-09 8.53951555e-09 2.32545409e-09
 8.25829869e-09]
% 18.12825088353049 da_MAE 0.09426598205408533 ref_MAE 0.11513859551233475
u_c taken from control states: [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
u_c before reduction of space:  [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
data[u_c] post encoding of state:  [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
J_b = 0.0, J_o = 510768.31339147966
J_b = 0.49999999999999994, J_o = 16054049.659494381
J_b = 0.009467220517203516, J_o = 104717.85790430768
J_b = 0.01022530979233209, J_o = 84975.52976424579
J_b = 0.02371517009464282, J_o = 31090.769636037643
J_b = 0.029493265349744988, J_o = 24266.409353273564
J_b = 0.0404187969339561, J_o = 17421.997074237985
J_b = 0.05102329842263369, J_o = 14391.40956762598
J_b = 0.06943780399832127, J_o = 12371.269794906422
J_b = 0.0711575839375504, J_o = 10910.261043451745
J_b = 0.07274323599412053, J_o = 10159.9122008337
J_b = 0.0784861417123178, J_o = 9483.841763576964
J_b = 0.09058293073678392, J_o = 8664.6971922954
J_b = 0.10467630051792685, J_o = 8122.641748447796
J_b = 0.116777179066531, J_o = 7755.949078163092
J_b = 0.12838945749507602, J_o = 9183.437883107796
J_b = 0.1181279941191219, J_o = 7721.881822725605
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06562202 -1.37215264 -1.40216528 -1.08762168 -1.87444243 -1.5745483
 -2.51880435 -1.84675713 -1.42149798 -1.17724024]
W_opt:  [ 0.01961272  0.02479688  0.01861037  0.0119151  -0.00020367 -0.01882959
 -0.0472982  -0.08843447 -0.13594125 -0.18294091]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7234 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.1617, add (DA)= 0.0002decode = 0.2506 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9741 s, inc stats = 3.9865, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.58490690e-11 3.59746263e-10 4.41930800e-10 1.12519721e-10
 1.62055892e-09]
u_DA:    [-1.22524139e-09  7.36627249e-09  8.98263947e-09 -2.20220586e-09
  9.86818836e-09]
ref_MAE: [6.91057792e-09 1.01319494e-08 1.26180021e-08 8.43164252e-09
 1.88434307e-08]
da_MAE:  [1.31109046e-09 7.00652623e-09 8.54070867e-09 2.31472558e-09
 8.24762944e-09]
% 18.009819590166096 da_MAE 0.09453695459833956 ref_MAE 0.11530277665665534
u_c taken from control states: [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
u_c before reduction of space:  [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
data[u_c] post encoding of state:  [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
J_b = 0.0, J_o = 510886.02265336696
J_b = 0.5, J_o = 16054365.341135472
J_b = 0.009462707721148612, J_o = 105060.68266171144
J_b = 0.01022207848597008, J_o = 85288.06382460301
J_b = 0.023709555536420658, J_o = 31384.86715242641
J_b = 0.029490799090961854, J_o = 24544.28959688314
J_b = 0.0404959102128601, J_o = 17641.735620700027
J_b = 0.05122403528032823, J_o = 14580.549526028262
J_b = 0.06980631205062517, J_o = 12541.783674239818
J_b = 0.0715054127778673, J_o = 11072.35838860743
J_b = 0.07312737905024512, J_o = 10313.57140371715
J_b = 0.07892876059908642, J_o = 9632.871492963097
J_b = 0.091198475285325, J_o = 8802.590759877308
J_b = 0.10547361861900971, J_o = 8255.06883378953
J_b = 0.11759238629064574, J_o = 7887.494381020647
J_b = 0.129287059687928, J_o = 9331.937875331252
J_b = 0.11894658407317614, J_o = 7853.417768966888
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06614609 -1.3734488  -1.40273574 -1.08791274 -1.87701523 -1.57562018
 -2.52831182 -1.84938509 -1.42048653 -1.17791112]
W_opt:  [ 1.98295110e-02  2.49256049e-02  1.86242285e-02  1.20666380e-02
 -7.41250386e-05 -1.88108292e-02 -4.73081019e-02 -8.85651039e-02
 -1.36118909e-01 -1.83130974e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5897 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1521, add (DA)= 0.0001decode = 0.2380 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8278 s, inc stats = 3.8402, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.43364723e-11 3.55566605e-10 4.39768385e-10 1.11517321e-10
 1.60581724e-09]
u_DA:    [-1.22646764e-09  7.36055402e-09  8.98242483e-09 -2.19313834e-09
  9.84448045e-09]
ref_MAE: [6.91209052e-09 1.01361290e-08 1.26201646e-08 8.43264492e-09
 1.88581724e-08]
da_MAE:  [1.31080411e-09 7.00498742e-09 8.54265645e-09 2.30465566e-09
 8.23866321e-09]
% 17.92454948628202 da_MAE 0.0948316914696143 ref_MAE 0.11554209069344586
u_c taken from control states: [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
u_c before reduction of space:  [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
data[u_c] post encoding of state:  [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
J_b = 0.0, J_o = 511092.89482449676
J_b = 0.49999999999999983, J_o = 16054452.954840595
J_b = 0.009459734323416279, J_o = 105422.38143380577
J_b = 0.010220307402897984, J_o = 85620.86599358685
J_b = 0.02371260971639543, J_o = 31678.667497517086
J_b = 0.029502632658964623, J_o = 24817.380838806486
J_b = 0.04059402957454891, J_o = 17853.996579345043
J_b = 0.051454784164941064, J_o = 14760.446441654376
J_b = 0.0702136714955338, J_o = 12706.257783559984
J_b = 0.07186489992020598, J_o = 11228.33900256346
J_b = 0.07350413889053721, J_o = 10462.713301310841
J_b = 0.0793524011807641, J_o = 9777.46822922419
J_b = 0.09178782240897657, J_o = 8935.866181258167
J_b = 0.10624711227933246, J_o = 8383.148390746945
J_b = 0.11838619668916375, J_o = 8014.166474861046
J_b = 0.1301240654115531, J_o = 9458.739235625602
J_b = 0.11975042725653287, J_o = 7979.826771447308
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06661681 -1.37473018 -1.40331735 -1.08814023 -1.87957898 -1.57671152
 -2.53794754 -1.85203304 -1.42017331 -1.17857986]
W_opt:  [ 0.02001421  0.02509045  0.01878379  0.01237296  0.00018438 -0.01879626
 -0.04745126 -0.08884727 -0.13639085 -0.18338368]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7388 s, v_trunc (Latent to Reduced) = 0.0866, dec (Reduced to Full) = 0.1490, add (DA)= 0.0001decode = 0.2377 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9766 s, inc stats = 3.9901, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.29778739e-11 3.51434584e-10 4.37563745e-10 1.10733856e-10
 1.59112741e-09]
u_DA:    [-1.22978856e-09  7.35655770e-09  8.98111846e-09 -2.18573603e-09
  9.82374585e-09]
ref_MAE: [6.91344912e-09 1.01402610e-08 1.26223692e-08 8.43342839e-09
 1.88728623e-08]
da_MAE:  [1.31276643e-09 7.00512312e-09 8.54355472e-09 2.29646989e-09
 8.23261844e-09]
% 17.866501734679773 da_MAE 0.09514760362948733 ref_MAE 0.11584506399828112
u_c taken from control states: [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
u_c before reduction of space:  [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
data[u_c] post encoding of state:  [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
J_b = 0.0, J_o = 511304.19797680795
J_b = 0.5000000000000001, J_o = 16054580.873633986
J_b = 0.00945687675610625, J_o = 105781.64942099122
J_b = 0.010218570142147602, J_o = 85953.09475016409
J_b = 0.023717809982590012, J_o = 31966.85366290988
J_b = 0.02951853259900114, J_o = 25083.64900906857
J_b = 0.04069607644947087, J_o = 18060.4084979204
J_b = 0.051686331040268575, J_o = 14935.840727228246
J_b = 0.0706066060670659, J_o = 12869.514338702444
J_b = 0.07219170458836827, J_o = 11384.886832492844
J_b = 0.07383352393818562, J_o = 10614.310315156166
J_b = 0.07971393081926685, J_o = 9925.271991145688
J_b = 0.09229828340794784, J_o = 9072.873187602414
J_b = 0.10695123325247075, J_o = 8514.733776771089
J_b = 0.11913741825865205, J_o = 8143.167560049202
J_b = 0.13095886633034712, J_o = 9585.482622594685
J_b = 0.12052149122109894, J_o = 8108.308330453037
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06702788 -1.37597857 -1.40392181 -1.08830421 -1.88212966 -1.5778229
 -2.54762098 -1.85469695 -1.42058877 -1.17922935]
W_opt:  [ 0.0201132   0.02515683  0.01893773  0.01275566  0.00056363 -0.01866675
 -0.04762378 -0.08913576 -0.13666211 -0.18359038]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7418 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1595, add (DA)= 0.0001decode = 0.2478 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9897 s, inc stats = 3.9951, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.17914433e-11 3.47408930e-10 4.35272486e-10 1.10169090e-10
 1.57651248e-09]
u_DA:    [-1.23518901e-09  7.35440424e-09  8.98061372e-09 -2.18106884e-09
  9.80462119e-09]
ref_MAE: [6.91463555e-09 1.01442867e-08 1.26246605e-08 8.43399315e-09
 1.88874772e-08]
da_MAE:  [1.31698045e-09 7.00699531e-09 8.54534123e-09 2.29123793e-09
 8.22810871e-09]
% 17.829192352907864 da_MAE 0.0954509817707775 ref_MAE 0.11616166921557004
u_c taken from control states: [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
u_c before reduction of space:  [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
data[u_c] post encoding of state:  [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
J_b = 0.0, J_o = 511473.3528410989
J_b = 0.5000000000000001, J_o = 16054689.500665536
J_b = 0.009454196376977097, J_o = 106089.11962156987
J_b = 0.010216930217611924, J_o = 86235.24445828144
J_b = 0.023726445122388067, J_o = 32196.727657191008
J_b = 0.02953963968129247, J_o = 25291.705793166897
J_b = 0.0407931389147516, J_o = 18216.911294915863
J_b = 0.05188804035347537, J_o = 15068.40577634273
J_b = 0.07091209604419309, J_o = 12996.408658013217
J_b = 0.07241681917805459, J_o = 11509.274428953968
J_b = 0.07404760763494374, J_o = 10736.251554044147
J_b = 0.0799417253067252, J_o = 10044.681433368134
J_b = 0.09264018711061053, J_o = 9183.477602833325
J_b = 0.10745749347424995, J_o = 8621.442940450093
J_b = 0.11965167752174555, J_o = 8247.723372263028
J_b = 0.13153658469886037, J_o = 9678.54834153565
J_b = 0.12105946790655417, J_o = 8212.191554565452
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06737421 -1.37718091 -1.40455797 -1.08840574 -1.88466159 -1.57896089
 -2.55712603 -1.85736044 -1.42187466 -1.1798498 ]
W_opt:  [ 0.02014327  0.02515009  0.0190622   0.01307556  0.0008879  -0.01850081
 -0.04767602 -0.08927928 -0.13680066 -0.18368338]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7275 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1686, add (DA)= 0.0001decode = 0.2568 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9844 s, inc stats = 3.9898, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [8.07918373e-11 3.43531796e-10 4.32861043e-10 1.09819411e-10
 1.56200501e-09]
u_DA:    [-1.24020686e-09  7.35209663e-09  8.98040721e-09 -2.17760293e-09
  9.78791862e-09]
ref_MAE: [6.91563516e-09 1.01481638e-08 1.26270719e-08 8.43434283e-09
 1.89019847e-08]
da_MAE:  [1.32099870e-09 7.00856484e-09 8.54754617e-09 2.28742234e-09
 8.22591361e-09]
% 17.79450418243926 da_MAE 0.09570943719860649 ref_MAE 0.11642705423371588
u_c taken from control states: [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
u_c before reduction of space:  [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
data[u_c] post encoding of state:  [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
J_b = 0.0, J_o = 511687.1212163918
J_b = 0.49999999999999994, J_o = 16054503.381274967
J_b = 0.009452921599357159, J_o = 106378.34293952465
J_b = 0.0102167079983445, J_o = 86498.15677102195
J_b = 0.023746460337085842, J_o = 32378.33600551547
J_b = 0.029576931989671, J_o = 25450.071311675798
J_b = 0.04089209413468378, J_o = 18335.76382065203
J_b = 0.052060957738463344, J_o = 15171.331742521204
J_b = 0.07113291242146687, J_o = 13101.335721256095
J_b = 0.07254317024519347, J_o = 11615.3306402794
J_b = 0.07413973890435109, J_o = 10843.640470097303
J_b = 0.08001896239772648, J_o = 10151.426946048734
J_b = 0.09276492160672901, J_o = 9285.354806497078
J_b = 0.10767382103268672, J_o = 8722.180998616135
J_b = 0.11983514003584762, J_o = 8346.989387628584
J_b = 0.1317195976523793, J_o = 9752.729626318582
J_b = 0.12126627105429891, J_o = 8310.692913494146
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06765481 -1.37832177 -1.40523273 -1.08845302 -1.88717004 -1.58013055
 -2.56623256 -1.86000961 -1.42417907 -1.18044168]
W_opt:  [ 0.0201594   0.02520292  0.01913118  0.01319806  0.00101472 -0.01842073
 -0.0476348  -0.08925972 -0.136753   -0.18357713]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6319 s, v_trunc (Latent to Reduced) = 0.0838, dec (Reduced to Full) = 0.1677, add (DA)= 0.0001decode = 0.2535 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8855 s, inc stats = 3.8911, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.99819758e-11 3.39852918e-10 4.30303309e-10 1.09656587e-10
 1.54763202e-09]
u_DA:    [-1.24556602e-09  7.35030721e-09  8.98115416e-09 -2.17692634e-09
  9.77396600e-09]
ref_MAE: [6.91644502e-09 1.01518427e-08 1.26296296e-08 8.43450565e-09
 1.89163576e-08]
da_MAE:  [1.32554800e-09 7.01045429e-09 8.55085085e-09 2.28658293e-09
 8.22633398e-09]
% 17.774194063888437 da_MAE 0.09589510100354215 ref_MAE 0.11662409375233301
u_c taken from control states: [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
u_c before reduction of space:  [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
data[u_c] post encoding of state:  [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
J_b = 0.0, J_o = 511954.60192750295
J_b = 0.49999999999999983, J_o = 16053958.861412881
J_b = 0.009453166562053176, J_o = 106654.50362095729
J_b = 0.010218082624650985, J_o = 86745.3541098228
J_b = 0.023779778050719888, J_o = 32508.530664487567
J_b = 0.02963400453473159, J_o = 25553.516021915028
J_b = 0.04100193358794204, J_o = 18408.253017062634
J_b = 0.05222215570529889, J_o = 15233.924172931222
J_b = 0.07129640107482735, J_o = 13173.633808920575
J_b = 0.07259062264604055, J_o = 11691.741452559361
J_b = 0.0741284404426579, J_o = 10924.778804316804
J_b = 0.07996897667439691, J_o = 10232.831987755757
J_b = 0.09272536806748125, J_o = 9363.50084214046
J_b = 0.10770151146075405, J_o = 8800.561835457569
J_b = 0.11981148080388508, J_o = 8423.963654066738
J_b = 0.13158974263954837, J_o = 9783.429254460276
J_b = 0.12126527937663736, J_o = 8386.763194418878
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0678751  -1.37938636 -1.40595059 -1.08846073 -1.88965047 -1.58133165
 -2.5747931  -1.86263957 -1.42745101 -1.18099784]
W_opt:  [ 0.02011531  0.02522241  0.01921418  0.01332368  0.0011789  -0.01833869
 -0.04761723 -0.0892673  -0.13669661 -0.18343097]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7175 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.1637, add (DA)= 0.0001decode = 0.2523 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9699 s, inc stats = 3.9821, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.93461701e-11 3.36419975e-10 4.27582182e-10 1.09630025e-10
 1.53341958e-09]
u_DA:    [-1.25139036e-09  7.34929083e-09  8.98321742e-09 -2.17715214e-09
  9.76284393e-09]
ref_MAE: [6.91708082e-09 1.01552756e-08 1.26323508e-08 8.43453222e-09
 1.89305701e-08]
da_MAE:  [1.33073653e-09 7.01287086e-09 8.55563524e-09 2.28678217e-09
 8.22942435e-09]
% 17.782951466078885 da_MAE 0.09598983044207153 ref_MAE 0.11675173477246394
u_c taken from control states: [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
u_c before reduction of space:  [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
data[u_c] post encoding of state:  [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
J_b = 0.0, J_o = 512246.1451552645
J_b = 0.49999999999999983, J_o = 16053451.638703523
J_b = 0.009453935974695666, J_o = 106927.63377327299
J_b = 0.010219814227081977, J_o = 86993.04516240605
J_b = 0.023821449576648127, J_o = 32618.77069542086
J_b = 0.029704308831795444, J_o = 25635.470538503145
J_b = 0.04111392695987371, J_o = 18469.10753074467
J_b = 0.052364296088466225, J_o = 15290.193088361455
J_b = 0.07141055713548913, J_o = 13245.231242021166
J_b = 0.07258278802975619, J_o = 11768.373192530755
J_b = 0.07404974957609087, J_o = 11007.869201355861
J_b = 0.07984176849901366, J_o = 10316.241363945746
J_b = 0.09258767344785811, J_o = 9444.611339335002
J_b = 0.1076227118989378, J_o = 8882.171069740227
J_b = 0.11971189625611497, J_o = 8503.079158143622
J_b = 0.13138891876936853, J_o = 9809.377810531536
J_b = 0.12119710761692085, J_o = 8464.691370011082
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06803898 -1.38036295 -1.40671476 -1.08844533 -1.89209962 -1.58256353
 -2.58265028 -1.86524095 -1.43158242 -1.18150579]
W_opt:  [ 0.02019872  0.02531471  0.01929231  0.0134268   0.00130649 -0.01832928
 -0.0476335  -0.08927616 -0.13670551 -0.1834027 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6788 s, v_trunc (Latent to Reduced) = 0.0859, dec (Reduced to Full) = 0.1859, add (DA)= 0.0001decode = 0.2744 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9533 s, inc stats = 3.9604, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.88731771e-11 3.33270811e-10 4.24685511e-10 1.09683063e-10
 1.51938640e-09]
u_DA:    [-1.25633940e-09  7.34869615e-09  8.98684869e-09 -2.17875824e-09
  9.75601687e-09]
ref_MAE: [6.91755382e-09 1.01584248e-08 1.26352474e-08 8.43447918e-09
 1.89446033e-08]
da_MAE:  [1.33521258e-09 7.01542534e-09 8.56216318e-09 2.28844130e-09
 8.23663047e-09]
% 17.885205678977133 da_MAE 0.09591951435808321 ref_MAE 0.11681148951441274
u_c taken from control states: [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
u_c before reduction of space:  [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
data[u_c] post encoding of state:  [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
J_b = 0.0, J_o = 512637.29378300434
J_b = 0.5000000000000001, J_o = 16052691.789080359
J_b = 0.009455091225389642, J_o = 107289.88095674467
J_b = 0.010222327687900403, J_o = 87319.50484377943
J_b = 0.023877982561135592, J_o = 32759.10717089477
J_b = 0.029798157787297153, J_o = 25739.84625989195
J_b = 0.041254660077760165, J_o = 18550.556066810652
J_b = 0.052539121660397134, J_o = 15365.568643666275
J_b = 0.0715669066513561, J_o = 13339.087879288343
J_b = 0.07259693116879273, J_o = 11866.33855768037
J_b = 0.07397217552154162, J_o = 11114.086644703968
J_b = 0.07970573898390673, J_o = 10421.783294767163
J_b = 0.09244706767790858, J_o = 9546.704269957027
J_b = 0.10756084469150047, J_o = 8984.541483010154
J_b = 0.11966312502653387, J_o = 8601.187864742793
J_b = 0.1312418933275545, J_o = 9837.481592658172
J_b = 0.12119938698717843, J_o = 8560.976984836907
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06815381 -1.38123741 -1.40752696 -1.08842907 -1.89451515 -1.58382754
 -2.58960336 -1.86780575 -1.43639779 -1.18195951]
W_opt:  [ 0.02074508  0.02536007  0.0193507   0.01350306  0.00138924 -0.01837003
 -0.04774676 -0.08939925 -0.13684181 -0.1834946 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7158 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.1706, add (DA)= 0.0001decode = 0.2590 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9749 s, inc stats = 3.9872, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.85417440e-11 3.30450985e-10 4.21606783e-10 1.09739088e-10
 1.50554586e-09]
u_DA:    [-1.26240183e-09  7.34759213e-09  8.99115822e-09 -2.18214614e-09
  9.74596991e-09]
ref_MAE: [6.91788525e-09 1.01612446e-08 1.26383262e-08 8.43442315e-09
 1.89584438e-08]
da_MAE:  [1.34094358e-09 7.01714114e-09 8.56955144e-09 2.29188522e-09
 8.24042405e-09]
% 18.0722328461787 da_MAE 0.09575766924067775 ref_MAE 0.1168806041801316
\% improve_point: 9.10, mse_ref_points: 1.3517294472565113e-05, mse_da_points: 1.2234551714033505e-05, % improve_overlap: 15.38, mse_ref_overlap: 0.21176, mse_da_overlap: 0.17860
DA - - L2: 2839.48, L1: 3853.77, % Improve: 17.71%, DA_MAE: 0.08, mse_ref: 0.22, mse_DA: 0.198, time(s): 4.8106s,
u_c taken from control states: [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
u_c before reduction of space:  [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
data[u_c] post encoding of state:  [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
J_b = 0.0, J_o = 512963.57879800966
J_b = 0.5000000000000001, J_o = 16052501.398219354
J_b = 0.009454641756567368, J_o = 107652.56613939287
J_b = 0.01022292464318143, J_o = 87654.16536536056
J_b = 0.023930589191309734, J_o = 32919.04529104207
J_b = 0.02988798951798025, J_o = 25865.286018871673
J_b = 0.04138612961420419, J_o = 18656.638961208308
J_b = 0.05270562837178718, J_o = 15464.589065347718
J_b = 0.07173331865292515, J_o = 13457.825610089129
J_b = 0.07261579108467828, J_o = 11987.349220549757
J_b = 0.07388877309048196, J_o = 11244.377841337355
J_b = 0.07955883783711797, J_o = 10550.639666725136
J_b = 0.09230389154653156, J_o = 9670.761560820618
J_b = 0.10754511544669261, J_o = 9106.06743656566
J_b = 0.11981200823213563, J_o = 8714.949495243112
J_b = 0.13137394488580073, J_o = 9879.08825112412
J_b = 0.12142223140537914, J_o = 8672.366642220724
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06823303 -1.38199336 -1.40838826 -1.08843764 -1.89689656 -1.5851098
 -2.59569659 -1.87032706 -1.44132572 -1.18234946]
W_opt:  [ 0.02091322  0.02514259  0.01947149  0.0137424   0.00164038 -0.01822882
 -0.04756446 -0.0892741  -0.1368561  -0.1836652 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7562 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.1588, add (DA)= 0.0001decode = 0.2473 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.0036 s, inc stats = 4.0128, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.83131012e-11 3.28013300e-10 4.18341945e-10 1.09709579e-10
 1.49190079e-09]
u_DA:    [-1.26905331e-09  7.34775281e-09  8.99681660e-09 -2.18815995e-09
  9.73991265e-09]
ref_MAE: [6.91811389e-09 1.01636823e-08 1.26415910e-08 8.43445266e-09
 1.89720889e-08]
da_MAE:  [1.34736641e-09 7.01973951e-09 8.57847465e-09 2.29786953e-09
 8.24801186e-09]
% 18.42773149641249 da_MAE 0.09554329715608521 ref_MAE 0.1171271792593132
u_c taken from control states: [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
u_c before reduction of space:  [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
data[u_c] post encoding of state:  [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
J_b = 0.0, J_o = 513268.46543048497
J_b = 0.49999999999999983, J_o = 16052450.113283489
J_b = 0.009453834857313293, J_o = 108007.89321287483
J_b = 0.010223059571145223, J_o = 87984.16910943146
J_b = 0.023980619430923947, J_o = 33081.49127014256
J_b = 0.029976073667117794, J_o = 25991.057841148664
J_b = 0.041530517164091216, J_o = 18752.555660378886
J_b = 0.05291848551058833, J_o = 15544.655291569547
J_b = 0.07200948782627285, J_o = 13554.708616862416
J_b = 0.07272943371970604, J_o = 12082.674446338096
J_b = 0.07389250755869671, J_o = 11349.082742818038
J_b = 0.07949589472271144, J_o = 10653.559739693375
J_b = 0.09224770908777999, J_o = 9768.193970111686
J_b = 0.10761217286782748, J_o = 9200.421069673106
J_b = 0.12007983258120017, J_o = 8801.292910621922
J_b = 0.13154773758865027, J_o = 9875.63371846588
J_b = 0.12177255095472625, J_o = 8756.020274236671
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06828953 -1.38262548 -1.40929623 -1.08849472 -1.89924437 -1.58639266
 -2.60114918 -1.87279587 -1.4457428  -1.18266342]
W_opt:  [ 0.02141594  0.02524428  0.01956559  0.01387747  0.00175056 -0.01827953
 -0.04766171 -0.08937187 -0.13701169 -0.18393825]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7321 s, v_trunc (Latent to Reduced) = 0.0865, dec (Reduced to Full) = 0.1869, add (DA)= 0.0001decode = 0.2759 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0081 s, inc stats = 4.0199, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.81500293e-11 3.25974916e-10 4.14900206e-10 1.09512990e-10
 1.47844825e-09]
u_DA:    [-1.27672459e-09  7.34913591e-09  9.00164126e-09 -2.19515663e-09
  9.73370784e-09]
ref_MAE: [6.91827696e-09 1.01657207e-08 1.26450327e-08 8.43464925e-09
 1.89855414e-08]
da_MAE:  [1.35487462e-09 7.02316100e-09 8.58674106e-09 2.30466962e-09
 8.25525959e-09]
% 18.957066738813158 da_MAE 0.09533360103572683 ref_MAE 0.11763345328146468
u_c taken from control states: [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
u_c before reduction of space:  [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
data[u_c] post encoding of state:  [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
J_b = 0.0, J_o = 513475.5111737174
J_b = 0.5, J_o = 16052677.218336549
J_b = 0.009451564720117435, J_o = 108330.18368683188
J_b = 0.010221682686808078, J_o = 88283.09963572457
J_b = 0.024017016237077374, J_o = 33250.41059349573
J_b = 0.030041538402085257, J_o = 26130.998123137404
J_b = 0.041641111602048995, J_o = 18867.72712417708
J_b = 0.05308187235535444, J_o = 15647.639701758952
J_b = 0.07221446852308137, J_o = 13671.030569578943
J_b = 0.07280479740954383, J_o = 12198.790868031472
J_b = 0.07388068828980439, J_o = 11473.02559827184
J_b = 0.0794280040043934, J_o = 10775.88409370663
J_b = 0.09219877950887424, J_o = 9884.959723326272
J_b = 0.10770642218621028, J_o = 9313.383726986416
J_b = 0.12035546727710147, J_o = 8906.60908622107
J_b = 0.1318156679266776, J_o = 9908.257859115654
J_b = 0.12213809350107117, J_o = 8858.543071307105
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06833407 -1.38314047 -1.41024868 -1.08861693 -1.90156133 -1.58766938
 -2.60606655 -1.87521016 -1.44945858 -1.18291475]
W_opt:  [ 0.02148944  0.02538492  0.01957077  0.01388323  0.00184246 -0.01820106
 -0.04758702 -0.08936117 -0.13710113 -0.18410723]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8088 s, v_trunc (Latent to Reduced) = 0.0918, dec (Reduced to Full) = 0.1493, add (DA)= 0.0001decode = 0.2434 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0523 s, inc stats = 4.0597, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.80214742e-11 3.24314247e-10 4.11289852e-10 1.09092090e-10
 1.46517247e-09]
u_DA:    [-1.28460300e-09  7.34988090e-09  9.00382698e-09 -2.20238240e-09
  9.72426538e-09]
ref_MAE: [6.91840552e-09 1.01673814e-08 1.26486431e-08 8.43507015e-09
 1.89988172e-08]
da_MAE:  [1.36262448e-09 7.02556665e-09 8.59253713e-09 2.31147449e-09
 8.25909291e-09]
% 19.50694100443598 da_MAE 0.09520370545457167 ref_MAE 0.11827567077531288
u_c taken from control states: [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
u_c before reduction of space:  [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
data[u_c] post encoding of state:  [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
J_b = 0.0, J_o = 513619.7662388358
J_b = 0.49999999999999983, J_o = 16053269.776712194
J_b = 0.00944862656849283, J_o = 108612.57626276057
J_b = 0.010219238023697277, J_o = 88552.57820870556
J_b = 0.024038050725591186, J_o = 33440.43038894668
J_b = 0.030080827861892843, J_o = 26303.318360250374
J_b = 0.04170701334624619, J_o = 19025.25205816399
J_b = 0.05318727239893852, J_o = 15794.973563624604
J_b = 0.07237412832857631, J_o = 13826.346296454942
J_b = 0.07287772620798363, J_o = 12352.081117571399
J_b = 0.07388718832564936, J_o = 11632.348539257246
J_b = 0.07939264589012857, J_o = 10933.38148804074
J_b = 0.09218840566320517, J_o = 10037.561767822961
J_b = 0.10781951249828568, J_o = 9462.516508178564
J_b = 0.12062584000191096, J_o = 9049.20136400249
J_b = 0.1321021303953425, J_o = 9992.172473957571
J_b = 0.1224925765273103, J_o = 8998.565130658697
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06837952 -1.3835525  -1.41123831 -1.088816   -1.90385177 -1.58892882
 -2.61065791 -1.87757052 -1.45228555 -1.18311835]
W_opt:  [ 0.02167734  0.02552453  0.01957269  0.01388852  0.00195602 -0.01809869
 -0.04751027 -0.0894161  -0.1373232  -0.18445845]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5892 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1501, add (DA)= 0.0001decode = 0.2358 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8252 s, inc stats = 3.8307, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.78902776e-11 3.22985597e-10 4.07538538e-10 1.08406505e-10
 1.45204868e-09]
u_DA:    [-1.29228185e-09  7.35255562e-09  9.00467651e-09 -2.21090634e-09
  9.71828393e-09]
ref_MAE: [6.91853672e-09 1.01687100e-08 1.26523944e-08 8.43575574e-09
 1.90119410e-08]
da_MAE:  [1.37017213e-09 7.02957002e-09 8.59713797e-09 2.31931285e-09
 8.26623526e-09]
% 20.130721044376816 da_MAE 0.0951087508284961 ref_MAE 0.11908051765603173
u_c taken from control states: [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
u_c before reduction of space:  [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
data[u_c] post encoding of state:  [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
J_b = 0.0, J_o = 513642.5661225709
J_b = 0.5000000000000001, J_o = 16054181.21499962
J_b = 0.009445276624216868, J_o = 108783.03299110362
J_b = 0.0102158647116595, J_o = 88723.5385401192
J_b = 0.02404123887148153, J_o = 33591.65826366258
J_b = 0.030090769540488532, J_o = 26448.837953966875
J_b = 0.04172187662923434, J_o = 19168.18039051794
J_b = 0.05321817380426167, J_o = 15932.77934915973
J_b = 0.07244327136881222, J_o = 13969.239269643747
J_b = 0.07289637421129119, J_o = 12493.66820939358
J_b = 0.07385466073146764, J_o = 11779.667385499199
J_b = 0.07931711819670803, J_o = 11080.882527415308
J_b = 0.09209096645305166, J_o = 10184.390257536104
J_b = 0.1077486734332595, J_o = 9608.352898142879
J_b = 0.12065109189104713, J_o = 9191.34748111757
J_b = 0.1321280013707605, J_o = 10093.452357019725
J_b = 0.1225761884696445, J_o = 9138.955713293079
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06843804 -1.38388633 -1.41225315 -1.08909981 -1.90612033 -1.59016202
 -2.61516974 -1.87987066 -1.45410954 -1.18329176]
W_opt:  [ 0.02187042  0.02560075  0.01962752  0.01392301  0.00195836 -0.01813153
 -0.04752811 -0.08949623 -0.13746491 -0.18466377]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6599 s, v_trunc (Latent to Reduced) = 0.0840, dec (Reduced to Full) = 0.1552, add (DA)= 0.0001decode = 0.2412 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9013 s, inc stats = 3.9122, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.77213780e-11 3.21909120e-10 4.03691696e-10 1.07429070e-10
 1.43905023e-09]
u_DA:    [-1.29861197e-09  7.35557515e-09  9.00332359e-09 -2.22042301e-09
  9.71375396e-09]
ref_MAE: [6.91870562e-09 1.01697865e-08 1.26562412e-08 8.43673317e-09
 1.90249394e-08]
da_MAE:  [1.37633335e-09 7.03366603e-09 8.59963190e-09 2.32785208e-09
 8.27470373e-09]
% 20.693013427974492 da_MAE 0.09505507478439719 ref_MAE 0.11985712595203638
u_c taken from control states: [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
u_c before reduction of space:  [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
data[u_c] post encoding of state:  [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
J_b = 0.0, J_o = 513641.3179372854
J_b = 0.49999999999999994, J_o = 16055064.378018543
J_b = 0.009442119610540839, J_o = 108919.71636330226
J_b = 0.0102126060856835, J_o = 88862.84703592962
J_b = 0.024040273385170504, J_o = 33725.03132051269
J_b = 0.03009403907814087, J_o = 26578.700631747415
J_b = 0.04172628607863323, J_o = 19297.494826078506
J_b = 0.05323032179970677, J_o = 16059.337811597914
J_b = 0.07247366727594541, J_o = 14101.30506504488
J_b = 0.07288066220523891, J_o = 12626.051183149038
J_b = 0.07379111590121491, J_o = 11918.28342355032
J_b = 0.0792022884650946, J_o = 11221.686188640522
J_b = 0.09190763724503372, J_o = 10327.884658719719
J_b = 0.10751721152948122, J_o = 9752.525327201432
J_b = 0.12048886183163227, J_o = 9333.864598028875
J_b = 0.13191040188876352, J_o = 10201.416438780778
J_b = 0.12244980709814599, J_o = 9280.389707032147
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.0685184  -1.38417347 -1.41327988 -1.08947724 -1.90837153 -1.59136932
 -2.6197029  -1.88210854 -1.45509325 -1.18345926]
W_opt:  [ 0.02192254  0.02565491  0.01960749  0.01392607  0.00195151 -0.01816648
 -0.04755006 -0.08955631 -0.13749156 -0.18468755]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7816 s, v_trunc (Latent to Reduced) = 0.0868, dec (Reduced to Full) = 0.1689, add (DA)= 0.0001decode = 0.2578 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0395 s, inc stats = 4.0453, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.74894442e-11 3.20983183e-10 3.99799777e-10 1.06129207e-10
 1.42615128e-09]
u_DA:    [-1.30397389e-09  7.35779243e-09  9.00167877e-09 -2.22885827e-09
  9.70924653e-09]
ref_MAE: [6.91893755e-09 1.01707124e-08 1.26601332e-08 8.43803303e-09
 1.90378384e-08]
da_MAE:  [1.38146333e-09 7.03680924e-09 8.60187899e-09 2.33498748e-09
 8.28309525e-09]
% 21.143856099551602 da_MAE 0.09507877503324987 ref_MAE 0.12057243777134431
u_c taken from control states: [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
u_c before reduction of space:  [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
data[u_c] post encoding of state:  [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
J_b = 0.0, J_o = 513639.41425087966
J_b = 0.49999999999999994, J_o = 16056016.97548004
J_b = 0.009438453696406718, J_o = 109079.86759610081
J_b = 0.01020891513441467, J_o = 89023.89830035766
J_b = 0.02403698856557777, J_o = 33885.26246982798
J_b = 0.030092195434846494, J_o = 26738.097682777458
J_b = 0.04172096272935738, J_o = 19458.616236303882
J_b = 0.0532287962571809, J_o = 16218.183342426142
J_b = 0.07249540582929107, J_o = 14262.688562810923
J_b = 0.07287864092282752, J_o = 12786.591575125509
J_b = 0.07375633326927299, J_o = 12083.21176591438
J_b = 0.07913071410362998, J_o = 11388.557339101015
J_b = 0.09176793237435826, J_o = 10498.394562317208
J_b = 0.10729090277505743, J_o = 9924.366113867942
J_b = 0.12033236343619977, J_o = 9504.914102639308
J_b = 0.13173301502799556, J_o = 10350.901133046682
J_b = 0.12231783287237409, J_o = 9450.8056710692
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06862947 -1.38444337 -1.4143054  -1.08992941 -1.91060747 -1.59255778
 -2.62419054 -1.88429163 -1.45561721 -1.18364701]
W_opt:  [ 0.02206721  0.02584029  0.01953891  0.0137807   0.00186135 -0.01819743
 -0.04754193 -0.0895536  -0.13747948 -0.18466394]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6295 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1858, add (DA)= 0.0001decode = 0.2720 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9017 s, inc stats = 3.9066, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.71688621e-11 3.20112855e-10 3.95912419e-10 1.04571922e-10
 1.41333972e-09]
u_DA:    [-1.30663902e-09  7.35905137e-09  9.00103982e-09 -2.23416347e-09
  9.70777114e-09]
ref_MAE: [6.91925813e-09 1.01715828e-08 1.26640205e-08 8.43959032e-09
 1.90506499e-08]
da_MAE:  [1.38380788e-09 7.03893851e-09 8.60512740e-09 2.33873539e-09
 8.29443142e-09]
% 21.490551219910312 da_MAE 0.09526873847243933 ref_MAE 0.12134684417323265
u_c taken from control states: [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
u_c before reduction of space:  [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
data[u_c] post encoding of state:  [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
J_b = 0.0, J_o = 513679.8839603903
J_b = 0.5000000000000001, J_o = 16056780.212102411
J_b = 0.009434989356392923, J_o = 109278.14633937404
J_b = 0.010205668066714288, J_o = 89217.24652338962
J_b = 0.024033868994370693, J_o = 34074.16393520685
J_b = 0.03009019889273168, J_o = 26924.46412879797
J_b = 0.04172649666551141, J_o = 19638.593130695295
J_b = 0.05325354048420017, J_o = 16392.44937245963
J_b = 0.07255745521340681, J_o = 14436.930752459717
J_b = 0.0729161206648113, J_o = 12959.456686940212
J_b = 0.07377024322043345, J_o = 12258.821668593147
J_b = 0.07911934468566101, J_o = 11565.69123730722
J_b = 0.09170546714543423, J_o = 10678.298474887679
J_b = 0.10715322518403299, J_o = 10104.928357472945
J_b = 0.12028775977653482, J_o = 9684.632781923057
J_b = 0.13168126093192814, J_o = 10516.457363755688
J_b = 0.12228985718370716, J_o = 9630.186079032348
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06878223 -1.38471734 -1.41531822 -1.09042688 -1.91283142 -1.59372251
 -2.62870351 -1.88642241 -1.4557813  -1.18386685]
W_opt:  [ 0.02214712  0.02603685  0.01948464  0.01362506  0.00185219 -0.01813258
 -0.04745715 -0.08951727 -0.13749801 -0.18471482]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6393 s, v_trunc (Latent to Reduced) = 0.0838, dec (Reduced to Full) = 0.1611, add (DA)= 0.0001decode = 0.2470 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8864 s, inc stats = 3.8998, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.67279780e-11 3.19229407e-10 3.92073227e-10 1.02858662e-10
 1.40059691e-09]
u_DA:    [-1.30837448e-09  7.35898640e-09  9.00134529e-09 -2.23681565e-09
  9.70544536e-09]
ref_MAE: [6.91969902e-09 1.01724662e-08 1.26678597e-08 8.44130358e-09
 1.90633927e-08]
da_MAE:  [1.38510246e-09 7.03975699e-09 8.60927206e-09 2.33967431e-09
 8.30484845e-09]
% 21.700022030874106 da_MAE 0.09563444410059586 ref_MAE 0.12213853257826592
u_c taken from control states: [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
u_c before reduction of space:  [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
data[u_c] post encoding of state:  [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
J_b = 0.0, J_o = 513723.6237682969
J_b = 0.4999999999999999, J_o = 16057307.689810835
J_b = 0.009432265086385484, J_o = 109448.18221731443
J_b = 0.010203217372758795, J_o = 89381.10396929187
J_b = 0.024028448846296176, J_o = 34242.08720893983
J_b = 0.030082818020568215, J_o = 27092.51791888446
J_b = 0.04172162819587626, J_o = 19802.94492860828
J_b = 0.05325771946849224, J_o = 16553.54633773344
J_b = 0.07258577565872316, J_o = 14595.55523747377
J_b = 0.07294384423086789, J_o = 13117.194700843293
J_b = 0.07379016429107521, J_o = 12417.989492075169
J_b = 0.07912181101504644, J_o = 11727.425017141795
J_b = 0.0916313847363092, J_o = 10845.631022561225
J_b = 0.10692788876552374, J_o = 10275.519979560258
J_b = 0.12006271448988053, J_o = 9857.406956101975
J_b = 0.13141493845334437, J_o = 10691.811679277878
J_b = 0.12204554356024183, J_o = 9803.631965901342
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06898096 -1.38501567 -1.41630642 -1.09094483 -1.91504545 -1.59485751
 -2.63340717 -1.88850201 -1.455513   -1.18411426]
W_opt:  [ 0.02234842  0.02616418  0.01938794  0.01337552  0.00172877 -0.01815015
 -0.04743327 -0.08948537 -0.13745774 -0.18462297]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7624 s, v_trunc (Latent to Reduced) = 0.0869, dec (Reduced to Full) = 0.1679, add (DA)= 0.0001decode = 0.2571 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0196 s, inc stats = 4.0248, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.61543931e-11 3.18267385e-10 3.88327355e-10 1.01074843e-10
 1.38791090e-09]
u_DA:    [-1.30841440e-09  7.35781818e-09  9.00146955e-09 -2.23762034e-09
  9.70182999e-09]
ref_MAE: [6.92027260e-09 1.01734282e-08 1.26716056e-08 8.44308740e-09
 1.90760788e-08]
da_MAE:  [1.38456879e-09 7.03955080e-09 8.61314220e-09 2.33869518e-09
 8.31391909e-09]
% 21.814607061665058 da_MAE 0.09604862805601529 ref_MAE 0.12284727932718728
u_c taken from control states: [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
u_c before reduction of space:  [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
data[u_c] post encoding of state:  [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
J_b = 0.0, J_o = 513818.18454605615
J_b = 0.5000000000000001, J_o = 16057632.120540218
J_b = 0.009429819583809102, J_o = 109661.42646867584
J_b = 0.010201300588917932, J_o = 89581.87661277724
J_b = 0.02402597735796586, J_o = 34435.16094417889
J_b = 0.030079742048097623, J_o = 27283.078923424648
J_b = 0.041730016002509016, J_o = 19983.585906047134
J_b = 0.053286367217333985, J_o = 16728.500627024616
J_b = 0.07264520354849105, J_o = 14767.501553577036
J_b = 0.07299510542505078, J_o = 13288.047437846742
J_b = 0.07383621381263698, J_o = 12589.429078014582
J_b = 0.07915696521252173, J_o = 11900.89686743473
J_b = 0.09160400212453482, J_o = 11023.782159582719
J_b = 0.10675765395402004, J_o = 10456.322925528419
J_b = 0.11992502673936715, J_o = 10040.164812571607
J_b = 0.13121972035392013, J_o = 10875.478084389659
J_b = 0.12188645687289273, J_o = 9987.145771129766
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06922244 -1.38535575 -1.41726143 -1.09146228 -1.91725063 -1.59597174
 -2.63820972 -1.89053751 -1.45509987 -1.18439563]
W_opt:  [ 0.02236679  0.02631221  0.01939262  0.01318678  0.00167399 -0.01810709
 -0.04740922 -0.08948016 -0.13747193 -0.18457314]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7202 s, v_trunc (Latent to Reduced) = 0.0865, dec (Reduced to Full) = 0.1534, add (DA)= 0.0001decode = 0.2420 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9622 s, inc stats = 3.9745, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.54574258e-11 3.17170753e-10 3.84707296e-10 9.92927499e-11
 1.37527558e-09]
u_DA:    [-1.30704502e-09  7.35443884e-09  9.00293995e-09 -2.23568252e-09
  9.69536153e-09]
ref_MAE: [6.92096957e-09 1.01745249e-08 1.26752256e-08 8.44486949e-09
 1.90887141e-08]
da_MAE:  [1.38250244e-09 7.03726809e-09 8.61823266e-09 2.33497527e-09
 8.32008595e-09]
% 21.848644124921236 da_MAE 0.09654657992591476 ref_MAE 0.12353794613651986
\% improve_point: 9.75, mse_ref_points: 1.4142139379863062e-05, mse_da_points: 1.2688624504913638e-05, % improve_overlap: 15.50, mse_ref_overlap: 0.22239, mse_da_overlap: 0.18733
DA - - L2: 3182.87, L1: 4068.27, % Improve: 18.06%, DA_MAE: 0.08, mse_ref: 0.23, mse_DA: 0.206, time(s): 4.7071s,
u_c taken from control states: [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
u_c before reduction of space:  [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
data[u_c] post encoding of state:  [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
J_b = 0.0, J_o = 513986.9052240937
J_b = 0.5, J_o = 16057881.662780732
J_b = 0.009427299032901848, J_o = 109956.52411212391
J_b = 0.010199554329156113, J_o = 89858.31627347117
J_b = 0.024028981441672127, J_o = 34683.30520055294
J_b = 0.030086436092460554, J_o = 27523.094084475277
J_b = 0.041763593391413605, J_o = 20203.902201410678
J_b = 0.0533598025645441, J_o = 16938.720791590138
J_b = 0.0727699019033939, J_o = 14973.649499625604
J_b = 0.07310239653856321, J_o = 13491.567684142865
J_b = 0.07394314815665061, J_o = 12791.902778910478
J_b = 0.07926647861757602, J_o = 12104.182670536647
J_b = 0.09167701361909543, J_o = 11230.168006775622
J_b = 0.10670820103630305, J_o = 10664.494422435191
J_b = 0.11994386893209381, J_o = 10249.318203130495
J_b = 0.1312473529036817, J_o = 11088.662596887998
J_b = 0.12189550909121642, J_o = 10196.82667593541
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06950484 -1.3857448  -1.41817738 -1.09196509 -1.91944687 -1.59707037
 -2.6430196  -1.89253414 -1.45478653 -1.18471312]
W_opt:  [ 0.02259111  0.0265879   0.01939262  0.01288281  0.00145724 -0.01817094
 -0.04738929 -0.08943719 -0.13746309 -0.18451857]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6994 s, v_trunc (Latent to Reduced) = 0.0863, dec (Reduced to Full) = 0.1454, add (DA)= 0.0001decode = 0.2338 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9333 s, inc stats = 3.9386, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.46423502e-11 3.15916177e-10 3.81235317e-10 9.75610792e-11
 1.36269157e-09]
u_DA:    [-1.30440741e-09  7.34909363e-09  9.00661731e-09 -2.23158846e-09
  9.68812259e-09]
ref_MAE: [6.92178464e-09 1.01757794e-08 1.26786976e-08 8.44660116e-09
 1.91012981e-08]
da_MAE:  [1.37904976e-09 7.03317745e-09 8.62538199e-09 2.32914954e-09
 8.32543102e-09]
% 21.788547266925267 da_MAE 0.0971923123405811 ref_MAE 0.12426864473708922
u_c taken from control states: [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
u_c before reduction of space:  [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
data[u_c] post encoding of state:  [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
J_b = 0.0, J_o = 514160.75313545094
J_b = 0.5, J_o = 16058286.741461087
J_b = 0.009424351056674597, J_o = 110274.61617017258
J_b = 0.010197339233177248, J_o = 90158.56040137046
J_b = 0.024035708867196585, J_o = 34943.15281781387
J_b = 0.03010069096406902, J_o = 27771.57511110357
J_b = 0.041809431953765436, J_o = 20430.520052479114
J_b = 0.05345279813973394, J_o = 17153.529220838816
J_b = 0.07292380255454792, J_o = 15186.37743080135
J_b = 0.07322468552140395, J_o = 13700.494112707003
J_b = 0.07405906057146708, J_o = 12999.785494412463
J_b = 0.07938767965363366, J_o = 12311.74329219145
J_b = 0.09178110157538964, J_o = 11439.012565918645
J_b = 0.10673153955751971, J_o = 10873.025950111321
J_b = 0.12014435409972259, J_o = 10456.236640034103
J_b = 0.13151435893692043, J_o = 11287.526054399676
J_b = 0.12211886121243376, J_o = 10403.471688532574
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.06982202 -1.38618205 -1.41904896 -1.09244164 -1.92163063 -1.59815915
 -2.64768762 -1.89448856 -1.45481491 -1.18505793]
W_opt:  [ 0.02290581  0.02683443  0.01931222  0.01253517  0.00123963 -0.01820986
 -0.04727708 -0.08928393 -0.13736603 -0.18447961]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6786 s, v_trunc (Latent to Reduced) = 0.0915, dec (Reduced to Full) = 0.1428, add (DA)= 0.0001decode = 0.2364 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9150 s, inc stats = 3.9210, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.37268865e-11 3.14506198e-10 3.77931506e-10 9.59198611e-11
 1.35017899e-09]
u_DA:    [-1.30111814e-09  7.34253292e-09  9.01330912e-09 -2.22804948e-09
  9.68359808e-09]
ref_MAE: [6.92270011e-09 1.01771894e-08 1.26820014e-08 8.44824238e-09
 1.91138107e-08]
da_MAE:  [1.37484503e-09 7.02802672e-09 8.63537762e-09 2.32396934e-09
 8.33341909e-09]
% 21.698729570750267 da_MAE 0.0979242359671986 ref_MAE 0.12506085205307044
u_c taken from control states: [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
u_c before reduction of space:  [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
data[u_c] post encoding of state:  [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
J_b = 0.0, J_o = 514364.05339455104
J_b = 0.5000000000000001, J_o = 16058844.228847494
J_b = 0.00942073732623467, J_o = 110652.88566302293
J_b = 0.010194560986153954, J_o = 90515.96232769378
J_b = 0.02405355633066712, J_o = 35222.161734119254
J_b = 0.030136914392079873, J_o = 28028.440678179762
J_b = 0.041896700340415184, J_o = 20654.928800327285
J_b = 0.053610412818730434, J_o = 17361.150622562094
J_b = 0.07316001039561894, J_o = 15396.671656305094
J_b = 0.07338637305484925, J_o = 13905.674226197247
J_b = 0.07419592481812373, J_o = 13204.754354417546
J_b = 0.0795269872211464, J_o = 12514.485538998779
J_b = 0.09194279352694272, J_o = 11638.869537287435
J_b = 0.10691223262958861, J_o = 11069.00540391758
J_b = 0.12063222481805466, J_o = 10646.884600442867
J_b = 0.13206320255436746, J_o = 11433.990713336028
J_b = 0.12268874458318334, J_o = 10592.179697416579
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07015904 -1.38665275 -1.41987341 -1.09288493 -1.92379835 -1.59924389
 -2.65198313 -1.89639429 -1.45543639 -1.18541905]
W_opt:  [ 0.02336953  0.02701683  0.01907896  0.01210867  0.00103046 -0.01816386
 -0.04699531 -0.08899959 -0.13727985 -0.18458906]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6044 s, v_trunc (Latent to Reduced) = 0.0834, dec (Reduced to Full) = 0.1585, add (DA)= 0.0001decode = 0.2446 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8492 s, inc stats = 3.8582, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.27541800e-11 3.12988373e-10 3.74806320e-10 9.43931489e-11
 1.33775832e-09]
u_DA:    [-1.30004397e-09  7.33566275e-09  9.02335656e-09 -2.22501630e-09
  9.67743289e-09]
ref_MAE: [6.92367281e-09 1.01787072e-08 1.26851266e-08 8.44976909e-09
 1.91262313e-08]
da_MAE:  [1.37279815e-09 7.02267438e-09 8.64855024e-09 2.31940945e-09
 8.33967457e-09]
% 21.650510998565554 da_MAE 0.09869267946645208 ref_MAE 0.12596467535945918
u_c taken from control states: [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
u_c before reduction of space:  [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
data[u_c] post encoding of state:  [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
J_b = 0.0, J_o = 514567.23805055337
J_b = 0.5, J_o = 16059331.675829973
J_b = 0.009417871199983965, J_o = 110994.74613729463
J_b = 0.01019239118681259, J_o = 90839.87678150996
J_b = 0.024078840962297007, J_o = 35449.415782792596
J_b = 0.030186128776004434, J_o = 28230.047509359618
J_b = 0.04199572510066624, J_o = 20826.898788620594
J_b = 0.05377556839229607, J_o = 17517.526135516284
J_b = 0.07339503799253407, J_o = 15560.650941349537
J_b = 0.07352808285182981, J_o = 14064.458332681457
J_b = 0.07429826973582213, J_o = 13364.907494010109
J_b = 0.07962287168415003, J_o = 12671.592077498648
J_b = 0.09207352112107271, J_o = 11791.186789652756
J_b = 0.10711303459103567, J_o = 11215.938192765483
J_b = 0.12118106866770882, J_o = 10787.157979720556
J_b = 0.13258317605564812, J_o = 11492.069184415184
J_b = 0.12337274884693344, J_o = 10728.918852969246
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07050333 -1.38713332 -1.42064961 -1.09329336 -1.92594631 -1.60031963
 -2.6558715  -1.89823983 -1.45653733 -1.18577597]
W_opt:  [ 0.02382275  0.02706644  0.01883186  0.01174657  0.00085213 -0.0180622
 -0.04665413 -0.08867626 -0.13723773 -0.1848346 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7699 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1667, add (DA)= 0.0001decode = 0.2550 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0249 s, inc stats = 4.0396, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.17604764e-11 3.11438678e-10 3.71864079e-10 9.29865188e-11
 1.32545093e-09]
u_DA:    [-1.30057796e-09  7.33001578e-09  9.03456622e-09 -2.22401372e-09
  9.67301425e-09]
ref_MAE: [6.92466652e-09 1.01802569e-08 1.26880689e-08 8.45117572e-09
 1.91385387e-08]
da_MAE:  [1.37233844e-09 7.01857710e-09 8.66270214e-09 2.31700024e-09
 8.34756331e-09]
% 21.633104158886848 da_MAE 0.09946285353740092 ref_MAE 0.12691947597243008
u_c taken from control states: [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
u_c before reduction of space:  [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
data[u_c] post encoding of state:  [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
J_b = 0.0, J_o = 514749.06665326597
J_b = 0.49999999999999983, J_o = 16059720.729064986
J_b = 0.00941599932269077, J_o = 111266.58021047362
J_b = 0.010190981435964926, J_o = 91099.25446319536
J_b = 0.024106118401499333, J_o = 35612.67094614316
J_b = 0.03023816831511532, J_o = 28369.026167653617
J_b = 0.042087428385562904, J_o = 20943.671445917116
J_b = 0.05392379231668314, J_o = 17620.273747478062
J_b = 0.07361603443245797, J_o = 15673.35039098216
J_b = 0.07365424527479224, J_o = 14170.902849002221
J_b = 0.07437407604978002, J_o = 13474.33947126314
J_b = 0.07968157111077746, J_o = 12777.910046055047
J_b = 0.09215731523426691, J_o = 11892.842934453058
J_b = 0.10726542429751368, J_o = 11312.235155857456
J_b = 0.12168209989990719, J_o = 10877.035856078965
J_b = 0.13293500398722297, J_o = 11467.348565131568
J_b = 0.12406648116704351, J_o = 10813.535828339285
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07084403 -1.38760371 -1.42137763 -1.09366565 -1.92807191 -1.60137761
 -2.65945165 -1.9000129  -1.45780158 -1.18610481]
W_opt:  [ 0.02414281  0.02699403  0.01863035  0.01156552  0.00082765 -0.01785659
 -0.04631243 -0.08840451 -0.13725508 -0.18514914]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7607 s, v_trunc (Latent to Reduced) = 0.0861, dec (Reduced to Full) = 0.1540, add (DA)= 0.0001decode = 0.2421 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0030 s, inc stats = 4.0133, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [7.07771313e-11 3.09921827e-10 3.69104428e-10 9.17043647e-11
 1.31327160e-09]
u_DA:    [-1.30158538e-09  7.32584878e-09  9.04621646e-09 -2.22568797e-09
  9.66949177e-09]
ref_MAE: [6.92564986e-09 1.01817738e-08 1.26908285e-08 8.45245788e-09
 1.91507181e-08]
da_MAE:  [1.37236252e-09 7.01592696e-09 8.67711203e-09 2.31739233e-09
 8.35622017e-09]
% 21.6719838695326 da_MAE 0.1000822961806324 ref_MAE 0.12777330657006541
u_c taken from control states: [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
u_c before reduction of space:  [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
data[u_c] post encoding of state:  [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
J_b = 0.0, J_o = 514887.6450928382
J_b = 0.4999999999999998, J_o = 16060003.784092313
J_b = 0.009414545538689386, J_o = 111475.48602997928
J_b = 0.010189919029037197, J_o = 91297.54279700728
J_b = 0.02413066226382152, J_o = 35725.69619832639
J_b = 0.030284449036916117, J_o = 28461.621603703978
J_b = 0.042161495856861686, J_o = 21021.252466025868
J_b = 0.05404069775888333, J_o = 17686.35993577047
J_b = 0.07379992180520169, J_o = 15749.319574654108
J_b = 0.07375488696412216, J_o = 14240.71731234859
J_b = 0.07442200550691865, J_o = 13548.20015853549
J_b = 0.0797036314183046, J_o = 12849.390858479574
J_b = 0.09218537526287483, J_o = 11960.855737242367
J_b = 0.1073455760986147, J_o = 11375.367375578855
J_b = 0.12208907001279473, J_o = 10934.732124069187
J_b = 0.13311950087496613, J_o = 11402.942344456656
J_b = 0.12471175226394092, J_o = 10864.631302253583
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07117369 -1.3880541  -1.4220596  -1.09400063 -1.93017441 -1.60241007
 -2.66289965 -1.90171051 -1.45888358 -1.1863911 ]
W_opt:  [ 0.02410985  0.02686824  0.01852222  0.01158592  0.00099861 -0.0175293
 -0.04596287 -0.08823232 -0.13740876 -0.18558601]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.7803 s, v_trunc (Latent to Reduced) = 0.0866, dec (Reduced to Full) = 0.1809, add (DA)= 0.0001decode = 0.2701 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0505 s, inc stats = 4.0791, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.98256739e-11 3.08469494e-10 3.66519370e-10 9.05507017e-11
 1.30122465e-09]
u_DA:    [-1.30271667e-09  7.32150227e-09  9.05812110e-09 -2.22954554e-09
  9.66330062e-09]
ref_MAE: [6.92660132e-09 1.01832261e-08 1.26934136e-08 8.45361154e-09
 1.91627650e-08]
da_MAE:  [1.37254235e-09 7.01303277e-09 8.69160173e-09 2.32009624e-09
 8.36207598e-09]
% 21.754702103784606 da_MAE 0.10043471261116042 ref_MAE 0.12835878360943437
u_c taken from control states: [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
u_c before reduction of space:  [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
data[u_c] post encoding of state:  [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
J_b = 0.0, J_o = 515010.73371964635
J_b = 0.5, J_o = 16060213.142235784
J_b = 0.009413099560265849, J_o = 111670.01254709193
J_b = 0.010188943284617228, J_o = 91479.50329085703
J_b = 0.024156426966241006, J_o = 35817.53205210343
J_b = 0.030332815094128517, J_o = 28531.98271081739
J_b = 0.0422393681053001, J_o = 21075.200245087948
J_b = 0.054166812083271225, J_o = 17726.982148182316
J_b = 0.07400846374962908, J_o = 15799.60675333611
J_b = 0.07387664268797495, J_o = 14283.630299754772
J_b = 0.07448683117365283, J_o = 13595.572195599176
J_b = 0.07973946605229901, J_o = 12894.084265238478
J_b = 0.0922320445342537, J_o = 12001.314199935785
J_b = 0.10746843673999266, J_o = 11409.842684070481
J_b = 0.12257058968892244, J_o = 10963.399354857313
J_b = 0.13333000345530158, J_o = 11299.034761182611
J_b = 0.12552811384922602, J_o = 10883.982342661091
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07148587 -1.38848211 -1.4226978  -1.09429852 -1.93225143 -1.60341964
 -2.66624377 -1.90334109 -1.45975395 -1.18663789]
W_opt:  [ 0.02367586  0.02662183  0.01854814  0.01180959  0.0013386  -0.01706773
 -0.04548601 -0.08799432 -0.13757432 -0.18611071]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6350 s, v_trunc (Latent to Reduced) = 0.0840, dec (Reduced to Full) = 0.1686, add (DA)= 0.0001decode = 0.2548 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.8900 s, inc stats = 3.9015, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.89246333e-11 3.07089287e-10 3.64100188e-10 8.95247745e-11
 1.28932368e-09]
u_DA:    [-1.30423813e-09  7.31670177e-09  9.07168910e-09 -2.23452804e-09
  9.65493056e-09]
ref_MAE: [6.92750236e-09 1.01846063e-08 1.26958328e-08 8.45463747e-09
 1.91746660e-08]
da_MAE:  [1.37316276e-09 7.00961248e-09 8.70758891e-09 2.32405281e-09
 8.36560687e-09]
% 21.889674164272495 da_MAE 0.10050129074924391 ref_MAE 0.12866581937016427
u_c taken from control states: [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
u_c before reduction of space:  [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
data[u_c] post encoding of state:  [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
J_b = 0.0, J_o = 515038.2169336523
J_b = 0.49999999999999994, J_o = 16060779.918491859
J_b = 0.009410670026537877, J_o = 111807.29136685052
J_b = 0.010186687810320616, J_o = 91611.77067829647
J_b = 0.024174880587686475, J_o = 35882.52609757422
J_b = 0.03037101546697274, J_o = 28578.595013558268
J_b = 0.04230366828768299, J_o = 21106.854801357375
J_b = 0.05428402891175352, J_o = 17743.478534987065
J_b = 0.07423112402829438, J_o = 15825.006486726377
J_b = 0.0740124837818453, J_o = 14299.853942215163
J_b = 0.07456253938981273, J_o = 13616.672484509269
J_b = 0.07978269457942794, J_o = 12912.560596147021
J_b = 0.09227942509569234, J_o = 12015.953911830573
J_b = 0.10758037150853694, J_o = 11418.640770021651
J_b = 0.12303561712802624, J_o = 10967.10351172122
J_b = 0.13346953782631038, J_o = 11165.29984309079
J_b = 0.1264701599649983, J_o = 10874.417646357386
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07177941 -1.38888529 -1.42329951 -1.09456176 -1.9343043  -1.60440425
 -2.66956023 -1.90491936 -1.46036884 -1.18685264]
W_opt:  [ 0.02286397  0.02632762  0.01870961  0.01224483  0.00186376 -0.01648118
 -0.04484799 -0.08765965 -0.13769539 -0.18670553]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8112 s, v_trunc (Latent to Reduced) = 0.0871, dec (Reduced to Full) = 0.1677, add (DA)= 0.0001decode = 0.2571 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.0684 s, inc stats = 4.0809, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.80774283e-11 3.05789178e-10 3.61819366e-10 8.86181819e-11
 1.27756112e-09]
u_DA:    [-1.30505976e-09  7.31174135e-09  9.08807769e-09 -2.23966819e-09
  9.64892930e-09]
ref_MAE: [6.92834957e-09 1.01859064e-08 1.26981136e-08 8.45554406e-09
 1.91864285e-08]
da_MAE:  [1.37313719e-09 7.00595217e-09 8.72625833e-09 2.32828637e-09
 8.37136817e-09]
% 22.05777863890039 da_MAE 0.10031552013023887 ref_MAE 0.12870497963547342
u_c taken from control states: [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
u_c before reduction of space:  [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
data[u_c] post encoding of state:  [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
J_b = 0.0, J_o = 515014.1518898242
J_b = 0.5000000000000001, J_o = 16061198.946192648
J_b = 0.009409128377615395, J_o = 111850.27976924459
J_b = 0.010185115994209706, J_o = 91655.01401594943
J_b = 0.024186419386366977, J_o = 35884.673473931405
J_b = 0.030396947443932183, J_o = 28567.776798625597
J_b = 0.04234602185200783, J_o = 21086.45958881679
J_b = 0.05436812768205238, J_o = 17710.26459870912
J_b = 0.0744151941353295, J_o = 15798.572667682076
J_b = 0.07413026735851877, J_o = 14264.502644711638
J_b = 0.07462889638164266, J_o = 13585.838873325356
J_b = 0.07981759215725107, J_o = 12880.07233676987
J_b = 0.09230136136676778, J_o = 11981.312635411532
J_b = 0.10763503374380086, J_o = 11379.710155682003
J_b = 0.12334870126242806, J_o = 10925.903309978865
J_b = 0.13339659568785495, J_o = 11012.85456138976
J_b = 0.12730072214516006, J_o = 10818.561679557135
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07205674 -1.38926663 -1.42387188 -1.094792   -1.93633338 -1.60535921
 -2.67301018 -1.90646187 -1.46061437 -1.18703908]
W_opt:  [ 0.02200186  0.02597939  0.01877528  0.01256558  0.00229928 -0.01586091
 -0.04415473 -0.08725384 -0.13773902 -0.18724891]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.6883 s, v_trunc (Latent to Reduced) = 0.1005, dec (Reduced to Full) = 0.1539, add (DA)= 0.0001decode = 0.2566 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.9450 s, inc stats = 3.9545, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.72769746e-11 3.04559496e-10 3.59649731e-10 8.78252262e-11
 1.26593486e-09]
u_DA:    [-1.30642088e-09  7.30730565e-09  9.10416308e-09 -2.24294442e-09
  9.64191439e-09]
ref_MAE: [6.92915002e-09 1.01871361e-08 1.27002832e-08 8.45633702e-09
 1.91980548e-08]
da_MAE:  [1.37369786e-09 7.00274615e-09 8.74451335e-09 2.33076964e-09
 8.37597953e-09]
% 22.218328100441777 da_MAE 0.09990030109006699 ref_MAE 0.1284368137767355
u_c taken from control states: [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
u_c before reduction of space:  [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
data[u_c] post encoding of state:  [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
J_b = 0.0, J_o = 515025.8354944153
J_b = 0.5, J_o = 16061356.343212772
J_b = 0.009408336526767813, J_o = 111898.52798730173
J_b = 0.010184439797154545, J_o = 91699.91200592011
J_b = 0.024199143353455233, J_o = 35885.60733400787
J_b = 0.030422791004915885, J_o = 28556.733975406234
J_b = 0.04238678319002433, J_o = 21066.350225905393
J_b = 0.05444965097914075, J_o = 17677.197348763755
J_b = 0.07460293523735718, J_o = 15770.152267336809
J_b = 0.07426243960181936, J_o = 14226.908935129359
J_b = 0.07471320924780098, J_o = 13552.722098768572
J_b = 0.07986816407350715, J_o = 12846.271286080411
J_b = 0.09231768598141142, J_o = 11947.27704769512
J_b = 0.10763945516910055, J_o = 11343.393466019035
J_b = 0.1235112185481732, J_o = 10889.814038163922
J_b = 0.13315149812171226, J_o = 10888.377995105551
J_b = 0.12802452398106395, J_o = 10766.346353507106
J_b = 0.1332235497901344, J_o = 10557.879930143738
J_b = 0.13398759203324792, J_o = 10449.267149085688
J_b = 0.14055678260321566, J_o = 10280.598181223677
J_b = 0.1502895283496267, J_o = 10110.153896274247
J_b = 0.1677841679380041, J_o = 10071.30785050162
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07231715 -1.38963365 -1.42442151 -1.09498869 -1.93833854 -1.60628317
 -2.67666148 -1.90798814 -1.46053072 -1.18720571]
W_opt:  [-0.01272178  0.00334165  0.00777248  0.01785272  0.02474515  0.01871902
 -0.0065261  -0.06063823 -0.13489877 -0.21521851]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7335 s, v_trunc (Latent to Reduced) = 0.0830, dec (Reduced to Full) = 0.1718, add (DA)= 0.0001decode = 0.2570 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.9906 s, inc stats = 4.9948, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.65253747e-11 3.03375980e-10 3.57566291e-10 8.71478571e-11
 1.25444566e-09]
u_DA:    [-1.41351401e-09  7.17857218e-09  8.69894521e-09 -2.06985850e-09
  9.16889688e-09]
ref_MAE: [6.92990162e-09 1.01883196e-08 1.27023667e-08 8.45701438e-09
 1.92095440e-08]
da_MAE:  [1.48003938e-09 6.87519620e-09 8.34137892e-09 2.15700636e-09
 7.91445122e-09]
% 22.753336397586086 da_MAE 0.09878855432459897 ref_MAE 0.12788714711752533
\% improve_point: 10.39, mse_ref_points: 1.4787280748403315e-05, mse_da_points: 1.3149731074698621e-05, % improve_overlap: 15.61, mse_ref_overlap: 0.23285, mse_da_overlap: 0.19589
DA - - L2: 3544.66, L1: 4274.89, % Improve: 18.49%, DA_MAE: 0.08, mse_ref: 0.24, mse_DA: 0.213, time(s): 4.6385s,
u_c taken from control states: [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
u_c before reduction of space:  [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
data[u_c] post encoding of state:  [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
J_b = 0.0, J_o = 515033.3259980859
J_b = 0.5, J_o = 16061362.925874721
J_b = 0.009408297110401224, J_o = 111908.05020163416
J_b = 0.010184428229275408, J_o = 91708.53937152388
J_b = 0.024204895451625318, J_o = 35875.21318031805
J_b = 0.030434779176658107, J_o = 28541.37369560157
J_b = 0.04239914898977107, J_o = 21050.037744011606
J_b = 0.05448546725042231, J_o = 17651.244598017096
J_b = 0.0747406216683695, J_o = 15744.680934584105
J_b = 0.0743796213549388, J_o = 14192.4458095096
J_b = 0.0747948909540399, J_o = 13521.941833409948
J_b = 0.07992080117380386, J_o = 12815.732520647887
J_b = 0.0923245043888003, J_o = 11918.00115542065
J_b = 0.10761595721131705, J_o = 11312.9935344259
J_b = 0.12357248579525065, J_o = 10861.767133889578
J_b = 0.13279413272370597, J_o = 10804.689736464868
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07255904 -1.38999561 -1.42495538 -1.09515296 -1.94032037 -1.60717176
 -2.68066828 -1.90952093 -1.46006085 -1.18736035]
W_opt:  [ 0.01626931  0.0225166   0.01759564  0.01407432  0.00608052 -0.01049406
 -0.03858194 -0.08382955 -0.13804801 -0.19215203]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.3953 s, v_trunc (Latent to Reduced) = 0.0837, dec (Reduced to Full) = 0.1471, add (DA)= 0.0001decode = 0.2328 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.6283 s, inc stats = 3.6511, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.58272224e-11 3.02208783e-10 3.55542598e-10 8.65820966e-11
 1.24309012e-09]
u_DA:    [-1.28715941e-09  7.25899060e-09  9.33757610e-09 -2.27515493e-09
  9.65738816e-09]
ref_MAE: [6.93059977e-09 1.01894868e-08 1.27043903e-08 8.45758015e-09
 1.92208995e-08]
da_MAE:  [1.35298663e-09 6.95678181e-09 8.98203350e-09 2.36173702e-09
 8.41429805e-09]
% 22.49964635203959 da_MAE 0.0984679963054919 ref_MAE 0.1270548993270088
u_c taken from control states: [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
u_c before reduction of space:  [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
data[u_c] post encoding of state:  [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
J_b = 0.0, J_o = 515085.7881001466
J_b = 0.49999999999999983, J_o = 16060957.138678504
J_b = 0.009409380772245237, J_o = 111917.18570231214
J_b = 0.01018576457175672, J_o = 91711.36671906378
J_b = 0.024209999576496097, J_o = 35861.64077933944
J_b = 0.030442688760939945, J_o = 28525.288595273865
J_b = 0.04240411703721732, J_o = 21034.215037017188
J_b = 0.054506017443384895, J_o = 17627.572768491194
J_b = 0.07485462327610477, J_o = 15717.560101278472
J_b = 0.07449830149103318, J_o = 14157.305612142298
J_b = 0.07489145449505813, J_o = 13489.258593079787
J_b = 0.07999549558993178, J_o = 12784.209591342815
J_b = 0.09234402414614484, J_o = 11889.109532745148
J_b = 0.1075823568799238, J_o = 11284.290754713318
J_b = 0.12355276089642414, J_o = 10837.521233846917
J_b = 0.1323499110674455, J_o = 10751.410011355909
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07277875 -1.39036581 -1.42547906 -1.09528428 -1.94227865 -1.60802636
 -2.68507922 -1.9110813  -1.45930171 -1.1875137 ]
W_opt:  [ 0.01615884  0.02251888  0.01769955  0.01419251  0.0059953  -0.01063221
 -0.03874623 -0.08394956 -0.13795365 -0.19181055]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.4939 s, v_trunc (Latent to Reduced) = 0.0867, dec (Reduced to Full) = 0.1510, add (DA)= 0.0001decode = 0.2398 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.7338 s, inc stats = 3.7463, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.51930975e-11 3.01014996e-10 3.53557529e-10 8.61298304e-11
 1.23186955e-09]
u_DA:    [-1.29737471e-09  7.26414053e-09  9.30432715e-09 -2.27304960e-09
  9.63902715e-09]
ref_MAE: [6.93123390e-09 1.01906806e-08 1.27063754e-08 8.45803241e-09
 1.92321201e-08]
da_MAE:  [1.36256781e-09 6.96312553e-09 8.95076962e-09 2.35917943e-09
 8.40715760e-09]
% 22.573095987304402 da_MAE 0.09755366719131826 ref_MAE 0.12599453437441138
u_c taken from control states: [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
u_c before reduction of space:  [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
data[u_c] post encoding of state:  [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
J_b = 0.0, J_o = 515187.74737414555
J_b = 0.5000000000000003, J_o = 16060165.306564385
J_b = 0.009411787864313074, J_o = 111919.69092685483
J_b = 0.010188549747807378, J_o = 91704.54729774762
J_b = 0.02421416459613406, J_o = 35843.94073274159
J_b = 0.03044613725797851, J_o = 28508.06098473491
J_b = 0.04240043683186984, J_o = 21019.157187213445
J_b = 0.05451124525599228, J_o = 17606.217477743467
J_b = 0.07494625888027971, J_o = 15689.855979947568
J_b = 0.07461457738717295, J_o = 14122.198007324148
J_b = 0.07499708473986327, J_o = 13455.345153089202
J_b = 0.08008838970140862, J_o = 12751.727806414325
J_b = 0.09238442482823889, J_o = 11859.543749635766
J_b = 0.10756935199259555, J_o = 11254.806286581808
J_b = 0.12356308557752248, J_o = 10813.198134306818
J_b = 0.131942477069776, J_o = 10709.802464278871
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07297686 -1.39075586 -1.42599797 -1.09538182 -1.94421442 -1.60884936
 -2.68989822 -1.91268948 -1.45840348 -1.18767937]
W_opt:  [ 0.01605005  0.02250956  0.01768008  0.01420281  0.00592542 -0.01070027
 -0.03893046 -0.08408568 -0.13788694 -0.19149326]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.5070 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1841, add (DA)= 0.0001decode = 0.2727 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 3.7798 s, inc stats = 3.7853, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.46212947e-11 2.99757235e-10 3.51590572e-10 8.57939021e-11
 1.22077790e-09]
u_DA:    [-1.30816392e-09  7.26615752e-09  9.28136106e-09 -2.26892599e-09
  9.62061969e-09]
ref_MAE: [6.93180570e-09 1.01919384e-08 1.27083424e-08 8.45836834e-09
 1.92432118e-08]
da_MAE:  [1.37278521e-09 6.96640029e-09 8.92977049e-09 2.35471989e-09
 8.39984179e-09]
% 22.496207101179643 da_MAE 0.0967401423915189 ref_MAE 0.12481988141897934
u_c taken from control states: [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
u_c before reduction of space:  [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
data[u_c] post encoding of state:  [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
J_b = 0.0, J_o = 515366.78880930494
J_b = 0.49999999999999983, J_o = 16059183.74895496
J_b = 0.009414898698454518, J_o = 111970.35141105544
J_b = 0.010192162082814083, J_o = 91742.77384076893
J_b = 0.02422082103235561, J_o = 35863.402492681416
J_b = 0.030454310459853955, J_o = 28523.86029821621
J_b = 0.04241979870992187, J_o = 21025.07181027851
J_b = 0.054565661350968936, J_o = 17600.22869092995
J_b = 0.0751132641064536, J_o = 15675.781221078187
J_b = 0.07479270167362617, J_o = 14099.503955333781
J_b = 0.07516889490419719, J_o = 13432.51227440685
J_b = 0.08025633916299549, J_o = 12730.109179104258
J_b = 0.09251013361112166, J_o = 11840.039222399493
J_b = 0.10765954716669336, J_o = 11234.24600174465
J_b = 0.12372854521010647, J_o = 10797.814301117956
J_b = 0.1316810546086145, J_o = 10676.8427345758
J_b = 0.13352599492605738, J_o = 10467.946211056995
J_b = 0.13129326855172868, J_o = 10390.955901938127
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07315626 -1.39117516 -1.42651765 -1.09544819 -1.94612773 -1.60964336
 -2.69514264 -1.91436506 -1.45747789 -1.18786885]
W_opt:  [ 0.01058362  0.01863902  0.01553082  0.0142337   0.0080829  -0.00691453
 -0.0345518  -0.08009421 -0.1352528  -0.19093533]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9414 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1453, add (DA)= 0.0001decode = 0.2335 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1751 s, inc stats = 4.1874, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.41035184e-11 2.98405115e-10 3.49620668e-10 8.55653261e-11
 1.20981499e-09]
u_DA:    [-1.27695993e-09  7.33892139e-09  8.77883849e-09 -2.13157232e-09
  9.64370261e-09]
ref_MAE: [6.93232348e-09 1.01932905e-08 1.27103123e-08 8.45859692e-09
 1.92541747e-08]
da_MAE:  [1.34106345e-09 7.04051628e-09 8.42921782e-09 2.21713764e-09
 8.43388762e-09]
% 22.623499144961468 da_MAE 0.09566656319431668 ref_MAE 0.12363774807230399
u_c taken from control states: [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
u_c before reduction of space:  [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
data[u_c] post encoding of state:  [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
J_b = 0.0, J_o = 515616.5245040893
J_b = 0.4999999999999999, J_o = 16057903.773324436
J_b = 0.009418581701506676, J_o = 112072.14493468424
J_b = 0.010196674551255178, J_o = 91823.80523169566
J_b = 0.024235395433331128, J_o = 35899.043648056046
J_b = 0.030474642481061083, J_o = 28550.8981782692
J_b = 0.0424603927387275, J_o = 21037.11469833924
J_b = 0.05464526098603191, J_o = 17600.07003815465
J_b = 0.07529630150874966, J_o = 15667.506773200083
J_b = 0.07498595596817273, J_o = 14083.113180043776
J_b = 0.07536231636257808, J_o = 13414.803594557598
J_b = 0.08045587789787483, J_o = 12712.863046947507
J_b = 0.09268996114535312, J_o = 11823.22473845223
J_b = 0.10785316524549757, J_o = 11214.483475624318
J_b = 0.12406210488325933, J_o = 10781.673013425985
J_b = 0.1316650669538045, J_o = 10647.624870799718
J_b = 0.1337137382889605, J_o = 10451.420049926353
J_b = 0.13151688005172155, J_o = 10372.146166359304
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07331652 -1.39163191 -1.42704299 -1.09548555 -1.94801827 -1.61041481
 -2.70069524 -1.91611663 -1.45676421 -1.18808884]
W_opt:  [ 0.00988295  0.01819382  0.01539505  0.01446894  0.00849966 -0.00646276
 -0.03438021 -0.08002435 -0.13519801 -0.19102418]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8946 s, v_trunc (Latent to Reduced) = 0.0862, dec (Reduced to Full) = 0.1638, add (DA)= 0.0001decode = 0.2520 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1467 s, inc stats = 4.1581, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.36409648e-11 2.96932273e-10 3.47629308e-10 8.54366600e-11
 1.19898251e-09]
u_DA:    [-1.27426659e-09  7.33305108e-09  8.78531567e-09 -2.12542959e-09
  9.63267617e-09]
ref_MAE: [6.93278603e-09 1.01947633e-08 1.27123036e-08 8.45872558e-09
 1.92650072e-08]
da_MAE:  [1.33790755e-09 7.03611880e-09 8.43768636e-09 2.21086625e-09
 8.43369366e-09]
% 22.28150867234632 da_MAE 0.09525331767377396 ref_MAE 0.12256197469427853
u_c taken from control states: [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
u_c before reduction of space:  [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
data[u_c] post encoding of state:  [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
J_b = 0.0, J_o = 515841.4373013091
J_b = 0.5, J_o = 16056797.290813074
J_b = 0.009421594804526734, J_o = 112178.11179297582
J_b = 0.01020047840018045, J_o = 91910.0256655442
J_b = 0.024248999884895803, J_o = 35940.884646742445
J_b = 0.030494913163305718, J_o = 28582.877562297035
J_b = 0.042504241589004385, J_o = 21052.364854175084
J_b = 0.05472657110389773, J_o = 17604.434668191818
J_b = 0.07545889336444554, J_o = 15665.990799176314
J_b = 0.07514860558492276, J_o = 14075.274545254752
J_b = 0.0755256074929694, J_o = 13405.606617456253
J_b = 0.08062653762776703, J_o = 12703.760307775181
J_b = 0.09285535863488044, J_o = 11813.228083914368
J_b = 0.10807000467696194, J_o = 11200.115597508797
J_b = 0.1244705638139809, J_o = 10769.702746429935
J_b = 0.13177440795533255, J_o = 10621.472109866774
J_b = 0.13411061174727695, J_o = 10438.089510504265
J_b = 0.13191993765374663, J_o = 10354.758338853419
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07345511 -1.39212507 -1.42757899 -1.0954969  -1.94988483 -1.61117125
 -2.70635497 -1.91794386 -1.45656384 -1.1883408 ]
W_opt:  [ 0.00923257  0.01777235  0.0151922   0.01470523  0.00893007 -0.00599274
 -0.03413131 -0.07990466 -0.13515764 -0.19127101]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.8902 s, v_trunc (Latent to Reduced) = 0.0836, dec (Reduced to Full) = 0.1714, add (DA)= 0.0001decode = 0.2571 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1475 s, inc stats = 4.1522, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.32409512e-11 2.95341986e-10 3.45597553e-10 8.53975892e-11
 1.18828746e-09]
u_DA:    [-1.27130900e-09  7.32693974e-09  8.79200070e-09 -2.11734905e-09
  9.62253496e-09]
ref_MAE: [6.93318604e-09 1.01963536e-08 1.27143354e-08 8.45876465e-09
 1.92757022e-08]
da_MAE:  [1.33454995e-09 7.03159775e-09 8.44640315e-09 2.20274664e-09
 8.43424750e-09]
% 21.937725044518157 da_MAE 0.09500459136934193 ref_MAE 0.1217035904007693
u_c taken from control states: [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
u_c before reduction of space:  [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
data[u_c] post encoding of state:  [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
J_b = 0.0, J_o = 516041.9199213969
J_b = 0.5000000000000002, J_o = 16055795.734530758
J_b = 0.00942384634617334, J_o = 112295.10180564655
J_b = 0.010203619070144058, J_o = 92004.81363012265
J_b = 0.024264483868742803, J_o = 35982.47554159977
J_b = 0.030518086687264138, J_o = 28614.087724306548
J_b = 0.04254644723248942, J_o = 21070.757441265556
J_b = 0.05478703274562643, J_o = 17617.85183455403
J_b = 0.07554266643635264, J_o = 15677.851160563085
J_b = 0.0752255269501108, J_o = 14085.250586801832
J_b = 0.07560158426813973, J_o = 13415.28679368025
J_b = 0.08070144984905703, J_o = 12714.257751818861
J_b = 0.09291254913673284, J_o = 11823.635694772365
J_b = 0.10816745526556612, J_o = 11206.694885031196
J_b = 0.12475441292136874, J_o = 10777.784413836729
J_b = 0.1318563468477639, J_o = 10616.957869735867
J_b = 0.13451193983157075, J_o = 10444.577106211851
J_b = 0.13229885558694982, J_o = 10356.109088925177
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07357122 -1.3926471  -1.4281318  -1.09548835 -1.9517264  -1.61191661
 -2.71196513 -1.91983942 -1.45703799 -1.18861911]
W_opt:  [ 0.00883437  0.01730031  0.01491147  0.01495156  0.00928108 -0.00567475
 -0.03401988 -0.07985738 -0.13514196 -0.19146904]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9699 s, v_trunc (Latent to Reduced) = 0.0887, dec (Reduced to Full) = 0.1642, add (DA)= 0.0001decode = 0.2557 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2257 s, inc stats = 4.2384, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.29058441e-11 2.93658618e-10 3.43502080e-10 8.54270316e-11
 1.17773562e-09]
u_DA:    [-1.26874227e-09  7.32119859e-09  8.79925962e-09 -2.10747766e-09
  9.61434521e-09]
ref_MAE: [6.93352115e-09 1.01980370e-08 1.27164309e-08 8.45873521e-09
 1.92862540e-08]
da_MAE:  [1.33164812e-09 7.02753997e-09 8.45575754e-09 2.19290469e-09
 8.43660960e-09]
% 21.65703516372768 da_MAE 0.09488609180557511 ref_MAE 0.12111628913186526
u_c taken from control states: [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
u_c before reduction of space:  [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
data[u_c] post encoding of state:  [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
J_b = 0.0, J_o = 516218.48563049524
J_b = 0.4999999999999999, J_o = 16054878.201826401
J_b = 0.009425975671134628, J_o = 112391.60628015661
J_b = 0.01020654316732138, J_o = 92081.27126200258
J_b = 0.02428166033831124, J_o = 36002.28683128363
J_b = 0.03054357442579506, J_o = 28624.402506622882
J_b = 0.04258390627828117, J_o = 21073.801742784046
J_b = 0.054830046030206546, J_o = 17619.439499882592
J_b = 0.07558099890686999, J_o = 15681.289581760862
J_b = 0.07525180175613344, J_o = 14088.4304293731
J_b = 0.07562313047780231, J_o = 13418.967214769435
J_b = 0.08071728969824236, J_o = 12718.624814308216
J_b = 0.09290951784576554, J_o = 11827.923095400132
J_b = 0.10819921183302264, J_o = 11207.366092123008
J_b = 0.12497367211269826, J_o = 10779.361855908448
J_b = 0.131921471980783, J_o = 10600.602774875835
J_b = 0.13520842032639366, J_o = 10448.619384209414
J_b = 0.13280374441453704, J_o = 10347.844033941756
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07366508 -1.39318732 -1.42870671 -1.09546896 -1.95354216 -1.61265198
 -2.71744574 -1.92178934 -1.4581504  -1.18891192]
W_opt:  [ 0.0083862   0.01685544  0.01455722  0.01512358  0.00971394 -0.00528586
 -0.03371349 -0.0796646  -0.13507619 -0.19172084]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9204 s, v_trunc (Latent to Reduced) = 0.0864, dec (Reduced to Full) = 0.1526, add (DA)= 0.0001decode = 0.2411 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.1616 s, inc stats = 4.1666, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.26349464e-11 2.91916614e-10 3.41322793e-10 8.54937984e-11
 1.16733163e-09]
u_DA:    [-1.26498921e-09  7.31546320e-09  8.80843313e-09 -2.09525133e-09
  9.61108981e-09]
ref_MAE: [6.93379205e-09 1.01997790e-08 1.27186102e-08 8.45866844e-09
 1.92966580e-08]
da_MAE:  [1.32762415e-09 7.02354659e-09 8.46711034e-09 2.18074513e-09
 8.44375818e-09]
% 21.440102330393035 da_MAE 0.09488394742405296 ref_MAE 0.12077911280269067
u_c taken from control states: [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
u_c before reduction of space:  [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
data[u_c] post encoding of state:  [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
J_b = 0.0, J_o = 516385.30831881677
J_b = 0.4999999999999999, J_o = 16054133.384656228
J_b = 0.009427844434133957, J_o = 112486.90854046156
J_b = 0.01020906163060697, J_o = 92159.86640860864
J_b = 0.02430164682273996, J_o = 36017.17054419439
J_b = 0.03057463181337706, J_o = 28628.722569721776
J_b = 0.04262239281699638, J_o = 21075.011690444713
J_b = 0.05486710339204837, J_o = 17620.78463643979
J_b = 0.07560547829071249, J_o = 15687.298966344217
J_b = 0.07526125449233562, J_o = 14093.477491622169
J_b = 0.0756251700520014, J_o = 13424.520308954136
J_b = 0.0807175339305508, J_o = 12723.473450348352
J_b = 0.0929134506088877, J_o = 11830.834805768607
J_b = 0.10827981955948003, J_o = 11204.971750614866
J_b = 0.1253020734654588, J_o = 10776.203437529792
J_b = 0.13213419663096423, J_o = 10572.037987361782
J_b = 0.1366067299258945, J_o = 10463.679593122062
J_b = 0.13369076782424974, J_o = 10329.922956908224
J_b = 0.13450342495940235, J_o = 10248.939284660266
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07373918 -1.3937339  -1.429308   -1.0954507  -1.95533146 -1.61338066
 -2.72269347 -1.92378104 -1.45985165 -1.18921132]
W_opt:  [ 0.00593224  0.01505458  0.01338943  0.01544855  0.0113512  -0.00289296
 -0.0311533  -0.07764942 -0.13438744 -0.19293392]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2073 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1688, add (DA)= 0.0001decode = 0.2566 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4639 s, inc stats = 4.4752, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.24210683e-11 2.90154077e-10 3.39043554e-10 8.55566732e-11
 1.15707926e-09]
u_DA:    [-1.31563014e-09  7.32686516e-09  8.74672510e-09 -2.10700963e-09
  9.52358727e-09]
ref_MAE: [6.93400593e-09 1.02015415e-08 1.27208894e-08 8.45860557e-09
 1.93069104e-08]
da_MAE:  [1.37805120e-09 7.03671109e-09 8.40768155e-09 2.19256630e-09
 8.36650801e-09]
% 21.352048450314307 da_MAE 0.0949152443586542 ref_MAE 0.12068368277677477
u_c taken from control states: [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
u_c before reduction of space:  [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
data[u_c] post encoding of state:  [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
J_b = 0.0, J_o = 516555.8692782489
J_b = 0.5, J_o = 16053594.914588924
J_b = 0.009429109352137057, J_o = 112611.45327121811
J_b = 0.010210922018020142, J_o = 92268.87679650699
J_b = 0.024324782689320465, J_o = 36051.26208476387
J_b = 0.030613411502599334, J_o = 28647.82686146373
J_b = 0.042677445472255326, J_o = 21085.997633532337
J_b = 0.05493545990111565, J_o = 17628.26125317055
J_b = 0.07568351564310265, J_o = 15701.293583420984
J_b = 0.0753048943219257, J_o = 14104.48437843552
J_b = 0.07565297360834494, J_o = 13436.480670563778
J_b = 0.08074110725211076, J_o = 12734.062418765632
J_b = 0.09294567071850758, J_o = 11838.63637681982
J_b = 0.10840793544825722, J_o = 11206.410540640756
J_b = 0.1257159428109007, J_o = 10776.263327870798
J_b = 0.13243128085460248, J_o = 10541.001120961655
J_b = 0.13890014301307874, J_o = 10534.589061480956
J_b = 0.13548266868516973, J_o = 10417.898888197169
J_b = 0.13497931976222302, J_o = 10308.993308000501
J_b = 0.140780039093215, J_o = 10167.436082906654
J_b = 0.14351461242240884, J_o = 10114.389507066879
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07380419 -1.39427191 -1.42994132 -1.09544838 -1.95709581 -1.61410126
 -2.72775073 -1.92580089 -1.4618856  -1.18951114]
W_opt:  [-0.00088423  0.01072377  0.0111643   0.01697801  0.01638849  0.00429332
 -0.02378713 -0.07272713 -0.13431305 -0.1992075 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.6326 s, v_trunc (Latent to Reduced) = 0.0858, dec (Reduced to Full) = 0.1736, add (DA)= 0.0001decode = 0.2616 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8943 s, inc stats = 4.9037, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.22334304e-11 2.88419153e-10 3.36642896e-10 8.55646771e-11
 1.14696986e-09]
u_DA:    [-1.31201745e-09  7.28721527e-09  8.63456344e-09 -2.03045260e-09
  9.41688562e-09]
ref_MAE: [6.93419356e-09 1.02032765e-08 1.27232900e-08 8.45859756e-09
 1.93170198e-08]
da_MAE:  [1.37425088e-09 6.99879612e-09 8.29792054e-09 2.11601728e-09
 8.26991577e-09]
% 21.272388525976467 da_MAE 0.09507420670239611 ref_MAE 0.12076348427484834
\% improve_point: 10.97, mse_ref_points: 1.5246252234944407e-05, mse_da_points: 1.3459859636760714e-05, % improve_overlap: 15.78, mse_ref_overlap: 0.24054, mse_da_overlap: 0.20192
DA - - L2: 3887.62, L1: 4452.79, % Improve: 18.84%, DA_MAE: 0.08, mse_ref: 0.25, mse_DA: 0.218, time(s): 4.5901s,
u_c taken from control states: [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
u_c before reduction of space:  [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
data[u_c] post encoding of state:  [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
J_b = 0.0, J_o = 516687.8356345998
J_b = 0.49999999999999983, J_o = 16053305.591211421
J_b = 0.00942966709039047, J_o = 112725.95598539826
J_b = 0.010211924827322567, J_o = 92371.59851047998
J_b = 0.024345500717343718, J_o = 36086.704948969666
J_b = 0.03064856414089337, J_o = 28670.484261907786
J_b = 0.04272148985741358, J_o = 21105.515578469705
J_b = 0.05498389401621885, J_o = 17646.156754928677
J_b = 0.0757359808936825, J_o = 15725.88171218528
J_b = 0.07533135005970239, J_o = 14126.037005428843
J_b = 0.07566433173809346, J_o = 13459.178739481833
J_b = 0.08074692684496959, J_o = 12755.722144350757
J_b = 0.09294675079958767, J_o = 11858.834793382204
J_b = 0.10847243852821448, J_o = 11221.48639407861
J_b = 0.1260282763035239, J_o = 10790.118115136014
J_b = 0.13268332020478354, J_o = 10530.080058863998
J_b = 0.14132587080410067, J_o = 10668.872037778367
J_b = 0.13581544685250105, J_o = 10422.294782192024
J_b = 0.13644332998510877, J_o = 10294.914628515708
J_b = 0.14159437883888626, J_o = 10167.492522503753
J_b = 0.14457212061668595, J_o = 10116.670326619203
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07386994 -1.3947925  -1.43061011 -1.09547541 -1.95883584 -1.61481419
 -2.73268353 -1.9278342  -1.46398513 -1.18980756]
W_opt:  [-0.00135822  0.01055757  0.0109195   0.01703863  0.01675805  0.00472079
 -0.02336603 -0.072449   -0.13436617 -0.19972708]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5388 s, v_trunc (Latent to Reduced) = 0.0860, dec (Reduced to Full) = 0.1566, add (DA)= 0.0001decode = 0.2449 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7837 s, inc stats = 4.7894, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.20436798e-11 2.86740432e-10 3.34107798e-10 8.54715932e-11
 1.13699976e-09]
u_DA:    [-1.30792445e-09  7.28121887e-09  8.64878891e-09 -2.02051224e-09
  9.41721485e-09]
ref_MAE: [6.93438331e-09 1.02049552e-08 1.27258251e-08 8.45869065e-09
 1.93269899e-08]
da_MAE:  [1.36996813e-09 6.99447844e-09 8.31468111e-09 2.10598383e-09
 8.28021509e-09]
% 21.10122042489191 da_MAE 0.09540896668898854 ref_MAE 0.12092578263287773
u_c taken from control states: [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
u_c before reduction of space:  [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
data[u_c] post encoding of state:  [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
J_b = 0.0, J_o = 516790.000762731
J_b = 0.5, J_o = 16053223.739809504
J_b = 0.009429350742166298, J_o = 112849.02341900828
J_b = 0.010212046703861525, J_o = 92482.92894832914
J_b = 0.024368718200533466, J_o = 36121.050993625046
J_b = 0.03068864256543508, J_o = 28690.3736928293
J_b = 0.04277087350569253, J_o = 21122.81007690102
J_b = 0.05503686828356136, J_o = 17662.241848517686
J_b = 0.07578635120880704, J_o = 15750.788168706951
J_b = 0.07534736805833558, J_o = 14148.067672933583
J_b = 0.07566111073302675, J_o = 13482.900279629956
J_b = 0.08073445976846039, J_o = 12778.332825843183
J_b = 0.09292465503972173, J_o = 11880.261445185668
J_b = 0.10850230460124195, J_o = 11238.267673047385
J_b = 0.12628123100734698, J_o = 10805.571532344211
J_b = 0.13290665177109584, J_o = 10525.176431810696
J_b = 0.14387466252053183, J_o = 10640.528366230174
J_b = 0.1370915368639889, J_o = 10405.021306963921
J_b = 0.1401929349010244, J_o = 10234.032150422589
J_b = 0.14363115290416653, J_o = 10153.54830419618
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07393781 -1.39529336 -1.4313136  -1.09553914 -1.96055138 -1.61552517
 -2.73737913 -1.92986357 -1.46617174 -1.19010164]
W_opt:  [-1.81333867e-04  1.12657429e-02  1.10938602e-02  1.65368360e-02
  1.56813464e-02  3.07971742e-03 -2.50127777e-02 -7.35971336e-02
 -1.34539402e-01 -1.98694405e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4391 s, v_trunc (Latent to Reduced) = 0.0830, dec (Reduced to Full) = 0.1546, add (DA)= 0.0001decode = 0.2398 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.6790 s, inc stats = 4.6848, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.18477810e-11 2.85125332e-10 3.31441124e-10 8.52521067e-11
 1.12717006e-09]
u_DA:    [-1.28317238e-09  7.26759579e-09  8.69306903e-09 -1.99666145e-09
  9.43125832e-09]
ref_MAE: [6.93457921e-09 1.02065703e-08 1.27284918e-08 8.45891014e-09
 1.93368196e-08]
da_MAE:  [1.34502016e-09 6.98247046e-09 8.36162791e-09 2.08191356e-09
 8.30408826e-09]
% 20.93278566779066 da_MAE 0.09577870762584981 ref_MAE 0.12113580633235078
u_c taken from control states: [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
u_c before reduction of space:  [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
data[u_c] post encoding of state:  [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
J_b = 0.0, J_o = 516851.4882319292
J_b = 0.5000000000000001, J_o = 16053396.540931847
J_b = 0.00942863371639601, J_o = 112944.14849130882
J_b = 0.0102115131855313, J_o = 92572.38971386642
J_b = 0.024392269409962416, J_o = 36136.225227297415
J_b = 0.030728434836759716, J_o = 28694.7344984655
J_b = 0.04280289539891585, J_o = 21136.70579958696
J_b = 0.055051971522706085, J_o = 17679.335040208498
J_b = 0.07578222755250848, J_o = 15779.085971671288
J_b = 0.07531801856739627, J_o = 14173.56493537747
J_b = 0.07560770464839077, J_o = 13511.291603082176
J_b = 0.08066368749147072, J_o = 12805.91357573371
J_b = 0.0928265264067589, J_o = 11907.981344441672
J_b = 0.10842761265127905, J_o = 11262.468295434264
J_b = 0.12638384606344583, J_o = 10828.401184189883
J_b = 0.13302792074652614, J_o = 10535.966109099569
J_b = 0.14618086736203323, J_o = 10354.37458337201
J_b = 0.14875932400205863, J_o = 10445.121763709283
J_b = 0.14719577775775358, J_o = 10259.963813524766
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07401027 -1.39577201 -1.43204884 -1.0956462  -1.962242   -1.61623649
 -2.74175758 -1.93187158 -1.46843626 -1.19039289]
W_opt:  [-0.0004161   0.01104902  0.0107969   0.01619538  0.01542477  0.00259711
 -0.02568213 -0.07465996 -0.13604232 -0.20065708]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.0106 s, v_trunc (Latent to Reduced) = 0.0836, dec (Reduced to Full) = 0.1516, add (DA)= 0.0001decode = 0.2373 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2479 s, inc stats = 4.2603, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.16386456e-11 2.83581874e-10 3.28654135e-10 8.48834021e-11
 1.11748309e-09]
u_DA:    [-1.25608479e-09  7.13353018e-09  8.63657247e-09 -1.87909900e-09
  9.26171763e-09]
ref_MAE: [6.93478835e-09 1.02081137e-08 1.27312788e-08 8.45927884e-09
 1.93465066e-08]
da_MAE:  [1.31772344e-09 6.84994830e-09 8.30791834e-09 1.96398241e-09
 8.14423454e-09]
% 20.739102860900445 da_MAE 0.09619045282244501 ref_MAE 0.12135927840134687
u_c taken from control states: [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
u_c before reduction of space:  [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
data[u_c] post encoding of state:  [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
J_b = 0.0, J_o = 516869.99618427665
J_b = 0.4999999999999999, J_o = 16053899.261951381
J_b = 0.009427820328038041, J_o = 112991.50981108761
J_b = 0.010210392498575032, J_o = 92626.2121887315
J_b = 0.02440886998253693, J_o = 36144.83834793744
J_b = 0.030754980868880774, J_o = 28702.60191431791
J_b = 0.04278958740526732, J_o = 21175.401079717998
J_b = 0.054980012719995454, J_o = 17730.59468954151
J_b = 0.07565069589570142, J_o = 15842.717690770722
J_b = 0.07519455937079915, J_o = 14235.960668267897
J_b = 0.07546358556654649, J_o = 13577.34723377207
J_b = 0.08049805483784948, J_o = 12871.779183314336
J_b = 0.09261606245502613, J_o = 11975.646102884091
J_b = 0.10821700327385096, J_o = 11327.641001796985
J_b = 0.1263189060749481, J_o = 10891.981102508
J_b = 0.13304247331202654, J_o = 10597.855081363068
J_b = 0.14716348143013952, J_o = 11041.30301838841
J_b = 0.13685151745500704, J_o = 10496.936809836963
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07409319 -1.39622553 -1.43281216 -1.09580317 -1.96390825 -1.61694542
 -2.74587426 -1.93384277 -1.47060078 -1.19067998]
W_opt:  [ 0.01190685  0.01933938  0.01519486  0.01499534  0.00892872 -0.00747167
 -0.03654081 -0.08257181 -0.13763315 -0.19388455]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9684 s, v_trunc (Latent to Reduced) = 0.0866, dec (Reduced to Full) = 0.1617, add (DA)= 0.0001decode = 0.2505 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2190 s, inc stats = 4.2236, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.13993232e-11 2.82119422e-10 3.25760680e-10 8.43427983e-11
 1.10793581e-09]
u_DA:    [-1.22574510e-09  7.17820699e-09  9.17338444e-09 -2.06793300e-09
  9.51198639e-09]
ref_MAE: [6.93502767e-09 1.02095762e-08 1.27341723e-08 8.45981944e-09
 1.93560539e-08]
da_MAE:  [1.28714442e-09 6.89608757e-09 8.84762376e-09 2.15227579e-09
 8.40405058e-09]
% 20.554704522707095 da_MAE 0.09656825617909562 ref_MAE 0.12155314622336172
u_c taken from control states: [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
u_c before reduction of space:  [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
data[u_c] post encoding of state:  [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
J_b = 0.0, J_o = 516880.56431145617
J_b = 0.49999999999999994, J_o = 16054484.287289008
J_b = 0.009426945891067306, J_o = 113031.69757823461
J_b = 0.010209113993796627, J_o = 92675.13103493713
J_b = 0.02442661618883228, J_o = 36146.329404816854
J_b = 0.030784039747011094, J_o = 28702.756837221965
J_b = 0.042778491026132785, J_o = 21206.892857258936
J_b = 0.05491453536610661, J_o = 17773.098092756452
J_b = 0.0755441080703218, J_o = 15897.340935055381
J_b = 0.07509809038588225, J_o = 14287.113388003832
J_b = 0.07534630295130304, J_o = 13631.664299264528
J_b = 0.08036526710776358, J_o = 12924.85238832055
J_b = 0.09245586208329253, J_o = 12029.151231002088
J_b = 0.10808666798848685, J_o = 11377.4719389518
J_b = 0.12634965395506512, J_o = 10940.201614414425
J_b = 0.13313546460072195, J_o = 10655.524626104561
J_b = 0.14564898134433035, J_o = 10831.267210764221
J_b = 0.1376314854997254, J_o = 10523.0575157925
J_b = 0.138769878552652, J_o = 10393.751182477597
J_b = 0.14282982649920997, J_o = 10282.215140661443
J_b = 0.14637293691241238, J_o = 10224.22772735412
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07419078 -1.39665632 -1.4335991  -1.09601235 -1.96555063 -1.61764948
 -2.74980255 -1.93576234 -1.47250777 -1.19096086]
W_opt:  [-0.00166634  0.01028358  0.01070161  0.0168222   0.01724509  0.00525864
 -0.02266803 -0.07186839 -0.13408404 -0.20018698]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5868 s, v_trunc (Latent to Reduced) = 0.0868, dec (Reduced to Full) = 0.1601, add (DA)= 0.0001decode = 0.2489 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8358 s, inc stats = 4.8395, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.11176580e-11 2.80730245e-10 3.22777729e-10 8.36223777e-11
 1.09852522e-09]
u_DA:    [-1.28039646e-09  7.26259251e-09  8.64106818e-09 -1.98290211e-09
  9.44240020e-09]
ref_MAE: [6.93530934e-09 1.02109654e-08 1.27371552e-08 8.46053986e-09
 1.93654644e-08]
da_MAE:  [1.34151412e-09 6.98186227e-09 8.31829045e-09 2.06652449e-09
 8.34387497e-09]
% 20.886398867751968 da_MAE 0.09626187106339812 ref_MAE 0.1216755016656171
u_c taken from control states: [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
u_c before reduction of space:  [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
data[u_c] post encoding of state:  [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
J_b = 0.0, J_o = 516919.31250465015
J_b = 0.49999999999999994, J_o = 16054868.123352567
J_b = 0.009426833846068891, J_o = 113067.18505913988
J_b = 0.010208660093798365, J_o = 92717.56986824244
J_b = 0.02444950571514295, J_o = 36127.280630790905
J_b = 0.03082134629684623, J_o = 28679.819845680435
J_b = 0.042778147096636764, J_o = 21214.023053778255
J_b = 0.0548672766939962, J_o = 17788.733027065886
J_b = 0.07547947162901375, J_o = 15924.991844935857
J_b = 0.07504189274772895, J_o = 14308.71609976632
J_b = 0.07526576700549235, J_o = 13656.373209774882
J_b = 0.0802709850987677, J_o = 12947.510425199836
J_b = 0.09234335255279644, J_o = 12051.33551829129
J_b = 0.10802194139495468, J_o = 11395.310962369285
J_b = 0.1264305600997636, J_o = 10957.076453229736
J_b = 0.13324307213173728, J_o = 10697.12655273281
J_b = 0.14221897521534205, J_o = 10555.354828253407
J_b = 0.138965488963247, J_o = 10395.26966426648
J_b = 0.13982336037230242, J_o = 10327.63850532305
Following minimisation and before DA stats:
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09 5.21368136e-09 4.81091920e-09 4.15861522e-09
 4.56102507e-09 3.50034723e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08 8.94967246e-09 1.68072792e-08 8.90473699e-09
 7.13345328e-09 4.28435352e-09]
u_0:     [1.32870462 1.76986973 1.92659501 1.36060061 1.41421702 1.56675831
 0.80852571 1.39584688 1.47563335 1.59607733]
u_c:     [-1.07430801 -1.39707092 -1.43440449 -1.09627662 -1.96717077 -1.61834675
 -2.75361777 -1.93762131 -1.4740643  -1.19123707]
W_opt:  [ 0.00385302  0.01386886  0.01252982  0.01568409  0.01334864 -0.00033973
 -0.02848541 -0.07588489 -0.13440674 -0.19569088]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2067 s, v_trunc (Latent to Reduced) = 0.1235, dec (Reduced to Full) = 0.1757, add (DA)= 0.0001decode = 0.3019 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.5087 s, inc stats = 4.5215, 
std:     [2.88623023e-09 3.22465857e-09 3.79060102e-09 3.44398569e-09
 5.72982122e-09]
mean:    [3.16147955e-09 4.78447003e-09 5.75697992e-09 3.85827322e-09
 1.23607789e-08]
u_0:     [6.99642699e-09 1.04916956e-08 1.30599329e-08 8.54416224e-09
 2.04639897e-08]
u_c:     [6.07792919e-11 2.79393319e-10 3.19724815e-10 8.27122445e-11
 1.08924213e-09]
u_DA:    [-1.24901769e-09  7.27369329e-09  8.74976125e-09 -2.00226225e-09
  9.55098979e-09]
ref_MAE: [6.93564770e-09 1.02123023e-08 1.27402081e-08 8.46145000e-09
 1.93747475e-08]
da_MAE:  [1.30979698e-09 6.99429997e-09 8.43003643e-09 2.08497449e-09
 8.46174766e-09]
% 20.850210520690933 da_MAE 0.0963314068838292 ref_MAE 0.12170772344127544
\% improve_point: 11.22, mse_ref_points: 1.545633447968094e-05, mse_da_points: 1.3604116669523857e-05, % improve_overlap: 15.94, mse_ref_overlap: 0.24419, mse_da_overlap: 0.20454
DA - - L2: 4089.99, L1: 4554.78, % Improve: 18.95%, DA_MAE: 0.08, mse_ref: 0.25, mse_DA: 0.220, time(s): 4.5883s,
Results of DA at 2020-08-28 14:05:36.257223. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              18.060426      0.078882  ...  31.732793     7.073777
1              17.851573      0.078878  ...   7.071589     7.061686
2              17.611737      0.078977  ...   7.234857     7.225208
3              17.385656      0.079162  ...   7.497739     7.481084
4              17.696141      0.079379  ...   4.803910     4.790127
..                   ...           ...  ...        ...          ...
102            20.932786      0.121136  ...   4.689083     4.678954
103            20.739103      0.121359  ...   4.264477     4.247907
104            20.554705      0.121553  ...   4.227653     4.218950
105            20.886399      0.121676  ...   4.842916     4.835784
106            20.850211      0.121708  ...   4.525622     4.508697

[107 rows x 20 columns]
data fp  /home/mredstone/unstructuredCAE/data/subdomain_6/
domain, other, pickle, dim 6 ['8'] /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/ 1
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
| Header             | Info                                                                         |
|--------------------+------------------------------------------------------------------------------|
| Experiment title   | Idx_80P_150E_1D0L                                                            |
| Home dir           | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/         |
| Results dir        | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/results/ |
| Data fp            | /home/mredstone/unstructuredCAE/data/subdomain_6/                            |
| Pickled data fp    | /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/     |
| Field name         | TracerGeorge                                                                 |
| Using Loader       | <class 'VarDACAE.UnstructuredMesh.DataLoaderUnstructuredMesh.DataLoaderUnstructuredMesh'>     |
| Compression Method | AE                                                                           |
| Percentage         | 80                                                                           |
| Seed               | 42                                                                           |
| 3D                 | False                                                                        |
| 2D                 | False                                                                        |
| 1D                 | True                                                                         |
Initialising model of type  <class 'VarDACAE.AEs.AE_general.GenCAE'>
91, 85, 32, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
89, 83, 30, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
87, 81, 28, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
85, 79, 26, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
83, 77, 24, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
81, 75, 22, stride=(1, 1, 1, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 0, )  
79, 73, 20, stride=(2, 2, 2, )  kernel_size=(3, 3, 2, )  padding=(0, 1, 1, )  
39, 37, 11, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 1, 0, )  
19, 19, 5, stride=(2, 2, 2, )  kernel_size=(3, 3, 3, )  padding=(0, 0, 1, )  
9, 9, 3, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
5, 5, 2, stride=(2, 2, 1, )  kernel_size=(3, 3, 2, )  padding=(1, 1, 0, )  
OUT: 3, 3, 1, Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': True}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
When creating TucodecEncode1D, inputSize =  26032 with Cstd =  64
Dim set in GenCAE:  1
block is  Tucodec1D  and layer_kwargs is  {'B': 'NeXt1D', 'Cstd': 64, 'S': None, 'A': 'prelu', 'AS': None, 'DIM': 1, 'clusterInputSize': 26032, 'encode': False}
When creating TucodecEncode1D in build, inputSize =  26032
DIM USED  1
Number of parameters: 567553
------------------------------ Training subdomain 6 at 2020-08-28 14:05:45.598545. ------------------------------
Loading data started 2020-08-28 14:05:45.598633
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
test_X type:  <class 'numpy.ndarray'>
test X shape 0 =  8  and batch  3
Train loader data <torch.utils.data.dataloader.DataLoader object at 0x7fde69656588>
Loading data finished 2020-08-28 14:05:58.919878
Loop AE Train begins at  14:05:58.923125
Training epoch begins:  0
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [1/150], TRAIN: -loss:13273.76, av_diff: 0.30, time taken (m): 0.04m
epoch [1/150], TEST: -loss:14363.3149, time taken(m): 0.01m
Training epoch begins:  1
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  2
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  3
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  4
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  5
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [6/150], TRAIN: -loss:7101.86, av_diff: 0.04, time taken (m): 0.03m
Training epoch begins:  6
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  7
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  8
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  9
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  10
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [11/150], TRAIN: -loss:6458.32, av_diff: 0.01, time taken (m): 0.03m
epoch [11/150], TEST: -loss:11308.0537, time taken(m): 0.01m
Training epoch begins:  11
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  12
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  13
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  14
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  15
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [16/150], TRAIN: -loss:6161.76, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  16
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  17
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  18
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  19
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  20
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [21/150], TRAIN: -loss:5967.57, av_diff: 0.01, time taken (m): 0.03m
epoch [21/150], TEST: -loss:10731.9553, time taken(m): 0.01m
Training epoch begins:  21
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  22
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  23
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  24
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  25
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [26/150], TRAIN: -loss:5790.73, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  26
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  27
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  28
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  29
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  30
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [31/150], TRAIN: -loss:5663.61, av_diff: 0.02, time taken (m): 0.03m
epoch [31/150], TEST: -loss:10777.1128, time taken(m): 0.01m
Training epoch begins:  31
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  32
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  33
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  34
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  35
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [36/150], TRAIN: -loss:5486.85, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  36
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  37
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  38
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  39
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  40
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [41/150], TRAIN: -loss:5278.09, av_diff: 0.02, time taken (m): 0.03m
epoch [41/150], TEST: -loss:10814.7847, time taken(m): 0.01m
Training epoch begins:  41
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  42
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  43
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  44
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  45
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [46/150], TRAIN: -loss:5070.75, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  46
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  47
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  48
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  49
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  50
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [51/150], TRAIN: -loss:4925.05, av_diff: 0.01, time taken (m): 0.03m
epoch [51/150], TEST: -loss:10497.5957, time taken(m): 0.01m
Training epoch begins:  51
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  52
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  53
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  54
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  55
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [56/150], TRAIN: -loss:4735.95, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  56
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  57
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  58
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  59
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  60
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [61/150], TRAIN: -loss:4602.11, av_diff: 0.02, time taken (m): 0.03m
epoch [61/150], TEST: -loss:10266.9285, time taken(m): 0.01m
Training epoch begins:  61
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  62
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  63
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  64
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  65
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [66/150], TRAIN: -loss:4440.75, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  66
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  67
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  68
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  69
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  70
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [71/150], TRAIN: -loss:4245.59, av_diff: 0.01, time taken (m): 0.03m
epoch [71/150], TEST: -loss:9858.2173, time taken(m): 0.01m
Training epoch begins:  71
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  72
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  73
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  74
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  75
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [76/150], TRAIN: -loss:4137.45, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  76
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  77
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  78
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  79
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  80
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [81/150], TRAIN: -loss:4000.24, av_diff: 0.01, time taken (m): 0.03m
epoch [81/150], TEST: -loss:9518.6580, time taken(m): 0.01m
Training epoch begins:  81
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  82
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  83
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  84
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  85
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [86/150], TRAIN: -loss:3848.86, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  86
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  87
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  88
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  89
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  90
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [91/150], TRAIN: -loss:3691.17, av_diff: 0.01, time taken (m): 0.03m
epoch [91/150], TEST: -loss:9239.6433, time taken(m): 0.01m
Training epoch begins:  91
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  92
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  93
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  94
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  95
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [96/150], TRAIN: -loss:3584.42, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  96
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  97
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  98
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  99
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  100
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [101/150], TRAIN: -loss:3477.88, av_diff: 0.01, time taken (m): 0.03m
epoch [101/150], TEST: -loss:8942.6113, time taken(m): 0.01m
Training epoch begins:  101
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  102
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  103
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  104
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  105
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [106/150], TRAIN: -loss:3416.93, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  106
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  107
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  108
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  109
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  110
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [111/150], TRAIN: -loss:3280.42, av_diff: 0.01, time taken (m): 0.03m
epoch [111/150], TEST: -loss:8616.0271, time taken(m): 0.01m
Training epoch begins:  111
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  112
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  113
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  114
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  115
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [116/150], TRAIN: -loss:3210.01, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  116
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  117
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  118
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  119
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  120
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [121/150], TRAIN: -loss:3081.16, av_diff: 0.01, time taken (m): 0.03m
epoch [121/150], TEST: -loss:8374.9048, time taken(m): 0.01m
Training epoch begins:  121
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  122
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  123
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  124
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  125
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [126/150], TRAIN: -loss:2942.19, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  126
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  127
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  128
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  129
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  130
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [131/150], TRAIN: -loss:2843.85, av_diff: 0.01, time taken (m): 0.03m
epoch [131/150], TEST: -loss:8096.5176, time taken(m): 0.01m
Training epoch begins:  131
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  132
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  133
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  134
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  135
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [136/150], TRAIN: -loss:2790.39, av_diff: 0.01, time taken (m): 0.03m
Training epoch begins:  136
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  137
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  138
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  139
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  140
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [141/150], TRAIN: -loss:2710.13, av_diff: 0.01, time taken (m): 0.03m
epoch [141/150], TEST: -loss:7921.4827, time taken(m): 0.01m
Training epoch begins:  141
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  142
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  143
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  144
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  145
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [146/150], TRAIN: -loss:2598.05, av_diff: 0.02, time taken (m): 0.03m
Training epoch begins:  146
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  147
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  148
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
Training epoch begins:  149
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([3, 26032])
Shape of y output of model torch.Size([3, 26032]) and x = torch.Size([3, 26032])
data shape in one loop:  torch.Size([2, 26032])
Shape of y output of model torch.Size([2, 26032]) and x = torch.Size([2, 26032])
epoch [150/150], TRAIN: -loss:2553.49, av_diff: 0.01, time taken (m): 0.03m
epoch [150/150], TEST: -loss:7707.3818, time taken(m): 0.01m
Loop AE Train Ends at  14:11:05.236353
------------------------------ DA subdomain 6 at 2020-08-28 14:11:05.317739. ------------------------------
----------------------------- START OF DA ----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
----------------------------- DA Loading Data and Splitting ----------------------
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Following loading data for BatchDA 
 train_X = (429, 26032) , test_X = (107, 26032), X = (537, 26032)
-----------------------------DA Init----------------------
Reading pickle file:  /home/mredstone/unstructuredCAE/code/Data_Assimilation/src/VarDACAE/X_6/X_80_1D_clustered.pickle
Shape read X:  (537, 26032)
Clustering in 1D
Splitting and setting training testing set: Hist frac = 0.8, hist IDX = 429
shape of mean (26032,) and std (26032,)
Normalising
Train from 0 to 429 - test from 429 to 536 and t_DA at 536
Selecting one DA index:  10
u_c before reduction of space:  [-0.8531082  -0.80088433  0.03712867 -0.14295814 -0.99493482 -0.66263901
 -0.84611558  0.09697116 -0.648397   -1.36865512]
----------------------------- DA Testing for each test case ----------------------
Taking mean of historical data
u_c taken from control states: [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
u_c before reduction of space:  [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
data[u_c] post encoding of state:  [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
Shape of w_0 =  (429,)
J_b = 0.0, J_o = 406666.58442652266
J_b = 0.5, J_o = 11594255.680779794
J_b = 0.004647428652760699, J_o = 277839.04720669537
J_b = 0.01227399450944837, J_o = 192599.41823139897
J_b = 0.01795017911209346, J_o = 163360.21982001123
J_b = 0.0291840496256828, J_o = 130448.20389412744
J_b = 0.038490269583999204, J_o = 112837.41087878938
J_b = 0.06280993499854971, J_o = 88215.12614088759
J_b = 0.09396848800317434, J_o = 78474.93723490472
J_b = 0.09897609120303916, J_o = 69694.68742505062
J_b = 0.10728648544811745, J_o = 63872.48498223983
J_b = 0.1246923453076221, J_o = 58321.45144133174
J_b = 0.1694797330939186, J_o = 49191.31741859205
J_b = 0.2741291122449703, J_o = 54393.9673960527
J_b = 0.20515167509459892, J_o = 45477.732859659816
J_b = 0.24195740792166798, J_o = 40904.064867671514
J_b = 0.2675622784795292, J_o = 41506.97954391374
J_b = 0.2528157605176286, J_o = 39879.52244199013
J_b = 0.265531700637376, J_o = 38073.899562876846
J_b = 0.2723767592106524, J_o = 36822.16283939533
J_b = 0.29130127614776913, J_o = 34631.386709840524
J_b = 0.31756082956828724, J_o = 32579.50974369129
J_b = 0.3786502243525866, J_o = 33770.99565372146
J_b = 0.34094762586493493, J_o = 31443.21984206938
J_b = 0.36594749842983565, J_o = 29870.782946202922
J_b = 0.38195201975809834, J_o = 28787.141287791776
J_b = 0.4061759975922199, J_o = 27402.724519608288
J_b = 0.44580398140335337, J_o = 27031.393415788283
J_b = 0.44266823815082784, J_o = 25995.668950285562
J_b = 0.44493757621694185, J_o = 25559.692318512676
J_b = 0.456451957063925, J_o = 25158.099539274775
J_b = 0.4864157881709951, J_o = 24918.571762998345
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.18979001 -0.4330939   0.31225862  0.07632564 -0.77938688 -0.59917589
 -0.94275377  0.10329801 -0.52626646 -1.22840425]
W_opt:  [-0.00818243 -0.01388272 -0.00942734  0.00062346  0.01682923  0.02994261
  0.03429331 -0.01279141 -0.10409683 -0.23432079]
----------------------------- DA Assimilate ----------------------
minCostFunction = 9.1141 s, v_trunc (Latent to Reduced) = 0.1045, dec (Reduced to Full) = 0.2223, add (DA)= 0.0001decode = 0.3302 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 9.4445 s, inc stats = 56.2780, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95971306 2.8606017  3.44302222 3.07860686 2.45294002]
u_DA:    [3.8929712  1.92557666 3.0146016  1.64600809 2.66530052]
ref_MAE: [0.11925866 0.69882131 0.90408743 1.22605341 0.07630631]
da_MAE:  [0.06674186 0.93502504 0.42842061 1.43259877 0.2123605 ]
% 17.87667269634517 da_MAE 0.006172783017117173 ref_MAE 0.007516479445959393
u_c taken from control states: [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
u_c before reduction of space:  [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
data[u_c] post encoding of state:  [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
J_b = 0.0, J_o = 421088.4660746515
J_b = 0.5000000000000001, J_o = 10601428.54643021
J_b = 0.005401445942664739, J_o = 282250.5638647008
J_b = 0.01413443379713269, J_o = 203083.68903230267
J_b = 0.017399555458160083, J_o = 178903.85273537601
J_b = 0.03219064119784543, J_o = 134476.58403547952
J_b = 0.040909622197198015, J_o = 121075.66104042549
J_b = 0.06544293929741372, J_o = 102334.37874190102
J_b = 0.0991410760200887, J_o = 98152.55378395022
J_b = 0.09110263731381185, J_o = 88186.85223936844
J_b = 0.09280699217736356, J_o = 84775.61403521369
J_b = 0.10381053735961425, J_o = 80753.80559610341
J_b = 0.12747435129960252, J_o = 74941.56491416629
J_b = 0.1906843694328251, J_o = 67104.57611769246
J_b = 0.2682131229163085, J_o = 77593.15706922126
J_b = 0.20882057840759355, J_o = 65585.88135573374
J_b = 0.23030920152882256, J_o = 62911.940693887576
J_b = 0.2341164722143376, J_o = 61957.205577653986
J_b = 0.23906505673542255, J_o = 61041.53204948065
J_b = 0.25761797805232534, J_o = 59274.8637580918
J_b = 0.2891114034138656, J_o = 57264.829017870245
J_b = 0.34964600480992597, J_o = 56373.301356520824
J_b = 0.33874845993398844, J_o = 54894.966713909846
J_b = 0.3376195950791636, J_o = 54328.73582877669
J_b = 0.34683382541310154, J_o = 53548.33331408405
J_b = 0.37610908231202456, J_o = 52178.346554658936
J_b = 0.42584157932240707, J_o = 53928.15823394452
J_b = 0.39075964761254234, J_o = 51677.061725229105
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1843939  -0.42663827  0.31007282  0.07341155 -0.78436123 -0.59222136
 -0.92413067  0.13399483 -0.52926793 -1.22296952]
W_opt:  [-0.01270935 -0.00754545 -0.00508844  0.004552    0.02157925  0.03167746
  0.02887422 -0.02483345 -0.11258216 -0.22883265]
----------------------------- DA Assimilate ----------------------
minCostFunction = 7.9579 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1727, add (DA)= 0.0001decode = 0.2800 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 8.2380 s, inc stats = 8.2517, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95948174 2.86219835 3.44235992 3.07760999 2.45160571]
u_DA:    [3.89395474 1.94974052 2.99983416 1.66915395 2.65028828]
ref_MAE: [0.11902734 0.70041795 0.90342514 1.22505654 0.074972  ]
da_MAE:  [0.065527   0.91245782 0.44252576 1.40845605 0.19868257]
% 17.94248462655435 da_MAE 0.006170374213824572 ref_MAE 0.007519572321612537
u_c taken from control states: [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
u_c before reduction of space:  [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
data[u_c] post encoding of state:  [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
J_b = 0.0, J_o = 453265.6860549223
J_b = 0.5, J_o = 9480042.086916223
J_b = 0.006591689169527755, J_o = 298788.4567951144
J_b = 0.016816522387305195, J_o = 232905.0443005605
J_b = 0.017202125186822036, J_o = 207916.2104398775
J_b = 0.025341801659374958, J_o = 174568.81709607656
J_b = 0.030955091641915698, J_o = 162405.4359269524
J_b = 0.05176300379424077, J_o = 136742.45357567904
J_b = 0.0776329959999405, J_o = 130745.72975906087
J_b = 0.07821902043659415, J_o = 120210.12011006288
J_b = 0.08347857702894682, J_o = 115209.35835723083
J_b = 0.09540776652178268, J_o = 111199.76853222177
J_b = 0.11512937266556927, J_o = 105584.88558270558
J_b = 0.16736854872909054, J_o = 101023.65375458205
J_b = 0.19031905392925763, J_o = 98807.13834269831
J_b = 0.17807566205451358, J_o = 96172.45054484808
J_b = 0.17876047537035228, J_o = 95502.41678488103
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1789977  -0.4199363   0.30792535  0.07055619 -0.78699059 -0.58756011
 -0.91125316  0.13594157 -0.53148825 -1.23565039]
W_opt:  [ 0.0038046   0.01165601  0.01226778  0.01135773  0.00853764 -0.00399088
 -0.02820558 -0.07433314 -0.13180586 -0.19006777]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7947 s, v_trunc (Latent to Reduced) = 0.1056, dec (Reduced to Full) = 0.1834, add (DA)= 0.0001decode = 0.2912 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0860 s, inc stats = 5.0951, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95925042 2.86385592 3.44170924 3.07663321 2.45090041]
u_DA:    [3.89436083 1.96610939 3.00213311 1.67691152 2.64431465]
ref_MAE: [0.11879602 0.70207552 0.90277445 1.22407976 0.0742667 ]
da_MAE:  [0.06488959 0.89774653 0.43957613 1.39972169 0.19341424]
% 18.140515942526207 da_MAE 0.00615819255752516 ref_MAE 0.0075228822028752034
u_c taken from control states: [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
u_c before reduction of space:  [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
data[u_c] post encoding of state:  [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
J_b = 0.0, J_o = 497482.90205921256
J_b = 0.49999999999999983, J_o = 8586813.18718946
J_b = 0.008073793585594884, J_o = 322350.4566450198
J_b = 0.019381398229925167, J_o = 278808.4850060432
J_b = 0.017238818799312394, J_o = 243682.7627003895
J_b = 0.02012758771767432, J_o = 219966.06104110647
J_b = 0.02765446037792538, J_o = 203097.11777447446
J_b = 0.038008899253344317, J_o = 183863.51505501842
J_b = 0.06250070909033544, J_o = 165367.6380622089
J_b = 0.07504490813685358, J_o = 155335.94189605222
J_b = 0.08329623540330496, J_o = 149250.3011400996
J_b = 0.10376881092216668, J_o = 142451.3119134368
J_b = 0.12469727121863769, J_o = 139336.29359325246
J_b = 0.12470406045635243, J_o = 136362.75104915764
J_b = 0.13349678694726144, J_o = 133056.7783831982
J_b = 0.14881217112046655, J_o = 130538.99284784251
J_b = 0.18077884040159836, J_o = 136340.9966088342
J_b = 0.15633484611736456, J_o = 129574.20397835805
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.17372891 -0.41353397  0.30584881  0.0681313  -0.78689972 -0.58384718
 -0.90373076  0.11014376 -0.53288285 -1.26704552]
W_opt:  [-0.00214956  0.01022496  0.01415954  0.01565268  0.01218019 -0.00304427
 -0.03033857 -0.07601448 -0.13199242 -0.18505514]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0600 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1880, add (DA)= 0.0001decode = 0.2945 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3546 s, inc stats = 5.3672, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95902457 2.86543938 3.44108005 3.07580368 2.45092479]
u_DA:    [3.89575648 1.97650062 2.99928484 1.72566383 2.61576562]
ref_MAE: [0.11857017 0.70365898 0.90214526 1.22325023 0.07429108]
da_MAE:  [0.06326809 0.88893876 0.44179521 1.35013985 0.16484084]
% 18.194589718721854 da_MAE 0.0061566466033936606 ref_MAE 0.007525965070311078
u_c taken from control states: [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
u_c before reduction of space:  [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
data[u_c] post encoding of state:  [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
J_b = 0.0, J_o = 541282.5446393499
J_b = 0.5000000000000001, J_o = 7815942.932913454
J_b = 0.010060503926212985, J_o = 336936.7136631108
J_b = 0.02121609471753664, J_o = 315140.0727265153
J_b = 0.018331293951459757, J_o = 266744.5476917291
J_b = 0.02095051057292992, J_o = 245299.1047347713
J_b = 0.028900858435525183, J_o = 226980.98699355288
J_b = 0.037876659055608525, J_o = 209274.21504712067
J_b = 0.06202163391970684, J_o = 187142.60298164634
J_b = 0.08060628683542957, J_o = 176781.71551060665
J_b = 0.08636275021206138, J_o = 170122.96100649604
J_b = 0.09941301900019596, J_o = 163683.87736830785
J_b = 0.1113075963563845, J_o = 159853.01209612977
J_b = 0.14446584394535622, J_o = 154476.79461600777
J_b = 0.17132511089476946, J_o = 151860.41541162724
J_b = 0.16810511734718703, J_o = 150256.1760899166
J_b = 0.1672802116137655, J_o = 149108.6761202152
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.16867364 -0.40788625  0.30387111  0.06650041 -0.78415361 -0.58046782
 -0.90327473  0.05004188 -0.53362122 -1.31412332]
W_opt:  [-0.01276277  0.00633642  0.01360705  0.01889661  0.01875999  0.00455946
 -0.02629253 -0.07483709 -0.13619925 -0.1951487 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8525 s, v_trunc (Latent to Reduced) = 0.1050, dec (Reduced to Full) = 0.1924, add (DA)= 0.0001decode = 0.2998 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1525 s, inc stats = 5.1560, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95880786 2.86683621 3.4404808  3.07524578 2.4516614 ]
u_DA:    [3.89593373 1.9611863  2.99207366 1.69884047 2.64943307]
ref_MAE: [0.11835346 0.70505581 0.90154602 1.22269233 0.07502769]
da_MAE:  [0.06287413 0.90564991 0.44840714 1.3764053  0.19777167]
% 17.700433516021548 da_MAE 0.0061960681058020346 ref_MAE 0.007528676480948712
u_c taken from control states: [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
u_c before reduction of space:  [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
data[u_c] post encoding of state:  [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
J_b = 0.0, J_o = 591970.4967840061
J_b = 0.5, J_o = 7342234.3323470205
J_b = 0.011886673041493908, J_o = 359943.4334398848
J_b = 0.02049549197108099, J_o = 310083.64583058335
J_b = 0.026253293017914434, J_o = 269661.9976229799
J_b = 0.032474195168116136, J_o = 256178.669913336
J_b = 0.0381441694601356, J_o = 244813.95141864443
J_b = 0.05193058378736661, J_o = 224557.14215772078
J_b = 0.06961079298440266, J_o = 207655.9665863883
J_b = 0.10703813527523492, J_o = 194707.85993457408
J_b = 0.11403315799362905, J_o = 187232.87964681408
J_b = 0.11736839952226721, J_o = 184263.94519183523
J_b = 0.1283040931570904, J_o = 180487.74111869742
J_b = 0.1535669115162616, J_o = 176600.7316437497
J_b = 0.17886038964914863, J_o = 172854.29203631272
J_b = 0.18948641649341566, J_o = 170857.29249928048
J_b = 0.21136791056983187, J_o = 171144.24592348412
J_b = 0.19929560814468708, J_o = 169925.2498577949
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.16398177 -0.40355572  0.30202361  0.06598544 -0.77868245 -0.57605417
 -0.90907651 -0.04333707 -0.53372071 -1.35313569]
W_opt:  [-0.0218935   0.00106489  0.01411984  0.02403446  0.0246685   0.01004859
 -0.02202336 -0.0737809  -0.13924622 -0.20227354]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0793 s, v_trunc (Latent to Reduced) = 0.1045, dec (Reduced to Full) = 0.1985, add (DA)= 0.0001decode = 0.3064 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3859 s, inc stats = 5.3992, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95860674 2.86790726 3.43992101 3.07506961 2.45312898]
u_DA:    [3.89962509 1.95397334 2.99715778 1.70752579 2.65639199]
ref_MAE: [0.11815234 0.70612686 0.90098623 1.22251616 0.07649527]
da_MAE:  [0.05898164 0.91393392 0.44276323 1.36754382 0.20326301]
% 17.3231561450609 da_MAE 0.006226248255097758 ref_MAE 0.00753082479300013
u_c taken from control states: [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
u_c before reduction of space:  [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
data[u_c] post encoding of state:  [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
J_b = 0.0, J_o = 665300.294152221
J_b = 0.4999999999999998, J_o = 7596839.621813044
J_b = 0.012336739336423956, J_o = 415935.7480553568
J_b = 0.020472099966610837, J_o = 354368.6707098385
J_b = 0.03211940464278528, J_o = 309863.2077051742
J_b = 0.0366734453602824, J_o = 297770.0067610939
J_b = 0.05529910589150538, J_o = 268009.41468809603
J_b = 0.07162240327614446, J_o = 251346.06795209783
J_b = 0.12260187277449044, J_o = 236127.19989822863
J_b = 0.13197288359527268, J_o = 225397.92293140088
J_b = 0.13138395500585098, J_o = 222355.22948150517
J_b = 0.14284967655266026, J_o = 217367.0677321775
J_b = 0.17803501859409981, J_o = 214062.29315709948
J_b = 0.18893975242199026, J_o = 210111.79757954174
J_b = 0.21090406187306193, J_o = 207316.98056727654
J_b = 0.22473752050805837, J_o = 205825.48931439186
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15978878 -0.40086482  0.3003202   0.06679666 -0.7706285  -0.56835382
 -0.91967352 -0.15144594 -0.53320028 -1.38517674]
W_opt:  [-0.03299858 -0.00733765  0.01500016  0.02904354  0.02982203  0.01511859
 -0.01674234 -0.06971141 -0.13643724 -0.20242054]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4628 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.1727, add (DA)= 0.0001decode = 0.2782 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7412 s, inc stats = 4.7484, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95842699 2.86857279 3.43940488 3.07534712 2.45528936]
u_DA:    [3.90030779 1.95283202 3.00987482 1.74821458 2.67421727]
ref_MAE: [0.11797259 0.70679239 0.9004701  1.22279367 0.07865565]
da_MAE:  [0.0581192  0.91574077 0.42953006 1.32713254 0.21892791]
% 17.234981488550158 da_MAE 0.006234025510544336 ref_MAE 0.007532198533468474
u_c taken from control states: [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
u_c before reduction of space:  [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
data[u_c] post encoding of state:  [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
J_b = 0.0, J_o = 745478.4419546626
J_b = 0.49999999999999994, J_o = 8383437.076934032
J_b = 0.011556964292045797, J_o = 491800.54197718203
J_b = 0.02187843488841107, J_o = 456889.0619825548
J_b = 0.021162293666594056, J_o = 406182.0988591775
J_b = 0.02736871340059652, J_o = 370255.5200360039
J_b = 0.03694833506148671, J_o = 352728.0851374088
J_b = 0.05142395592780454, J_o = 326577.5589897514
J_b = 0.07879761498462307, J_o = 305824.190804889
J_b = 0.08918415574124387, J_o = 295902.99907946313
J_b = 0.11104505266143595, J_o = 283575.0580130328
J_b = 0.14452976672861956, J_o = 276932.8435010903
J_b = 0.15834637725126216, J_o = 270566.1381358818
J_b = 0.16227257288512562, J_o = 267666.031256429
J_b = 0.17923233858060902, J_o = 262949.25409088924
J_b = 0.21299594874023314, J_o = 258953.88144411257
J_b = 0.25772576763718114, J_o = 256350.56973739152
J_b = 0.2493824829863551, J_o = 254743.21721263794
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.1561692  -0.40000284  0.2987707   0.06909187 -0.76023416 -0.55649011
 -0.93451934 -0.26957457 -0.53211445 -1.41199628]
W_opt:  [-0.04256187 -0.01657993  0.01643953  0.03563121  0.03657326  0.0222243
 -0.00937416 -0.06463593 -0.13515831 -0.20672625]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1434 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1751, add (DA)= 0.0001decode = 0.2821 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4257 s, inc stats = 5.4383, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95827183 2.86878598 3.43893538 3.07613228 2.45807752]
u_DA:    [3.90191764 1.95979201 3.03222223 1.7884272  2.64491875]
ref_MAE: [0.11781743 0.70700558 0.9000006  1.22357883 0.08144381]
da_MAE:  [0.05635419 0.90899397 0.40671315 1.28770508 0.18684124]
% 17.72157177807048 da_MAE 0.006197726540786389 ref_MAE 0.007532626321044038
u_c taken from control states: [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
u_c before reduction of space:  [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
data[u_c] post encoding of state:  [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
J_b = 0.0, J_o = 792427.7050013194
J_b = 0.4999999999999997, J_o = 8510776.960501209
J_b = 0.011487175163246231, J_o = 537964.0168625526
J_b = 0.022244404982226396, J_o = 500614.4971649416
J_b = 0.021444600911314712, J_o = 448275.67962541676
J_b = 0.028012889510113506, J_o = 408836.4172338466
J_b = 0.03862962139961305, J_o = 389418.0139931591
J_b = 0.05370657328412837, J_o = 362617.521727558
J_b = 0.08224011488524319, J_o = 341349.08088795556
J_b = 0.09246052834497705, J_o = 331624.84843232343
J_b = 0.11250520690755851, J_o = 320226.1585093977
J_b = 0.1443088081588861, J_o = 313239.0716324105
J_b = 0.1625654386575992, J_o = 307153.19348937937
J_b = 0.16604189672276679, J_o = 304296.8667394316
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15313978 -0.4013763   0.29737433  0.07291227 -0.74799567 -0.54111581
 -0.95400505 -0.39960588 -0.53067801 -1.43519682]
W_opt:  [-0.01528448 -0.00475864  0.01072643  0.01910886  0.0151762  -0.00118512
 -0.02889345 -0.07120252 -0.12164255 -0.16903427]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9855 s, v_trunc (Latent to Reduced) = 0.1056, dec (Reduced to Full) = 0.2046, add (DA)= 0.0001decode = 0.3123 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.2979 s, inc stats = 4.3103, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95814197 2.86844629 3.43851228 3.07743919 2.46136035]
u_DA:    [3.90153659 1.96599806 3.09080364 1.81174125 2.64797424]
ref_MAE: [0.11768757 0.70666589 0.8995775  1.22488574 0.08472664]
da_MAE:  [0.05660538 0.90244822 0.34770865 1.26569794 0.18661389]
% 18.389154667685094 da_MAE 0.00614703797132961 ref_MAE 0.007532133684315126
u_c taken from control states: [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
u_c before reduction of space:  [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
data[u_c] post encoding of state:  [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
J_b = 0.0, J_o = 809554.5583730134
J_b = 0.4999999999999998, J_o = 8402709.487533748
J_b = 0.01158070356252363, J_o = 556733.2965660156
J_b = 0.022387752667546005, J_o = 516112.2532281798
J_b = 0.02223392284505267, J_o = 463223.81373534276
J_b = 0.030508714611352267, J_o = 420454.4564450801
J_b = 0.04099645865793999, J_o = 402936.8018252557
J_b = 0.058372545254009756, J_o = 373771.91868956777
J_b = 0.08517543667226674, J_o = 353777.28946699447
J_b = 0.09489364272075003, J_o = 345339.01313308574
J_b = 0.11751426302948902, J_o = 333096.5810212473
J_b = 0.14922636225902092, J_o = 325888.19525539596
J_b = 0.1610346572970281, J_o = 321088.77013367764
J_b = 0.1675849351634266, J_o = 317995.80585371057
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.15060191 -0.40504329  0.29609822  0.07803771 -0.73515003 -0.52401771
 -0.97757085 -0.53169156 -0.52928149 -1.45542751]
W_opt:  [-0.01439123 -0.00264649  0.00701124  0.01539475  0.01460503 -0.00020096
 -0.02728939 -0.07010986 -0.12169418 -0.17025172]
----------------------------- DA Assimilate ----------------------
minCostFunction = 3.9774 s, v_trunc (Latent to Reduced) = 0.1056, dec (Reduced to Full) = 0.1875, add (DA)= 0.0001decode = 0.2953 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.2728 s, inc stats = 4.2784, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95803318 2.86753935 3.43812562 3.07919254 2.46480604]
u_DA:    [3.90228344 1.96213056 3.09782493 1.77545953 2.65181283]
ref_MAE: [0.11757878 0.70575895 0.89919084 1.22663909 0.08817233]
da_MAE:  [0.05574974 0.90540879 0.34030069 1.30373301 0.18700678]
% 18.343367647131544 da_MAE 0.006149206861749145 ref_MAE 0.007530566329476033
u_c taken from control states: [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
u_c before reduction of space:  [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
data[u_c] post encoding of state:  [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
J_b = 0.0, J_o = 777051.2355946329
J_b = 0.4999999999999997, J_o = 7976681.039584277
J_b = 0.012015719722429943, J_o = 526286.1555155746
J_b = 0.022291171070656517, J_o = 476385.7091904664
J_b = 0.025090855767318634, J_o = 423805.1710556996
J_b = 0.038697234839255745, J_o = 384263.9611900738
J_b = 0.04473263109080614, J_o = 372445.9467968887
J_b = 0.0715890933674058, J_o = 334946.81147587125
J_b = 0.09485116825191263, J_o = 321840.49662310083
J_b = 0.10501294643258835, J_o = 315315.5664985987
J_b = 0.1265161629928047, J_o = 305674.33826793457
J_b = 0.15095303799434243, J_o = 301318.1571840477
J_b = 0.15563219460713246, J_o = 297024.00486219395
J_b = 0.16309004150066786, J_o = 293962.05924017006
J_b = 0.1798527649423074, J_o = 290426.9145235135
J_b = 0.22224946009507027, J_o = 287842.6686177223
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14835036 -0.41088086  0.29488054  0.08389684 -0.72355852 -0.50645741
 -1.00453994 -0.6484496  -0.52844105 -1.47295772]
W_opt:  [-0.02816858 -0.0078043   0.00206255  0.01533559  0.02469142  0.01672762
 -0.01028242 -0.06515882 -0.13549878 -0.20524259]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5448 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1813, add (DA)= 0.0001decode = 0.2883 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8332 s, inc stats = 4.8381, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95793666 2.86609556 3.43775667 3.08119687 2.46791533]
u_DA:    [3.90408074 1.95065621 3.08174136 1.73763252 2.65894835]
ref_MAE: [0.11748226 0.70431517 0.89882188 1.22864342 0.09128162]
da_MAE:  [0.05385593 0.91543935 0.3560153  1.34356436 0.19103302]
% 18.03979738489457 da_MAE 0.006169744605070035 ref_MAE 0.007527732250789896
\% improve_point: 13.02, mse_ref_points: 3.515884780171926e-05, mse_da_points: 3.058122277902106e-05, % improve_overlap: 13.02, mse_ref_overlap: 0.91577, mse_da_overlap: 0.79657
DA - - L2: 176227.91, L1: 9717.08, % Improve: 17.90%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.796, time(s): 10.8577s,
u_c taken from control states: [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
u_c before reduction of space:  [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
data[u_c] post encoding of state:  [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
J_b = 0.0, J_o = 710725.5139660775
J_b = 0.5, J_o = 7324273.266248098
J_b = 0.012697165046271611, J_o = 464212.102796776
J_b = 0.021605975926589978, J_o = 379801.0608683787
J_b = 0.05376562851363682, J_o = 395507.2469332606
J_b = 0.033382258172112184, J_o = 345897.54775335675
J_b = 0.044376992140290276, J_o = 326723.19216358446
J_b = 0.04925530362675614, J_o = 317128.37018062087
J_b = 0.0685284999834456, J_o = 291137.2148787594
J_b = 0.08367665487372275, J_o = 276298.7902771023
J_b = 0.12052882372035842, J_o = 261558.58032091477
J_b = 0.13474785791159252, J_o = 254656.7825927693
J_b = 0.1361999054271364, J_o = 251673.56475510407
J_b = 0.14958917943686947, J_o = 246845.4284624063
J_b = 0.17354340942788993, J_o = 243668.26153629398
J_b = 0.18791602405806207, J_o = 240666.52254231006
J_b = 0.21990961576004073, J_o = 236834.65163793787
J_b = 0.23510043012899084, J_o = 235191.44456066884
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14612547 -0.41784581  0.29366001  0.0899274  -0.71504074 -0.49072673
 -1.03524204 -0.74667171 -0.52870831 -1.48807057]
W_opt:  [-0.0188255  -0.0068351   0.00088504  0.01252223  0.02595511  0.02587942
  0.00132733 -0.05650348 -0.13363953 -0.21211536]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1205 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1808, add (DA)= 0.0001decode = 0.2879 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4085 s, inc stats = 5.4150, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95784129 2.86437295 3.43738685 3.08325985 2.47020013]
u_DA:    [3.89664976 1.96190317 3.04443579 1.74213674 2.67572166]
ref_MAE: [0.11738689 0.70259255 0.89845206 1.2307064  0.09356642]
da_MAE:  [0.06119153 0.90246978 0.39295106 1.3411231  0.20552154]
% 18.401185032641155 da_MAE 0.006139278726878209 ref_MAE 0.007523735153916198
u_c taken from control states: [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
u_c before reduction of space:  [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
data[u_c] post encoding of state:  [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
J_b = 0.0, J_o = 657805.9308549743
J_b = 0.5, J_o = 7161521.451141309
J_b = 0.01214870179300625, J_o = 428203.3260222033
J_b = 0.023179172388894314, J_o = 374400.73097060027
J_b = 0.027776323741491894, J_o = 323682.7466456387
J_b = 0.03876110807373157, J_o = 299325.59909868496
J_b = 0.04338427417561193, J_o = 288833.09087404446
J_b = 0.06707357209479255, J_o = 255775.97364890407
J_b = 0.08858751321954368, J_o = 239108.5748661179
J_b = 0.1272820655782702, J_o = 228958.82234353948
J_b = 0.13704171922971792, J_o = 221725.5585057232
J_b = 0.13312650036260182, J_o = 219428.3055094604
J_b = 0.13782775512654916, J_o = 215643.31654817142
J_b = 0.15451215338970084, J_o = 212408.26206870525
J_b = 0.18350266598866746, J_o = 209172.00990990383
J_b = 0.22203958609347976, J_o = 206199.41879996445
J_b = 0.2164590678899666, J_o = 205332.2861909085
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14376786 -0.4249202   0.29239468  0.09565538 -0.71061537 -0.4781826
 -1.06685687 -0.82088487 -0.53028733 -1.50095156]
W_opt:  [-0.00432599 -0.00644195 -0.00245062  0.00638429  0.017883    0.01924345
 -0.00462263 -0.05906789 -0.13194808 -0.20641005]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8315 s, v_trunc (Latent to Reduced) = 0.1045, dec (Reduced to Full) = 0.2042, add (DA)= 0.0001decode = 0.3109 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1425 s, inc stats = 5.1529, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95774023 2.86262327 3.43700345 3.08521932 2.47138718]
u_DA:    [3.89662496 1.9598132  3.02868327 1.71978703 2.67147803]
ref_MAE: [0.11728582 0.70084287 0.89806867 1.23266587 0.09475347]
da_MAE:  [0.06111527 0.90281007 0.40832018 1.36543229 0.20009085]
% 18.522774842420965 da_MAE 0.006126114146995447 ref_MAE 0.007518805574376626
u_c taken from control states: [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
u_c before reduction of space:  [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
data[u_c] post encoding of state:  [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
J_b = 0.0, J_o = 552077.7996061819
J_b = 0.4999999999999999, J_o = 8393100.306245647
J_b = 0.008861976940969202, J_o = 362672.2274157813
J_b = 0.021411949220919983, J_o = 309611.6848949227
J_b = 0.02004023590679909, J_o = 268967.35236274905
J_b = 0.02546892681229011, J_o = 235168.3158239693
J_b = 0.03454574026720154, J_o = 218548.15292166057
J_b = 0.04782133846905166, J_o = 195545.42422416035
J_b = 0.07602038397383203, J_o = 173336.27340311598
J_b = 0.09178667201840972, J_o = 163996.02576835154
J_b = 0.10397961478895382, J_o = 158011.35568406168
J_b = 0.12142181701076786, J_o = 152518.5276289964
J_b = 0.13235456276725424, J_o = 148932.88351530122
J_b = 0.14080007238839565, J_o = 146463.01322779636
J_b = 0.1566770214514958, J_o = 143407.1460927742
J_b = 0.19061804721442904, J_o = 145703.79246766822
J_b = 0.16760904295888576, J_o = 142508.32861034304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.14114901 -0.43165333  0.2910435   0.1005689  -0.71100587 -0.46887648
 -1.09617237 -0.85963009 -0.53324845 -1.51172333]
W_opt:  [ 1.00352152e-02 -1.08736427e-04 -1.34970961e-04  2.00708907e-03
  4.54818828e-03 -7.40035121e-04 -2.32242513e-02 -6.85397468e-02
 -1.30427669e-01 -1.92856383e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8471 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.2024, add (DA)= 0.0001decode = 0.3088 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1560 s, inc stats = 5.1615, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95762796 2.86095799 3.43659404 3.08690017 2.47128244]
u_DA:    [3.89667616 1.94781211 3.02848367 1.6722805  2.6939586 ]
ref_MAE: [0.11717356 0.6991776  0.89765926 1.23434672 0.09464873]
da_MAE:  [0.0609518  0.91314588 0.40811038 1.41461967 0.22267617]
% 18.302143477137115 da_MAE 0.0061378971456739475 ref_MAE 0.007512923113174061
u_c taken from control states: [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
u_c before reduction of space:  [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
data[u_c] post encoding of state:  [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
J_b = 0.0, J_o = 486302.3219459745
J_b = 0.5, J_o = 10096260.784188362
J_b = 0.00639651480737372, J_o = 327420.8425560721
J_b = 0.016487423420383503, J_o = 245946.04851900268
J_b = 0.01919017079677581, J_o = 216938.85159469128
J_b = 0.03468447779716598, J_o = 168482.31722642493
J_b = 0.041366650751662466, J_o = 156282.16199651553
J_b = 0.06669532391291681, J_o = 131217.9975027293
J_b = 0.09473622534444824, J_o = 120278.79154586581
J_b = 0.11856310347237717, J_o = 113560.89749588717
J_b = 0.11846352846922513, J_o = 110743.86333068743
J_b = 0.1205631841416692, J_o = 108406.0365295032
J_b = 0.1343253401903228, J_o = 105966.2913763638
J_b = 0.15452049348317728, J_o = 103600.3536149486
J_b = 0.16581025015278747, J_o = 102295.82570778948
J_b = 0.17683189746125252, J_o = 101213.21013697953
J_b = 0.19694141884690156, J_o = 101348.02411700331
J_b = 0.18594838616246853, J_o = 100599.63551790098
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13811955 -0.43778365  0.28956593  0.10416987 -0.7167217  -0.463063
 -1.12041199 -0.85615704 -0.53763442 -1.5205935 ]
W_opt:  [ 0.01088045  0.00049282  0.00110411  0.00417734  0.00919998  0.00590279
 -0.01522895 -0.0638298  -0.1367149  -0.21363832]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0910 s, v_trunc (Latent to Reduced) = 0.1027, dec (Reduced to Full) = 0.2001, add (DA)= 0.0001decode = 0.3051 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.3963 s, inc stats = 5.4019, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9574981  2.85944181 3.43614634 3.08813201 2.46974923]
u_DA:    [3.89448752 1.95444639 3.01449411 1.6639062  2.68017196]
ref_MAE: [0.1170437  0.69766141 0.89721156 1.23557856 0.09311552]
da_MAE:  [0.06301058 0.90499541 0.42165223 1.42422582 0.21042273]
% 18.59156689029601 da_MAE 0.0061111151342107 ref_MAE 0.007506734745742511
u_c taken from control states: [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
u_c before reduction of space:  [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
data[u_c] post encoding of state:  [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
J_b = 0.0, J_o = 442273.16802463646
J_b = 0.5000000000000001, J_o = 11750464.020008354
J_b = 0.0048866096074125735, J_o = 304519.1109428605
J_b = 0.012805962095053955, J_o = 213910.88535898726
J_b = 0.019144673944971886, J_o = 180344.7485694251
J_b = 0.03133635414911659, J_o = 145226.5669833173
J_b = 0.03897894617074105, J_o = 130625.29667802816
J_b = 0.05776072929452772, J_o = 109718.75377334733
J_b = 0.07891231449964382, J_o = 99787.54743030769
J_b = 0.10146640542254605, J_o = 93871.94650999378
J_b = 0.10153335017586526, J_o = 90218.12920928116
J_b = 0.10474537073832624, J_o = 87549.92427187532
J_b = 0.11419731796816839, J_o = 85073.4068088796
J_b = 0.14248468931044583, J_o = 83007.22448497574
J_b = 0.15586249447039935, J_o = 80189.75823667421
J_b = 0.1555093370662127, J_o = 79552.3291892815
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13460519 -0.442974    0.28794052  0.10609192 -0.72739305 -0.46092201
 -1.13751103 -0.80746231 -0.54325373 -1.52769992]
W_opt:  [ 0.01785805  0.01040113  0.00662649  0.00571449  0.00612717 -0.00347317
 -0.02933118 -0.07528665 -0.13856487 -0.20312518]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4376 s, v_trunc (Latent to Reduced) = 0.1145, dec (Reduced to Full) = 0.1786, add (DA)= 0.0001decode = 0.2953 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7331 s, inc stats = 4.7383, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95734745 2.8581581  3.43565384 3.08878952 2.46688677]
u_DA:    [3.89621419 1.94453041 3.02266302 1.67019443 2.68452729]
ref_MAE: [0.11689305 0.6963777  0.89671906 1.23623607 0.09025305]
da_MAE:  [0.06113326 0.91362768 0.41299083 1.4185951  0.21764053]
% 18.633924858399844 da_MAE 0.006102999582036697 ref_MAE 0.007500668517457354
u_c taken from control states: [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
u_c before reduction of space:  [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
data[u_c] post encoding of state:  [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
J_b = 0.0, J_o = 411812.14439992624
J_b = 0.5000000000000001, J_o = 13106961.045303086
J_b = 0.004042178001924782, J_o = 286677.5725489858
J_b = 0.010574028664598827, J_o = 195583.715686053
J_b = 0.01931675772103909, J_o = 153517.488985183
J_b = 0.02850067840904271, J_o = 128171.83451886296
J_b = 0.03610599212161292, J_o = 112505.83102759026
J_b = 0.049779983253813026, J_o = 95852.31952710354
J_b = 0.06612214810836146, J_o = 84551.34977238245
J_b = 0.09448389251685026, J_o = 79474.72240234292
J_b = 0.1008795672604561, J_o = 74207.31269926528
J_b = 0.09721909332992108, J_o = 72638.4084434041
J_b = 0.10097668401532221, J_o = 70043.3402229668
J_b = 0.11858756405784338, J_o = 68070.51032635642
J_b = 0.1331344488584866, J_o = 66365.90655539761
J_b = 0.14410608197394917, J_o = 66949.42181851964
J_b = 0.13705988179198922, J_o = 66068.58585967403
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.13057553 -0.44705289  0.28615548  0.10604607 -0.74208147 -0.46238439
 -1.14539738 -0.71432104 -0.5497788  -1.5117266 ]
W_opt:  [ 0.0103827   0.01331652  0.01115351  0.00941524  0.00803033 -0.00372979
 -0.03178666 -0.0798325  -0.1413071  -0.20291776]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7327 s, v_trunc (Latent to Reduced) = 0.1037, dec (Reduced to Full) = 0.1861, add (DA)= 0.0001decode = 0.2920 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0248 s, inc stats = 5.0376, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95717471 2.85714928 3.43511298 3.08877384 2.46294677]
u_DA:    [3.8975878  1.94734243 3.02870173 1.6834638  2.67224793]
ref_MAE: [0.11672031 0.69536889 0.89617819 1.23622039 0.08631306]
da_MAE:  [0.0595869  0.90980685 0.40641125 1.40531004 0.20930116]
% 18.5858333831555 da_MAE 0.006102425100068189 ref_MAE 0.007495532231862954
u_c taken from control states: [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
u_c before reduction of space:  [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
data[u_c] post encoding of state:  [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
J_b = 0.0, J_o = 391282.38148114755
J_b = 0.49999999999999994, J_o = 14244314.42669598
J_b = 0.0035035700153666486, J_o = 274693.1891740085
J_b = 0.009098775201478912, J_o = 185585.70824849326
J_b = 0.019504298339574008, J_o = 135542.79992680324
J_b = 0.027212281587018102, J_o = 114891.16779461931
J_b = 0.03499420965810384, J_o = 99277.06718895491
J_b = 0.04727673334172707, J_o = 84201.19441803786
J_b = 0.0635787603111674, J_o = 73306.27715938057
J_b = 0.09315775731725028, J_o = 72483.20531455775
J_b = 0.07743741547743001, J_o = 68801.94844772038
J_b = 0.08668515601814782, J_o = 64843.153820904365
J_b = 0.09087778589227102, J_o = 62708.39002615286
J_b = 0.10222534529379954, J_o = 59694.20272195821
J_b = 0.12315425479218181, J_o = 58239.603322765906
J_b = 0.12477792597178537, J_o = 56314.85233978347
J_b = 0.1281490567209547, J_o = 56172.32840549895
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.12598288 -0.45004655  0.28420052  0.10388577 -0.75970879 -0.46706836
 -1.14308842 -0.57924398 -0.55691768 -1.44919704]
W_opt:  [ 0.00784747  0.01307969  0.01351639  0.01293316  0.01000924 -0.00271272
 -0.03266127 -0.0828594  -0.14478622 -0.20557983]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7817 s, v_trunc (Latent to Reduced) = 0.1044, dec (Reduced to Full) = 0.1872, add (DA)= 0.0001decode = 0.2937 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0755 s, inc stats = 5.0801, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95697784 2.85640887 3.43452062 3.08803483 2.45821844]
u_DA:    [3.89711662 1.94233511 3.02387702 1.65563062 2.67814078]
ref_MAE: [0.11652344 0.69462848 0.89558584 1.23548138 0.08158473]
da_MAE:  [0.05986122 0.91407376 0.4106436  1.43240421 0.21992234]
% 18.336544387729617 da_MAE 0.006118153195034032 ref_MAE 0.007491910731873004
u_c taken from control states: [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
u_c before reduction of space:  [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
data[u_c] post encoding of state:  [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
J_b = 0.0, J_o = 377757.8794706167
J_b = 0.5000000000000002, J_o = 14682240.884426553
J_b = 0.003347006495311734, J_o = 263269.25928082236
J_b = 0.008664642192538888, J_o = 174376.67225099145
J_b = 0.01980114312640749, J_o = 120666.54518737242
J_b = 0.027015700236814696, J_o = 101564.26732601604
J_b = 0.03503290254620285, J_o = 85836.66039233442
J_b = 0.04698539119391893, J_o = 71282.00644809725
J_b = 0.06396522181340791, J_o = 62323.736338266564
J_b = 0.08094281439501803, J_o = 56476.17252266455
J_b = 0.08000542561066042, J_o = 53585.907131798
J_b = 0.08330516579118974, J_o = 50991.024921177006
J_b = 0.09140272713729135, J_o = 48820.26169649009
J_b = 0.11706824462654224, J_o = 47448.82056253316
J_b = 0.12422222226102478, J_o = 44700.98063918232
J_b = 0.12397949645514889, J_o = 44210.1446711097
J_b = 0.12372728442317957, J_o = 43986.538733044734
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.12078358 -0.45228304  0.28208255  0.09969061 -0.77893206 -0.47576826
 -1.13304175 -0.41946661 -0.5644705  -1.35963211]
W_opt:  [-2.04601438e-04  4.71866790e-03  7.76102692e-03  1.05857753e-02
  1.02224042e-02  3.63620075e-05 -2.78179910e-02 -7.78270101e-02
 -1.42228762e-01 -2.07486716e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9912 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.1845, add (DA)= 0.0001decode = 0.2918 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.2831 s, inc stats = 5.2947, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95675496 2.85585573 3.43387888 3.08659972 2.45306202]
u_DA:    [3.88890916 1.91967102 3.00287697 1.56157287 2.73103163]
ref_MAE: [0.11630056 0.69407533 0.8949441  1.23404627 0.07642831]
da_MAE:  [0.0678458  0.93618471 0.43100191 1.52502684 0.27796961]
% 17.859907764716056 da_MAE 0.006151831934667927 ref_MAE 0.007489438795669331
u_c taken from control states: [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
u_c before reduction of space:  [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
data[u_c] post encoding of state:  [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
J_b = 0.0, J_o = 377995.62999276415
J_b = 0.4999999999999999, J_o = 14534251.231964529
J_b = 0.003418649425011718, J_o = 262026.58607334594
J_b = 0.008869230762747685, J_o = 172081.87694965716
J_b = 0.019901997016379774, J_o = 119270.55936641309
J_b = 0.02715997994721109, J_o = 99896.62804116857
J_b = 0.03553399258351786, J_o = 83440.55253834501
J_b = 0.04806648764406254, J_o = 68435.91762625323
J_b = 0.06607099757171131, J_o = 60728.780271282085
J_b = 0.07506089517392622, J_o = 54057.353234737566
J_b = 0.07757797519857217, J_o = 51189.00777532575
J_b = 0.08539305109047633, J_o = 47984.1283523093
J_b = 0.10010589601826428, J_o = 45245.95807156051
J_b = 0.11792414167721327, J_o = 42916.09974436564
J_b = 0.1219403108425717, J_o = 41721.08843446027
J_b = 0.13062022624963415, J_o = 42301.53215419145
J_b = 0.12523754146528895, J_o = 41221.444128378454
J_b = 0.12734591951612653, J_o = 40685.61853626377
J_b = 0.12926764767404833, J_o = 40388.0132622779
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.11508536 -0.45410256  0.27983615  0.09378411 -0.79782812 -0.48820434
 -1.11562984 -0.25057513 -0.57183441 -1.26010595]
W_opt:  [-0.00077439  0.00347466  0.00751218  0.01082355  0.01087055  0.00200047
 -0.02410868 -0.07424246 -0.14062988 -0.21006568]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.2593 s, v_trunc (Latent to Reduced) = 0.1030, dec (Reduced to Full) = 0.2046, add (DA)= 0.0001decode = 0.3097 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.5692 s, inc stats = 5.5803, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95651069 2.85540571 3.43319822 3.08457918 2.44799337]
u_DA:    [3.89026262 1.91950706 3.00394043 1.56988991 2.72172375]
ref_MAE: [0.11605629 0.69362532 0.89426344 1.23202573 0.07135966]
da_MAE:  [0.06624807 0.93589866 0.4292578  1.51468927 0.27373037]
% 17.77694591142457 da_MAE 0.0061573858467013735 ref_MAE 0.00748863675152261
u_c taken from control states: [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
u_c before reduction of space:  [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
data[u_c] post encoding of state:  [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
J_b = 0.0, J_o = 385548.8680414957
J_b = 0.5, J_o = 14094548.512500545
J_b = 0.0036369598295878276, J_o = 265323.27186060906
J_b = 0.009468683410605812, J_o = 173396.18367580598
J_b = 0.0199070415257727, J_o = 123904.36702989413
J_b = 0.027560269809322423, J_o = 103090.27088626666
J_b = 0.03621925519618026, J_o = 85788.42192841556
J_b = 0.04959759911327601, J_o = 69976.8237080443
J_b = 0.06795086609972664, J_o = 62404.75942599033
J_b = 0.07468834585993255, J_o = 55648.45763821151
J_b = 0.07829959171911012, J_o = 52399.81845131792
J_b = 0.0867126821402611, J_o = 49163.97203289503
J_b = 0.10310850306473873, J_o = 45674.25905881554
J_b = 0.12891225084804186, J_o = 44042.113618038995
J_b = 0.1257653983683715, J_o = 42337.40434628456
J_b = 0.12553069683321746, J_o = 42436.47275399587
J_b = 0.12561439280272552, J_o = 42011.109888228006
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.10902823 -0.45599325  0.27748982  0.08635244 -0.81477853 -0.50250241
 -1.09078385 -0.07237719 -0.57839827 -1.15562493]
W_opt:  [ 0.00710743  0.00854507  0.00896136  0.00868486  0.0055001  -0.00510581
 -0.02982467 -0.07512606 -0.13511156 -0.19855034]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7689 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1723, add (DA)= 0.0001decode = 0.2787 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0477 s, inc stats = 5.0595, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95625104 2.8549381  3.43248729 3.0820369  2.44344662]
u_DA:    [3.89246762 1.92337111 3.0017468  1.57794008 2.71892123]
ref_MAE: [0.11579664 0.6931577  0.8935525  1.22948345 0.06681291]
da_MAE:  [0.06378342 0.93156699 0.43074049 1.50409682 0.27547461]
% 17.810134044524574 da_MAE 0.006155247996935718 ref_MAE 0.007489059539615492
\% improve_point: 13.04, mse_ref_points: 3.486536501664882e-05, mse_da_points: 3.0318281394604273e-05, % improve_overlap: 13.04, mse_ref_overlap: 0.90811, mse_da_overlap: 0.78970
DA - - L2: 148528.43, L1: 8274.20, % Improve: 18.08%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.789, time(s): 8.1618s,
u_c taken from control states: [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
u_c before reduction of space:  [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
data[u_c] post encoding of state:  [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
J_b = 0.0, J_o = 395917.65132133296
J_b = 0.5, J_o = 13664231.805980138
J_b = 0.0039069828417750765, J_o = 269973.39492879313
J_b = 0.010178067934826262, J_o = 176059.42492517686
J_b = 0.019833520798781257, J_o = 130268.16412205252
J_b = 0.028082004093021636, J_o = 107318.37903676546
J_b = 0.0369154795641109, J_o = 89330.12978062812
J_b = 0.05113841973878727, J_o = 72659.56794358132
J_b = 0.06934287578937287, J_o = 64827.99161826752
J_b = 0.07574960252199325, J_o = 58170.45161816303
J_b = 0.08021369043091477, J_o = 54577.66166984427
J_b = 0.08918962760758428, J_o = 51201.32476215883
J_b = 0.10738591494107934, J_o = 47580.7865673805
J_b = 0.13139714302839484, J_o = 45660.22092650815
J_b = 0.12809474701631532, J_o = 44251.97995020468
J_b = 0.12719767331423631, J_o = 44255.43198841077
J_b = 0.12758755053127477, J_o = 43834.52030852754
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.10256075 -0.45854801  0.27504604  0.07754793 -0.82948698 -0.51952001
 -1.0612933   0.0985559  -0.58415486 -1.05622415]
W_opt:  [ 0.00694957  0.00839703  0.00844306  0.00726652  0.00319927 -0.00800698
 -0.03209666 -0.07505123 -0.1321808  -0.194315  ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9448 s, v_trunc (Latent to Reduced) = 0.1406, dec (Reduced to Full) = 0.2105, add (DA)= 0.0002decode = 0.3541 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2990 s, inc stats = 5.3067, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9559738  2.85430624 3.43174682 3.07902499 2.43950125]
u_DA:    [3.89166994 1.91964525 2.99428419 1.56517054 2.72188462]
ref_MAE: [0.1155194  0.69252584 0.89281204 1.22647154 0.06286754]
da_MAE:  [0.06430386 0.93466099 0.43746263 1.51385445 0.28238337]
% 17.67910786060075 da_MAE 0.006166339747930371 ref_MAE 0.007490613363966601
u_c taken from control states: [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
u_c before reduction of space:  [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
data[u_c] post encoding of state:  [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
J_b = 0.0, J_o = 405354.56460075633
J_b = 0.5000000000000002, J_o = 13265030.791984936
J_b = 0.00420453680499707, J_o = 272929.5869048451
J_b = 0.01092528025341522, J_o = 177705.88019021176
J_b = 0.019618332852970318, J_o = 135865.34839396883
J_b = 0.02864533885289404, J_o = 110117.82634700518
J_b = 0.03745355134628539, J_o = 91902.84960030287
J_b = 0.052457580398272544, J_o = 74434.06545424425
J_b = 0.07020100809130174, J_o = 66335.99178270569
J_b = 0.07713252643045129, J_o = 59849.03486507642
J_b = 0.08247259344352759, J_o = 55978.245124805515
J_b = 0.09207704640505429, J_o = 52483.01243316279
J_b = 0.11209508702119017, J_o = 49556.4138547132
J_b = 0.12430699331958012, J_o = 47001.251763312575
J_b = 0.12645212688228138, J_o = 45978.415562919196
J_b = 0.1340210504827778, J_o = 46745.633464484505
J_b = 0.12909520599658683, J_o = 45548.145005842336
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.09566115 -0.46191922  0.27251958  0.06761547 -0.84171393 -0.54037423
 -1.03005819  0.2426086  -0.5891547  -0.97340609]
W_opt:  [ 0.0079026   0.00866343  0.00855972  0.00712131  0.00249798 -0.01024933
 -0.03546087 -0.07743196 -0.13212408 -0.19167821]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8392 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.1611, add (DA)= 0.0001decode = 0.2683 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1076 s, inc stats = 5.1199, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95567803 2.85347245 3.4309813  3.07562723 2.43622151]
u_DA:    [3.89136176 1.91724653 2.9926639  1.56153907 2.719314  ]
ref_MAE: [0.11522363 0.69169206 0.89204652 1.22307378 0.0595878 ]
da_MAE:  [0.06431627 0.93622593 0.4383174  1.51408816 0.28309248]
% 17.51965861318381 da_MAE 0.006180763324588455 ref_MAE 0.007493619959211759
u_c taken from control states: [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
u_c before reduction of space:  [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
data[u_c] post encoding of state:  [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
J_b = 0.0, J_o = 413739.5931587501
J_b = 0.5000000000000001, J_o = 12990269.69931791
J_b = 0.004484356805331445, J_o = 274588.0743201203
J_b = 0.011575701338584224, J_o = 178844.45937435207
J_b = 0.019309748916718078, J_o = 140307.68471609973
J_b = 0.029247380684179067, J_o = 111225.14437359314
J_b = 0.03790908604084709, J_o = 93220.45225701321
J_b = 0.05364472446508958, J_o = 75128.79642071249
J_b = 0.07075597978466211, J_o = 66954.34376063621
J_b = 0.07824337679146288, J_o = 60748.04194544611
J_b = 0.08447189939598547, J_o = 56696.35951854602
J_b = 0.09458717511955562, J_o = 53280.403190715726
J_b = 0.11378058924417725, J_o = 50570.90964452525
J_b = 0.12037000768565034, J_o = 48479.41119755772
J_b = 0.12485882047659878, J_o = 47275.45725530992
J_b = 0.13492309864705673, J_o = 49209.619030957765
J_b = 0.12724291142154748, J_o = 47026.82811945957
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.08847367 -0.4666202   0.26995239  0.05698638 -0.85075604 -0.56421102
 -0.99857866  0.3524116  -0.59316881 -0.91354165]
W_opt:  [ 0.01088248  0.010152    0.00903821  0.00716515  0.00198789 -0.01229395
 -0.03888799 -0.08056059 -0.13285986 -0.18870837]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7290 s, v_trunc (Latent to Reduced) = 0.1036, dec (Reduced to Full) = 0.1720, add (DA)= 0.0001decode = 0.2777 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0069 s, inc stats = 5.0195, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95536993 2.85230978 3.43020345 3.07199115 2.43379607]
u_DA:    [3.89175586 1.9186722  2.99639402 1.57172172 2.70486787]
ref_MAE: [0.11491553 0.69052938 0.89126866 1.2194377  0.05716236]
da_MAE:  [0.06361407 0.93363758 0.43380943 1.50026943 0.2710718 ]
% 17.462316485685623 da_MAE 0.0061882871487470015 ref_MAE 0.0074975294741265385
u_c taken from control states: [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
u_c before reduction of space:  [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
data[u_c] post encoding of state:  [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
J_b = 0.0, J_o = 421369.1862364438
J_b = 0.5000000000000003, J_o = 12841512.765549466
J_b = 0.004721640750909775, J_o = 275788.1381536456
J_b = 0.012075537649775186, J_o = 180085.49933998627
J_b = 0.018996604055522417, J_o = 143811.34831633916
J_b = 0.02993736490954077, J_o = 111024.57329763622
J_b = 0.03842362496373181, J_o = 93525.40729533834
J_b = 0.05482009022221944, J_o = 75042.84666430808
J_b = 0.07125612331903426, J_o = 66912.67937006286
J_b = 0.07936400416335021, J_o = 61055.10128659549
J_b = 0.08662697824437816, J_o = 56946.41344464659
J_b = 0.09681397655200462, J_o = 53911.63549222678
J_b = 0.10953122316171682, J_o = 51231.82820263661
J_b = 0.11850918827596021, J_o = 49414.42557225178
J_b = 0.13065368733438662, J_o = 47553.592962462106
J_b = 0.1486992601481546, J_o = 54459.947861471126
J_b = 0.13310795712667367, J_o = 47331.78993734784
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.08109618 -0.47304046  0.26737647  0.04606086 -0.85666366 -0.59051712
 -0.96930913  0.42052658 -0.59624405 -0.88148541]
W_opt:  [ 0.01147323  0.01088099  0.01086668  0.01011783  0.00576583 -0.00883521
 -0.03697698 -0.0816863  -0.13697772 -0.1957814 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8102 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1763, add (DA)= 0.0001decode = 0.2827 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0930 s, inc stats = 5.1021, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95505368 2.85072188 3.42942295 3.06825367 2.43221142]
u_DA:    [3.89216018 1.92278646 2.99154659 1.58531744 2.68631526]
ref_MAE: [0.11459928 0.68894149 0.89048816 1.21570022 0.05557771]
da_MAE:  [0.06289349 0.92793543 0.43787635 1.48293624 0.25410384]
% 17.483345051585903 da_MAE 0.006190122133982511 ref_MAE 0.007501663922092228
u_c taken from control states: [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
u_c before reduction of space:  [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
data[u_c] post encoding of state:  [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
J_b = 0.0, J_o = 427109.34104212554
J_b = 0.5000000000000002, J_o = 12858200.71696471
J_b = 0.004871112000988639, J_o = 276215.61822720827
J_b = 0.012323628175751767, J_o = 180760.79999094334
J_b = 0.018712906642950427, J_o = 145449.21504007772
J_b = 0.030570935724249775, J_o = 109227.22854333835
J_b = 0.038906812456645574, J_o = 92250.1203668519
J_b = 0.05547964690381718, J_o = 73853.7264053426
J_b = 0.07106292281265804, J_o = 65794.11140254686
J_b = 0.08031345081355597, J_o = 60166.69167415466
J_b = 0.0891397573493333, J_o = 56156.09423015023
J_b = 0.0984281668835979, J_o = 53662.80964725166
J_b = 0.10421329110630498, J_o = 51663.96767494633
J_b = 0.11499408004034742, J_o = 49474.64812002597
J_b = 0.12394376006777447, J_o = 48130.16473323746
J_b = 0.14212259425096238, J_o = 62213.74085039006
J_b = 0.1255049826204688, J_o = 47934.248835527906
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.07356942 -0.48118944  0.26481464  0.03522455 -0.85984512 -0.61920501
 -0.94513053  0.43784022 -0.59869381 -0.8814341 ]
W_opt:  [ 0.01294032  0.01317613  0.01323417  0.01103212  0.00506968 -0.0109313
 -0.040213   -0.0849353  -0.13825728 -0.19259977]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7885 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1965, add (DA)= 0.0001decode = 0.3036 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0922 s, inc stats = 5.1048, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95473103 2.84870643 3.42864671 3.06454671 2.43135803]
u_DA:    [3.89229971 1.91612034 3.01557277 1.58839757 2.68342465]
ref_MAE: [0.11427663 0.68692603 0.88971193 1.21199326 0.05472432]
da_MAE:  [0.06243132 0.93258609 0.41307394 1.47614914 0.25206662]
% 17.561520441228453 da_MAE 0.006187586469103427 ref_MAE 0.0075057018302869235
u_c taken from control states: [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
u_c before reduction of space:  [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
data[u_c] post encoding of state:  [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
J_b = 0.0, J_o = 430647.3419680752
J_b = 0.5, J_o = 13031635.892384991
J_b = 0.00490040953360752, J_o = 276657.64589854266
J_b = 0.012270856829908382, J_o = 181520.2703209866
J_b = 0.01845554678817457, J_o = 146008.810245448
J_b = 0.030963754157201775, J_o = 107335.28411294665
J_b = 0.039216645442630364, J_o = 90591.32168725927
J_b = 0.055146184367282185, J_o = 72849.32765386357
J_b = 0.0696624638747578, J_o = 64829.030442242816
J_b = 0.08127358385552017, J_o = 58971.17696740941
J_b = 0.09159439401746008, J_o = 54974.62999809034
J_b = 0.10262490172399978, J_o = 53088.77121872148
J_b = 0.10305783286774954, J_o = 51306.054874895344
J_b = 0.10751710426004676, J_o = 49768.511459301255
J_b = 0.11490582589543029, J_o = 48569.51503448701
J_b = 0.1289749499335057, J_o = 47118.44787701256
J_b = 0.15041085670395085, J_o = 47417.23846440411
J_b = 0.13817792469697882, J_o = 46449.5480730366
J_b = 0.1383607867882103, J_o = 46155.85877184549
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.06603568 -0.49101381  0.26229555  0.02492451 -0.86022986 -0.64813583
 -0.92527569  0.4166843  -0.60058141 -0.90625469]
W_opt:  [ 0.00714416  0.01131118  0.01842404  0.01856044  0.01398521 -0.00125557
 -0.03248386 -0.08329954 -0.14509048 -0.20965698]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3086 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1773, add (DA)= 0.0001decode = 0.2837 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.5924 s, inc stats = 5.6051, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95440808 2.84627661 3.42788343 3.0610232  2.43125483]
u_DA:    [3.89337758 1.92160434 3.005335   1.6124073  2.66822861]
ref_MAE: [0.11395368 0.68449621 0.88894865 1.20846975 0.05462112]
da_MAE:  [0.06103049 0.92467226 0.42254843 1.4486159  0.23697378]
% 17.7143238144854 da_MAE 0.00617911296235132 ref_MAE 0.007509342146524255
u_c taken from control states: [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
u_c before reduction of space:  [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
data[u_c] post encoding of state:  [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
J_b = 0.0, J_o = 432544.75002526806
J_b = 0.49999999999999994, J_o = 13172670.131260006
J_b = 0.004900286960460478, J_o = 276859.11493887857
J_b = 0.01217937602800874, J_o = 182180.02834913082
J_b = 0.018248745655272205, J_o = 146359.99614944716
J_b = 0.031324836369846315, J_o = 105648.78114180166
J_b = 0.03956255654578374, J_o = 89005.27597711545
J_b = 0.05481093676850248, J_o = 71988.44021421859
J_b = 0.06846601256308474, J_o = 64204.521160835975
J_b = 0.08181085749750014, J_o = 58186.530280832085
J_b = 0.0922951417571609, J_o = 54231.62549024765
J_b = 0.10280122777671136, J_o = 52280.88657375192
J_b = 0.10303108401703198, J_o = 50611.95813915829
J_b = 0.10711487404200139, J_o = 49144.097753691065
J_b = 0.1149965146824043, J_o = 47887.83566035329
J_b = 0.12941218379089903, J_o = 49332.44924892998
J_b = 0.11934202936630794, J_o = 47405.73925111421
J_b = 0.13139236678336122, J_o = 46360.099352924124
J_b = 0.13675149166167036, J_o = 45718.738204124376
J_b = 0.1407136016766658, J_o = 45121.029767636646
J_b = 0.1445067003395973, J_o = 44637.662361990675
J_b = 0.15710170091887843, J_o = 43870.26096175724
J_b = 0.17037162684916254, J_o = 43496.5469490433
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.05860868 -0.50227273  0.25983047  0.01549907 -0.85793405 -0.67444998
 -0.90866588  0.37999157 -0.6019716  -0.94252154]
W_opt:  [-0.0114325  -0.00492038  0.01678332  0.02632527  0.02944225  0.02121066
 -0.00705101 -0.0664231  -0.14575235 -0.23927676]
----------------------------- DA Assimilate ----------------------
minCostFunction = 6.4786 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1988, add (DA)= 0.0001decode = 0.3063 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 6.7850 s, inc stats = 6.7977, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9540897  2.84349198 3.42713651 3.05779888 2.43187065]
u_DA:    [3.89458993 1.92935056 3.01713173 1.6335229  2.65713535]
ref_MAE: [0.1136353  0.68171159 0.88820173 1.20524543 0.05523694]
da_MAE:  [0.05949978 0.91414143 0.41000479 1.42427598 0.22526469]
% 17.616560643049393 da_MAE 0.006188526307253596 ref_MAE 0.007511857183383636
u_c taken from control states: [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
u_c before reduction of space:  [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
data[u_c] post encoding of state:  [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
J_b = 0.0, J_o = 433266.1971025304
J_b = 0.5000000000000002, J_o = 13221176.795674589
J_b = 0.004907357421214347, J_o = 276743.27824188094
J_b = 0.012141423137599767, J_o = 182767.40188130087
J_b = 0.01806701176186101, J_o = 147014.29347828336
J_b = 0.03164806128958633, J_o = 104574.18412380555
J_b = 0.03984701559391595, J_o = 88155.16923626416
J_b = 0.05469011520973722, J_o = 71689.33513216299
J_b = 0.06792312485900087, J_o = 64308.70239626678
J_b = 0.0812476838360553, J_o = 58523.51511301254
J_b = 0.09109436870367502, J_o = 54789.95655725234
J_b = 0.09754766160381537, J_o = 52332.324301354136
J_b = 0.10105930219855654, J_o = 50741.052224596366
J_b = 0.11459032884448066, J_o = 48105.668036189585
J_b = 0.13112031743932548, J_o = 47634.480633838684
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.05130107 -0.51451283  0.25741801  0.00718725 -0.85351386 -0.69702305
 -0.89622996  0.33393761 -0.60314587 -0.9852956 ]
W_opt:  [ 0.013212    0.01471392  0.02013526  0.01969833  0.01277344 -0.00488758
 -0.0371227  -0.08713789 -0.14645883 -0.20649978]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.3078 s, v_trunc (Latent to Reduced) = 0.1037, dec (Reduced to Full) = 0.1850, add (DA)= 0.0002decode = 0.2911 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.5990 s, inc stats = 4.6116, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95377645 2.84046469 3.42640554 3.05495551 2.43305632]
u_DA:    [3.89831978 1.93220695 3.03138626 1.66279765 2.67234552]
ref_MAE: [0.11332205 0.67868429 0.88747075 1.20240206 0.05642261]
da_MAE:  [0.05545667 0.90825774 0.39501927 1.39215785 0.2392892 ]
% 17.906312545029788 da_MAE 0.0061679484778960495 ref_MAE 0.007513304212676857
u_c taken from control states: [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
u_c before reduction of space:  [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
data[u_c] post encoding of state:  [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
J_b = 0.0, J_o = 433630.10415202327
J_b = 0.5000000000000002, J_o = 13126578.768498082
J_b = 0.0049450308282167135, J_o = 276928.4760113148
J_b = 0.012212259767351545, J_o = 184242.1042245883
J_b = 0.017859557324472548, J_o = 149314.62126865936
J_b = 0.031960044258541556, J_o = 105174.21572895991
J_b = 0.04003800433570223, J_o = 89327.76286138549
J_b = 0.05520431899365714, J_o = 72839.41106905042
J_b = 0.0688814594973595, J_o = 65871.58571637965
J_b = 0.08031835769307931, J_o = 60366.4748443268
J_b = 0.08920294456980671, J_o = 56455.217506184024
J_b = 0.0986034763922919, J_o = 53929.29862407345
J_b = 0.10410234925752503, J_o = 52003.15980259601
J_b = 0.11400923653605848, J_o = 49958.86495812597
J_b = 0.1254250026938953, J_o = 48607.0938075696
J_b = 0.14656086124047932, J_o = 49807.11450360046
J_b = 0.13260974186251132, J_o = 47958.980087132666
J_b = 0.13573252786888154, J_o = 47475.60317671021
J_b = 0.1380361544232446, J_o = 47015.92910878219
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 4.41635068e-02 -5.27336482e-01  2.55061069e-01  1.83818017e-04
 -8.47375863e-01 -7.14763394e-01 -8.87438151e-01  2.84664439e-01
 -6.04223724e-01 -1.03078191e+00]
W_opt:  [ 0.00648716  0.01620067  0.02392254  0.0243783   0.01878277  0.0026323
 -0.02933857 -0.08180245 -0.14633617 -0.21369198]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3363 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.1796, add (DA)= 0.0001decode = 0.2852 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6217 s, inc stats = 5.6342, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95347048 2.83729307 3.42569139 3.05255973 2.43470276]
u_DA:    [3.89753549 1.93165293 3.0422646  1.68088587 2.66035896]
ref_MAE: [0.11301608 0.67551267 0.8867566  1.20000628 0.05806905]
da_MAE:  [0.055935   0.90564014 0.38342679 1.37167385 0.2256562 ]
% 18.05593936176603 da_MAE 0.006156962331434385 ref_MAE 0.007513616342026418
u_c taken from control states: [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
u_c before reduction of space:  [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
data[u_c] post encoding of state:  [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
J_b = 0.0, J_o = 435626.5082206713
J_b = 0.49999999999999983, J_o = 12851888.560741238
J_b = 0.005049428646813387, J_o = 278695.47832978505
J_b = 0.012473138840749012, J_o = 188001.873000709
J_b = 0.01763897396239052, J_o = 154705.79480751487
J_b = 0.032486898860425543, J_o = 108152.5638683417
J_b = 0.04038137879531563, J_o = 93427.50167846303
J_b = 0.05682315626832007, J_o = 76252.0199326093
J_b = 0.07202855555892676, J_o = 69463.64316054677
J_b = 0.08245480300712497, J_o = 64231.962998135576
J_b = 0.08982450325512038, J_o = 60607.94981565057
J_b = 0.09987071237660179, J_o = 57922.96627447088
J_b = 0.11033001966014461, J_o = 55668.447495779634
J_b = 0.11861629436412506, J_o = 53967.522469379925
J_b = 0.1331839720434572, J_o = 52552.67681919396
J_b = 0.14619042490026907, J_o = 52769.46040681032
J_b = 0.13895263521655354, J_o = 51825.184204599274
J_b = 0.13796861875699917, J_o = 51475.07989335124
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.03723639 -0.54048199  0.25274353 -0.00557094 -0.84001171 -0.72601094
 -0.8793696   0.25528984 -0.6051652  -1.06581362]
W_opt:  [-0.0016328   0.0147457   0.02616453  0.02721631  0.02013832  0.00265485
 -0.02957465 -0.08174616 -0.14600004 -0.21209481]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1195 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1964, add (DA)= 0.0001decode = 0.3033 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4229 s, inc stats = 5.4355, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95317354 2.83404184 3.42498917 3.0505911  2.43667811]
u_DA:    [3.89834128 1.93006801 3.05167633 1.67708877 2.66606044]
ref_MAE: [0.11271914 0.67226144 0.88605439 1.19803765 0.0600444 ]
da_MAE:  [0.05483226 0.90397383 0.37331284 1.37350233 0.22938233]
% 17.993650259375144 da_MAE 0.006160672346750377 ref_MAE 0.007512433325267814
\% improve_point: 12.55, mse_ref_points: 3.467014939660186e-05, mse_da_points: 3.031742018968772e-05, % improve_overlap: 12.55, mse_ref_overlap: 0.90303, mse_da_overlap: 0.78968
DA - - L2: 101315.43, L1: 6829.50, % Improve: 17.96%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.789, time(s): 7.2638s,
u_c taken from control states: [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
u_c before reduction of space:  [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
data[u_c] post encoding of state:  [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
J_b = 0.0, J_o = 436647.75381468446
J_b = 0.49999999999999994, J_o = 12579882.03272965
J_b = 0.00513491065254226, J_o = 280237.66123829904
J_b = 0.01269147986744676, J_o = 191936.25845487637
J_b = 0.017380128209932576, J_o = 160221.73036346535
J_b = 0.032898458394920845, J_o = 111479.15162799056
J_b = 0.04065683213099491, J_o = 97938.1032735543
J_b = 0.05827695334470527, J_o = 80225.36474504393
J_b = 0.07489679931881184, J_o = 72379.60156019028
J_b = 0.09115510750422488, J_o = 67351.75892016017
J_b = 0.09888226508503034, J_o = 64332.76941629907
J_b = 0.10222311378532309, J_o = 62241.015027891044
J_b = 0.10888900325871718, J_o = 60171.953093757365
J_b = 0.12649062867475314, J_o = 58037.44618137038
J_b = 0.13918539821350687, J_o = 56495.04367554233
J_b = 0.14504681803061506, J_o = 56645.80304609968
J_b = 0.14175893971696868, J_o = 56169.22435771684
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.03040054 -0.55379285  0.25041883 -0.01048628 -0.83247312 -0.73059517
 -0.87028157  0.26134509 -0.60610805 -1.0802221 ]
W_opt:  [-0.00786396  0.01090243  0.02672396  0.03195794  0.02575824  0.00692161
 -0.02639353 -0.07997279 -0.14606911 -0.2133794 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8607 s, v_trunc (Latent to Reduced) = 0.1157, dec (Reduced to Full) = 0.1673, add (DA)= 0.0001decode = 0.2855 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1463 s, inc stats = 5.1591, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95288051 2.83074972 3.42428479 3.04890962 2.43870025]
u_DA:    [3.89959111 1.93296866 3.06141442 1.6856514  2.65538412]
ref_MAE: [0.11242611 0.66896932 0.88535    1.19635617 0.06206654]
da_MAE:  [0.0532894  0.89778106 0.36287037 1.36325822 0.21668387]
% 18.147037401934913 da_MAE 0.006147265128942255 ref_MAE 0.007510131501443748
u_c taken from control states: [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
u_c before reduction of space:  [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
data[u_c] post encoding of state:  [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
J_b = 0.0, J_o = 440336.5541202225
J_b = 0.5000000000000002, J_o = 12209078.208492495
J_b = 0.005285435372795642, J_o = 283727.19715821376
J_b = 0.013071740704380795, J_o = 198251.41815591985
J_b = 0.01716622945097243, J_o = 168179.40952283744
J_b = 0.03382715021677797, J_o = 115965.24394891379
J_b = 0.04156671817371326, J_o = 103863.05389057376
J_b = 0.060408372905288506, J_o = 86984.65438185411
J_b = 0.083602966822326, J_o = 84917.00135025183
J_b = 0.08211405984582738, J_o = 76684.79605104498
J_b = 0.08349171418189845, J_o = 74334.1821574244
J_b = 0.09202953598947136, J_o = 71462.56231960666
J_b = 0.10587339297754511, J_o = 68101.79478115024
J_b = 0.13967668685201898, J_o = 64373.35920139106
J_b = 0.17237656859821507, J_o = 66542.12690442355
J_b = 0.15060062875701177, J_o = 63368.72038729795
J_b = 0.1545430097615913, J_o = 62499.62574787235
J_b = 0.15205176915479213, J_o = 62226.118000266695
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.0233923  -0.56710955  0.24802576 -0.01518392 -0.82619277 -0.73082779
 -0.8600566   0.29911559 -0.6073508  -1.0733721 ]
W_opt:  [-0.01267417  0.0056006   0.02275895  0.0335292   0.03177281  0.01484064
 -0.01869762 -0.07504526 -0.14580812 -0.21918533]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0975 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.2201, add (DA)= 0.0001decode = 0.3283 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4259 s, inc stats = 5.4336, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95258008 2.82745615 3.42355969 3.04730262 2.44038488]
u_DA:    [3.90081371 1.93971143 3.05434599 1.71036565 2.64391428]
ref_MAE: [0.11212568 0.66567576 0.88462491 1.19474917 0.06375117]
da_MAE:  [0.05176637 0.88774473 0.3692137  1.33693697 0.20352939]
% 18.47270698662853 da_MAE 0.006120232132825347 ref_MAE 0.0075069733172933315
u_c taken from control states: [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
u_c before reduction of space:  [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
data[u_c] post encoding of state:  [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
J_b = 0.0, J_o = 443552.85971898853
J_b = 0.5000000000000001, J_o = 11895404.783962479
J_b = 0.00540140629990025, J_o = 287375.5739642658
J_b = 0.013391579443887637, J_o = 204017.07839717023
J_b = 0.017093080443818926, J_o = 174887.69871957556
J_b = 0.03453213798051309, J_o = 120772.89793965404
J_b = 0.042193115000090736, J_o = 109568.80562197466
J_b = 0.06136536346672904, J_o = 94089.04199635139
J_b = 0.0870531527278198, J_o = 93866.66038517165
J_b = 0.07286224171315848, J_o = 88807.30863816754
J_b = 0.07992823791978151, J_o = 84378.77216084221
J_b = 0.08962825346556777, J_o = 80204.99255976365
J_b = 0.09979279628484551, J_o = 77256.95649760016
J_b = 0.12438469441720952, J_o = 74084.82246450777
J_b = 0.14495747881156548, J_o = 71840.53110345101
J_b = 0.13951029234253184, J_o = 70730.8273817898
J_b = 0.13968230614259788, J_o = 70055.16059727987
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.01604584 -0.58026358  0.24552121 -0.02020663 -0.82164031 -0.72832433
 -0.84607747  0.37618168 -0.6086617  -1.04034068]
W_opt:  [-0.00959429  0.00426355  0.01571462  0.02537546  0.0257704   0.01230214
 -0.01910106 -0.07265932 -0.13966989 -0.20789027]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7191 s, v_trunc (Latent to Reduced) = 0.1057, dec (Reduced to Full) = 0.1700, add (DA)= 0.0001decode = 0.2777 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.9970 s, inc stats = 5.0061, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95226516 2.82420282 3.42280081 3.04558442 2.44160603]
u_DA:    [3.89996457 1.93883385 3.05534963 1.70664323 2.65877124]
ref_MAE: [0.11181076 0.66242242 0.88386603 1.19303096 0.06497232]
da_MAE:  [0.0523006  0.88536897 0.36745118 1.33894118 0.21716521]
% 18.4434918270893 da_MAE 0.0061195708228625485 ref_MAE 0.00750347330943625
u_c taken from control states: [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
u_c before reduction of space:  [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
data[u_c] post encoding of state:  [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
J_b = 0.0, J_o = 439184.6747701004
J_b = 0.49999999999999983, J_o = 11865288.604269922
J_b = 0.005324908352188158, J_o = 285851.3921195755
J_b = 0.013287632416758899, J_o = 202071.5658799246
J_b = 0.017216163360440257, J_o = 172676.4196016034
J_b = 0.03400461912509013, J_o = 120711.35883376787
J_b = 0.041677060206482694, J_o = 109224.8061245009
J_b = 0.06017375617116663, J_o = 92918.40862048599
J_b = 0.08342720360405785, J_o = 92216.89916493846
J_b = 0.07096098746364776, J_o = 88261.99365577806
J_b = 0.08096451266676216, J_o = 83344.7594312893
J_b = 0.08896260617455477, J_o = 80006.55265839155
J_b = 0.09944948069430438, J_o = 76880.60541962214
J_b = 0.12017869504397505, J_o = 74104.54096976858
J_b = 0.13671732678386503, J_o = 71860.59407216297
J_b = 0.1367351648844596, J_o = 70812.0074302036
J_b = 0.1379080430595041, J_o = 72970.85266834461
J_b = 0.13691911770212223, J_o = 70482.9022669561
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [ 0.00828287 -0.59309718  0.24288426 -0.02594082 -0.81836854 -0.72384784
 -0.82622043  0.49890562 -0.60964402 -0.97885732]
W_opt:  [-0.00414312  0.00459465  0.01020608  0.01884435  0.02211463  0.01097575
 -0.01851298 -0.07033051 -0.13660125 -0.20312028]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3335 s, v_trunc (Latent to Reduced) = 0.1106, dec (Reduced to Full) = 0.1834, add (DA)= 0.0001decode = 0.2962 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.6299 s, inc stats = 5.6339, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95193239 2.82102874 3.42200182 3.04362282 2.44248364]
u_DA:    [3.90026089 1.94829489 3.05301921 1.72372936 2.65203078]
ref_MAE: [0.11147799 0.65924834 0.88306704 1.19106937 0.06584993]
da_MAE:  [0.0516715  0.87273385 0.3689826  1.31989346 0.20954714]
% 18.40124678326438 da_MAE 0.006120323964737733 ref_MAE 0.007500511617477111
u_c taken from control states: [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
u_c before reduction of space:  [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
data[u_c] post encoding of state:  [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
J_b = 0.0, J_o = 436908.0926628353
J_b = 0.5000000000000001, J_o = 12113089.828749005
J_b = 0.005081997323596047, J_o = 288258.78845530044
J_b = 0.01277706267946285, J_o = 202511.02264847682
J_b = 0.017418674616885153, J_o = 171750.57691255113
J_b = 0.03256047604536144, J_o = 125059.04128258154
J_b = 0.04026511394650528, J_o = 112128.65121162264
J_b = 0.05837074403508036, J_o = 94342.04549797565
J_b = 0.0753743382139092, J_o = 86930.16652416781
J_b = 0.08769864632838677, J_o = 82424.95356341681
J_b = 0.09335440703941457, J_o = 79731.91986454457
J_b = 0.1013425032788865, J_o = 77211.32709578864
J_b = 0.11276296931770644, J_o = 75147.32160050876
J_b = 0.12455071346739635, J_o = 73277.08789971135
J_b = 0.1353063969348981, J_o = 71994.91241776408
J_b = 0.14650716760823362, J_o = 75363.13634110164
J_b = 0.1372963866908011, J_o = 71792.47111000962
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-9.08317390e-05 -6.05243197e-01  2.40087602e-01 -3.27246829e-02
 -8.16244327e-01 -7.20811692e-01 -8.00842799e-01  6.53427108e-01
 -6.10274417e-01 -8.95744763e-01]
W_opt:  [-0.00085454  0.00415082  0.00695988  0.01388622  0.01735861  0.00762411
 -0.01896048 -0.06837709 -0.13469007 -0.20149368]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7354 s, v_trunc (Latent to Reduced) = 0.1033, dec (Reduced to Full) = 0.1976, add (DA)= 0.0001decode = 0.3039 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0395 s, inc stats = 5.0448, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95157343 2.81802471 3.42115443 3.04130215 2.44305344]
u_DA:    [3.89967235 1.94983073 3.04108761 1.70821913 2.66255869]
ref_MAE: [0.11111903 0.65624432 0.88221965 1.1887487  0.06641973]
da_MAE:  [0.05190108 0.86819399 0.38006682 1.33308302 0.21950525]
% 18.37099241309384 da_MAE 0.006121361440706835 ref_MAE 0.007499002648280074
u_c taken from control states: [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
u_c before reduction of space:  [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
data[u_c] post encoding of state:  [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
J_b = 0.0, J_o = 428000.09478548425
J_b = 0.5000000000000001, J_o = 12802862.002433442
J_b = 0.004595483169610254, J_o = 287281.9909204206
J_b = 0.01165361040189638, J_o = 198056.02687367494
J_b = 0.017896337903558806, J_o = 162760.99546506975
J_b = 0.030502078666239323, J_o = 124941.83279458244
J_b = 0.03841976332928286, J_o = 109212.39875218278
J_b = 0.05333254161647839, J_o = 92299.86850758496
J_b = 0.0670769693426028, J_o = 84538.20303904153
J_b = 0.08484957326099793, J_o = 79508.51365385677
J_b = 0.08803806777847487, J_o = 76388.93493350976
J_b = 0.0895438855489624, J_o = 74459.16811929955
J_b = 0.09537356218330635, J_o = 72530.24649129859
J_b = 0.1145756544121064, J_o = 70099.81491689631
J_b = 0.129061388443745, J_o = 68569.47919971649
J_b = 0.13402305999315056, J_o = 69364.15067498767
J_b = 0.1308494018684942, J_o = 68128.79253130374
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.00913889 -0.61644106  0.23710978 -0.04062878 -0.81423574 -0.72103074
 -0.76739927  0.84218109 -0.61014646 -0.78979778]
W_opt:  [ 0.00506047  0.00708554  0.0075912   0.01211364  0.01308773  0.00213105
 -0.02376702 -0.07100578 -0.13457329 -0.19860626]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8263 s, v_trunc (Latent to Reduced) = 0.1041, dec (Reduced to Full) = 0.1805, add (DA)= 0.0001decode = 0.2868 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1132 s, inc stats = 5.1235, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95118557 2.81525519 3.42025215 3.03859826 2.44359222]
u_DA:    [3.899812   1.94994456 3.04004294 1.71418436 2.65897617]
ref_MAE: [0.11073117 0.6534748  0.88131737 1.18604481 0.06695851]
da_MAE:  [0.05137357 0.86531063 0.38020921 1.3244139  0.21538395]
% 18.39780080381765 da_MAE 0.006119503920043835 ref_MAE 0.0074991899487068326
u_c taken from control states: [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
u_c before reduction of space:  [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
data[u_c] post encoding of state:  [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
J_b = 0.0, J_o = 418468.5125032787
J_b = 0.5, J_o = 13504211.476879172
J_b = 0.004189173522934238, J_o = 284263.0723699404
J_b = 0.010650394094055148, J_o = 193564.7710548331
J_b = 0.018309426545924257, J_o = 152897.3148917873
J_b = 0.02929493301035429, J_o = 120558.27150781466
J_b = 0.03767064480643123, J_o = 103169.61006952688
J_b = 0.050771574927469997, J_o = 87643.49177162579
J_b = 0.06345001267369085, J_o = 79055.86372253016
J_b = 0.08535324116734219, J_o = 74673.22011250335
J_b = 0.0864842410950903, J_o = 70263.12886871464
J_b = 0.08577076955789195, J_o = 68833.58617775442
J_b = 0.09057749714789105, J_o = 66814.01882861464
J_b = 0.10760367822207897, J_o = 65423.104362616636
J_b = 0.11221301647988399, J_o = 63594.2694542509
J_b = 0.11948585770555291, J_o = 63022.75821277948
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.01880724 -0.62664575  0.23395867 -0.04954147 -0.81054982 -0.72374313
 -0.72333041  1.07358884 -0.60870119 -0.62204888]
W_opt:  [ 0.01037261  0.01044513  0.00841007  0.00997965  0.00803113 -0.00482158
 -0.03155107 -0.07648834 -0.13479699 -0.19252692]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4755 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1840, add (DA)= 0.0001decode = 0.2899 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7656 s, inc stats = 4.7806, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95077111 2.81273131 3.41929737 3.03554934 2.44458092]
u_DA:    [3.89854877 1.95478976 3.02913867 1.70615671 2.6645076 ]
ref_MAE: [0.11031671 0.65095091 0.88036258 1.18299589 0.06794721]
da_MAE:  [0.05222235 0.85794155 0.39015869 1.32939264 0.21992667]
% 18.29980525916124 da_MAE 0.006128667588893203 ref_MAE 0.007501411236942523
u_c taken from control states: [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
u_c before reduction of space:  [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
data[u_c] post encoding of state:  [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
J_b = 0.0, J_o = 408962.09741750825
J_b = 0.5000000000000001, J_o = 14168320.008441914
J_b = 0.0038676675232168782, J_o = 279810.9687207608
J_b = 0.009811294960074568, J_o = 189165.77600670443
J_b = 0.018549610020322273, J_o = 143499.68600405307
J_b = 0.0285313112168818, J_o = 114486.505063831
J_b = 0.03727861475589271, J_o = 96281.75922907807
J_b = 0.04977291651760062, J_o = 81323.05809399013
J_b = 0.06268822915957195, J_o = 72247.71492029703
J_b = 0.08453485303911328, J_o = 67741.11813521074
J_b = 0.08626935148005685, J_o = 63213.015658585246
J_b = 0.08560107208616043, J_o = 61791.98096046448
J_b = 0.09120254639027896, J_o = 59585.97985957702
J_b = 0.10946875797302127, J_o = 59070.867422291376
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.02927116 -0.63596782  0.23062255 -0.05934362 -0.8038605  -0.72942622
 -0.66747151  1.34114982 -0.60560842 -0.38514289]
W_opt:  [ 0.01128688  0.01151593  0.00884899  0.00792952  0.00392754 -0.0096996
 -0.03616075 -0.07881759 -0.13308869 -0.18600005]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.1690 s, v_trunc (Latent to Reduced) = 0.1077, dec (Reduced to Full) = 0.1896, add (DA)= 0.0001decode = 0.2998 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4689 s, inc stats = 4.4824, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.95032256 2.81042572 3.41828653 3.03219616 2.44637526]
u_DA:    [3.89859183 1.94274069 3.04092435 1.66784366 2.66856347]
ref_MAE: [0.10986816 0.64864532 0.87935174 1.17964271 0.06974155]
da_MAE:  [0.05173073 0.86768503 0.37736218 1.36435249 0.22218821]
% 18.130305646764487 da_MAE 0.00614508854434192 ref_MAE 0.007505938055452218
u_c taken from control states: [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
u_c before reduction of space:  [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
data[u_c] post encoding of state:  [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
J_b = 0.0, J_o = 403953.14525563555
J_b = 0.5, J_o = 14701604.634608103
J_b = 0.003661870829074042, J_o = 277617.5134836867
J_b = 0.009246752164063494, J_o = 187358.12321981002
J_b = 0.018680114138958454, J_o = 137899.21340546978
J_b = 0.028136663370759263, J_o = 110579.67947270082
J_b = 0.03718359086209462, J_o = 91869.91274555498
J_b = 0.049618906000320415, J_o = 76970.07071420865
J_b = 0.06324052222976027, J_o = 67576.57766860962
J_b = 0.08544227089572223, J_o = 63109.4323212198
J_b = 0.08610236155807607, J_o = 58589.36047852283
J_b = 0.08544783677530873, J_o = 57058.42428708071
J_b = 0.09052120473212964, J_o = 55021.44535076608
J_b = 0.10800268940228638, J_o = 53453.189993681124
J_b = 0.11381536519296635, J_o = 51524.382769803306
J_b = 0.12107689398663729, J_o = 51175.78556567616
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.04066529 -0.64457527  0.22711252 -0.06988103 -0.79334319 -0.73897791
 -0.60229623  1.62789077 -0.60082376 -0.12265434]
W_opt:  [ 0.01223595  0.01350417  0.01201957  0.01070523  0.00666156 -0.00686556
 -0.03426012 -0.07989123 -0.13897702 -0.19803415]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5840 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.2104, add (DA)= 0.0001decode = 0.3182 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.9022 s, inc stats = 4.9157, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94983413 2.80829687 3.41722299 3.02859144 2.4491964 ]
u_DA:    [3.89591201 1.94851958 3.00669836 1.66368605 2.67256459]
ref_MAE: [0.10937972 0.64651647 0.87828821 1.17603799 0.07256269]
da_MAE:  [0.05392212 0.85977729 0.41052463 1.3649054  0.22336819]
% 18.0882251776266 da_MAE 0.006153490047529583 ref_MAE 0.007512338807056122
u_c taken from control states: [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
u_c before reduction of space:  [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
data[u_c] post encoding of state:  [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
J_b = 0.0, J_o = 403659.0168663482
J_b = 0.5000000000000002, J_o = 14907354.829780798
J_b = 0.003616693040654603, J_o = 277245.39474336745
J_b = 0.009104609436789628, J_o = 186745.97508363315
J_b = 0.01874340446059137, J_o = 135980.30902001885
J_b = 0.028057194124235733, J_o = 109036.12680482742
J_b = 0.03724805172680406, J_o = 90034.9077799457
J_b = 0.04985069627068926, J_o = 74946.18922018692
J_b = 0.06404428426916568, J_o = 65372.784630438975
J_b = 0.08632620771936955, J_o = 60577.76886691341
J_b = 0.08681053404727189, J_o = 56161.82271020149
J_b = 0.08651592821349628, J_o = 54483.20805186672
J_b = 0.09195426333051318, J_o = 52418.71516955819
J_b = 0.10886325442571508, J_o = 50184.72128172543
J_b = 0.1204965952016973, J_o = 48331.57952191333
J_b = 0.1297031542366666, J_o = 48249.23305213175
J_b = 0.1252434375908319, J_o = 47880.04771456716
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.05306977 -0.65280912  0.22345179 -0.08096859 -0.77974383 -0.75272567
 -0.53020579  1.90598491 -0.5943589   0.12195723]
W_opt:  [ 0.01251789  0.01389928  0.01387753  0.01214698  0.00790283 -0.00568768
 -0.03356281 -0.08046379 -0.14101318 -0.2019732 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7756 s, v_trunc (Latent to Reduced) = 0.1029, dec (Reduced to Full) = 0.1688, add (DA)= 0.0001decode = 0.2739 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0496 s, inc stats = 5.0581, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94930238 2.80626043 3.41611379 3.02479853 2.45284428]
u_DA:    [3.89483327 1.93954435 3.01008128 1.63869792 2.68173856]
ref_MAE: [0.10884798 0.64448003 0.87717901 1.17224508 0.07621056]
da_MAE:  [0.05446911 0.86671608 0.40603251 1.38610061 0.22889428]
% 17.992755975972006 da_MAE 0.006167193368485882 ref_MAE 0.007520303165753143
\% improve_point: 12.57, mse_ref_points: 3.462635133254889e-05, mse_da_points: 3.02718839056707e-05, % improve_overlap: 12.57, mse_ref_overlap: 0.90190, mse_da_overlap: 0.78851
DA - - L2: 77295.43, L1: 6095.66, % Improve: 18.04%, DA_MAE: 0.01, mse_ref: 0.90, mse_DA: 0.788, time(s): 6.7283s,
u_c taken from control states: [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
u_c before reduction of space:  [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
data[u_c] post encoding of state:  [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
J_b = 0.0, J_o = 405984.5752358541
J_b = 0.49999999999999994, J_o = 14964804.617113302
J_b = 0.003646337535567903, J_o = 277943.0610279763
J_b = 0.00915506565256414, J_o = 186764.89495356503
J_b = 0.018764504756421527, J_o = 135912.67847187642
J_b = 0.028102111508734547, J_o = 108740.35002005285
J_b = 0.03733060851035128, J_o = 89571.58237970558
J_b = 0.050003671632765784, J_o = 74387.73186558929
J_b = 0.06436072140772686, J_o = 64732.58212150726
J_b = 0.08670436610027778, J_o = 59558.92568714435
J_b = 0.08777941554578893, J_o = 55157.72622513583
J_b = 0.0878720315223169, J_o = 53353.16780559675
J_b = 0.09358430730573575, J_o = 51282.91606311227
J_b = 0.11071014609054391, J_o = 48827.562644247075
J_b = 0.12429395700466205, J_o = 47063.92882223173
J_b = 0.1328696241961079, J_o = 46878.51809876502
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.06678139 -0.66096301  0.21965074 -0.09249024 -0.76498781 -0.77087143
 -0.45649173  2.14231359 -0.58650321  0.31018744]
W_opt:  [ 0.01336479  0.01472725  0.01594738  0.01410881  0.01004438 -0.00363491
 -0.03216885 -0.08141294 -0.14494    -0.20910065]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4509 s, v_trunc (Latent to Reduced) = 0.1036, dec (Reduced to Full) = 0.1849, add (DA)= 0.0001decode = 0.2907 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7418 s, inc stats = 4.7549, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94871461 2.80424376 3.41496207 3.02085712 2.45680241]
u_DA:    [3.89457662 1.93455113 3.00533269 1.63201502 2.68700231]
ref_MAE: [0.1082602  0.64246336 0.87602729 1.16830367 0.08016869]
da_MAE:  [0.05413798 0.86969263 0.40962939 1.3888421  0.2301999 ]
% 17.849486074879355 da_MAE 0.0061856305355345274 ref_MAE 0.007529630966365794
u_c taken from control states: [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
u_c before reduction of space:  [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
data[u_c] post encoding of state:  [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
J_b = 0.0, J_o = 409353.9934722316
J_b = 0.49999999999999994, J_o = 15036006.77167967
J_b = 0.003681009956554025, J_o = 279365.7132788178
J_b = 0.009210707250685452, J_o = 187453.4103293498
J_b = 0.018773032819438523, J_o = 136498.90308476545
J_b = 0.02817869981888788, J_o = 108928.82637690789
J_b = 0.037451123669278, J_o = 89562.54579657884
J_b = 0.0501383228069523, J_o = 74342.11986240157
J_b = 0.06451135452658734, J_o = 64586.762628962344
J_b = 0.08724615100216063, J_o = 59101.65908602504
J_b = 0.08907650133371302, J_o = 54584.506024211114
J_b = 0.0894842918984829, J_o = 52694.83186270525
J_b = 0.09536917227034149, J_o = 50643.36292074845
J_b = 0.11346830479603663, J_o = 48513.62323255274
J_b = 0.12348399996689548, J_o = 46610.29755167251
J_b = 0.13084797488051622, J_o = 46350.51322983278
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.08213869 -0.6691943   0.21570817 -0.1043989  -0.75056186 -0.79438485
 -0.39019709  2.2844521  -0.57806153  0.38825588]
W_opt:  [ 0.01425615  0.01604122  0.01711077  0.01430379  0.00933339 -0.00489947
 -0.03330022 -0.082074   -0.14450077 -0.2072797 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4755 s, v_trunc (Latent to Reduced) = 0.1037, dec (Reduced to Full) = 0.1898, add (DA)= 0.0001decode = 0.2962 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7719 s, inc stats = 4.7850, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94805628 2.80220795 3.41376748 3.01678332 2.460672  ]
u_DA:    [3.89426754 1.93011884 3.00981327 1.625425   2.69177963]
ref_MAE: [0.10760188 0.64042755 0.87483269 1.16422987 0.08403829]
da_MAE:  [0.05378874 0.87208911 0.4039542  1.39135833 0.23110763]
% 17.749110359479985 da_MAE 0.006201479451007169 ref_MAE 0.007539711093838525
u_c taken from control states: [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
u_c before reduction of space:  [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
data[u_c] post encoding of state:  [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
J_b = 0.0, J_o = 413548.24398767506
J_b = 0.5000000000000001, J_o = 15089031.423081951
J_b = 0.003721078636935351, J_o = 281557.916254671
J_b = 0.009277011633395452, J_o = 189079.89125316998
J_b = 0.018720867985733834, J_o = 138338.7304215258
J_b = 0.02824213496357731, J_o = 110192.13935985978
J_b = 0.037529678356820695, J_o = 90665.25923472813
J_b = 0.05017781911731484, J_o = 75468.37982991399
J_b = 0.06443414541963477, J_o = 65619.5562305799
J_b = 0.08785733315919414, J_o = 59876.24044917643
J_b = 0.09050083920022009, J_o = 55114.521785062185
J_b = 0.09121285944124065, J_o = 53187.86693588775
J_b = 0.09731127766189497, J_o = 51143.66971514355
J_b = 0.11727704705633522, J_o = 49999.669107776455
J_b = 0.12102526690512314, J_o = 47613.03932887872
J_b = 0.12542626852622923, J_o = 47139.61856131928
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.09907259 -0.67783549  0.21165686 -0.11647751 -0.73721474 -0.82317984
 -0.33506472  2.3271408  -0.56933449  0.34883345]
W_opt:  [ 0.01516858  0.01751402  0.01803328  0.01381912  0.0074665  -0.00758917
 -0.0356737  -0.0825951  -0.14208574 -0.20192109]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4995 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1890, add (DA)= 0.0001decode = 0.2952 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7949 s, inc stats = 4.8046, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94733038 2.80007076 3.41253993 3.01265139 2.46425221]
u_DA:    [3.8938773  1.92665765 3.014081   1.61659699 2.69568642]
ref_MAE: [0.10687598 0.63829036 0.87360515 1.16009794 0.0876185 ]
da_MAE:  [0.05345308 0.87341311 0.39845893 1.39605439 0.23143421]
% 17.691364477044623 da_MAE 0.006215307869287206 ref_MAE 0.007551222092065655
u_c taken from control states: [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
u_c before reduction of space:  [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
data[u_c] post encoding of state:  [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
J_b = 0.0, J_o = 418518.3464779303
J_b = 0.5, J_o = 15075714.588335339
J_b = 0.0037792214605168895, J_o = 284415.0661650746
J_b = 0.00939313424034634, J_o = 191507.75519545496
J_b = 0.01861941403632598, J_o = 141528.1801613131
J_b = 0.02833641640018814, J_o = 112532.3693176055
J_b = 0.037630665092388806, J_o = 92849.23216319665
J_b = 0.05028282555171071, J_o = 77630.70275704093
J_b = 0.06444127189378433, J_o = 67677.70765877349
J_b = 0.08874389064403077, J_o = 61678.56846793134
J_b = 0.09225200150903683, J_o = 56587.0390253215
J_b = 0.09319261251757298, J_o = 54664.953114614436
J_b = 0.09971773503883884, J_o = 52465.8307503322
J_b = 0.11823780422638776, J_o = 50777.1789523735
J_b = 0.1297661988474232, J_o = 48636.244976466005
J_b = 0.13087216600280918, J_o = 48008.54313282923
J_b = 0.13710924611878636, J_o = 47226.03761420914
J_b = 0.14656166413024044, J_o = 47654.143575619426
J_b = 0.14073293628541597, J_o = 46817.90160917658
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.11704317 -0.68743512  0.2075828  -0.12830916 -0.7244687  -0.85411754
 -0.2934512   2.2911304  -0.56027101  0.22734008]
W_opt:  [ 6.59109740e-03  1.36499775e-02  1.90200605e-02  1.62736079e-02
  1.25467139e-02  1.20353746e-04 -2.64773326e-02 -7.68160016e-02
 -1.44696355e-01 -2.17105510e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.4176 s, v_trunc (Latent to Reduced) = 0.1395, dec (Reduced to Full) = 0.1734, add (DA)= 0.0001decode = 0.3153 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.7330 s, inc stats = 5.7433, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94656003 2.79769652 3.41130549 3.00860393 2.46767119]
u_DA:    [3.88975485 1.91684847 3.00604744 1.57718434 2.70207453]
ref_MAE: [0.10610563 0.63591612 0.87237071 1.15605048 0.09103748]
da_MAE:  [0.05680518 0.88084805 0.40525806 1.43141959 0.23440334]
% 17.477132373298407 da_MAE 0.006240776300076574 ref_MAE 0.007562481139539643
u_c taken from control states: [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
u_c before reduction of space:  [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
data[u_c] post encoding of state:  [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
J_b = 0.0, J_o = 423413.02492138394
J_b = 0.49999999999999983, J_o = 15011869.267290976
J_b = 0.0038509972443977916, J_o = 287132.5920549894
J_b = 0.009548808925192826, J_o = 193843.93618764807
J_b = 0.018512879097010933, J_o = 144916.6133441041
J_b = 0.028476964945023903, J_o = 114914.56652749755
J_b = 0.037774640652230726, J_o = 95091.7801725354
J_b = 0.050489887270675556, J_o = 79790.66237775139
J_b = 0.06463496950443505, J_o = 69739.57596060932
J_b = 0.08994144016718449, J_o = 63685.07401746728
J_b = 0.0939004767757662, J_o = 58307.770545243264
J_b = 0.09423440854976962, J_o = 56398.46240528851
J_b = 0.10032563187955586, J_o = 54255.045860117025
J_b = 0.12001600098012483, J_o = 53307.14012429648
J_b = 0.12256391472691165, J_o = 50913.69073462453
J_b = 0.127157050756383, J_o = 50352.815614607796
J_b = 0.13091509327780557, J_o = 49822.002445356695
J_b = 0.13279580812461367, J_o = 49552.4730200443
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.13573083 -0.69829014  0.20351976 -0.13959673 -0.71234153 -0.88459042
 -0.26885771  2.17313866 -0.55114176  0.0690553 ]
W_opt:  [ 0.01333384  0.01937078  0.02303242  0.0172367   0.00924168 -0.00682813
 -0.03526433 -0.08347771 -0.14541475 -0.20883425]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0619 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.1884, add (DA)= 0.0001decode = 0.2945 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3565 s, inc stats = 5.3698, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94575895 2.79501179 3.4100744  3.0047426  2.47092416]
u_DA:    [3.89075308 1.91732999 3.01027586 1.58256764 2.7032198 ]
ref_MAE: [0.10530455 0.63323139 0.87113961 1.15218915 0.09429045]
da_MAE:  [0.05500586 0.8776818  0.39979853 1.42217495 0.23229564]
% 17.429900351318693 da_MAE 0.0062530290889832585 ref_MAE 0.00757299448055483
u_c taken from control states: [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
u_c before reduction of space:  [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
data[u_c] post encoding of state:  [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
J_b = 0.0, J_o = 427685.2912292315
J_b = 0.5000000000000002, J_o = 14919474.232737321
J_b = 0.003922619253611627, J_o = 289517.8340786823
J_b = 0.009707829395241967, J_o = 196106.85919605684
J_b = 0.018369541766750295, J_o = 148475.99154464234
J_b = 0.028602241339830834, J_o = 117403.12550071483
J_b = 0.03790362307637078, J_o = 97455.75181547337
J_b = 0.0507973639186756, J_o = 81960.0427316138
J_b = 0.06510112900687799, J_o = 71800.22925739763
J_b = 0.09161043340076187, J_o = 65974.84493336391
J_b = 0.09489950187564151, J_o = 60250.31836115179
J_b = 0.09445537937011518, J_o = 58328.99627575843
J_b = 0.10016233566104846, J_o = 56114.01516398467
J_b = 0.11625520454355709, J_o = 53684.9887833964
J_b = 0.12996848071229353, J_o = 51995.2429968194
J_b = 0.1402378655780297, J_o = 51758.96070175001
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.15495987 -0.71011338  0.19945268 -0.15005143 -0.70125899 -0.91304277
 -0.26544     1.9672618  -0.54242604 -0.12575287]
W_opt:  [ 0.01663645  0.02316611  0.02868166  0.02203918  0.01189997 -0.006295
 -0.03655642 -0.08641794 -0.14973205 -0.21433283]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4746 s, v_trunc (Latent to Reduced) = 0.1031, dec (Reduced to Full) = 0.1853, add (DA)= 0.0001decode = 0.2906 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7653 s, inc stats = 4.7784, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94493466 2.7920876  3.40884207 3.00116618 2.47389692]
u_DA:    [3.89623151 1.93135125 3.00005973 1.63404707 2.6775442 ]
ref_MAE: [0.10448026 0.6303072  0.86990729 1.14861273 0.09726321]
da_MAE:  [0.04870315 0.86073635 0.40878234 1.36711911 0.20364727]
% 17.673861488769358 da_MAE 0.006246403270563206 ref_MAE 0.0075873876553934246
u_c taken from control states: [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
u_c before reduction of space:  [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
data[u_c] post encoding of state:  [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
J_b = 0.0, J_o = 430268.6954337411
J_b = 0.4999999999999998, J_o = 14831292.029902628
J_b = 0.003970137375512521, J_o = 291122.4596340088
J_b = 0.009812465360403085, J_o = 198038.0434113008
J_b = 0.018183445192723423, J_o = 151702.74017159067
J_b = 0.028640475163335895, J_o = 119736.2601634627
J_b = 0.0379557653203506, J_o = 99679.1582577106
J_b = 0.05114904998220368, J_o = 83878.89360336163
J_b = 0.06580999921334581, J_o = 73603.34519055505
J_b = 0.09325764083052084, J_o = 67912.71998390554
J_b = 0.09525513221447748, J_o = 61949.294801092845
J_b = 0.09478624624894622, J_o = 60000.50144907011
J_b = 0.10065453252621354, J_o = 57722.45203087652
J_b = 0.11515240736253879, J_o = 54821.52381822305
J_b = 0.13896946932382745, J_o = 54505.748975705494
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.17438793 -0.72253132  0.19542261 -0.15932483 -0.69133603 -0.9374826
 -0.28438338  1.68824246 -0.53437725 -0.3483557 ]
W_opt:  [ 0.01861992  0.02522082  0.03136932  0.02509742  0.01383434 -0.00627826
 -0.03773188 -0.08771127 -0.15008684 -0.21339034]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2101 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1750, add (DA)= 0.0001decode = 0.2813 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.4915 s, inc stats = 4.5042, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94410183 2.78901632 3.40762096 2.99799387 2.47655864]
u_DA:    [3.89489369 1.91676435 3.01833554 1.62085191 2.68105135]
ref_MAE: [0.10364743 0.62723592 0.86868618 1.14544042 0.09992493]
da_MAE:  [0.04920814 0.87225197 0.38928542 1.37714196 0.20449271]
% 17.77947881539064 da_MAE 0.006251894427497086 ref_MAE 0.007603812694716124
u_c taken from control states: [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
u_c before reduction of space:  [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
data[u_c] post encoding of state:  [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
J_b = 0.0, J_o = 430923.14867054636
J_b = 0.49999999999999983, J_o = 14785130.219419807
J_b = 0.003978913597999899, J_o = 291889.3645469862
J_b = 0.009828105386092977, J_o = 199404.8233147008
J_b = 0.018012856633825996, J_o = 153917.77272152313
J_b = 0.028581710833889395, J_o = 121498.35136366972
J_b = 0.03791604957641997, J_o = 101359.66804351097
J_b = 0.051417214962756155, J_o = 85258.42010968774
J_b = 0.06655344655617527, J_o = 74861.45959851072
J_b = 0.09434630561033672, J_o = 68960.68280341262
J_b = 0.0954781183299398, J_o = 63101.36033927165
J_b = 0.09532104908064636, J_o = 61093.116648910596
J_b = 0.10124346380760764, J_o = 58839.84144954157
J_b = 0.11592831647667785, J_o = 55734.51379634542
J_b = 0.14167434465261206, J_o = 58192.76954732725
J_b = 0.12369933099412549, J_o = 54852.972141142774
J_b = 0.14052918329491088, J_o = 53530.16852023925
J_b = 0.1422408298203423, J_o = 53096.68521211692
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.19351544 -0.73517308  0.19149786 -0.16703474 -0.68225062 -0.9556392
 -0.32328505  1.3712904  -0.52688391 -0.58078227]
W_opt:  [ 0.01699057  0.02730349  0.03372321  0.02792548  0.01623275 -0.00528244
 -0.03810804 -0.08942121 -0.1523062  -0.21618004]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1179 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.1938, add (DA)= 0.0001decode = 0.3011 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4191 s, inc stats = 5.4265, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94328189 2.78588968 3.40643176 2.99535641 2.4789957 ]
u_DA:    [3.89685613 1.92813386 3.02311264 1.64578115 2.67227879]
ref_MAE: [0.10282749 0.62410929 0.86749698 1.14280296 0.10236199]
da_MAE:  [0.04642576 0.85775583 0.38331912 1.34957525 0.19328308]
% 17.976249014337316 da_MAE 0.006247952703001015 ref_MAE 0.007617248209110949
u_c taken from control states: [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
u_c before reduction of space:  [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
data[u_c] post encoding of state:  [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
J_b = 0.0, J_o = 429845.071477477
J_b = 0.5000000000000001, J_o = 14723761.826752476
J_b = 0.0039609244782440635, J_o = 292088.9026853898
J_b = 0.009792421690021131, J_o = 200612.2035847495
J_b = 0.01782037961311845, J_o = 155984.6254008428
J_b = 0.02840743515788686, J_o = 123498.73795995652
J_b = 0.03773556463967082, J_o = 103363.68743467238
J_b = 0.05163366909663006, J_o = 86877.87968555395
J_b = 0.06741340328687294, J_o = 76354.75806791405
J_b = 0.09485590732351329, J_o = 69928.3080591693
J_b = 0.09583262463413515, J_o = 64480.68775420076
J_b = 0.0962310936856495, J_o = 62362.60630316524
J_b = 0.10222262211287875, J_o = 60177.60596021774
J_b = 0.11809191308344495, J_o = 56893.75751262701
J_b = 0.14166283576603403, J_o = 60621.28145168255
J_b = 0.12407952243821023, J_o = 56148.572030753305
J_b = 0.1406874984705597, J_o = 54697.40139010849
J_b = 0.14521647195538687, J_o = 54073.75517206895
J_b = 0.15601480732479006, J_o = 53543.42246061126
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.21184903 -0.74772644  0.18774426 -0.17286072 -0.67352262 -0.9657056
 -0.37828419  1.04658272 -0.51975965 -0.7713343 ]
W_opt:  [ 0.00303344  0.02668722  0.04048472  0.03651928  0.02598856  0.00557249
 -0.02748678 -0.08368783 -0.15433591 -0.22961879]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.4187 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1797, add (DA)= 0.0001decode = 0.2867 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.7056 s, inc stats = 5.7161, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94249599 2.78278491 3.40529443 2.99336342 2.48133689]
u_DA:    [3.89869031 1.93708132 3.01638107 1.6865946  2.64740016]
ref_MAE: [0.10204159 0.62100451 0.86635964 1.14080997 0.10470317]
da_MAE:  [0.04380568 0.84570359 0.38891335 1.30676882 0.16606328]
% 18.219648536203906 da_MAE 0.006238066927389028 ref_MAE 0.007627830910155235
u_c taken from control states: [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
u_c before reduction of space:  [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
data[u_c] post encoding of state:  [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
J_b = 0.0, J_o = 429180.20691050903
J_b = 0.5000000000000001, J_o = 14551308.923942884
J_b = 0.003960330549555724, J_o = 293102.2451003529
J_b = 0.009820929448690546, J_o = 202900.69868283602
J_b = 0.017601213470419, J_o = 159786.53315894053
J_b = 0.028212638546146234, J_o = 127288.96114784175
J_b = 0.03743809066642672, J_o = 107394.2230969583
J_b = 0.05188998011128125, J_o = 90369.50601977811
J_b = 0.06845388003935106, J_o = 79771.80815216749
J_b = 0.09486407360686085, J_o = 72665.35097731453
J_b = 0.09653826759081643, J_o = 67731.65294754937
J_b = 0.09789119133710986, J_o = 65416.73730325907
J_b = 0.10423282511053147, J_o = 63275.84472469885
J_b = 0.12226564550427764, J_o = 59770.77193624462
J_b = 0.14741208844980278, J_o = 65077.04251634002
J_b = 0.1277387041371404, J_o = 59113.58680601529
J_b = 0.14191485761712358, J_o = 57908.5629764192
J_b = 0.14553226305420083, J_o = 57370.38688822089
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.22882362 -0.76010021  0.18421941 -0.17652949 -0.66428188 -0.96585234
 -0.4399695   0.745761   -0.51264793 -0.92060017]
W_opt:  [ 0.0045929   0.03063445  0.04324691  0.03785261  0.02345898 -0.00038026
 -0.03521958 -0.08933041 -0.15335821 -0.21801803]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0527 s, v_trunc (Latent to Reduced) = 0.1460, dec (Reduced to Full) = 0.1906, add (DA)= 0.0001decode = 0.3396 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3925 s, inc stats = 5.4062, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94176834 2.77972456 3.4042264  2.99210838 2.48381561]
u_DA:    [3.89963632 1.93375613 3.03740756 1.67439174 2.65525046]
ref_MAE: [0.10131394 0.61794416 0.86529161 1.13955493 0.10718189]
da_MAE:  [0.04213202 0.84596842 0.36681883 1.31771663 0.17143486]
% 18.25179180181473 da_MAE 0.006241803405463636 ref_MAE 0.0076354008767157274
\% improve_point: 12.60, mse_ref_points: 3.47766175949086e-05, mse_da_points: 3.0393749198615813e-05, % improve_overlap: 12.60, mse_ref_overlap: 0.90583, mse_da_overlap: 0.79169
DA - - L2: 62529.73, L1: 5529.98, % Improve: 17.99%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.791, time(s): 6.4155s,
u_c taken from control states: [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
u_c before reduction of space:  [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
data[u_c] post encoding of state:  [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
J_b = 0.0, J_o = 427734.25647887815
J_b = 0.5, J_o = 14362722.917933885
J_b = 0.00396089758546952, J_o = 293438.2310037989
J_b = 0.009862449208805432, J_o = 204355.53347882722
J_b = 0.017442879422851852, J_o = 162621.57421660115
J_b = 0.027996664235830422, J_o = 130444.70047494971
J_b = 0.03702222727685007, J_o = 111018.6971335874
J_b = 0.051845798255153605, J_o = 93624.14620737139
J_b = 0.0690269723013265, J_o = 83009.26703645813
J_b = 0.09454517522248716, J_o = 75476.87091972763
J_b = 0.09699672685051698, J_o = 70840.78646046126
J_b = 0.09923596027191976, J_o = 68352.87593881453
J_b = 0.10606110766110884, J_o = 66201.90061278902
J_b = 0.12642973082205225, J_o = 62755.21619668798
J_b = 0.14915029757994144, J_o = 63689.387514466594
J_b = 0.13521148540968703, J_o = 61764.25192494323
J_b = 0.14451813071568442, J_o = 60907.515275809055
J_b = 0.1449445534553571, J_o = 60596.7297069482
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.24395592 -0.7723125   0.18091602 -0.17792127 -0.65366498 -0.95393289
 -0.49833441  0.50936966 -0.50507712 -1.03534552]
W_opt:  [-0.00023834  0.02813832  0.04253791  0.0406053   0.02746389  0.00281899
 -0.03306949 -0.0880076  -0.15194866 -0.21585708]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0909 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1931, add (DA)= 0.0001decode = 0.2999 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3909 s, inc stats = 5.3956, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94111966 2.77670414 3.40322547 2.99163227 2.48666347]
u_DA:    [3.90107744 1.9386285  3.03832155 1.69467604 2.64393863]
ref_MAE: [0.10066526 0.61492374 0.86429069 1.13907882 0.11002975]
da_MAE:  [0.04004222 0.83807564 0.36490392 1.29695622 0.15727516]
% 18.249551635266236 da_MAE 0.006246682157374296 ref_MAE 0.00764115950716797
u_c taken from control states: [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
u_c before reduction of space:  [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
data[u_c] post encoding of state:  [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
J_b = 0.0, J_o = 424837.5046910527
J_b = 0.4999999999999998, J_o = 14197203.664802723
J_b = 0.0039396807764166646, J_o = 292896.3247919158
J_b = 0.00986175467915174, J_o = 204796.3878169229
J_b = 0.017363836014991915, J_o = 163993.114782379
J_b = 0.02770255367946456, J_o = 132726.3407442548
J_b = 0.03647592222080122, J_o = 113897.31380250957
J_b = 0.05141776102055346, J_o = 96353.75482866069
J_b = 0.0690211792379328, J_o = 85723.63977418152
J_b = 0.09421050363256575, J_o = 78052.27964322924
J_b = 0.09690864975784587, J_o = 73567.70648678008
J_b = 0.09953121985387514, J_o = 71013.44607661053
J_b = 0.10670124378198657, J_o = 68828.98346173837
J_b = 0.12887504158771965, J_o = 65645.36595637843
J_b = 0.1460249889800806, J_o = 64954.30808017487
J_b = 0.14488266306593423, J_o = 63603.51881461154
J_b = 0.1432197013526503, J_o = 63389.69453117018
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.25729254 -0.78424626  0.17780211 -0.17721826 -0.64180672 -0.93071102
 -0.54964151  0.33568235 -0.49712834 -1.12294947]
W_opt:  [-0.00336819  0.02431832  0.03861808  0.04025689  0.03052448  0.00673197
 -0.02947619 -0.08518539 -0.14931186 -0.21258051]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8180 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1789, add (DA)= 0.0001decode = 0.2859 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1041 s, inc stats = 5.1168, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94054796 2.77375261 3.40228196 2.99187276 2.48984431]
u_DA:    [3.9023524  1.94200293 3.03945515 1.71356041 2.63025957]
ref_MAE: [0.10009356 0.61197221 0.86334717 1.13931931 0.1132106 ]
da_MAE:  [0.03819555 0.83174968 0.3628268  1.27831235 0.14041526]
% 18.261137936280587 da_MAE 0.006253566927753367 ref_MAE 0.007650665509483613
u_c taken from control states: [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
u_c before reduction of space:  [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
data[u_c] post encoding of state:  [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
J_b = 0.0, J_o = 420644.87212672975
J_b = 0.5, J_o = 14027011.712456325
J_b = 0.003908571129222685, J_o = 291433.6398334444
J_b = 0.009849790998039405, J_o = 204168.19036755766
J_b = 0.01735794910436702, J_o = 164055.34839234973
J_b = 0.02736725344035938, J_o = 134123.8215739941
J_b = 0.03587506911935787, J_o = 115931.59050691538
J_b = 0.0508569609651477, J_o = 98281.07216158854
J_b = 0.06883354223879491, J_o = 87584.5736058789
J_b = 0.09428581982236518, J_o = 80000.72352060187
J_b = 0.09653999002246728, J_o = 75624.70484474917
J_b = 0.0988976566929423, J_o = 73129.25655000453
J_b = 0.1061644694329729, J_o = 70904.8395075941
J_b = 0.12894256462184195, J_o = 67705.01921679871
J_b = 0.1463358331018596, J_o = 66927.48485960717
J_b = 0.1454115183973159, J_o = 65609.77641838968
J_b = 0.14368011396411304, J_o = 65388.87593412853
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.26923516 -0.79566961  0.1748395  -0.17479023 -0.62972195 -0.8989001
 -0.59260993  0.20685039 -0.48920929 -1.18987026]
W_opt:  [-0.00627407  0.01996064  0.03465214  0.03864094  0.03232873  0.01053334
 -0.02517014 -0.08180015 -0.14712483 -0.211018  ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8394 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1834, add (DA)= 0.0001decode = 0.2898 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1293 s, inc stats = 5.1429, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.94003601 2.77092732 3.40138429 2.99270336 2.49308591]
u_DA:    [3.90283795 1.94266413 3.03879697 1.72482392 2.62067437]
ref_MAE: [0.09958161 0.60914692 0.86244951 1.14014991 0.1164522 ]
da_MAE:  [0.03719807 0.82826319 0.36258732 1.26787944 0.12758846]
% 18.206588035345078 da_MAE 0.006265446259179327 ref_MAE 0.007660086685082646
u_c taken from control states: [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
u_c before reduction of space:  [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
data[u_c] post encoding of state:  [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
J_b = 0.0, J_o = 415863.1966152444
J_b = 0.5000000000000001, J_o = 13908457.516971901
J_b = 0.0038699656746171342, J_o = 289132.73458733637
J_b = 0.00981772285792817, J_o = 202228.83801279834
J_b = 0.017464700459327912, J_o = 162214.19401168393
J_b = 0.02707978338123379, J_o = 133822.73360097216
J_b = 0.03539880661918584, J_o = 116106.17482116562
J_b = 0.050293252672455845, J_o = 98447.56720341218
J_b = 0.06839049874798855, J_o = 87557.98476414086
J_b = 0.09541664819863366, J_o = 80476.26183536222
J_b = 0.09619600771292837, J_o = 76026.54081252491
J_b = 0.09714202352252448, J_o = 73823.0742129257
J_b = 0.10389628278710508, J_o = 71549.57127774003
J_b = 0.1247536695447149, J_o = 67990.54984518905
J_b = 0.15094059240193608, J_o = 69071.41108127507
J_b = 0.13471040742016133, J_o = 66929.6663360016
J_b = 0.1464915258105205, J_o = 66025.86857629761
J_b = 0.1463347443628351, J_o = 65702.74183096019
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.28006625 -0.80636556  0.17199083 -0.17100776 -0.61814682 -0.86025627
 -0.62473576  0.12584373 -0.48147038 -1.24064437]
W_opt:  [-0.0088461   0.01490691  0.03075431  0.03648503  0.03302332  0.01346573
 -0.02143647 -0.0787087  -0.14589992 -0.21165977]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0940 s, v_trunc (Latent to Reduced) = 0.1053, dec (Reduced to Full) = 0.2058, add (DA)= 0.0001decode = 0.3132 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4073 s, inc stats = 5.4151, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93957172 2.76828194 3.40052114 2.99399729 2.4961908 ]
u_DA:    [3.90304913 1.94087108 3.03923547 1.72680179 2.61795966]
ref_MAE: [0.09911732 0.60650154 0.86158636 1.14144384 0.11955709]
da_MAE:  [0.03652259 0.82741086 0.36128567 1.26719551 0.12176886]
% 18.123018561022953 da_MAE 0.006279863050079077 ref_MAE 0.007669876123559174
u_c taken from control states: [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
u_c before reduction of space:  [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
data[u_c] post encoding of state:  [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
J_b = 0.0, J_o = 411907.6643964993
J_b = 0.5000000000000001, J_o = 13837269.150015876
J_b = 0.003821151862419672, J_o = 287567.2160292684
J_b = 0.009755248831944046, J_o = 200802.83075828146
J_b = 0.01763188920137114, J_o = 160456.5302012402
J_b = 0.026841272480315214, J_o = 133621.93210447382
J_b = 0.03506301722999237, J_o = 116214.12891859887
J_b = 0.049772756317281626, J_o = 98657.03847288681
J_b = 0.06773248636389351, J_o = 87516.1727618562
J_b = 0.0967493212432137, J_o = 81306.15548948891
J_b = 0.0960803153663812, J_o = 76527.03590952541
J_b = 0.09537824710312823, J_o = 74668.82187555484
J_b = 0.10152905858301511, J_o = 72308.629442111
J_b = 0.12052469967062518, J_o = 69152.60168878688
J_b = 0.14220505168037145, J_o = 68017.58448603128
J_b = 0.14753211258891075, J_o = 67022.69114116066
J_b = 0.14254878640541724, J_o = 66612.76564469132
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.29001522 -0.81617625  0.16923187 -0.16620012 -0.60705064 -0.81527229
 -0.64301976  0.10317322 -0.47373656 -1.27876268]
W_opt:  [-0.00657647  0.01175827  0.02644327  0.03223424  0.02987222  0.01161277
 -0.02224528 -0.07730603 -0.14311294 -0.20709682]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7739 s, v_trunc (Latent to Reduced) = 0.1065, dec (Reduced to Full) = 0.1863, add (DA)= 0.0001decode = 0.2955 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0695 s, inc stats = 5.0812, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93914523 2.7658555  3.39968518 2.99564192 2.49916722]
u_DA:    [3.90292645 1.93947435 3.0391222  1.73150122 2.61943451]
ref_MAE: [0.09869083 0.6040751  0.8607504  1.14308847 0.12253351]
da_MAE:  [0.03621878 0.82638115 0.36056298 1.2641407  0.12026729]
% 18.04449504306184 da_MAE 0.0062937924452083505 ref_MAE 0.007679523722677683
u_c taken from control states: [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
u_c before reduction of space:  [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
data[u_c] post encoding of state:  [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
J_b = 0.0, J_o = 407885.73850500607
J_b = 0.5000000000000001, J_o = 13843466.325052818
J_b = 0.003765496247406606, J_o = 285452.67669929273
J_b = 0.009660169158628648, J_o = 198463.4399932079
J_b = 0.01787434548665612, J_o = 157151.80111157012
J_b = 0.02672420587018888, J_o = 131677.08644375697
J_b = 0.03500244167011817, J_o = 114285.56981118002
J_b = 0.049508887839747114, J_o = 96904.63232738251
J_b = 0.0671889846068565, J_o = 85722.19927384
J_b = 0.09577183242128046, J_o = 79596.7176140637
J_b = 0.0958108339540024, J_o = 74935.1906585324
J_b = 0.09522619186430395, J_o = 73081.66341597789
J_b = 0.10144402176084218, J_o = 70852.3881588894
J_b = 0.12497481821379637, J_o = 69181.67069953162
J_b = 0.1298608613428872, J_o = 66870.63830520122
J_b = 0.13600353570077015, J_o = 66525.40952798373
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.29936198 -0.82496017  0.16652832 -0.16078756 -0.59666666 -0.7652329
 -0.64700795  0.13648826 -0.46604966 -1.30743554]
W_opt:  [-0.00112526  0.01343035  0.02318583  0.02689897  0.02382339  0.00582453
 -0.02728907 -0.07915434 -0.14188474 -0.20215221]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5270 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1894, add (DA)= 0.0001decode = 0.2964 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8236 s, inc stats = 4.8361, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93874457 2.76368301 3.398866   2.99749349 2.50195261]
u_DA:    [3.90254826 1.93999783 3.03398357 1.7349198  2.62671752]
ref_MAE: [0.09829017 0.60190261 0.85993122 1.14494004 0.12531889]
da_MAE:  [0.03619631 0.82368517 0.36488243 1.26257369 0.12476491]
% 17.934785808296677 da_MAE 0.006309758531153577 ref_MAE 0.007688712682104332
u_c taken from control states: [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
u_c before reduction of space:  [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
data[u_c] post encoding of state:  [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
J_b = 0.0, J_o = 405250.84672407625
J_b = 0.5, J_o = 13847725.668900978
J_b = 0.003753649212526813, J_o = 283180.71842258034
J_b = 0.009659989639347506, J_o = 195389.0004616766
J_b = 0.018169802556960258, J_o = 153116.70985647693
J_b = 0.02681982780366631, J_o = 128410.75560710888
J_b = 0.03522053112951105, J_o = 110888.05541187953
J_b = 0.04956248411216538, J_o = 93709.70618864929
J_b = 0.06683501605417541, J_o = 82963.79234846188
J_b = 0.0921753398620011, J_o = 76471.5748957433
J_b = 0.09354820997549708, J_o = 72360.02072888461
J_b = 0.09473431019361948, J_o = 70306.10995071154
J_b = 0.10174766936624272, J_o = 68220.45511680987
J_b = 0.12689485317350568, J_o = 66665.7266360571
J_b = 0.12950047256732736, J_o = 64442.849585801094
J_b = 0.1333526959968861, J_o = 64120.304003081474
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.30841322 -0.83257983  0.16383808 -0.1552219  -0.58763386 -0.71251853
 -0.63824734  0.21405049 -0.45860872 -1.31356408]
W_opt:  [ 0.00140849  0.01437818  0.02172667  0.02382576  0.01912105  0.00083304
 -0.03119341 -0.08144849 -0.1434652  -0.20343022]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5960 s, v_trunc (Latent to Reduced) = 0.1055, dec (Reduced to Full) = 0.1833, add (DA)= 0.0001decode = 0.2909 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8871 s, inc stats = 4.9003, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93835657 2.76179847 3.39805086 2.99939743 2.50437555]
u_DA:    [3.90070206 1.93902829 3.02597811 1.73414495 2.63795838]
ref_MAE: [0.09790217 0.60001807 0.85911608 1.14684398 0.12774184]
da_MAE:  [0.03765451 0.82277017 0.37207276 1.26525248 0.13358283]
% 17.885284769228733 da_MAE 0.00632149185321638 ref_MAE 0.007698366651398305
u_c taken from control states: [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
u_c before reduction of space:  [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
data[u_c] post encoding of state:  [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
J_b = 0.0, J_o = 410015.39697466244
J_b = 0.49999999999999994, J_o = 13469951.118960433
J_b = 0.003937647741464855, J_o = 284970.92920881166
J_b = 0.010192925375966467, J_o = 195370.09547029826
J_b = 0.018550594991944905, J_o = 154336.64830440996
J_b = 0.027520264037653792, J_o = 128730.81410125658
J_b = 0.03609855541459603, J_o = 110941.40050155544
J_b = 0.05099123596201328, J_o = 93284.03121043352
J_b = 0.06823923632410057, J_o = 83398.22186942458
J_b = 0.08746386616648702, J_o = 76604.33741197512
J_b = 0.09144281883233206, J_o = 73125.74758176679
J_b = 0.09473678993496884, J_o = 70809.61663778775
J_b = 0.10145326435102626, J_o = 68828.90734770271
J_b = 0.12360573392409104, J_o = 65941.00899028785
J_b = 0.13603134006569317, J_o = 65066.744591375114
J_b = 0.1368163870322989, J_o = 63867.116291111124
J_b = 0.13689828624233785, J_o = 63530.4526788364
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.3173831  -0.83883069  0.16112802 -0.14986737 -0.58029734 -0.65945997
 -0.61766264  0.33420571 -0.45149844 -1.28389087]
W_opt:  [-2.62962872e-05  1.25855384e-02  1.96119982e-02  2.17722890e-02
  1.62039618e-02 -1.94748809e-03 -3.32405816e-02 -8.33751462e-02
 -1.47272281e-01 -2.10310147e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7488 s, v_trunc (Latent to Reduced) = 0.1037, dec (Reduced to Full) = 0.1856, add (DA)= 0.0001decode = 0.2915 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0405 s, inc stats = 5.0529, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93797206 2.76025246 3.39722972 3.00122915 2.50634349]
u_DA:    [3.89672724 1.92550847 3.0249918  1.69165627 2.66268059]
ref_MAE: [0.09751765 0.59847207 0.85829493 1.1486757  0.12970978]
da_MAE:  [0.04124482 0.834744   0.37223791 1.30957288 0.1563371 ]
% 17.725053421808134 da_MAE 0.006342613066179179 ref_MAE 0.007709045499229018
u_c taken from control states: [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
u_c before reduction of space:  [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
data[u_c] post encoding of state:  [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
J_b = 0.0, J_o = 411131.0425244837
J_b = 0.5000000000000001, J_o = 13839721.941198535
J_b = 0.0038385852359778053, J_o = 286132.9163614521
J_b = 0.009909445541762079, J_o = 195046.05684244205
J_b = 0.018995674507041965, J_o = 150468.36243007577
J_b = 0.02768782149645012, J_o = 125796.33654915015
J_b = 0.03665120556279527, J_o = 107299.69368027055
J_b = 0.05143500768576282, J_o = 89766.73884015437
J_b = 0.06902126235883492, J_o = 79816.83748531312
J_b = 0.08708700082635228, J_o = 72822.1784088838
J_b = 0.09184173196132689, J_o = 69215.9868904234
J_b = 0.096479441357968, J_o = 66681.48704081567
J_b = 0.10370224607439857, J_o = 64659.115032700094
J_b = 0.12448570442396527, J_o = 61718.43648406405
J_b = 0.1386166450547483, J_o = 61317.424110522436
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.32644971 -0.84351401  0.15837773 -0.14500292 -0.57482739 -0.60831119
 -0.58867726  0.48183275 -0.44483193 -1.22880673]
W_opt:  [ 0.00551481  0.01465524  0.01936721  0.0204519   0.01337651 -0.00548424
 -0.0370486  -0.08716619 -0.1510025  -0.21379078]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.1986 s, v_trunc (Latent to Reduced) = 0.1043, dec (Reduced to Full) = 0.1743, add (DA)= 0.0001decode = 0.2808 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.4796 s, inc stats = 4.4920, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9375834  2.75909416 3.39639638 3.00289321 2.50781074]
u_DA:    [3.89405804 1.90916012 3.02710824 1.66091433 2.6786243 ]
ref_MAE: [0.097129   0.59731376 0.8574616  1.15033976 0.13117703]
da_MAE:  [0.04352535 0.84993404 0.36928814 1.34197888 0.17081356]
% 17.701710483190112 da_MAE 0.0063533188531005895 ref_MAE 0.007719867436373496
u_c taken from control states: [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
u_c before reduction of space:  [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
data[u_c] post encoding of state:  [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
J_b = 0.0, J_o = 411559.36813321884
J_b = 0.5, J_o = 14327621.223226946
J_b = 0.003707900626890542, J_o = 286888.5448932479
J_b = 0.009523103166679137, J_o = 194697.67767256036
J_b = 0.0194248364544228, J_o = 145739.17235556917
J_b = 0.027820555492286365, J_o = 122068.28196840646
J_b = 0.037073261225349735, J_o = 103133.78105400123
J_b = 0.05166180709934149, J_o = 85792.52379032937
J_b = 0.06990483885336847, J_o = 75437.80059564917
J_b = 0.08875515824452838, J_o = 68080.71432067534
J_b = 0.09428169298089266, J_o = 64213.79374036187
J_b = 0.09999594588749439, J_o = 61444.03159071863
J_b = 0.10768068023000028, J_o = 59364.763587706904
J_b = 0.12804341829227414, J_o = 56422.08363110147
J_b = 0.14267384055530988, J_o = 55905.94593193398
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.33580646 -0.84645791  0.15556748 -0.14086362 -0.5715078  -0.56066461
 -0.55456381  0.64071073 -0.43875791 -1.15956302]
W_opt:  [ 0.00917403  0.01533089  0.01918334  0.01992259  0.01259876 -0.00654564
 -0.03883693 -0.09018443 -0.15483405 -0.21822891]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2096 s, v_trunc (Latent to Reduced) = 0.1032, dec (Reduced to Full) = 0.1757, add (DA)= 0.0001decode = 0.2810 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.4907 s, inc stats = 51.6002, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9371823  2.75836606 3.39554487 3.00430921 2.50870118]
u_DA:    [3.8930927  1.90694587 3.02540336 1.64570106 2.679076  ]
ref_MAE: [0.0967279  0.59658566 0.85661009 1.15175576 0.13206747]
da_MAE:  [0.0440896  0.85142018 0.37014152 1.35860815 0.17037482]
% 17.688587713415977 da_MAE 0.006363635452256182 ref_MAE 0.007731170290335783
\% improve_point: 12.70, mse_ref_points: 3.49696078940064e-05, mse_da_points: 3.052650098969752e-05, % improve_overlap: 12.70, mse_ref_overlap: 0.91087, mse_da_overlap: 0.79516
DA - - L2: 52724.69, L1: 5238.54, % Improve: 17.99%, DA_MAE: 0.01, mse_ref: 0.91, mse_DA: 0.795, time(s): 6.9552s,
u_c taken from control states: [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
u_c before reduction of space:  [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
data[u_c] post encoding of state:  [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
J_b = 0.0, J_o = 417933.575503013
J_b = 0.5, J_o = 14426841.175554823
J_b = 0.0037368958660082686, J_o = 291346.7761921973
J_b = 0.009585576271793812, J_o = 197444.40233772315
J_b = 0.0198444316120793, J_o = 146606.00624809816
J_b = 0.028307069986010947, J_o = 122797.6675992923
J_b = 0.03773679056380346, J_o = 103558.25051195684
J_b = 0.052458698433143006, J_o = 86041.10502141921
J_b = 0.07124778622608545, J_o = 75319.49122670159
J_b = 0.09094032808948345, J_o = 67542.92457272526
J_b = 0.09760246276856865, J_o = 63359.30984134118
J_b = 0.10469303071674811, J_o = 60335.22126064154
J_b = 0.11271690766236403, J_o = 58201.742886157364
J_b = 0.131587154059729, J_o = 55329.4049256175
J_b = 0.14766537725858292, J_o = 54618.219294643655
J_b = 0.15134346043631652, J_o = 52979.399387496676
J_b = 0.1499638492797298, J_o = 52590.204220264146
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.34545512 -0.84766238  0.15268726 -0.13755992 -0.56999116 -0.51627934
 -0.5147908   0.82112181 -0.43304099 -1.07287299]
W_opt:  [ 0.00882866  0.01514241  0.01880566  0.02004849  0.013445   -0.00515191
 -0.03765984 -0.09084824 -0.15798256 -0.22404075]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7897 s, v_trunc (Latent to Reduced) = 0.1050, dec (Reduced to Full) = 0.1867, add (DA)= 0.0001decode = 0.2939 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0837 s, inc stats = 5.0875, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93676869 2.75806816 3.39467217 3.00543937 2.509108  ]
u_DA:    [3.89302628 1.91362926 3.01470715 1.64349087 2.6765747 ]
ref_MAE: [0.09631429 0.59628776 0.85573739 1.15288592 0.13247429]
da_MAE:  [0.04374241 0.8444389  0.37996502 1.3619485  0.1674667 ]
% 17.659573910128927 da_MAE 0.006375463536713685 ref_MAE 0.007742810961112999
u_c taken from control states: [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
u_c before reduction of space:  [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
data[u_c] post encoding of state:  [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
J_b = 0.0, J_o = 424471.16300831083
J_b = 0.5000000000000002, J_o = 14424872.74514565
J_b = 0.00379679135916266, J_o = 295718.6627076476
J_b = 0.009734735374070163, J_o = 200260.77446279384
J_b = 0.020173189415667245, J_o = 148449.791887709
J_b = 0.028799468552903596, J_o = 124192.38047378509
J_b = 0.038306382238436264, J_o = 104799.234601047
J_b = 0.05303894418794011, J_o = 87236.11341681253
J_b = 0.07182847732806306, J_o = 76320.7454036406
J_b = 0.09243345252691926, J_o = 68310.97847037515
J_b = 0.09975015724249069, J_o = 63913.417278342386
J_b = 0.10751078457278249, J_o = 60766.282435250265
J_b = 0.11564480721110823, J_o = 58642.937077160816
J_b = 0.13311464497690506, J_o = 55910.66864824047
J_b = 0.14908044526652323, J_o = 54759.70744727443
J_b = 0.15641424068119184, J_o = 53383.88335536054
J_b = 0.15340672464807908, J_o = 53036.53560312514
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.35533957 -0.84740926  0.14974212 -0.13512417 -0.56966562 -0.47501745
 -0.47069351  1.02059923 -0.42745918 -0.97338262]
W_opt:  [ 0.00811452  0.01652121  0.02031262  0.02149313  0.01492873 -0.00332382
 -0.03606656 -0.09070605 -0.15909574 -0.22654761]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7202 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1884, add (DA)= 0.0001decode = 0.2941 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0145 s, inc stats = 5.0271, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93634497 2.75813076 3.3937798  3.0062726  2.50919532]
u_DA:    [3.89355352 1.91538343 3.01410264 1.63812423 2.6799473 ]
ref_MAE: [0.09589057 0.59635037 0.85484501 1.15371915 0.13256161]
da_MAE:  [0.04279146 0.84274733 0.37967716 1.36814838 0.17075197]
% 17.65845110379246 da_MAE 0.006385173500867439 ref_MAE 0.007754497682471364
u_c taken from control states: [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
u_c before reduction of space:  [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
data[u_c] post encoding of state:  [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
J_b = 0.0, J_o = 429079.52791344305
J_b = 0.5000000000000001, J_o = 14425665.321157373
J_b = 0.0038370761161380424, J_o = 298850.96316178906
J_b = 0.009833026859243293, J_o = 202367.18566757813
J_b = 0.020411148424921255, J_o = 149704.7587694642
J_b = 0.02922684246455575, J_o = 124943.80666858655
J_b = 0.03875227391416926, J_o = 105524.67343170692
J_b = 0.05333907221764568, J_o = 88101.40833631091
J_b = 0.07172489584859215, J_o = 77161.40369630285
J_b = 0.09322603486983205, J_o = 69179.74630121121
J_b = 0.1002287147006767, J_o = 64730.9719298477
J_b = 0.10763219409660713, J_o = 61608.771958522935
J_b = 0.11596031159837351, J_o = 59556.57431788164
J_b = 0.13260079695654992, J_o = 56977.5982372765
J_b = 0.14666888430545716, J_o = 55485.67230708753
J_b = 0.15833074897029722, J_o = 54595.486237070305
J_b = 0.1529930047195275, J_o = 54164.809272879866
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.36564073 -0.84600416  0.14673222 -0.13362291 -0.57060828 -0.43862404
 -0.4264805   1.21062192 -0.422158   -0.87696726]
W_opt:  [ 0.00714108  0.01563437  0.02156005  0.02332382  0.01647369 -0.00173365
 -0.0346885  -0.0898424  -0.15866543 -0.22689215]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7364 s, v_trunc (Latent to Reduced) = 0.1197, dec (Reduced to Full) = 0.1937, add (DA)= 0.0001decode = 0.3154 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0520 s, inc stats = 5.0768, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93590339 2.75847828 3.3928678  3.00678617 2.50894246]
u_DA:    [3.89410116 1.91801195 3.01364019 1.62170528 2.68244274]
ref_MAE: [0.09544899 0.59669788 0.85393301 1.15423272 0.13230875]
da_MAE:  [0.04180223 0.84046633 0.37922761 1.38508089 0.17350028]
% 17.637789349528695 da_MAE 0.0063961882648740235 ref_MAE 0.007765925919616416
u_c taken from control states: [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
u_c before reduction of space:  [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
data[u_c] post encoding of state:  [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
J_b = 0.0, J_o = 431541.385266014
J_b = 0.4999999999999999, J_o = 14570639.157368748
J_b = 0.0038035514046962635, J_o = 301257.40790287504
J_b = 0.009728920019653014, J_o = 204411.08405222336
J_b = 0.02063989614939273, J_o = 149685.21915470422
J_b = 0.02959988934047346, J_o = 124646.82860615582
J_b = 0.03916108825075789, J_o = 105259.93725280334
J_b = 0.05341656989200378, J_o = 88203.70003738433
J_b = 0.07124269605903219, J_o = 77297.09508226078
J_b = 0.09401222224019164, J_o = 69636.08671311176
J_b = 0.09949174342558348, J_o = 65187.655657121766
J_b = 0.10570859911545562, J_o = 62183.52584039568
J_b = 0.11475225337016019, J_o = 60215.19301681072
J_b = 0.13201412051405226, J_o = 57779.14141816521
J_b = 0.14158368054779216, J_o = 56327.42985831092
J_b = 0.15682028564296463, J_o = 56710.16602822302
J_b = 0.14789494847218826, J_o = 55776.385903292794
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.37655961 -0.84383367  0.14365591 -0.13309281 -0.57305015 -0.40864556
 -0.38601185  1.37412613 -0.41728969 -0.79312532]
W_opt:  [ 0.01324417  0.01486439  0.02109813  0.02384837  0.01648489 -0.00250025
 -0.03575505 -0.08998239 -0.15720374 -0.2231055 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8039 s, v_trunc (Latent to Reduced) = 0.1036, dec (Reduced to Full) = 0.1810, add (DA)= 0.0001decode = 0.2872 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0912 s, inc stats = 5.1047, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93543533 2.7590151  3.39193568 3.00696751 2.50828746]
u_DA:    [3.89502362 1.92446142 3.01277615 1.61473841 2.6877448 ]
ref_MAE: [0.09498093 0.5972347  0.85300089 1.15441406 0.13165375]
da_MAE:  [0.04041171 0.83455368 0.37915952 1.3922291  0.17945734]
% 17.5306702332005 da_MAE 0.0064138604400800076 ref_MAE 0.0077772675711281205
u_c taken from control states: [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
u_c before reduction of space:  [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
data[u_c] post encoding of state:  [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
J_b = 0.0, J_o = 432188.92202527414
J_b = 0.5000000000000001, J_o = 14799510.750912298
J_b = 0.0037301879026532237, J_o = 302620.79905764386
J_b = 0.009513551472464386, J_o = 205869.88175374863
J_b = 0.02084534499013437, J_o = 148432.57484698968
J_b = 0.029935624592321092, J_o = 123203.88207816856
J_b = 0.03954423810763316, J_o = 103864.94015819926
J_b = 0.05348984430660893, J_o = 87170.60827710817
J_b = 0.07087456297510984, J_o = 76233.27014062111
J_b = 0.09545210270942389, J_o = 69258.71439745084
J_b = 0.09849044972719986, J_o = 64680.14331087691
J_b = 0.10261432076288632, J_o = 61964.88310523225
J_b = 0.11110547326191039, J_o = 59735.17283811228
J_b = 0.1361200584660926, J_o = 57148.19256354935
J_b = 0.15175445160752157, J_o = 55967.1074127429
J_b = 0.146800670272065, J_o = 55700.75545327297
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.38800315 -0.84141744  0.14053008 -0.13346055 -0.57671373 -0.3853037
 -0.35144553  1.50747096 -0.41276986 -0.72600556]
W_opt:  [ 0.01795059  0.01164188  0.01447655  0.02144747  0.01801261  0.00054054
 -0.03186497 -0.08584334 -0.15454264 -0.22343072]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4895 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.2036, add (DA)= 0.0001decode = 0.3102 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7998 s, inc stats = 4.8052, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93494478 2.75961269 3.39098855 3.00684171 2.50730475]
u_DA:    [3.89348695 1.91605852 3.01566755 1.58255592 2.70384856]
ref_MAE: [0.09449038 0.5978323  0.85205377 1.15428826 0.13067104]
da_MAE:  [0.04145783 0.84355418 0.375321   1.42428579 0.19654381]
% 17.291048169988976 da_MAE 0.006441926460939997 ref_MAE 0.007788668963161177
u_c taken from control states: [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
u_c before reduction of space:  [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
data[u_c] post encoding of state:  [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
J_b = 0.0, J_o = 431704.26801978203
J_b = 0.5, J_o = 14969408.843303405
J_b = 0.00367223385610621, J_o = 302846.3449373377
J_b = 0.009344970415434587, J_o = 206347.52117765017
J_b = 0.020967908601220383, J_o = 146975.97141351295
J_b = 0.030138058472563112, J_o = 121686.72010655007
J_b = 0.03965921424125115, J_o = 102617.22878990143
J_b = 0.05324855376920181, J_o = 86321.29999351979
J_b = 0.07019566719255688, J_o = 75344.00980236231
J_b = 0.09669658999787566, J_o = 69491.58568962775
J_b = 0.09726051711286172, J_o = 64490.56877579948
J_b = 0.09852132332852079, J_o = 62245.16721645039
J_b = 0.1063038708154078, J_o = 60088.95493113701
J_b = 0.1295946276863371, J_o = 59262.022717944
J_b = 0.13069683302460505, J_o = 56755.31261913506
J_b = 0.13343759115911275, J_o = 56241.11348808493
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.39993838 -0.8393232   0.13737082 -0.13467273 -0.5815825  -0.36921501
 -0.326371    1.59803788 -0.40866828 -0.68307211]
W_opt:  [ 0.02956075  0.0207071   0.01262907  0.01471726  0.01284239 -0.00411093
 -0.03610449 -0.0860882  -0.14839336 -0.20978682]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5434 s, v_trunc (Latent to Reduced) = 0.1047, dec (Reduced to Full) = 0.1971, add (DA)= 0.0001decode = 0.3039 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.8475 s, inc stats = 4.8600, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93443316 2.76013066 3.3900313  3.00642704 2.50599876]
u_DA:    [3.89698284 1.9322375  3.01520582 1.61960547 2.68886203]
ref_MAE: [0.09397876 0.59835026 0.85109651 1.15387359 0.12936505]
da_MAE:  [0.03745032 0.82789316 0.37482547 1.38682156 0.18286327]
% 17.435290378880484 da_MAE 0.006440418612976499 ref_MAE 0.00780044966249004
u_c taken from control states: [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
u_c before reduction of space:  [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
data[u_c] post encoding of state:  [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
J_b = 0.0, J_o = 431751.6529962821
J_b = 0.4999999999999997, J_o = 15007105.500564065
J_b = 0.003649699668293952, J_o = 303434.3498630124
J_b = 0.009285505210453295, J_o = 207194.61909693893
J_b = 0.020996791977277975, J_o = 147268.7038589906
J_b = 0.030188100704534867, J_o = 122048.3188154261
J_b = 0.03949604832377096, J_o = 103429.13581162282
J_b = 0.05272583558464244, J_o = 87515.50519390767
J_b = 0.0692738057618879, J_o = 76518.0099075393
J_b = 0.09723732321534771, J_o = 71918.30088579674
J_b = 0.09588859340464267, J_o = 66218.05442948846
J_b = 0.09547320954613346, J_o = 64313.78178231088
J_b = 0.1027156200709632, J_o = 61973.50219182375
J_b = 0.12262067481107489, J_o = 60685.764336537904
J_b = 0.12732831923683874, J_o = 58464.953962346335
J_b = 0.13275270645513046, J_o = 57986.05616671855
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.41246481 -0.83795053  0.13417722 -0.13672641 -0.58806717 -0.36154221
 -0.31418982  1.63229859 -0.40518702 -0.66859154]
W_opt:  [ 0.02566726  0.0250054   0.01661885  0.01170964  0.0107222  -0.0030735
 -0.03399728 -0.08353998 -0.1459024  -0.20826857]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5162 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.1752, add (DA)= 0.0001decode = 0.2826 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7989 s, inc stats = 4.8043, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93389619 2.76047015 3.38906364 3.0057245  2.50425932]
u_DA:    [3.89812224 1.93697724 3.01757229 1.63682432 2.68024254]
ref_MAE: [0.09344178 0.59868976 0.85012886 1.15317105 0.12762561]
da_MAE:  [0.03577395 0.82349291 0.37149135 1.36890018 0.17598322]
% 17.432782075671444 da_MAE 0.006450618231648389 ref_MAE 0.00781256580252016
u_c taken from control states: [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
u_c before reduction of space:  [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
data[u_c] post encoding of state:  [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
J_b = 0.0, J_o = 431371.3863827207
J_b = 0.5000000000000002, J_o = 14919585.904321877
J_b = 0.003655529016186847, J_o = 303596.48730282794
J_b = 0.009318280210437459, J_o = 207638.71669843473
J_b = 0.020957185748631778, J_o = 148330.58332645535
J_b = 0.030130263954088212, J_o = 123254.94687043902
J_b = 0.039209386576348516, J_o = 105082.10215461525
J_b = 0.052172746878085735, J_o = 89442.34782077096
J_b = 0.06841518140313875, J_o = 78462.924030968
J_b = 0.09711631511106722, J_o = 74664.72193481895
J_b = 0.09483193454575277, J_o = 68437.31662890487
J_b = 0.09384139558408025, J_o = 66703.5918658769
J_b = 0.10085834155726754, J_o = 64242.73702745298
J_b = 0.11937876535904045, J_o = 62758.460790666664
J_b = 0.12559889783406306, J_o = 60671.27808963192
J_b = 0.1325246009956308, J_o = 60255.973222160304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.42561389 -0.83759426  0.13095059 -0.13959267 -0.59646874 -0.36268952
 -0.31754209  1.60721246 -0.40246996 -0.6818627 ]
W_opt:  [ 0.02058381  0.02362967  0.02268551  0.01388212  0.00909037 -0.00389067
 -0.03329029 -0.08200162 -0.14410899 -0.20694813]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4700 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1766, add (DA)= 0.0001decode = 0.2825 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7527 s, inc stats = 4.7593, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93333252 2.76055827 3.38808597 3.00474399 2.50200569]
u_DA:    [3.8987264  1.94028795 3.01936292 1.64944087 2.67409368]
ref_MAE: [0.09287812 0.59877787 0.84915119 1.15219054 0.12537198]
da_MAE:  [0.03460612 0.82027032 0.36872305 1.35530312 0.17208798]
% 17.3770826312295 da_MAE 0.0064650276409587435 ref_MAE 0.007824739003227657
u_c taken from control states: [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
u_c before reduction of space:  [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
data[u_c] post encoding of state:  [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
J_b = 0.0, J_o = 429558.931268497
J_b = 0.5, J_o = 14754575.38786304
J_b = 0.003678814835353837, J_o = 302335.095520696
J_b = 0.009407890690193805, J_o = 206699.3326467794
J_b = 0.02086309771984632, J_o = 148792.2517308943
J_b = 0.02997992062499559, J_o = 123928.61352671222
J_b = 0.03885456591272529, J_o = 106134.09715589226
J_b = 0.05165314477880111, J_o = 90652.72241805049
J_b = 0.06767230233643891, J_o = 79699.8311676035
J_b = 0.09675735527306056, J_o = 75948.8879666622
J_b = 0.0947437760956576, J_o = 69613.06432503543
J_b = 0.09356573920105717, J_o = 67920.5836144931
J_b = 0.10051348940553131, J_o = 65437.35975833281
J_b = 0.11946171499066789, J_o = 63979.000750037456
J_b = 0.12499728457479899, J_o = 61907.76270116642
J_b = 0.13204836601461845, J_o = 61515.355744730885
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.43934078 -0.83864783  0.12770954 -0.1431833  -0.60683218 -0.3725918
 -0.33841116  1.51796927 -0.40063369 -0.72424645]
W_opt:  [ 0.01982067  0.02102757  0.02449109  0.01749608  0.00921305 -0.00603394
 -0.03472942 -0.08189474 -0.14288388 -0.20524145]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4715 s, v_trunc (Latent to Reduced) = 0.1178, dec (Reduced to Full) = 0.1691, add (DA)= 0.0001decode = 0.2891 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7608 s, inc stats = 4.7666, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93274409 2.76029769 3.38710393 3.00351568 2.49922582]
u_DA:    [3.89890308 1.9423878  3.02357036 1.6595481  2.66965073]
ref_MAE: [0.09228969 0.59851729 0.84816915 1.15096223 0.12259211]
da_MAE:  [0.03384102 0.81790989 0.36353357 1.34396758 0.17042491]
% 17.375174769453768 da_MAE 0.006475106418772526 ref_MAE 0.007836756568870408
u_c taken from control states: [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
u_c before reduction of space:  [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
data[u_c] post encoding of state:  [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
J_b = 0.0, J_o = 425914.8132532878
J_b = 0.5, J_o = 14573053.307827681
J_b = 0.003697281382478933, J_o = 299574.4765448184
J_b = 0.00948689886087193, J_o = 204608.9623257697
J_b = 0.02065160741150138, J_o = 148690.33237704958
J_b = 0.029641204717915905, J_o = 124183.01368188724
J_b = 0.03831951092602019, J_o = 106733.13151948072
J_b = 0.05100795835522427, J_o = 91349.84555088863
J_b = 0.06684850899781965, J_o = 80441.66568462265
J_b = 0.09597410537041513, J_o = 76050.29953660029
J_b = 0.09532605493510743, J_o = 70023.51571108747
J_b = 0.09427780131415807, J_o = 68284.61157864303
J_b = 0.10114509832593253, J_o = 65911.94414453012
J_b = 0.12129417801623466, J_o = 64485.69690552956
J_b = 0.1249549649847681, J_o = 62562.67213116365
J_b = 0.13139943469248494, J_o = 62162.74846431098
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.45375481 -0.84119099  0.12445411 -0.14748613 -0.61968679 -0.39198099
 -0.37964377  1.35909737 -0.40000195 -0.7960374 ]
W_opt:  [ 0.01997581  0.02199834  0.02493443  0.0188272   0.0096359  -0.00808869
 -0.03735265 -0.08345822 -0.14276455 -0.2036334 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5035 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1836, add (DA)= 0.0001decode = 0.2897 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7933 s, inc stats = 4.8100, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93212621 2.7596687  3.38611754 3.00204374 2.49577772]
u_DA:    [3.89836064 1.94442729 3.02966993 1.67547663 2.66327254]
ref_MAE: [0.09167181 0.59788831 0.84718276 1.14949029 0.11914401]
da_MAE:  [0.03376556 0.81524141 0.35644761 1.3265671  0.16749481]
% 17.436050732017307 da_MAE 0.00648028497704671 ref_MAE 0.007848806936321888
\% improve_point: 12.71, mse_ref_points: 3.519515298370806e-05, mse_da_points: 3.071940426863694e-05, % improve_overlap: 12.71, mse_ref_overlap: 0.91676, mse_da_overlap: 0.80019
DA - - L2: 45582.22, L1: 4990.55, % Improve: 17.92%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.800, time(s): 6.6677s,
u_c taken from control states: [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
u_c before reduction of space:  [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
data[u_c] post encoding of state:  [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
J_b = 0.0, J_o = 422336.31515130005
J_b = 0.5000000000000001, J_o = 14340720.344232403
J_b = 0.0037395277040699975, J_o = 296469.660723247
J_b = 0.009623033870789003, J_o = 202370.29938622814
J_b = 0.020268205748019887, J_o = 149519.67721340744
J_b = 0.029134833254377625, J_o = 125218.98708503535
J_b = 0.03759339979055184, J_o = 108076.71434974202
J_b = 0.05025701867364695, J_o = 92690.29543815779
J_b = 0.06596835821937541, J_o = 81863.1988870364
J_b = 0.09495917728774166, J_o = 76544.31882149985
J_b = 0.09578145077359383, J_o = 70897.63044439965
J_b = 0.09559233214445077, J_o = 69057.32431680548
J_b = 0.10363262380444851, J_o = 66472.06964075124
J_b = 0.12167752098280606, J_o = 64155.73900006899
J_b = 0.13962946973599472, J_o = 62851.97698686293
J_b = 0.1401893704950199, J_o = 62533.75056264435
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.46876316 -0.84515839  0.12119529 -0.1523866  -0.63496497 -0.42034183
 -0.43884356  1.15370948 -0.40057676 -0.88565493]
W_opt:  [ 0.01696097  0.02352193  0.02845721  0.02195829  0.01273212 -0.00599846
 -0.03606303 -0.08411617 -0.14633741 -0.21147955]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.6036 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1835, add (DA)= 0.0001decode = 0.2903 s, unnorm = 0.0006 s, TOTAL = unnormalising + decoding + minimising = 4.8945 s, inc stats = 4.9000, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93148284 2.75868746 3.38513012 3.00036735 2.49167953]
u_DA:    [3.89659599 1.93549086 3.04242526 1.68051993 2.67180889]
ref_MAE: [0.09102844 0.59690706 0.84619533 1.1478139  0.11504582]
da_MAE:  [0.03488686 0.8231966  0.34270486 1.31984742 0.18012936]
% 17.495221417974605 da_MAE 0.006485370340221769 ref_MAE 0.007860599654569197
u_c taken from control states: [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
u_c before reduction of space:  [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
data[u_c] post encoding of state:  [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
J_b = 0.0, J_o = 420402.1349773324
J_b = 0.5, J_o = 14059499.740846252
J_b = 0.00382843320756772, J_o = 293815.896034611
J_b = 0.009865670473926152, J_o = 200533.00437281805
J_b = 0.01973976409098013, J_o = 151758.37166579277
J_b = 0.028577189773152874, J_o = 127202.99818155525
J_b = 0.03684175060469291, J_o = 110226.2724126078
J_b = 0.04968206945401929, J_o = 94621.52082984489
J_b = 0.0654823185393498, J_o = 84010.93963746532
J_b = 0.09347353727325437, J_o = 77873.57561856646
J_b = 0.09519034391926467, J_o = 72855.03153315825
J_b = 0.09517774143274949, J_o = 70848.68281844794
J_b = 0.10207417914496826, J_o = 68611.84021730401
J_b = 0.12397610127904937, J_o = 67046.64243691575
J_b = 0.12844654351847534, J_o = 64975.36172865797
J_b = 0.1334405644037226, J_o = 64633.44660200036
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.48400615 -0.85051594  0.11796236 -0.15768247 -0.65182541 -0.45519273
 -0.51052149  0.93732374 -0.40200575 -0.97868892]
W_opt:  [ 0.02027852  0.02756259  0.03080104  0.0221826   0.01045328 -0.01066741
 -0.04188233 -0.08871367 -0.14709582 -0.20606008]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.6238 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1857, add (DA)= 0.0001decode = 0.2927 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.9167 s, inc stats = 4.9223, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93082942 2.7573624  3.38415054 2.9985557  2.48715691]
u_DA:    [3.89904707 1.94535794 3.04755919 1.72196963 2.66001573]
ref_MAE: [0.09037502 0.595582   0.84521576 1.14600225 0.1105232 ]
da_MAE:  [0.03178235 0.81200446 0.33659135 1.27658608 0.17285882]
% 17.73588286174541 da_MAE 0.006475707462359929 ref_MAE 0.007871849461991716
u_c taken from control states: [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
u_c before reduction of space:  [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
data[u_c] post encoding of state:  [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
J_b = 0.0, J_o = 423140.88591794606
J_b = 0.5000000000000001, J_o = 13719280.18198516
J_b = 0.0039985623295338115, J_o = 293650.15159982484
J_b = 0.010298359050180653, J_o = 200680.59022543722
J_b = 0.019214595048434226, J_o = 156523.2169236783
J_b = 0.02826245707676819, J_o = 130831.8513570471
J_b = 0.03641673146282785, J_o = 113819.04042019865
J_b = 0.04983136134621562, J_o = 97587.9418336108
J_b = 0.06610564567805881, J_o = 87228.34251799736
J_b = 0.09101190560635346, J_o = 79898.4794119029
J_b = 0.09571553899157424, J_o = 75479.97645292986
J_b = 0.09780660688392939, J_o = 73105.03160015009
J_b = 0.10479746632297042, J_o = 70928.19038352279
J_b = 0.12504882356086391, J_o = 68138.26547993335
J_b = 0.13890646696802386, J_o = 67255.27248580779
J_b = 0.14041574327252218, J_o = 66149.4678000394
J_b = 0.1401510935307173, J_o = 65882.81626428336
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.49937618 -0.85704658  0.1147625  -0.16327743 -0.6699608  -0.49529319
 -0.58968599  0.72477535 -0.40423375 -1.06725591]
W_opt:  [ 0.01674918  0.02800949  0.03366199  0.02473183  0.01254094 -0.0096709
 -0.04229593 -0.09158606 -0.15269555 -0.21406839]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7720 s, v_trunc (Latent to Reduced) = 0.1030, dec (Reduced to Full) = 0.1906, add (DA)= 0.0001decode = 0.2957 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0678 s, inc stats = 5.0828, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.93017055 2.7557472  3.38318099 2.99664174 2.4822923 ]
u_DA:    [3.89910801 1.93708692 3.04887542 1.71248233 2.67208667]
ref_MAE: [0.08971615 0.59396681 0.8442462  1.14408829 0.10565859]
da_MAE:  [0.03106255 0.81866028 0.33430557 1.28415941 0.18979437]
% 17.668688168739916 da_MAE 0.0064897455372065664 ref_MAE 0.00788247556471279
u_c taken from control states: [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
u_c before reduction of space:  [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
data[u_c] post encoding of state:  [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
J_b = 0.0, J_o = 431791.9381570879
J_b = 0.4999999999999999, J_o = 13269434.055960244
J_b = 0.00429927901446758, J_o = 296273.99235921196
J_b = 0.011047705825478659, J_o = 202891.58862983782
J_b = 0.018843129621051457, J_o = 163615.90919943427
J_b = 0.02852799045679096, J_o = 135369.73392351024
J_b = 0.036635634880902775, J_o = 118314.87809417727
J_b = 0.051352572700009966, J_o = 100793.60789831184
J_b = 0.06861199116305525, J_o = 90597.3464849512
J_b = 0.08935244485587905, J_o = 82555.91607779375
J_b = 0.0985064487337975, J_o = 78178.99774961143
J_b = 0.10453006385618072, J_o = 75375.9706989339
J_b = 0.11036211160460782, J_o = 73409.23538546044
J_b = 0.1285754657681264, J_o = 70418.00960877257
J_b = 0.1472905691470683, J_o = 73186.39492698108
J_b = 0.13372297160007032, J_o = 69763.97884632697
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.51475859 -0.86436464  0.11159743 -0.16905589 -0.68891043 -0.53895568
 -0.66985698  0.53475317 -0.40712728 -1.13683102]
W_opt:  [ 0.01833853  0.03046624  0.03532648  0.02560356  0.01133784 -0.01248818
 -0.04579245 -0.09421607 -0.15195913 -0.20805645]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4265 s, v_trunc (Latent to Reduced) = 0.1031, dec (Reduced to Full) = 0.1698, add (DA)= 0.0001decode = 0.2749 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7016 s, inc stats = 4.7142, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92951115 2.75393726 3.38222197 2.994665   2.47720928]
u_DA:    [3.90153929 1.93284884 3.05537748 1.72284892 2.66425617]
ref_MAE: [0.08905675 0.59215686 0.84328719 1.14211155 0.10057557]
da_MAE:  [0.02797186 0.82108842 0.32684449 1.27181608 0.18704688]
% 17.834168100038884 da_MAE 0.006484682993442713 ref_MAE 0.007892189299973219
u_c taken from control states: [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
u_c before reduction of space:  [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
data[u_c] post encoding of state:  [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
J_b = 0.0, J_o = 444723.8531262102
J_b = 0.49999999999999994, J_o = 12850055.943585718
J_b = 0.004665876257233913, J_o = 301238.7473890643
J_b = 0.011935742059037649, J_o = 207112.70614721364
J_b = 0.01869123027332781, J_o = 171693.9079348813
J_b = 0.029360843238321898, J_o = 139737.90468747745
J_b = 0.03751653753953704, J_o = 122800.49666246347
J_b = 0.05444763471768219, J_o = 103474.25714750652
J_b = 0.07330333764918401, J_o = 93389.52498924517
J_b = 0.0886280990125892, J_o = 85605.93764495399
J_b = 0.10198202592389886, J_o = 80705.52739773682
J_b = 0.11303857313358248, J_o = 78206.99910706998
J_b = 0.11535409112852976, J_o = 76320.87064044714
J_b = 0.12479766256554763, J_o = 73940.22996401812
J_b = 0.1341581270674454, J_o = 72451.96974909326
J_b = 0.1602690465725116, J_o = 78102.63205627956
J_b = 0.1390143734756608, J_o = 72034.57457534524
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.52996079 -0.87208084  0.10847447 -0.17486399 -0.7078768  -0.58366725
 -0.74494197  0.38424871 -0.41044727 -1.18835144]
W_opt:  [ 0.01360372  0.03048281  0.03802563  0.02881494  0.01326421 -0.01150946
 -0.04522938 -0.09492002 -0.15389176 -0.21151871]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7951 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1819, add (DA)= 0.0001decode = 0.2892 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0845 s, inc stats = 5.0971, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92885948 2.75202884 3.38127572 2.99267812 2.47212177]
u_DA:    [3.90367455 1.94028133 3.03657022 1.74709541 2.65103768]
ref_MAE: [0.08840508 0.59024844 0.84234093 1.14012467 0.09548806]
da_MAE:  [0.02518493 0.81174751 0.3447055  1.24558271 0.17891591]
% 17.8593915003883 da_MAE 0.006489862676582772 ref_MAE 0.007900918674851857
u_c taken from control states: [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
u_c before reduction of space:  [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
data[u_c] post encoding of state:  [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
J_b = 0.0, J_o = 459891.7789785882
J_b = 0.4999999999999999, J_o = 12527453.446089981
J_b = 0.0050401527373331485, J_o = 307683.3986623229
J_b = 0.01280765436732075, J_o = 212857.26743631746
J_b = 0.018687532734928885, J_o = 179980.2918855326
J_b = 0.03059678070697233, J_o = 143402.30216956962
J_b = 0.03888731988507846, J_o = 126815.60529202907
J_b = 0.058815817451887735, J_o = 105667.34964712201
J_b = 0.0797265545618157, J_o = 95661.78617794898
J_b = 0.08991364518714019, J_o = 88774.16469865845
J_b = 0.1035114402955017, J_o = 83263.71994005152
J_b = 0.11658143388218067, J_o = 81349.89578065684
J_b = 0.12198577167745017, J_o = 78962.7878019884
J_b = 0.12954955184785139, J_o = 77112.77491834908
J_b = 0.13756233716573757, J_o = 75777.59940632225
J_b = 0.15460955245372948, J_o = 74673.00214900135
J_b = 0.16504259917709857, J_o = 73306.65062233528
J_b = 0.16124428395614568, J_o = 72956.57252338463
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.54493281 -0.87974664  0.10539625 -0.18057042 -0.7263104  -0.62787677
 -0.81136442  0.27438464 -0.41408279 -1.21743986]
W_opt:  [ 0.00082406  0.02893143  0.04521474  0.03817007  0.0224817  -0.00276281
 -0.03642684 -0.09095337 -0.15862978 -0.22870097]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1504 s, v_trunc (Latent to Reduced) = 0.1058, dec (Reduced to Full) = 0.1928, add (DA)= 0.0001decode = 0.3009 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4515 s, inc stats = 5.4618, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92821768 2.75013289 3.38034302 2.99072603 2.46717717]
u_DA:    [3.90343589 1.93736    3.03863298 1.73280458 2.6416202 ]
ref_MAE: [0.08776328 0.58835249 0.84140823 1.13817258 0.09054346]
da_MAE:  [0.02478179 0.81277289 0.34171003 1.25792145 0.17444303]
% 18.03120594141693 da_MAE 0.006482653475372392 ref_MAE 0.007908684701081782
u_c taken from control states: [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
u_c before reduction of space:  [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
data[u_c] post encoding of state:  [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
J_b = 0.0, J_o = 472826.0113448702
J_b = 0.4999999999999998, J_o = 12343438.1901288
J_b = 0.0053273790014878525, J_o = 313444.09788250603
J_b = 0.013435538074589455, J_o = 218528.90219875437
J_b = 0.018658482361455658, J_o = 187099.78148084658
J_b = 0.03175802914495265, J_o = 146039.8445893036
J_b = 0.04018709509859596, J_o = 129979.45114751335
J_b = 0.06279528558607186, J_o = 107542.8860615001
J_b = 0.08660635799772168, J_o = 98006.40093929185
J_b = 0.0927165525018407, J_o = 91643.71049846441
J_b = 0.10248197194315761, J_o = 86834.25703627845
J_b = 0.11297634326533255, J_o = 83932.67944111282
J_b = 0.14340815665573442, J_o = 83780.42309681309
J_b = 0.12716710294281716, J_o = 81892.03243690358
J_b = 0.1398455156350314, J_o = 79763.5575776646
J_b = 0.1444342780163367, J_o = 78744.82531983568
J_b = 0.1561576228234599, J_o = 79088.1267466081
J_b = 0.14929890851962763, J_o = 78174.79818249198
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.55985294 -0.88679584  0.10234991 -0.18610693 -0.74431281 -0.67146914
 -0.86944041  0.19170574 -0.41819613 -1.23147738]
W_opt:  [ 0.00978981  0.03136683  0.04357677  0.03553562  0.01837999 -0.00855489
 -0.0428407  -0.09386723 -0.1541351  -0.21386995]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0084 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.2011, add (DA)= 0.0002decode = 0.3068 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3155 s, inc stats = 5.3203, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92757809 2.74838944 3.37941998 2.98883206 2.46234823]
u_DA:    [3.90568592 1.94490945 3.03522947 1.76208861 2.62726862]
ref_MAE: [0.08712369 0.58660904 0.8404852  1.13627861 0.08571452]
da_MAE:  [0.02189217 0.80347999 0.34419051 1.22674345 0.16492038]
% 18.14708524282551 da_MAE 0.006479140280301662 ref_MAE 0.00791558895553412
u_c taken from control states: [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
u_c before reduction of space:  [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
data[u_c] post encoding of state:  [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
J_b = 0.0, J_o = 480178.3175596113
J_b = 0.5000000000000002, J_o = 12336154.685592512
J_b = 0.0054672529764185325, J_o = 316257.19380633894
J_b = 0.013685875894693215, J_o = 221472.2447430872
J_b = 0.018560770933694834, J_o = 190539.22918888068
J_b = 0.03242367854147258, J_o = 146547.87571671544
J_b = 0.04088023184085052, J_o = 130888.35040346341
J_b = 0.06490383608640192, J_o = 107675.89282883004
J_b = 0.09129528671485343, J_o = 99000.16113017073
J_b = 0.0950764772699438, J_o = 92467.39752537213
J_b = 0.10124855999966934, J_o = 88583.53598659651
J_b = 0.11083591132842059, J_o = 85845.9811428563
J_b = 0.13701226579802447, J_o = 84805.06114450138
J_b = 0.13719364432612588, J_o = 81598.59592943509
J_b = 0.13760190114266677, J_o = 80809.99400629426
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.57466197 -0.89282506  0.09934732 -0.19126122 -0.76147792 -0.71335057
 -0.91737525  0.1352628  -0.42267095 -1.23232769]
W_opt:  [ 0.01598136  0.03370461  0.04135537  0.03231317  0.01484693 -0.01251236
 -0.04679961 -0.09494665 -0.14923307 -0.20095722]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.3880 s, v_trunc (Latent to Reduced) = 0.1035, dec (Reduced to Full) = 0.1786, add (DA)= 0.0001decode = 0.2844 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.6726 s, inc stats = 4.6936, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92694327 2.74689826 3.3785102  2.98706884 2.45774389]
u_DA:    [3.90556235 1.94106496 3.05699744 1.76289079 2.62839708]
ref_MAE: [0.08648887 0.58511786 0.83957541 1.13451539 0.08111018]
da_MAE:  [0.02138092 0.8058333  0.32151276 1.22417805 0.17065319]
% 18.35581365199125 da_MAE 0.006467498584553088 ref_MAE 0.007921566585262229
u_c taken from control states: [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
u_c before reduction of space:  [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
data[u_c] post encoding of state:  [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
J_b = 0.0, J_o = 481957.62667255895
J_b = 0.49999999999999994, J_o = 12497229.850857727
J_b = 0.00543689767866215, J_o = 316877.78100059065
J_b = 0.013529578524946613, J_o = 222215.3487339296
J_b = 0.01838398653752724, J_o = 191066.8117124142
J_b = 0.03231526823941355, J_o = 146634.50532196136
J_b = 0.04063317531706724, J_o = 131062.50246018733
J_b = 0.0647001219347281, J_o = 107717.91739123399
J_b = 0.09102831394057012, J_o = 99243.1642339812
J_b = 0.09488547613948502, J_o = 92667.01421608287
J_b = 0.10048779080126403, J_o = 88945.48085054563
J_b = 0.10997134816190429, J_o = 86324.03687089664
J_b = 0.13224054024839269, J_o = 84171.78373747725
J_b = 0.13552207107791836, J_o = 81981.10168311602
J_b = 0.13818944512811274, J_o = 80920.06887900604
J_b = 0.14460533027670774, J_o = 80337.5838499578
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.58902787 -0.89771575  0.09642381 -0.19572932 -0.77685869 -0.7506975
 -0.95344012  0.11099935 -0.42713489 -1.21977954]
W_opt:  [ 0.00642229  0.03278812  0.04436335  0.03565567  0.01831554 -0.00979778
 -0.04515028 -0.09685491 -0.15490005 -0.2109757 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4333 s, v_trunc (Latent to Reduced) = 0.1032, dec (Reduced to Full) = 0.1826, add (DA)= 0.0001decode = 0.2879 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7213 s, inc stats = 4.7268, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92632745 2.74568866 3.37762437 2.98554036 2.45361818]
u_DA:    [3.90556246 1.94185742 3.051431   1.77140679 2.62152149]
ref_MAE: [0.08587305 0.58390826 0.83868959 1.13298691 0.07698447]
da_MAE:  [0.02076499 0.80383124 0.32619337 1.21413358 0.16790331]
% 18.391182302637013 da_MAE 0.006468937405390716 ref_MAE 0.007926762803230448
u_c taken from control states: [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
u_c before reduction of space:  [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
data[u_c] post encoding of state:  [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
J_b = 0.0, J_o = 479337.7450120823
J_b = 0.5000000000000001, J_o = 12912914.398303911
J_b = 0.005194809786050247, J_o = 317079.88457093854
J_b = 0.012880922520584776, J_o = 221871.13801273445
J_b = 0.018233228376167098, J_o = 189068.9785087799
J_b = 0.03140229720029178, J_o = 147261.80361122437
J_b = 0.039596986387424114, J_o = 130880.87293297282
J_b = 0.061488087148709666, J_o = 108445.15009842326
J_b = 0.08461441766856165, J_o = 99451.21049084775
J_b = 0.09160405894302076, J_o = 92827.12917449251
J_b = 0.09905691781286562, J_o = 88551.8449398471
J_b = 0.1088218406350902, J_o = 85825.12322701934
J_b = 0.12679239443775164, J_o = 82883.73325772076
J_b = 0.13493047849845657, J_o = 81003.3505075869
J_b = 0.14351422832051006, J_o = 79383.08384035416
J_b = 0.15441373759189403, J_o = 89227.39638935655
J_b = 0.1445805567227418, J_o = 79215.23837728238
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.60301009 -0.90131542  0.09357838 -0.19940739 -0.79051773 -0.78311268
 -0.97935332  0.10681916 -0.43169857 -1.20096833]
W_opt:  [ 0.00218183  0.03266306  0.04759548  0.0387951   0.02006441 -0.00896345
 -0.04505164 -0.09842097 -0.1575996  -0.21372566]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8424 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1800, add (DA)= 0.0001decode = 0.2870 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1295 s, inc stats = 5.1421, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92572808 2.74479837 3.37676221 2.98428214 2.4499543 ]
u_DA:    [3.9039741  1.93236062 3.07385506 1.74473404 2.63411261]
ref_MAE: [0.08527367 0.58301797 0.83782743 1.13172869 0.07332059]
da_MAE:  [0.02175397 0.81243775 0.30290715 1.2395481  0.18415831]
% 18.396009265119417 da_MAE 0.0064723648617198625 ref_MAE 0.007931431788363915
\% improve_point: 12.65, mse_ref_points: 3.548769883269102e-05, mse_da_points: 3.099928054534546e-05, % improve_overlap: 12.65, mse_ref_overlap: 0.92439, mse_da_overlap: 0.80749
DA - - L2: 40427.22, L1: 4870.71, % Improve: 17.93%, DA_MAE: 0.01, mse_ref: 0.92, mse_DA: 0.807, time(s): 6.4631s,
u_c taken from control states: [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
u_c before reduction of space:  [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
data[u_c] post encoding of state:  [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
J_b = 0.0, J_o = 471905.02440472797
J_b = 0.5000000000000003, J_o = 13466593.487163704
J_b = 0.004853136149514402, J_o = 314823.57079421397
J_b = 0.01201417756316656, J_o = 218924.0224484203
J_b = 0.018201999705358775, J_o = 183016.42085257565
J_b = 0.030346404294345944, J_o = 144813.82633100788
J_b = 0.03871344805553391, J_o = 127015.75279036397
J_b = 0.0572029511623071, J_o = 106376.99463141338
J_b = 0.07728987440456205, J_o = 96786.43548380409
J_b = 0.0906647263937134, J_o = 89308.77806811075
J_b = 0.09883849964848082, J_o = 84871.6125527191
J_b = 0.10850344185955334, J_o = 81837.08315162841
J_b = 0.11916324910498642, J_o = 79297.37396281137
J_b = 0.1305976513335282, J_o = 77170.97228465547
J_b = 0.14528351152384195, J_o = 75181.57195169994
J_b = 0.16425759465308035, J_o = 77262.89713375807
J_b = 0.1505446259760326, J_o = 74713.04625008165
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.61676545 -0.90340406  0.0907969  -0.20224441 -0.80285135 -0.81075523
 -0.99704094  0.11354169 -0.4365506  -1.18002072]
W_opt:  [-0.00328114  0.02929602  0.04862051  0.04308577  0.02517537 -0.00461921
 -0.04131533 -0.09823934 -0.1622846  -0.22309814]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7841 s, v_trunc (Latent to Reduced) = 0.1041, dec (Reduced to Full) = 0.1873, add (DA)= 0.0001decode = 0.2936 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0779 s, inc stats = 5.0832, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92513842 2.7442818  3.37591942 2.98331164 2.44664595]
u_DA:    [3.90510829 1.93806064 3.06102666 1.7782734  2.61136256]
ref_MAE: [0.08468402 0.5825014  0.83698464 1.13075819 0.07001224]
da_MAE:  [0.02003013 0.80622115 0.31489276 1.20503824 0.16471661]
% 18.477189185173078 da_MAE 0.006469607924235128 ref_MAE 0.007935948061126557
u_c taken from control states: [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
u_c before reduction of space:  [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
data[u_c] post encoding of state:  [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
J_b = 0.0, J_o = 463380.3962931584
J_b = 0.5000000000000002, J_o = 14018455.875225095
J_b = 0.004525875232402438, J_o = 311849.7716492732
J_b = 0.011191285946692565, J_o = 215788.90711067978
J_b = 0.01825747256745921, J_o = 176075.1030322156
J_b = 0.029545299697326822, J_o = 140850.17759784719
J_b = 0.03828939237352397, J_o = 121704.00672565767
J_b = 0.054747416862998874, J_o = 102497.61492025295
J_b = 0.0731580502783896, J_o = 92136.89003112812
J_b = 0.09350115737466924, J_o = 84153.1999534332
J_b = 0.09846145996204379, J_o = 79890.7007097473
J_b = 0.10477397860997947, J_o = 76717.70435743818
J_b = 0.11353262374974091, J_o = 74519.65179038963
J_b = 0.13104862508238216, J_o = 71858.87751746044
J_b = 0.14409530187270891, J_o = 71042.30089405087
J_b = 0.1486664594847925, J_o = 69859.66581927122
J_b = 0.1458400056697075, J_o = 69554.31828951638
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.63032559 -0.90391647  0.08808863 -0.2041538  -0.81399923 -0.83359642
 -1.01008981  0.11659222 -0.44182929 -1.16617258]
W_opt:  [-0.00065531  0.02633886  0.04143451  0.0386202   0.02476596 -0.00324278
 -0.03949924 -0.0964846  -0.16087232 -0.22147064]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7358 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.1750, add (DA)= 0.0001decode = 0.2805 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0165 s, inc stats = 5.0219, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92455714 2.74415506 3.37509882 2.98265846 2.44365566]
u_DA:    [3.90300038 1.93884992 3.06543971 1.75632734 2.6202267 ]
ref_MAE: [0.08410274 0.58237467 0.83616403 1.130105   0.06702195]
da_MAE:  [0.02155676 0.80530514 0.30965911 1.22633112 0.17657104]
% 18.34147098109899 da_MAE 0.006484143497359049 ref_MAE 0.007940558782118403
u_c taken from control states: [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
u_c before reduction of space:  [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
data[u_c] post encoding of state:  [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
J_b = 0.0, J_o = 453612.85955077613
J_b = 0.5, J_o = 14561953.410676964
J_b = 0.00422546362129279, J_o = 307524.86841979966
J_b = 0.010435975508748623, J_o = 211747.85592305282
J_b = 0.018382854108517515, J_o = 167805.969490039
J_b = 0.02891327670505572, J_o = 135262.67830304272
J_b = 0.037975272811347875, J_o = 115280.1421850639
J_b = 0.0532230437912327, J_o = 97150.43917102377
J_b = 0.07091042148024405, J_o = 86230.75695070511
J_b = 0.09581128560631928, J_o = 78713.71035887673
J_b = 0.0971044455502935, J_o = 74164.33226041465
J_b = 0.09977582644669682, J_o = 71493.32094419962
J_b = 0.10708317372823066, J_o = 69309.21146253406
J_b = 0.12775369329125025, J_o = 65853.09681122247
J_b = 0.151653272711645, J_o = 67455.5122149457
J_b = 0.13601327657132686, J_o = 64933.96156037776
J_b = 0.144628695051039, J_o = 64167.76743056573
J_b = 0.14470931223320618, J_o = 63870.15414565679
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.64380594 -0.9028612   0.08546107 -0.20511391 -0.82451332 -0.85313341
 -1.02246477  0.09722723 -0.44780387 -1.16989894]
W_opt:  [ 0.00210268  0.0252844   0.0367567   0.03363774  0.02350318 -0.00115035
 -0.03686983 -0.09395365 -0.15963636 -0.22142389]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0337 s, v_trunc (Latent to Reduced) = 0.1040, dec (Reduced to Full) = 0.1844, add (DA)= 0.0001decode = 0.2906 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3246 s, inc stats = 5.3379, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92397928 2.74441606 3.37430267 2.98233001 2.44083538]
u_DA:    [3.90273442 1.93972057 3.05904257 1.75417177 2.62106535]
ref_MAE: [0.08352488 0.58263566 0.83536788 1.12977656 0.06420167]
da_MAE:  [0.02124486 0.80469549 0.31526009 1.22815825 0.18022997]
% 18.185840635608162 da_MAE 0.00650063154660805 ref_MAE 0.00794560696719367
u_c taken from control states: [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
u_c before reduction of space:  [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
data[u_c] post encoding of state:  [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
J_b = 0.0, J_o = 446332.869446348
J_b = 0.49999999999999967, J_o = 15026261.89186882
J_b = 0.00398175945262695, J_o = 305000.7802042603
J_b = 0.009822140424210073, J_o = 209935.80558375004
J_b = 0.01851381050804365, J_o = 162152.66031166262
J_b = 0.028469875462739765, J_o = 131734.5991677958
J_b = 0.0377042509500528, J_o = 111474.76271532789
J_b = 0.052314855800844634, J_o = 93982.99120975699
J_b = 0.06999583018631096, J_o = 82667.41971528325
J_b = 0.09743784977670306, J_o = 75819.49652520486
J_b = 0.09648741278229103, J_o = 70820.4931236832
J_b = 0.09752011481915612, J_o = 68483.83744886969
J_b = 0.10410943749800915, J_o = 66285.87858620203
J_b = 0.12323121504665276, J_o = 62686.40941563716
J_b = 0.14753703493293677, J_o = 66574.25287330968
J_b = 0.12957629395447987, J_o = 61813.64012283825
J_b = 0.1450831486934294, J_o = 60844.06223738966
J_b = 0.14692537948957954, J_o = 60311.8959508897
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.65710882 -0.90033253  0.08293159 -0.2050574  -0.83449021 -0.86968965
 -1.03615299  0.05360313 -0.45451455 -1.19229896]
W_opt:  [ 0.00177831  0.02139299  0.03392181  0.03104548  0.02402861  0.00287959
 -0.03226908 -0.09029491 -0.15849721 -0.22345919]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0881 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1777, add (DA)= 0.0001decode = 0.2839 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3722 s, inc stats = 5.3766, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92340902 2.74504147 3.37353624 2.98234935 2.43815919]
u_DA:    [3.90163864 1.9385516  3.0581802  1.74021121 2.6261075 ]
ref_MAE: [0.08295462 0.58326107 0.83460145 1.1297959  0.06152548]
da_MAE:  [0.02177038 0.80648986 0.31535604 1.24213814 0.18794831]
% 18.076038218239876 da_MAE 0.006513705230125567 ref_MAE 0.00795091581078273
u_c taken from control states: [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
u_c before reduction of space:  [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
data[u_c] post encoding of state:  [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
J_b = 0.0, J_o = 440903.2462928241
J_b = 0.5000000000000001, J_o = 15259604.395364836
J_b = 0.0038308427675299117, J_o = 303273.20586904476
J_b = 0.00945722567952612, J_o = 209141.15069747512
J_b = 0.018584474568754887, J_o = 159197.00839553156
J_b = 0.028171461899704396, J_o = 130248.40405101197
J_b = 0.03736867784616937, J_o = 110219.39745080977
J_b = 0.05169278352590493, J_o = 93030.32782815816
J_b = 0.06955753260353176, J_o = 81462.76945054754
J_b = 0.09870998185692684, J_o = 75168.58598925584
J_b = 0.09633176153874484, J_o = 69803.55539792674
J_b = 0.09654542780638951, J_o = 67660.86016173223
J_b = 0.10293404069093735, J_o = 65397.83878235202
J_b = 0.12110302900175378, J_o = 61823.002808084704
J_b = 0.1465434438311977, J_o = 64290.11358741892
J_b = 0.12895313841347142, J_o = 60811.8472276369
J_b = 0.14713045745408704, J_o = 59902.378374164065
J_b = 0.14764718586732045, J_o = 59182.07966981954
J_b = 0.14690047795815003, J_o = 58908.371856510304
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.66986096 -0.89658358  0.08051647 -0.20384863 -0.84326127 -0.88206488
 -1.05073644 -0.00613446 -0.46170348 -1.22758168]
W_opt:  [ 0.00033539  0.01653897  0.03089047  0.02947574  0.02402635  0.00479036
 -0.02908106 -0.08665417 -0.15588066 -0.2232116 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3661 s, v_trunc (Latent to Reduced) = 0.1044, dec (Reduced to Full) = 0.2166, add (DA)= 0.0001decode = 0.3239 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6902 s, inc stats = 5.7037, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92286238 2.74596868 3.37280446 2.98276285 2.43580646]
u_DA:    [3.90062469 1.93732273 3.05380714 1.72641996 2.63201092]
ref_MAE: [0.08240798 0.58418828 0.83386967 1.1302094  0.05917275]
da_MAE:  [0.02223768 0.80864595 0.31899731 1.25634289 0.19620447]
% 17.96851150255186 da_MAE 0.006526713978888224 ref_MAE 0.00795635200389087
u_c taken from control states: [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
u_c before reduction of space:  [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
data[u_c] post encoding of state:  [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
J_b = 0.0, J_o = 434946.3900004159
J_b = 0.5000000000000001, J_o = 15363970.078708116
J_b = 0.00372048665398783, J_o = 300699.3234878844
J_b = 0.009207290095399246, J_o = 207564.0534472633
J_b = 0.018637921194182398, J_o = 156308.44714387073
J_b = 0.02793490477780658, J_o = 128590.07709059524
J_b = 0.037012370658560716, J_o = 108982.81154769122
J_b = 0.05114543786536453, J_o = 92002.23121686942
J_b = 0.06908783710298556, J_o = 80231.60932246677
J_b = 0.10008647975212223, J_o = 74689.52544051823
J_b = 0.09636377223715079, J_o = 68795.79933738385
J_b = 0.09587485180316309, J_o = 66847.80188909115
J_b = 0.10220608127845071, J_o = 64460.97448248944
J_b = 0.11930203284385428, J_o = 60943.8416723524
J_b = 0.14794430230526026, J_o = 60740.24197221143
J_b = 0.13300443117448904, J_o = 59560.04587091581
J_b = 0.15543406768729282, J_o = 59149.54951000035
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.68163167 -0.89208329  0.07821795 -0.20138083 -0.84998559 -0.88848303
 -1.06356706 -0.06793405 -0.46896186 -1.25695748]
W_opt:  [ 0.00174245  0.01674946  0.03169137  0.03113835  0.02614752  0.00679247
 -0.02741242 -0.08588914 -0.15751889 -0.22832699]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7238 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.1978, add (DA)= 0.0001decode = 0.3033 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.0272 s, inc stats = 5.0326, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9223578  2.74708172 3.37210801 2.98360705 2.43400274]
u_DA:    [3.90216328 1.94140318 3.04273828 1.75204963 2.62020241]
ref_MAE: [0.0819034  0.58530132 0.83317322 1.1310536  0.05736903]
da_MAE:  [0.02019452 0.80567854 0.32936973 1.23155742 0.18619968]
% 18.026365870696658 da_MAE 0.006526564618934886 ref_MAE 0.007961785137694435
u_c taken from control states: [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
u_c before reduction of space:  [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
data[u_c] post encoding of state:  [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
J_b = 0.0, J_o = 428009.20262601523
J_b = 0.5000000000000003, J_o = 15395435.636207145
J_b = 0.0036315524957652233, J_o = 296962.6165666392
J_b = 0.009021051859626412, J_o = 204732.39844863839
J_b = 0.018718868149601026, J_o = 152530.26206576242
J_b = 0.027735982006829685, J_o = 126023.76519444965
J_b = 0.03666575856154905, J_o = 106914.6595336157
J_b = 0.050634790146758764, J_o = 90111.15832120948
J_b = 0.06852216343352509, J_o = 78155.34849204685
J_b = 0.10139024805407382, J_o = 73697.00511658014
J_b = 0.09654244968753421, J_o = 67009.96066053546
J_b = 0.09543449244301826, J_o = 65259.00956566903
J_b = 0.10193907285545105, J_o = 62663.83699125115
J_b = 0.11810278919640722, J_o = 59345.059439063116
J_b = 0.15576177014379866, J_o = 60806.09825206152
J_b = 0.13181248155491104, J_o = 58115.38765522056
J_b = 0.14630355409350948, J_o = 57120.50241857807
J_b = 0.15394522175434644, J_o = 56716.05922666964
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.69238483 -0.88733415  0.07602816 -0.19781574 -0.85495272 -0.8890253
 -1.07442555 -0.1300578  -0.47629803 -1.28160474]
W_opt:  [-1.11170837e-04  1.36927367e-02  2.84496316e-02  2.82177327e-02
  2.35985137e-02  4.90283925e-03 -2.85974797e-02 -8.58311867e-02
 -1.56402587e-01 -2.26479006e-01]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.0737 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1962, add (DA)= 0.0001decode = 0.3022 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.3760 s, inc stats = 5.3902, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92189685 2.7482563  3.3714445  2.98482663 2.43267036]
u_DA:    [3.89969422 1.93159299 3.05021299 1.70124115 2.64975882]
ref_MAE: [0.08144245 0.5864759  0.83250972 1.13227318 0.05603665]
da_MAE:  [0.02220262 0.81666332 0.32123151 1.28358548 0.21708846]
% 17.818857878449485 da_MAE 0.006547557247550435 ref_MAE 0.00796722590915837
u_c taken from control states: [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
u_c before reduction of space:  [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
data[u_c] post encoding of state:  [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
J_b = 0.0, J_o = 420807.35831177165
J_b = 0.5, J_o = 15346491.118973615
J_b = 0.0035714425762075307, J_o = 292508.37861536944
J_b = 0.008914311258526937, J_o = 201016.0753035903
J_b = 0.018803157632534553, J_o = 148430.16622407836
J_b = 0.027561499450449115, J_o = 123030.80665957772
J_b = 0.03634239740427367, J_o = 104405.14173536064
J_b = 0.05021055103864955, J_o = 87703.9180972337
J_b = 0.0679791852480366, J_o = 75568.32383239389
J_b = 0.1019991594071377, J_o = 72077.62175600672
J_b = 0.09734928344782155, J_o = 64639.25394108283
J_b = 0.0956888075169226, J_o = 63025.738053497305
J_b = 0.10283426750374544, J_o = 60168.605723214925
J_b = 0.11967473317712231, J_o = 57718.428147875224
J_b = 0.13706899894457483, J_o = 55590.9104049958
J_b = 0.14488938372306182, J_o = 55229.520302019
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.70240287 -0.88215654  0.07392869 -0.19339404 -0.85882685 -0.88498295
 -1.08220967 -0.18683882 -0.48377065 -1.30224817]
W_opt:  [ 0.00423571  0.01457995  0.02649016  0.02548073  0.01971707  0.00080434
 -0.03221733 -0.08671675 -0.15291166 -0.21769722]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4787 s, v_trunc (Latent to Reduced) = 0.1042, dec (Reduced to Full) = 0.1908, add (DA)= 0.0001decode = 0.2971 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.7759 s, inc stats = 4.7885, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.9214674  2.74953686 3.37080836 2.98633923 2.43163117]
u_DA:    [3.9015642  1.94125951 3.04193265 1.73654358 2.62602644]
ref_MAE: [0.081013   0.58775646 0.83187358 1.13378578 0.05499746]
da_MAE:  [0.0199032  0.80827735 0.32887571 1.24979565 0.19439527]
% 17.89572498868798 da_MAE 0.0065458545178143914 ref_MAE 0.007972611069170915
u_c taken from control states: [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
u_c before reduction of space:  [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
data[u_c] post encoding of state:  [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
J_b = 0.0, J_o = 413955.5730535509
J_b = 0.4999999999999998, J_o = 15224362.482446756
J_b = 0.003545707134489901, J_o = 287657.5949687919
J_b = 0.008896438871902874, J_o = 196649.2001508043
J_b = 0.01886884088886453, J_o = 144334.28113657772
J_b = 0.02740784772617955, J_o = 119833.21730250985
J_b = 0.03606928754009779, J_o = 101581.77159711628
J_b = 0.04992496470611233, J_o = 84884.77762939707
J_b = 0.0675535440517559, J_o = 72646.78732056373
J_b = 0.1007643691670795, J_o = 68569.73813394022
J_b = 0.0994169474926114, J_o = 61649.48099921243
J_b = 0.09713949708579966, J_o = 60022.52028465204
J_b = 0.10417685687666929, J_o = 57175.186135404365
J_b = 0.1265604849388886, J_o = 55667.50826809801
J_b = 0.13057173832172872, J_o = 53492.72787157882
J_b = 0.13802373770531978, J_o = 53262.80780957487
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.71172978 -0.87653083  0.07190812 -0.18834675 -0.86189191 -0.87641184
 -1.08633913 -0.22795398 -0.49124274 -1.3194783 ]
W_opt:  [ 0.00610429  0.01376562  0.02344433  0.02243953  0.01630963 -0.00237719
 -0.03460365 -0.08690715 -0.15020654 -0.21192399]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4627 s, v_trunc (Latent to Reduced) = 0.1037, dec (Reduced to Full) = 0.1705, add (DA)= 0.0001decode = 0.2763 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7392 s, inc stats = 4.7516, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92106759 2.75092824 3.37019613 2.98806585 2.430809  ]
u_DA:    [3.9008529  1.94031676 3.04135407 1.71789846 2.63437253]
ref_MAE: [0.08061318 0.58914785 0.83126135 1.1355124  0.05417529]
da_MAE:  [0.02021468 0.81061149 0.32884206 1.27016739 0.20356353]
% 17.826021769692836 da_MAE 0.00655569303076544 ref_MAE 0.00797782116911992
u_c taken from control states: [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
u_c before reduction of space:  [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
data[u_c] post encoding of state:  [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
J_b = 0.0, J_o = 408447.9389021333
J_b = 0.5000000000000001, J_o = 15099199.703405814
J_b = 0.003545282946381527, J_o = 283186.8431061258
J_b = 0.008931919990320001, J_o = 192340.19913151133
J_b = 0.01891107646010686, J_o = 140595.0146677065
J_b = 0.02726943488352317, J_o = 116759.69124975111
J_b = 0.03584667122607855, J_o = 98755.02683009315
J_b = 0.04966139575589037, J_o = 82103.4483406174
J_b = 0.06703598780104934, J_o = 70043.23224994999
J_b = 0.09860676834758655, J_o = 64688.700203114175
J_b = 0.09992148935425021, J_o = 58759.255024488404
J_b = 0.09861980680566375, J_o = 57002.93403500841
J_b = 0.10795925802110871, J_o = 53890.230474707365
J_b = 0.1285489366362722, J_o = 52846.67409867421
J_b = 0.1345418385605395, J_o = 50714.07863611153
J_b = 0.13911658405298544, J_o = 50102.83601864136
J_b = 0.14745679382947366, J_o = 50343.37214332206
J_b = 0.14257785527526343, J_o = 49801.398702524275
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.7204439  -0.87044214  0.0699481  -0.18307547 -0.86511547 -0.8643732
 -1.08618706 -0.25233996 -0.49871285 -1.33384759]
W_opt:  [ 0.00443754  0.01154465  0.02103557  0.02166541  0.01687151 -0.000623
 -0.03228652 -0.085655   -0.15150152 -0.21727681]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3425 s, v_trunc (Latent to Reduced) = 0.1110, dec (Reduced to Full) = 0.1925, add (DA)= 0.0002decode = 0.3057 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6484 s, inc stats = 5.6613, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92069404 2.75243413 3.36960224 2.98986908 2.42994432]
u_DA:    [3.89752927 1.92545251 3.04717595 1.66225037 2.65807405]
ref_MAE: [0.08023964 0.59065374 0.83066746 1.13731563 0.05331061]
da_MAE:  [0.02316476 0.82698163 0.32242629 1.32761871 0.22812973]
% 17.716513682943827 da_MAE 0.006568767698149475 ref_MAE 0.007983093561250655
\% improve_point: 12.56, mse_ref_points: 3.580367588735654e-05, mse_da_points: 3.130779125303347e-05, % improve_overlap: 12.56, mse_ref_overlap: 0.93263, mse_da_overlap: 0.81554
DA - - L2: 36252.97, L1: 4713.61, % Improve: 17.94%, DA_MAE: 0.01, mse_ref: 0.93, mse_DA: 0.815, time(s): 6.3264s,
u_c taken from control states: [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
u_c before reduction of space:  [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
data[u_c] post encoding of state:  [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
J_b = 0.0, J_o = 405566.03422581253
J_b = 0.49999999999999994, J_o = 14983748.567200352
J_b = 0.003572902475444632, J_o = 280197.6883097909
J_b = 0.009025496950479666, J_o = 189068.8637239124
J_b = 0.01895606562542793, J_o = 138016.76788190307
J_b = 0.027202614377372807, J_o = 114530.87962274191
J_b = 0.035757193530179615, J_o = 96593.6344595903
J_b = 0.04954014593966714, J_o = 79990.4150132053
J_b = 0.06664926577787442, J_o = 68429.3005446627
J_b = 0.09676927017077964, J_o = 63219.913323739645
J_b = 0.09637153770497593, J_o = 57754.0962142599
J_b = 0.09504366594461304, J_o = 55971.322289929216
J_b = 0.10219534143848134, J_o = 53379.41958837387
J_b = 0.1255765444012884, J_o = 51900.11320697058
J_b = 0.12876158431597284, J_o = 49755.08671984896
J_b = 0.13450228507456555, J_o = 49446.870248923
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.72862573 -0.86405878  0.06802482 -0.1779548  -0.86939186 -0.84957817
 -1.08057387 -0.25208324 -0.50616262 -1.34576369]
W_opt:  [ 0.00990468  0.01410638  0.01925078  0.01885827  0.01311059 -0.00428934
 -0.03506303 -0.08594004 -0.14810375 -0.20954734]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5795 s, v_trunc (Latent to Reduced) = 0.1039, dec (Reduced to Full) = 0.2074, add (DA)= 0.0001decode = 0.3140 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8937 s, inc stats = 4.9059, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92034331 2.75401291 3.36901949 2.9916208  2.42879723]
u_DA:    [3.90013815 1.93936096 3.04487259 1.70435015 2.64021167]
ref_MAE: [0.07988891 0.59223251 0.83008471 1.13906735 0.05216352]
da_MAE:  [0.02020515 0.81465195 0.3241469  1.28727064 0.21141444]
% 17.859613794146398 da_MAE 0.006561796943689741 ref_MAE 0.007988514842437063
u_c taken from control states: [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
u_c before reduction of space:  [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
data[u_c] post encoding of state:  [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
J_b = 0.0, J_o = 406561.039048323
J_b = 0.49999999999999983, J_o = 14832906.527880572
J_b = 0.003650530057032184, J_o = 279523.68858394533
J_b = 0.009234502803324229, J_o = 187555.91907016543
J_b = 0.018995497618817307, J_o = 137638.68065629012
J_b = 0.027265340431491532, J_o = 113978.54379615282
J_b = 0.035819727100855625, J_o = 95976.38408280595
J_b = 0.04960190909675466, J_o = 79386.2557141472
J_b = 0.066401154159544, J_o = 68463.40074878318
J_b = 0.0931805799131305, J_o = 62571.53658221658
J_b = 0.09328961969837571, J_o = 57972.45908848409
J_b = 0.09311718559208589, J_o = 56035.191981447024
J_b = 0.10043252643326617, J_o = 53539.19511715771
J_b = 0.12162111386212222, J_o = 51378.77350142117
J_b = 0.13200402183707585, J_o = 49367.354387267
J_b = 0.13831269430881776, J_o = 49121.31958966241
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.73650667 -0.85780095  0.06611288 -0.17336518 -0.8750587  -0.83325326
 -1.06972481 -0.22888246 -0.5136124  -1.35563449]
W_opt:  [ 0.0110407   0.01482194  0.01876875  0.01863142  0.01326352 -0.00342886
 -0.033807   -0.08564207 -0.14962814 -0.2135938 ]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4523 s, v_trunc (Latent to Reduced) = 0.1036, dec (Reduced to Full) = 0.1941, add (DA)= 0.0001decode = 0.2999 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7523 s, inc stats = 4.7652, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.92000547 2.75556063 3.36844018 2.99319085 2.42727717]
u_DA:    [3.90008127 1.93730371 3.04507465 1.69884402 2.64433117]
ref_MAE: [0.07955107 0.59378023 0.82950539 1.1406374  0.05064345]
da_MAE:  [0.0199242  0.81825691 0.32336552 1.29434682 0.217054  ]
% 17.860252771746566 da_MAE 0.006567023959837647 ref_MAE 0.007994940551239975
u_c taken from control states: [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
u_c before reduction of space:  [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
data[u_c] post encoding of state:  [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
J_b = 0.0, J_o = 410741.346637494
J_b = 0.4999999999999998, J_o = 14694579.914716193
J_b = 0.003762642792238562, J_o = 280687.4371521155
J_b = 0.009514638323942887, J_o = 187397.9848110188
J_b = 0.019059189436844513, J_o = 138598.47673064042
J_b = 0.027485583789337263, J_o = 114274.21087202936
J_b = 0.036087978499065615, J_o = 96053.67419113043
J_b = 0.04993347331506321, J_o = 79395.23761631103
J_b = 0.06643098505198759, J_o = 68962.77965679762
J_b = 0.09000115475663466, J_o = 62485.49852176242
J_b = 0.09170049234131036, J_o = 58404.49703894176
J_b = 0.09302549975970603, J_o = 56233.46835908651
J_b = 0.10039336686615283, J_o = 53906.589227534816
J_b = 0.12129476541235729, J_o = 51106.01771299927
J_b = 0.13613469759256563, J_o = 49897.89156504964
J_b = 0.13808404514751996, J_o = 49051.394167693186
J_b = 0.13627938924197858, J_o = 48813.13837671305
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.74435184 -0.8515662   0.06417269 -0.1697249  -0.88293258 -0.81743711
 -1.05417697 -0.18670252 -0.52127051 -1.36379192]
W_opt:  [ 0.01047314  0.01444412  0.01739497  0.01687847  0.01157262 -0.00447847
 -0.03390768 -0.08499116 -0.14867975 -0.21277651]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.7205 s, v_trunc (Latent to Reduced) = 0.1034, dec (Reduced to Full) = 0.1945, add (DA)= 0.0001decode = 0.3001 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.0208 s, inc stats = 5.0333, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91966918 2.75710264 3.3678523  2.99443614 2.42516509]
u_DA:    [3.89892232 1.93089526 3.04698029 1.67626438 2.65705042]
ref_MAE: [0.07921477 0.59532225 0.82891751 1.14188269 0.04853138]
da_MAE:  [0.02074685 0.82620739 0.32087201 1.31817176 0.23188533]
% 17.8141816522209 da_MAE 0.006575734938976115 ref_MAE 0.008001057933316558
u_c taken from control states: [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
u_c before reduction of space:  [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
data[u_c] post encoding of state:  [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
J_b = 0.0, J_o = 417399.40598875016
J_b = 0.49999999999999983, J_o = 14544576.790376794
J_b = 0.003912765320232501, J_o = 283082.92183887266
J_b = 0.00988079231823464, J_o = 187990.11303390673
J_b = 0.01918407977284658, J_o = 140249.26302518975
J_b = 0.027916568970350008, J_o = 114757.99698079444
J_b = 0.03660491605077615, J_o = 96217.2155897579
J_b = 0.050578893483086675, J_o = 79394.485225066
J_b = 0.06676377360137363, J_o = 69195.6670720181
J_b = 0.08879448233792087, J_o = 62499.17909388962
J_b = 0.09158491101981536, J_o = 58530.56327501401
J_b = 0.0937190448062388, J_o = 56234.81791431284
J_b = 0.10101873137535408, J_o = 54015.7916251352
J_b = 0.12149036638049464, J_o = 51278.870315007916
J_b = 0.13434510110273115, J_o = 50303.11693158155
J_b = 0.1349769350519747, J_o = 49366.15347818021
J_b = 0.13437817086171788, J_o = 49148.64991424482
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.75235922 -0.84523726  0.06216967 -0.1673728  -0.89352652 -0.80399796
 -1.03516247 -0.12812284 -0.52934331 -1.3587782 ]
W_opt:  [ 0.01216795  0.01623723  0.01824295  0.01648176  0.01008209 -0.00647878
 -0.03576605 -0.08590349 -0.14828721 -0.21089674]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8730 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1736, add (DA)= 0.0001decode = 0.2803 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.1534 s, inc stats = 5.1644, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91932592 2.75866795 3.36724538 2.99524076 2.42232338]
u_DA:    [3.89945924 1.9317226  3.04748095 1.68015585 2.65951734]
ref_MAE: [0.07887152 0.59688756 0.8283106  1.14268731 0.04568967]
da_MAE:  [0.01986668 0.82694536 0.31976443 1.31508491 0.23719396]
% 17.783943079646114 da_MAE 0.006582817368288373 ref_MAE 0.008006729603519447
u_c taken from control states: [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
u_c before reduction of space:  [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
data[u_c] post encoding of state:  [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
J_b = 0.0, J_o = 425960.0447532175
J_b = 0.5000000000000001, J_o = 14356947.051267695
J_b = 0.004101707241869811, J_o = 286397.2105082906
J_b = 0.010342654505241381, J_o = 189127.4906842876
J_b = 0.019386416606398015, J_o = 142432.81787842643
J_b = 0.028574489479265542, J_o = 115312.51256837453
J_b = 0.03734705784743427, J_o = 96464.49097045793
J_b = 0.05150912403149594, J_o = 79383.7379396081
J_b = 0.06743329802033246, J_o = 69167.46194214051
J_b = 0.08973386477646575, J_o = 62375.97061997535
J_b = 0.09312720030927003, J_o = 58297.051878777915
J_b = 0.09520620653823458, J_o = 56003.74382748866
J_b = 0.1021815216215831, J_o = 53863.21235714873
J_b = 0.12119879607619961, J_o = 51265.33517480787
J_b = 0.13311602550977894, J_o = 50381.515515043466
J_b = 0.13407732044574264, J_o = 49468.22232099211
J_b = 0.1335809763286158, J_o = 49250.411914124335
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.76064729 -0.83888054  0.06009439 -0.16638873 -0.90661839 -0.79460875
 -1.01443594 -0.06421828 -0.53790484 -1.34108706]
W_opt:  [ 0.01431859  0.01809181  0.01974149  0.01673628  0.00906888 -0.00816432
 -0.03780164 -0.08742145 -0.14864319 -0.20962953]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1402 s, v_trunc (Latent to Reduced) = 0.1124, dec (Reduced to Full) = 0.1907, add (DA)= 0.0002decode = 0.3054 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.4458 s, inc stats = 5.4565, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91897064 2.76024014 3.36661658 2.9955774  2.41881164]
u_DA:    [3.89992922 1.93290742 3.04629444 1.68244314 2.66021782]
ref_MAE: [0.07851624 0.59845974 0.82768179 1.14302395 0.04217793]
da_MAE:  [0.01904141 0.82733272 0.32032214 1.31313427 0.24140618]
% 17.74199745615175 da_MAE 0.0065904680577501115 ref_MAE 0.00801194759651137
u_c taken from control states: [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
u_c before reduction of space:  [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
data[u_c] post encoding of state:  [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
J_b = 0.0, J_o = 436404.4762274171
J_b = 0.5000000000000001, J_o = 14202172.668837618
J_b = 0.004295104325359566, J_o = 291246.11223606835
J_b = 0.010808899491467969, J_o = 191605.40728284276
J_b = 0.01967357595687619, J_o = 145405.99433911205
J_b = 0.02941804632122831, J_o = 116368.73028668293
J_b = 0.03832067170450348, J_o = 97164.17411913021
J_b = 0.05271860906842011, J_o = 79766.42861277735
J_b = 0.06856103467140469, J_o = 69355.72280893404
J_b = 0.09224765885350601, J_o = 62394.255179808155
J_b = 0.09613217140341318, J_o = 58047.02917415386
J_b = 0.09799518997333581, J_o = 55766.265545311144
J_b = 0.10467224440946714, J_o = 53704.21833552771
J_b = 0.12323016911682896, J_o = 51486.75336192812
J_b = 0.1316831222581057, J_o = 50247.36136891345
J_b = 0.1346243032992392, J_o = 49616.41698890423
J_b = 0.13420485053803552, J_o = 49366.63253418871
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.76926854 -0.83260659  0.05795435 -0.16661507 -0.92160443 -0.79045492
 -0.99464192 -0.01279976 -0.54700125 -1.32205488]
W_opt:  [ 0.01734774  0.01934181  0.02080547  0.01703845  0.00859299 -0.00925295
 -0.03952872 -0.08916071 -0.1496061  -0.20917114]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.8035 s, v_trunc (Latent to Reduced) = 0.1046, dec (Reduced to Full) = 0.1955, add (DA)= 0.0001decode = 0.3022 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.1059 s, inc stats = 5.1189, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91860107 2.76179185 3.36596814 2.99549997 2.41479181]
u_DA:    [3.90025247 1.93508378 3.04327712 1.67798287 2.66090759]
ref_MAE: [0.07814667 0.60001145 0.82703336 1.14294652 0.0381581 ]
da_MAE:  [0.0183486  0.82670807 0.32269102 1.3175171  0.24611577]
% 17.647314181178093 da_MAE 0.0066016385871873265 ref_MAE 0.008016300284013938
u_c taken from control states: [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
u_c before reduction of space:  [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
data[u_c] post encoding of state:  [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
J_b = 0.0, J_o = 447281.6241116872
J_b = 0.5, J_o = 14069344.181266854
J_b = 0.004471871753569134, J_o = 297030.4679135499
J_b = 0.011232223293003307, J_o = 195314.70808128454
J_b = 0.019949474243454876, J_o = 149394.49247339234
J_b = 0.0302860464553457, J_o = 118353.8565965036
J_b = 0.03934274395878997, J_o = 98787.91106028075
J_b = 0.0540636942904588, J_o = 80994.28237775552
J_b = 0.07007577820834862, J_o = 70305.45259733521
J_b = 0.09544583860858777, J_o = 63031.917987001274
J_b = 0.09980181565624288, J_o = 58303.02005659424
J_b = 0.10201925083168409, J_o = 56002.71249554638
J_b = 0.10881559382450337, J_o = 54033.065208601976
J_b = 0.12892609587996498, J_o = 52762.127113962575
J_b = 0.13037117145484775, J_o = 50976.791334321286
J_b = 0.13281946954404314, J_o = 50683.1392853305
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.77819942 -0.8267984   0.05577488 -0.16766982 -0.93742743 -0.79129803
 -0.97739798  0.01769406 -0.55652192 -1.30956356]
W_opt:  [ 0.02356476  0.0219608   0.02104632  0.01608823  0.00679962 -0.01189124
 -0.04273748 -0.0912096  -0.1491848  -0.20536989]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.4874 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1730, add (DA)= 0.0001decode = 0.2789 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.7664 s, inc stats = 4.7790, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91821823 2.76322836 3.36530777 2.99513916 2.41054747]
u_DA:    [3.90140558 1.94023983 3.04154443 1.68859296 2.65327582]
ref_MAE: [0.07776383 0.60144797 0.82637298 1.14258571 0.03391376]
da_MAE:  [0.01681265 0.82298853 0.32376334 1.3065462  0.24272834]
% 17.633664131000884 da_MAE 0.006605089984070654 ref_MAE 0.008019162093814428
u_c taken from control states: [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
u_c before reduction of space:  [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
data[u_c] post encoding of state:  [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
J_b = 0.0, J_o = 457075.7658654966
J_b = 0.4999999999999998, J_o = 13984307.884159593
J_b = 0.004612661640908839, J_o = 302610.3014480521
J_b = 0.011557779286490537, J_o = 199403.75243369967
J_b = 0.02012112737297561, J_o = 153755.58656825268
J_b = 0.030983931183263758, J_o = 120896.44738410892
J_b = 0.040165992448852654, J_o = 101039.73129842844
J_b = 0.055213425943877056, J_o = 82864.2501269109
J_b = 0.0715556374935486, J_o = 71899.4942210591
J_b = 0.09844350107457261, J_o = 64372.418692871615
J_b = 0.1029419463759696, J_o = 59282.77869895967
J_b = 0.10534027922671499, J_o = 57007.18695312641
J_b = 0.11249703303545736, J_o = 54873.02445849934
J_b = 0.1307296511763491, J_o = 52426.06743002767
J_b = 0.1486165402559853, J_o = 51958.863973393425
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.78725894 -0.82164083  0.05359896 -0.16899452 -0.9525849  -0.79513204
 -0.96312237  0.02786934 -0.56618508 -1.30745675]
W_opt:  [ 0.02443386  0.02218838  0.02196749  0.01771468  0.01054003 -0.00663958
 -0.03814032 -0.09030275 -0.15438317 -0.21858974]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.2331 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1957, add (DA)= 0.0001decode = 0.3030 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 4.5363 s, inc stats = 4.5485, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91782988 2.76450396 3.36464846 2.99468599 2.40648166]
u_DA:    [3.90363271 1.94420482 3.03462099 1.68811991 2.64308015]
ref_MAE: [0.07737547 0.60272357 0.82571368 1.14213254 0.02984795]
da_MAE:  [0.01419717 0.82029914 0.33002748 1.30656608 0.23659849]
% 17.628919633908037 da_MAE 0.006606373341896419 ref_MAE 0.008020258217489558
u_c taken from control states: [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
u_c before reduction of space:  [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
data[u_c] post encoding of state:  [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
J_b = 0.0, J_o = 464867.1660373667
J_b = 0.5000000000000002, J_o = 13915532.935933772
J_b = 0.004732455037677314, J_o = 306802.2491598876
J_b = 0.011824663604221599, J_o = 202656.3908206168
J_b = 0.020174909610017305, J_o = 157566.52418172534
J_b = 0.03150146038101473, J_o = 123043.63507613445
J_b = 0.040743039010998315, J_o = 103042.87323025597
J_b = 0.05606971745627687, J_o = 84565.88093783661
J_b = 0.07271375376319864, J_o = 73465.01538203421
J_b = 0.10039929973515975, J_o = 65942.23890638768
J_b = 0.10473569223107146, J_o = 60806.27097585112
J_b = 0.10606870619106078, J_o = 58593.70383235735
J_b = 0.11228814068110639, J_o = 56638.02986757706
J_b = 0.13122323834660599, J_o = 55357.52702283039
J_b = 0.13362230726087018, J_o = 53560.20751517845
J_b = 0.13693300790869403, J_o = 53247.800946328236
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.7962345  -0.81718919  0.05146337 -0.17004293 -0.96600741 -0.79974121
 -0.95211636  0.01790349 -0.57586045 -1.31784295]
W_opt:  [ 0.02939175  0.02449679  0.02091679  0.01396861  0.00488575 -0.01277046
 -0.0433356  -0.09120138 -0.14874856 -0.20548153]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.5420 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1988, add (DA)= 0.0001decode = 0.3059 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 4.8481 s, inc stats = 4.8537, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91744512 2.76560497 3.36400138 2.99432735 2.40288123]
u_DA:    [3.90145493 1.94733708 3.03009059 1.68241096 2.65344494]
ref_MAE: [0.07699072 0.60382457 0.8250666  1.1417739  0.02624752]
da_MAE:  [0.01599018 0.81826789 0.33391079 1.31191638 0.25056371]
% 17.543032724695045 da_MAE 0.006612609425953647 ref_MAE 0.008019467177195174
u_c taken from control states: [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
u_c before reduction of space:  [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
data[u_c] post encoding of state:  [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
J_b = 0.0, J_o = 469506.4676752015
J_b = 0.5000000000000001, J_o = 13850263.401349843
J_b = 0.004841041023274816, J_o = 308210.6363228156
J_b = 0.012054801664895596, J_o = 203662.99121107018
J_b = 0.020105014671689597, J_o = 159526.1947287075
J_b = 0.031857961649932695, J_o = 123401.44112276754
J_b = 0.04106318921979153, J_o = 103468.58581870652
J_b = 0.05660378798407566, J_o = 84810.2421460954
J_b = 0.07340124195034946, J_o = 73803.74336294217
J_b = 0.10082042904565072, J_o = 66485.82107841148
J_b = 0.1046403064539014, J_o = 61474.84615550511
J_b = 0.1050390760472795, J_o = 59295.43229904381
J_b = 0.11074964958228761, J_o = 57260.264815431365
J_b = 0.12595604993691498, J_o = 54721.87235166152
J_b = 0.14030530067372954, J_o = 54042.48515584673
J_b = 0.14391158315928054, J_o = 53021.54110742822
J_b = 0.14120268357238797, J_o = 52810.22460223565
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.80488352 -0.81339051  0.04939532 -0.17039262 -0.97694208 -0.80224535
 -0.94213683  0.00197175 -0.58538666 -1.33314003]
W_opt:  [ 0.02934254  0.0245164   0.02081864  0.01376555  0.00517718 -0.01113508
 -0.04073658 -0.0893327  -0.14892607 -0.20896007]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1060 s, v_trunc (Latent to Reduced) = 0.1123, dec (Reduced to Full) = 0.1990, add (DA)= 0.0006decode = 0.3140 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4201 s, inc stats = 5.4265, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91707436 2.76654448 3.36337476 2.99420772 2.39994813]
u_DA:    [3.9003788  1.9489133  3.02953372 1.68675286 2.65345818]
ref_MAE: [0.07661996 0.60476409 0.82443998 1.14165427 0.02331442]
da_MAE:  [0.01669556 0.81763118 0.33384104 1.30745486 0.25351005]
% 17.577127911648947 da_MAE 0.006607623424334322 ref_MAE 0.008016735230060234
\% improve_point: 12.44, mse_ref_points: 3.6146594121086654e-05, mse_da_points: 3.165657309711382e-05, % improve_overlap: 12.44, mse_ref_overlap: 0.94157, mse_da_overlap: 0.82463
DA - - L2: 32836.25, L1: 4589.95, % Improve: 17.92%, DA_MAE: 0.01, mse_ref: 0.94, mse_DA: 0.824, time(s): 6.1960s,
u_c taken from control states: [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
u_c before reduction of space:  [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
data[u_c] post encoding of state:  [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
J_b = 0.0, J_o = 471150.0210319433
J_b = 0.5, J_o = 13908740.088067288
J_b = 0.00487690069379485, J_o = 307821.3029583995
J_b = 0.01208995715914635, J_o = 203191.1452247413
J_b = 0.019974729841586263, J_o = 159381.58014968535
J_b = 0.0319314453417377, J_o = 122350.38562181353
J_b = 0.0410876972414512, J_o = 102443.35487786916
J_b = 0.056573933351170315, J_o = 83891.45435685327
J_b = 0.07332110606225264, J_o = 73068.46990134337
J_b = 0.10007840474528149, J_o = 65976.70374957047
J_b = 0.10276614429742358, J_o = 60989.68359802196
J_b = 0.10328905187346547, J_o = 58794.16967637774
J_b = 0.1093517682102624, J_o = 56655.212113424626
J_b = 0.12446334104180788, J_o = 53791.321996632236
J_b = 0.14372473508293926, J_o = 55051.78478065399
J_b = 0.1311964831181292, J_o = 53012.61467806608
J_b = 0.14245386665558885, J_o = 52089.292048943855
J_b = 0.1438046161569004, J_o = 51756.73329268765
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.81307191 -0.8101649   0.04741716 -0.16969034 -0.98476426 -0.7994981
 -0.93118733 -0.00564861 -0.59458136 -1.34580591]
W_opt:  [ 0.02965027  0.02592298  0.02107068  0.01365932  0.00505123 -0.01070685
 -0.03967426 -0.08865525 -0.14941934 -0.21130675]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.1158 s, v_trunc (Latent to Reduced) = 0.1045, dec (Reduced to Full) = 0.1798, add (DA)= 0.0001decode = 0.2864 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.4024 s, inc stats = 5.4149, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91672335 2.76734226 3.36277538 2.99444796 2.39784992]
u_DA:    [3.90089675 1.94657709 3.03670759 1.68915275 2.65493175]
ref_MAE: [0.07626895 0.60556186 0.8238406  1.14189451 0.02121621]
da_MAE:  [0.0158266  0.82076517 0.32606779 1.30529522 0.25708183]
% 17.670505894471255 da_MAE 0.006596398161194773 ref_MAE 0.008012193239933681
u_c taken from control states: [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
u_c before reduction of space:  [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
data[u_c] post encoding of state:  [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
J_b = 0.0, J_o = 469532.2721185129
J_b = 0.4999999999999999, J_o = 14096750.417739872
J_b = 0.00481586678220754, J_o = 306223.9072995477
J_b = 0.01188555258561548, J_o = 201905.90235292402
J_b = 0.019810636887080367, J_o = 157546.81933494855
J_b = 0.03169575579598735, J_o = 120554.66124208254
J_b = 0.040849488873265095, J_o = 100498.95305324683
J_b = 0.05600225372592186, J_o = 82343.65423499458
J_b = 0.07245642143598532, J_o = 71711.89098611863
J_b = 0.09846490512200097, J_o = 64651.62013006915
J_b = 0.10020922043724678, J_o = 59720.609059562994
J_b = 0.10142697814449582, J_o = 57406.50451058443
J_b = 0.10789892732786065, J_o = 55242.10966408478
J_b = 0.12461300772707051, J_o = 52037.0306909606
J_b = 0.14758213009553395, J_o = 55220.41907062415
J_b = 0.13073119960976676, J_o = 51336.92630466807
J_b = 0.1424887903321021, J_o = 50350.62792318622
J_b = 0.14454239164306287, J_o = 49961.57419472728
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.82073422 -0.80751522  0.04554401 -0.16770267 -0.98937926 -0.79030383
 -0.91876798 -0.00937736 -0.60338874 -1.3562496 ]
W_opt:  [ 0.02662878  0.0264143   0.02222417  0.01457828  0.00554597 -0.01030143
 -0.03907541 -0.08823902 -0.14986666 -0.21307998]
----------------------------- DA Assimilate ----------------------
minCostFunction = 4.9848 s, v_trunc (Latent to Reduced) = 0.1025, dec (Reduced to Full) = 0.1702, add (DA)= 0.0001decode = 0.2748 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.2598 s, inc stats = 5.2653, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91639489 2.76799759 3.36220782 2.99512792 2.396612  ]
u_DA:    [3.9016581  1.94284602 3.04833469 1.6926386  2.6486035 ]
ref_MAE: [0.07594049 0.6062172  0.82327303 1.14257447 0.01997829]
da_MAE:  [0.01473679 0.82515158 0.31387312 1.30248932 0.25199151]
% 17.83471857076654 da_MAE 0.00657830427532541 ref_MAE 0.00800618480323847
u_c taken from control states: [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
u_c before reduction of space:  [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
data[u_c] post encoding of state:  [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
J_b = 0.0, J_o = 464424.82591649285
J_b = 0.4999999999999999, J_o = 14441562.562622752
J_b = 0.004632519978164632, J_o = 304052.84254053934
J_b = 0.011399790690527973, J_o = 200268.0774119037
J_b = 0.019740840042556634, J_o = 153718.43807542624
J_b = 0.031191424231958417, J_o = 118133.673046716
J_b = 0.040467152615776165, J_o = 97660.53455352578
J_b = 0.05502974564553675, J_o = 80156.02453330118
J_b = 0.07104125223351039, J_o = 69585.8349240165
J_b = 0.09680385360681093, J_o = 62659.958547355534
J_b = 0.09761106916619268, J_o = 57692.04169543977
J_b = 0.09907672887350535, J_o = 55327.75628867781
J_b = 0.10560703315155703, J_o = 53169.42748308713
J_b = 0.12339613146942316, J_o = 49716.69691388252
J_b = 0.1461663532251891, J_o = 54463.42497358321
J_b = 0.12850514974862468, J_o = 49064.420594342366
J_b = 0.14266654771391749, J_o = 47843.035951309415
J_b = 0.14631256256183844, J_o = 47311.9243238752
J_b = 0.1541980274173528, J_o = 46464.37161249064
J_b = 0.15967753952642091, J_o = 45877.84935128729
J_b = 0.1596157960758396, J_o = 45582.460306103036
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.82788789 -0.80550029  0.04376801 -0.16439943 -0.99150463 -0.77465693
 -0.90542781 -0.01171266 -0.61201411 -1.36477759]
W_opt:  [ 0.00880054  0.01863768  0.02215241  0.01908532  0.01379138  0.00227053
 -0.02381638 -0.07751942 -0.15045621 -0.23118859]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.9029 s, v_trunc (Latent to Reduced) = 0.1038, dec (Reduced to Full) = 0.1959, add (DA)= 0.0001decode = 0.3018 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 6.2049 s, inc stats = 6.2174, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91608823 2.76849594 3.36166969 2.99625791 2.39604189]
u_DA:    [3.9011754  1.94265651 3.04884811 1.70767307 2.62579533]
ref_MAE: [0.07563383 0.60671554 0.82273491 1.14370446 0.01940818]
da_MAE:  [0.01491283 0.82583943 0.31282158 1.28858485 0.22975344]
% 17.904702254037044 da_MAE 0.006566945515287744 ref_MAE 0.007999173759754924
u_c taken from control states: [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
u_c before reduction of space:  [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
data[u_c] post encoding of state:  [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
J_b = 0.0, J_o = 457610.1590947684
J_b = 0.5, J_o = 14804131.06223258
J_b = 0.0044180676347850304, J_o = 301491.89306936646
J_b = 0.0108596368924007, J_o = 198469.9920528151
J_b = 0.019773598396515983, J_o = 148983.33804391747
J_b = 0.0307239533527697, J_o = 115195.08083717803
J_b = 0.040167423566412314, J_o = 94356.78455267566
J_b = 0.05432887851865695, J_o = 77323.51894777233
J_b = 0.07019369364534718, J_o = 66726.27149637157
J_b = 0.09566642528879643, J_o = 59986.31931452691
J_b = 0.09576210349126436, J_o = 55060.88885535829
J_b = 0.09718742916660575, J_o = 52714.91355806779
J_b = 0.10364232300916561, J_o = 50589.75108217447
J_b = 0.12178732092333494, J_o = 47131.91325785773
J_b = 0.1466848298784157, J_o = 50848.76699418244
J_b = 0.1283551359456059, J_o = 46273.91215565517
J_b = 0.14268989073004565, J_o = 45466.90116255751
J_b = 0.1441021203278303, J_o = 44876.359868698695
J_b = 0.1428743245322163, J_o = 44636.70180171116
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.83460612 -0.80396541  0.04206414 -0.15995432 -0.99220432 -0.75297692
 -0.89137848 -0.00536414 -0.6207104  -1.37156608]
W_opt:  [ 0.01173584  0.0200992   0.02275859  0.01939558  0.01075131 -0.00606349
 -0.03566719 -0.08612092 -0.14976318 -0.21576109]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3688 s, v_trunc (Latent to Reduced) = 0.1048, dec (Reduced to Full) = 0.1903, add (DA)= 0.0001decode = 0.2978 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6667 s, inc stats = 5.6948, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91580024 2.76887555 3.36115342 2.99777853 2.39585421]
u_DA:    [3.90092702 1.94041878 3.05542942 1.68778266 2.6442913 ]
ref_MAE: [0.07534584 0.60709516 0.82221863 1.14522508 0.0192205 ]
da_MAE:  [0.01487322 0.82845677 0.305724   1.30999587 0.24843709]
% 17.89483722082789 da_MAE 0.006561527062004685 ref_MAE 0.007991613243192022
u_c taken from control states: [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
u_c before reduction of space:  [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
data[u_c] post encoding of state:  [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
J_b = 0.0, J_o = 450836.82543403114
J_b = 0.5, J_o = 15090148.509837614
J_b = 0.0042319620746066235, J_o = 298991.3521654528
J_b = 0.01040657069132113, J_o = 196850.07482751616
J_b = 0.019870006702160187, J_o = 144583.64110322378
J_b = 0.03039800230068915, J_o = 112443.7967857787
J_b = 0.03996314078350446, J_o = 91478.3089519532
J_b = 0.05394683610245621, J_o = 74672.28387119043
J_b = 0.06997405743026172, J_o = 63984.580478767246
J_b = 0.09537202947496771, J_o = 57426.42588603422
J_b = 0.09483371312792443, J_o = 52584.590099211244
J_b = 0.09606166255216814, J_o = 50302.12785658105
J_b = 0.1023973925087579, J_o = 48211.87743951631
J_b = 0.1204215078622642, J_o = 44802.31647242575
J_b = 0.14650865887828898, J_o = 48886.9963943062
J_b = 0.12709796889568134, J_o = 43948.80702575689
J_b = 0.1403545678780167, J_o = 43202.69247669635
J_b = 0.14326239028490204, J_o = 42599.46405534592
J_b = 0.14126595439186604, J_o = 42383.89661410899
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.84095879 -0.80281594  0.04041071 -0.15463164 -0.9923155  -0.72599672
 -0.87685148  0.01357596 -0.62957736 -1.37675941]
W_opt:  [ 0.00819512  0.01779906  0.02100802  0.01990437  0.01251989 -0.00447955
 -0.03474277 -0.0859461  -0.14958201 -0.21520895]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3522 s, v_trunc (Latent to Reduced) = 0.1049, dec (Reduced to Full) = 0.1717, add (DA)= 0.0001decode = 0.2787 s, unnorm = 0.0002 s, TOTAL = unnormalising + decoding + minimising = 5.6311 s, inc stats = 5.6436, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91552792 2.76915985 3.36065243 2.99959935 2.39582438]
u_DA:    [3.90025377 1.93904563 3.0540433  1.67813335 2.64836844]
ref_MAE: [0.07507352 0.60737945 0.82171765 1.1470459  0.01919067]
da_MAE:  [0.01527415 0.83011422 0.30660913 1.32146601 0.25254406]
% 17.871582228115642 da_MAE 0.006556820378183665 ref_MAE 0.007983619502320804
u_c taken from control states: [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
u_c before reduction of space:  [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
data[u_c] post encoding of state:  [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
J_b = 0.0, J_o = 445041.2572374558
J_b = 0.4999999999999998, J_o = 15293187.03323677
J_b = 0.004085824925191651, J_o = 296929.6608039115
J_b = 0.010060596246525546, J_o = 195632.25958242192
J_b = 0.01998817763991842, J_o = 141100.84296767236
J_b = 0.030155021385002433, J_o = 110438.68113258202
J_b = 0.03972678405427598, J_o = 89649.22584367235
J_b = 0.05353515526291156, J_o = 73043.14182140431
J_b = 0.06975013363143716, J_o = 62248.21572188964
J_b = 0.09557128226694234, J_o = 55931.5968122905
J_b = 0.09436418963852683, J_o = 51075.30796109961
J_b = 0.09522014545995618, J_o = 48900.023941929656
J_b = 0.10141947038993655, J_o = 46812.2610767844
J_b = 0.11907268960661105, J_o = 43435.68970598083
J_b = 0.14515706316075921, J_o = 47269.64254502785
J_b = 0.12588945845563418, J_o = 42578.5999514767
J_b = 0.1395007326781086, J_o = 41796.14211535321
J_b = 0.14330778487738285, J_o = 41198.79648445398
J_b = 0.1408702877735517, J_o = 40976.71390065444
Following minimisation and before DA stats:
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842 0.21802538
 0.0106784  0.03475928 0.24608794 0.00336705]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153 1.46110939
 0.03079883 0.17062887 2.22091941 0.00641547]
u_0:     [-2.59227041 -3.25860133 -2.67153302 -3.5077128  -1.06385885 -2.30535316
  1.2963359  -2.0220171  -2.1575169   1.1108939 ]
u_c:     [-0.84706931 -0.8018513   0.03877767 -0.14881252 -0.99284572 -0.6952094
 -0.86159287  0.04752825 -0.63874432 -1.37902152]
W_opt:  [ 0.00697636  0.01669899  0.01915975  0.01901644  0.01307993 -0.00301861
 -0.03336793 -0.08545165 -0.14955392 -0.21539909]
----------------------------- DA Assimilate ----------------------
minCostFunction = 5.3652 s, v_trunc (Latent to Reduced) = 0.1051, dec (Reduced to Full) = 0.1774, add (DA)= 0.0001decode = 0.2846 s, unnorm = 0.0001 s, TOTAL = unnormalising + decoding + minimising = 5.6499 s, inc stats = 5.6612, 
std:     [0.04286703 0.24732595 0.30299952 0.34208713 0.26823842]
mean:    [3.95157732 2.96771706 3.348408   3.05249684 2.66200153]
u_0:     [3.8404544  2.1617804  2.53893478 1.85255345 2.37663371]
u_c:     [3.91526598 2.76939843 3.36015762 3.00159    2.39568216]
u_DA:    [3.89957985 1.93709957 3.05021703 1.66901762 2.65385197]
ref_MAE: [0.07481158 0.60761803 0.82122283 1.14903655 0.01904845]
da_MAE:  [0.01568613 0.83229886 0.30994058 1.33257238 0.25816981]
% 17.816572042773135 da_MAE 0.006554807718505551 ref_MAE 0.007975826613021134
\% improve_point: 12.37, mse_ref_points: 3.635055790904895e-05, mse_da_points: 3.1862340057992244e-05, % improve_overlap: 12.37, mse_ref_overlap: 0.94689, mse_da_overlap: 0.82999
DA - - L2: 31086.99, L1: 4529.63, % Improve: 17.91%, DA_MAE: 0.01, mse_ref: 0.95, mse_DA: 0.829, time(s): 6.1656s,
Results of DA at 2020-08-28 14:24:08.719843. 
      percent_improvement  ref_MAE_mean  ...       time  time_online
0              17.876673      0.007516  ...  66.511056     9.444458
1              17.942485      0.007520  ...   8.256204     8.237991
2              18.140516      0.007523  ...   5.099253     5.086013
3              18.194590      0.007526  ...   5.371340     5.354625
4              17.700434      0.007529  ...   5.159467     5.152466
..                   ...           ...  ...        ...          ...
102            17.834719      0.008006  ...   5.269417     5.259769
103            17.904702      0.007999  ...   6.221617     6.204865
104            17.894837      0.007992  ...   5.699527     5.666702
105            17.871582      0.007984  ...   5.647563     5.631069
106            17.816572      0.007976  ...   5.664833     5.649947

[107 rows x 20 columns]
------------------------- Ended at 2020-08-28 14:24:09.939430 -------------------- 

